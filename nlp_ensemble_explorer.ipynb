{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Copyright (c) 2019 Regents of the University of Minnesota.\n",
    " \n",
    "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    " \n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pymysql\n",
    "import time \n",
    "import functools as ft\n",
    "import glob   \n",
    "import operator as op\n",
    "import shelve\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, permutations\n",
    "from sqlalchemy.engine import create_engine\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from scipy import stats  \n",
    "from scipy.stats.mstats import gmean\n",
    "from pythonds.basic.stack import Stack\n",
    "from pythonds.trees.binaryTree import BinaryTree\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from typing import List, Set, Tuple "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cell below contains the configurable parameters to ensure that our ensemble explorer runs properaly on your machine. \n",
    "Please read carfully through steps (1-11) before running the rest of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-1: CHOOSE YOUR CORPUS\n",
    "# TODO: allow for list of corpora\n",
    "corpus = 'fairview' #options include 'fairview', 'mipacq' OR 'i2b2'\n",
    "\n",
    "# STEP-2: CHOOSE YOUR DATA DIRECTORY; this is where output data will be saved on your machine\n",
    "data_directory = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/' \n",
    "\n",
    "# STEP-3: CHOOSE WHICH SYSTEMS YOU'D LIKE TO EVALUATE AGAINST THE CORPUS REFERENCE SET\n",
    "systems = ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['clamp', 'quick_umls', 'biomedicus']\n",
    "\n",
    "# STEP-4: CHOOSE TYPE OF RUN\n",
    "rtype = 2      # OPTIONS INCLUDE: 1->Single systems; 2->Ensemble; 3->Tests; 4 -> generate signiicance test data;  \n",
    "               # 5 -> signiicance testing\n",
    "               # The Ensemble can include the max system set ['ctakes','biomedicus','clamp','metamap','quick_umls']\n",
    "    \n",
    "# STEP-5: CHOOSE WHAT TYPE OF ANALYSIS YOU'D LIKE TO RUN ON THE CORPUS\n",
    "analysis_type = 'entity' #options include 'entity' OR 'full'\n",
    "\n",
    "# STEP-(6A): ENTER DETAILS FOR ACCESSING MANUAL ANNOTATION DATA\n",
    "database_type = 'mysql+pymysql' # We use mysql+pymql as default\n",
    "database_username = 'gms'\n",
    "database_password = 'nej123' \n",
    "database_url = 'localhost' # HINT: use localhost if you're running database on your local machine\n",
    "database_name = 'concepts' # Enter database name\n",
    "table_name = corpus + '_all' # Enter the table within the database where your reference data is stored\n",
    "\n",
    "# STEP-(6B): ENTER DETAILS FOR ACCESSING SYSTEM ANNOTATION DATA\n",
    "system_annotation = 'analytical_'+corpus+'.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "\n",
    "# STEP-7: WE'LL CREATE A 'SYSTEM OUTPUT' DIRECTORY FOR YOU INSIDE THE DIRECTORY YOU SPECIFIED IN (STEP 2)\n",
    "single_sys_dir = Path(data_directory + \"single_system_out\")\n",
    "single_sys_dir.mkdir(parents=True, exist_ok=True)\n",
    "dir_out = Path(data_directory + 'single_system_out/')\n",
    "\n",
    "# STEP-8: CREATE A DB CONNECTION POOL\n",
    "engine_request = str(database_type)+'://'+database_username+':'+database_password+\"@\"+database_url+'/'+database_name\n",
    "engine = create_engine(engine_request, pool_pre_ping=True, pool_size=20, max_overflow=30)\n",
    "\n",
    "# STEP-(9A): FILTER BY SEMTYPE\n",
    "filter_semtype = False\n",
    "\n",
    "# STEP-(9B): IF STEP-(9A) == True -> GET REFERENCE SEMTYPES\n",
    "\n",
    "### Fairview -> ['drug', 'finding', 'anatomy', 'procedure']\n",
    "### i2b2 -> ['test, treatment', 'problem']\n",
    "### MiPACQ -> ['procedures', 'disorders, sign_symptom', 'anatomy', 'chemicals_and_drugs']\n",
    "\n",
    "# semtypes = ['Anatomy']\n",
    "\n",
    "if filter_semtype:\n",
    "    if corpus == 'fairview':\n",
    "        semtypes = ['Drug', 'Finding', 'Anatomy', 'Procedure']\n",
    "    elif corpus == 'i2b2':\n",
    "        semtypes = ['test,treatment', 'problem']\n",
    "    elif corpus == 'mipacq':\n",
    "        semtypes = ['Procedures', 'Disorders,Sign_Symptom', 'Anatomy', 'Chemicals_and_drugs']\n",
    "\n",
    "# STEP-10: Set data directory/table for source documents for vectorization\n",
    "src_table = 'sofa'\n",
    "\n",
    "# STEP-11: Specificy match type from {'exact', 'overlap'}\n",
    "run_type = 'overlap'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "****** TODO \n",
    "-> add 'semtype' to output file name -> done\n",
    "-> filter for case when a system has no equivalent semtypes for a given reference -> done: still need to validate that all semtypes in corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_semtype:\n",
    "    print(semtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config class for analysis\n",
    "class AnalysisConfig():\n",
    "    \"\"\"\n",
    "    Configuration object:\n",
    "    systems to use\n",
    "    notes by corpus\n",
    "    paths by output, gold and system location\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self = self    \n",
    "        self.systems = systems\n",
    "        self.data_dir = data_directory\n",
    "    \n",
    "    def corpus_config(self): \n",
    "        usys_data = system_annotation\n",
    "        ref_data = database_name+'.'+table_name\n",
    "        return usys_data, ref_data\n",
    "\n",
    "analysisConf =  AnalysisConfig()\n",
    "usys, ref = analysisConf.corpus_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test', 'treatment'}\n"
     ]
    }
   ],
   "source": [
    "class SemanticTypes(object):\n",
    "    '''\n",
    "    Filter semantic types based on: https://metamap.nlm.nih.gov/SemanticTypesAndGroups.shtml\n",
    "    :params: semtypes list from corpus, system to query\n",
    "    :return: list of equivalent system semtypes \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, semtypes, corpus):\n",
    "        self = self\n",
    "        \n",
    "        sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name FROM concepts.semantic_groups sg join semantic_types st on sg.tui = st.tui where \" + corpus + \"_name in ({})\"\\\n",
    "           .format(', '.join(['%s' for _ in semtypes]))  \n",
    "        \n",
    "        stypes = pd.read_sql(sql, params=[semtypes], con=engine) \n",
    "       \n",
    "        if len(stypes['tui'].tolist()) > 0:\n",
    "            self.biomedicus_types = set(stypes['tui'].tolist())\n",
    "            self.qumls_types = set(stypes['tui'].tolist())\n",
    "        else:\n",
    "            self.biomedicus_types = None\n",
    "            self.qumls_types = None\n",
    "        \n",
    "        if stypes['clamp_name'].dropna(inplace=True) or len(stypes['clamp_name']) == 0:\n",
    "            self.clamp_types = None\n",
    "        else:\n",
    "            self.clamp_types = set(stypes['clamp_name'].tolist()[0].split(','))\n",
    "            \n",
    "        if len(stypes['ctakes_name'].tolist()) > 0:\n",
    "            self.ctakes_types = set(stypes['ctakes_name'].tolist()[0].split(','))\n",
    "        else:\n",
    "            self.ctakes_types = None\n",
    "            \n",
    "        if len(stypes['abbreviation'].tolist()) > 0:\n",
    "            self.metamap_types = set(stypes['abbreviation'].tolist())\n",
    "        else:\n",
    "            self.metamap_types = None\n",
    "            \n",
    "        self.reference_types =  set(semtypes)\n",
    "    \n",
    "    def get_system_type(self, system):  \n",
    "        \n",
    "        if system == 'biomedicus':\n",
    "            semtypes = self.biomedicus_types\n",
    "        elif system == 'ctakes':\n",
    "            semtypes = self.ctakes_types\n",
    "        elif system == 'clamp':\n",
    "            semtypes = self.clamp_types\n",
    "        elif system == 'metamap':\n",
    "            semtypes = self.metamap_types\n",
    "        elif system == 'quick_umls':\n",
    "            semtypes = self.qumls_types\n",
    "        elif system == 'reference':\n",
    "            semtypes = self.reference_types\n",
    "            \n",
    "        return semtypes\n",
    "    \n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('biomedicus'))\n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('quick_umls'))\n",
    "# print(SemanticTypes(['Anatomy'], corpus).get_system_type('clamp'))\n",
    "print(SemanticTypes(['test,treatment'], 'i2b2').get_system_type('clamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semtypes = ['test,treatment']\n",
    "# semtypes = ['problem']\n",
    "# corpus = 'i2b2'\n",
    "# sys = 'clamp'\n",
    "\n",
    "# is semantic type in particular system\n",
    "def system_semtype_check(sys, semtype, corpus):\n",
    "    st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "    if st:\n",
    "        return sys\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# print(system_semtype_check(sys, semtypes, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for systems\n",
    "class AnnotationSystems():\n",
    "    \"\"\"   \n",
    "    System annotations of interest for UMLS concept extraction\n",
    "    NB: ctakes combines all \"mentions\" annotation types\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"   \n",
    "        \n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\"]\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\"]\n",
    "        self.ctakes_types = [\"ctakes_mentions\"]\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\"]\n",
    "        self.qumls_types = [\"concept_jaccard_score_False\"]\n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "        \n",
    "        elif system == \"quick_umls\":\n",
    "            types = self.qumls_types\n",
    "            \n",
    "        return types, view\n",
    "    \n",
    "annSys = AnnotationSystems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np # access to Numpy from Python layer\n",
    "import math\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"\n",
    "    metrics class:\n",
    "    returns an instance with confusion matrix metrics\n",
    "    \"\"\"\n",
    "    def __init__(self, system_only, gold_only, gold_system_match, system_n, neither = 0): # neither: no sys or manual annotation\n",
    "\n",
    "        self = self    \n",
    "        self.system_only = system_only\n",
    "        self.gold_only = gold_only\n",
    "        self.gold_system_match = gold_system_match\n",
    "        self.system_n = system_n\n",
    "        self.neither = neither\n",
    "        \n",
    "    def get_confusion_metrics(self, corpus = None, test = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        compute confusion matrix measures, as per  \n",
    "        https://stats.stackexchange.com/questions/51296/how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\n",
    "        \"\"\"\n",
    "        cdef:\n",
    "            int TP, FP, FN\n",
    "            double TM\n",
    "\n",
    "        TP = self.gold_system_match\n",
    "        FP = self.system_only\n",
    "        FN = self.gold_only\n",
    "        \n",
    "        TM = TP/math.sqrt(self.system_n) # TigMetric\n",
    "       \n",
    "        if not test:\n",
    "            \n",
    "            if corpus == 'casi':\n",
    "                recall = TP/(TP + FN)\n",
    "                precision = TP/(TP + FP)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "            else:\n",
    "                if self.neither == 0:\n",
    "                    confusion = [[0, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                else:\n",
    "                    confusion = [[self.neither, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                c = np.asarray(confusion)\n",
    "                recall = np.diag(c) / np.sum(c, axis = 1)\n",
    "                precision = np.diag(c) / np.sum(c, axis = 0)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            F = 2*(precision*recall)/(precision + recall)\n",
    "        \n",
    "        # Tignanelli Metric\n",
    "        if FN == 0:\n",
    "            TP_FN_R = TP\n",
    "        elif FN > 0:\n",
    "            TP_FN_R = TP/FN\n",
    " \n",
    "        return F, recall, precision, TP, FP, FN, TP_FN_R, TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out(name: str, analysis_type: str, c: object):\n",
    "   \n",
    "    \"\"\"\n",
    "    write matching and reference-only sets to file for use in merging combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    # write output to file\n",
    "    dir_out = analysisConf.data_dir + 'single_system_out/'\n",
    "    with open(dir_out + name + '_' + analysis_type + '_' + c.corpus + '_matches.txt', 'w') as f:\n",
    "        for item in list(c.matches):\n",
    "            f.write(\"%s\\n\" % str(item))\n",
    "\n",
    "    # write to file\n",
    "    with open(dir_out + name + '_' + analysis_type + '_' + c.corpus + '_ref_only.txt', 'w') as f:\n",
    "        for item in list(c.false_negatives):\n",
    "            f.write(\"%s\\n\" % str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_set(df, analysis_type = 'entity', df_type = 'sys', corpus = None):\n",
    "    \n",
    "    # get values for creation of series of type tuple\n",
    "    if 'entity' in analysis_type: \n",
    "        if corpus == 'casi':\n",
    "            arg = df.case, df.overlap\n",
    "        else:    \n",
    "            if df_type == 'sys':\n",
    "                arg = df.begin, df.end, df.note_id\n",
    "            else:\n",
    "                arg = df.start, df.end, df.file\n",
    "            \n",
    "    elif 'cui' in analysis_type:\n",
    "        if df_type == 'sys':\n",
    "            arg = df.cui, df.note_id\n",
    "        else:\n",
    "            arg = df.value, df.file\n",
    "    elif 'full' in analysis_type:\n",
    "        if df_type == 'sys':\n",
    "            arg = df.begin, df.end, df.cui, df.note_id\n",
    "        else:\n",
    "            arg = df.start, df.end, df.value, df.file\n",
    "    \n",
    "    return set(list(zip(*arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "\n",
    "from __main__ import write_out, df_to_set, engine\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "def get_cooccurences(ref, sys, analysis_type: str, corpus: str, single_sys = True, name = None):\n",
    "    \"\"\"\n",
    "    get coocurences between system and reference; exact match; TODO: add relaxed -> done in single system evals during ensemble run\n",
    "    \"\"\"\n",
    "    # cooccurences\n",
    "    class Coocurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = set()\n",
    "            self.false_negatives = set()\n",
    "            self.corpus = corpus\n",
    "\n",
    "    c = Coocurences()\n",
    "    \n",
    "    if c.corpus != 'casi':\n",
    "        if 'entity' in analysis_type and single_sys: # mipacq n -> 16793\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            ref = ref[['start', 'end', 'file']].drop_duplicates()\n",
    "            sys.name = name\n",
    "        elif 'cui' in analysis_type and single_sys: # mipacq n -> 10799\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            # do not overestimate FP\n",
    "            sys = sys[~sys['cui'].isnull()] \n",
    "            ref = ref[['value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "            sys.name = name\n",
    "        elif 'full' in analysis_type and single_sys: # mipacq n -> 17393\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            sys = sys[~sys['cui'].isnull()]\n",
    "            ref = ref[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "            sys.name = name\n",
    "\n",
    "        # matches via inner join\n",
    "        matches = pd.merge(sys, ref, how = 'inner', left_on=['begin','end','note_id'], right_on = ['start','end','file']) \n",
    "        # reference-only via left outer join\n",
    "        fn = pd.merge(ref, sys, how = 'left', left_on=['start','end','file'], right_on = ['begin','end','note_id']) \n",
    "\n",
    "        fn = fn[fn['begin'].isnull()] # get as outer join with no match\n",
    "\n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['start', 'end', 'file']\n",
    "        else:\n",
    "            cols_to_keep = ['start', 'end', 'value', 'file']\n",
    "\n",
    "        matches = matches[cols_to_keep]\n",
    "        fn = fn[cols_to_keep]\n",
    "\n",
    "        # use for metrics \n",
    "        c.matches = c.matches.union(df_to_set(matches, analysis_type, 'ref'))\n",
    "        c.false_negatives = c.false_negatives.union(df_to_set(fn, analysis_type, 'ref'))\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        c.ref_only = len(c.false_negatives)\n",
    "        \n",
    "    else:\n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where overlap = 1 and `system` = %(sys.name)s\"  \n",
    "        \n",
    "        matches = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where (overlap = 0 or overlap is null) and `system` = %(sys.name)s\"  \n",
    "        \n",
    "        fn = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        c.matches = df_to_set(matches, 'entity', 'sys', 'casi')\n",
    "        c.fn = df_to_set(fn, 'entity', 'sys', 'casi')\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(matches) + len(fn)\n",
    "        c.ref_n = len(matches) + len(fn)\n",
    "        c.ref_only = len(fn)\n",
    "        \n",
    "    # sanity check\n",
    "    if len(ref) - c.ref_system_match < 0:\n",
    "        print('Error: ref_system_match > len(ref)!')\n",
    "    if len(ref) != c.ref_system_match + c.ref_only:\n",
    "        print('Error: ref count mismatch!')\n",
    "   \n",
    "    # save TP/FN\n",
    "    if single_sys and corpus != 'casi':\n",
    "        print(analysis_type)\n",
    "        write_out(sys.name, analysis_type, c)\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vector(doc: str, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.begin, a.end) for a in ann if a.label == lab]\n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v\n",
    "\n",
    "# test confusion matrix elements for vectorized annotation set; includes TN\n",
    "# https://kawahara.ca/how-to-compute-truefalse-positives-and-truefalse-negatives-in-python-for-binary-classification-problems/\n",
    "def confused(sys1, ann1):\n",
    "    TP = np.sum(np.logical_and(ann1 == 1, sys1 == 1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(ann1 == 0, sys1 == 0))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(ann1 == 0, sys1 == 1))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(ann1 == 1, sys1 == 0))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def vectorized_coocurences(r: object, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> np.int64:\n",
    "    docs = get_docs(corpus)\n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    sys = get_sys_ann(r)\n",
    "    cvals = []\n",
    "    labels = [\"concept\"]\n",
    "\n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        s1 = list(sys.loc[sys[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        ann1 = label_vector(docs[n][1], a1, labels)\n",
    "        sys1 = label_vector(docs[n][1], s1, labels)\n",
    "\n",
    "        TP, TN, FP, FN = confused(sys1, ann1)\n",
    "        cvals.append([TP, TN, FP, FN])\n",
    "\n",
    "    return np.sum(cvals, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_dict(ref_only: int, system_only: int, ref_system_match: int, system_n: int, ref_n: int) -> dict:\n",
    "    \"\"\"\n",
    "    Generate dictionary of confusion matrix params and measures\n",
    "    :params: ref_only, system_only, reference_system_match -> sets\n",
    "    matches, system_n, reference_n -> counts\n",
    "    :return: dictionary object\n",
    "    \"\"\"\n",
    "\n",
    "    if ref_only + ref_system_match != ref_n:\n",
    "        print('ERROR!')\n",
    "\n",
    "    # get evaluation metrics\n",
    "    F, recall, precision, TP, FP, FN, TP_FN_R, TM  = Metrics(system_only, ref_only, ref_system_match, system_n).get_confusion_metrics()\n",
    "\n",
    "    d = {\n",
    "         'F': F[1], \n",
    "         'precision': precision[1], \n",
    "         'recall': recall[1], \n",
    "         'TP': TP, \n",
    "         'FN': FN, \n",
    "         'FP': FP, \n",
    "         'TP/FN': TP_FN_R,\n",
    "         'n_gold': ref_n, \n",
    "         'n_sys': system_n, \n",
    "         'TM': TM\n",
    "    }\n",
    "    \n",
    "    if system_n - FP != TP:\n",
    "        print('inconsistent system n!')\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metric_data(analysis_type: str, corpus: str):\n",
    "   \n",
    "    usys_file, ref_table = AnalysisConfig().corpus_config()\n",
    "    systems = AnalysisConfig().systems\n",
    "    \n",
    "    sys_ann = pd.read_csv(analysisConf.data_dir + usys_file, dtype={'note_id': str})\n",
    "    \n",
    "    sql = \"SELECT * FROM \" + ref_table  \n",
    "    \n",
    "    ref_ann = pd.read_sql(sql, con=engine)\n",
    "    sys_ann = sys_ann.drop_duplicates()\n",
    "    \n",
    "    return ref_ann, sys_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of 2.\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(analysis_type: str, corpus: str, filter_semtype, single_sys = None):\n",
    "    start = time.time()\n",
    "\n",
    "    systems = AnalysisConfig().systems\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    ref_ann, sys_ann = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    for sys in systems:\n",
    "        \n",
    "        if filter_semtype:\n",
    "            st = SemanticTypes(semtypes, corpus).get_system_type(sys)\n",
    "            ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes, corpus).get_system_type('reference'))]\n",
    "            \n",
    "        types, _ = AnnotationSystems().get_system_type(sys) # system types for iterable\n",
    "        for t in types:\n",
    "            print(t)\n",
    "\n",
    "            if filter_semtype:\n",
    "                system_annotations = sys_ann[sys_ann['semtypes'].isin(st)].copy()\n",
    "            else:\n",
    "                system_annotations = sys_ann.copy()\n",
    "\n",
    "            system = system_annotations[system_annotations['type'] == str(t)]\n",
    "\n",
    "            if sys == 'quick_umls':\n",
    "                system = system[system.score.astype(float) >= .8]\n",
    "\n",
    "            if sys == 'metamap':\n",
    "                system = system[system.score.abs().astype(int) >= 800]\n",
    "\n",
    "            system = system.drop_duplicates()\n",
    "            system.name = sys\n",
    "\n",
    "            c = get_cooccurences(ref_ann, system, analysis_type, corpus, True, system.name) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            if corpus == 'casi':\n",
    "                if sys == 'biomedicus':\n",
    "                    t = 'biomedicus.v2.Acronym'\n",
    "            \n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "            d['system'] = sys\n",
    "            d['type'] = t\n",
    "                \n",
    "            data = pd.DataFrame(d,  index=[0])\n",
    "            metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "            metrics.drop_duplicates(keep='last', inplace=True)\n",
    "        else:\n",
    "            print(\"NO EXACT MATCHES FOR\", t)\n",
    "        elapsed = (time.time() - start)\n",
    "        print(\"elapsed:\", sys, elapsed)\n",
    "     \n",
    "    elapsed = (time.time() - start)\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    if single_sys is None:\n",
    "        file_name = 'metrics_'\n",
    "    \n",
    "    metrics.to_csv(analysisConf.data_dir + corpus + '_' + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "    \n",
    "    print(\"total elapsed time:\", elapsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_n(analysis_type: str, corpus: str, filter_semtype) -> int:\n",
    "    \n",
    "    ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes, corpus).get_system_type('reference'))]\n",
    "            \n",
    "    if corpus == 'casi':\n",
    "        return len(ref_ann)\n",
    "        \n",
    "    else:\n",
    "        # do not overestimate fn\n",
    "        if 'entity' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'file']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type:\n",
    "            ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        elif 'full' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "        return ref_n\n",
    "    \n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_data(system: str, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> pd.DataFrame:\n",
    "   \n",
    "    _, data = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    out = data[data['system'] == system].copy()\n",
    "    \n",
    "    if filter_semtype:\n",
    "        st = SemanticTypes([semtype], corpus).get_system_type(system)\n",
    "    \n",
    "    if corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap'] \n",
    "        out = out[cols_to_keep].drop_duplicates()\n",
    "        return out\n",
    "        \n",
    "    else:\n",
    "        if filter_semtype:\n",
    "            out = out[out['semtypes'].isin(st)].copy()\n",
    "            \n",
    "        else:\n",
    "            out = out[out['system']== system].copy()\n",
    "        \n",
    "        if system == 'quick_umls':\n",
    "            out = out[(out.score.astype(float) >= 0.8) & (out[\"type\"] == 'concept_jaccard_score_False')]\n",
    "            # fix for leading spacxe on semantic type field\n",
    "            out = out.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) \n",
    "        \n",
    "        if system == 'metamap':\n",
    "            out = out[out.score.abs().astype(int) >= 800]\n",
    "            \n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "        elif 'cui' in analysis_type:\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "        elif 'full' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "        #out = out[cols_to_keep]\n",
    "\n",
    "        return out.drop_duplicates()\n",
    "\n",
    "# read in system/reference matches from file\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_system_matches(system: str, analysis_type: str, corpus: str):\n",
    "   \n",
    "    if corpus == 'casi':\n",
    "        \n",
    "        sql = \"select `case`, overlap from test.amia_2019_cases where overlap = 1 and `system` = %(system)s\"  \n",
    "        data_matches = df_to_set(pd.read_sql(sql, params={\"system\":system}, con=engine), 'entity', 'sys', 'casi')\n",
    "        \n",
    "        sql = \"select `case`, overlap from test.amia_2019_cases where (overlap = 0 or overlap is null) and `system` = %(system)s\"  \n",
    "        data_fn = df_to_set(pd.read_sql(sql, params={\"system\":system}, con=engine), 'entity', 'sys', 'casi')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        dir_test = analysisConf.data_dir + 'single_system_out/'\n",
    "\n",
    "        file = dir_test + system + '_' + analysis_type + '_' + corpus + '_matches.txt'\n",
    "        data_matches = set(literal_eval(line.strip()) for line in open(file))\n",
    "\n",
    "        file = dir_test + system + '_' + analysis_type + '_' + corpus + '_ref_only.txt'\n",
    "        data_fn = set(literal_eval(line.strip()) for line in open(file)) \n",
    "\n",
    "    return data_matches, data_fn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GENERATE merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTotals(object):\n",
    "    \"\"\" \n",
    "    returns an instance with merged match set numbers using either union or intersection of elements in set \n",
    "    \"\"\"\n",
    "    def __init__(self, ref_n, sys_n, match_set):\n",
    "\n",
    "        self = self    \n",
    "        self.ref_ann = ref_n\n",
    "        self.sys_n = sys_n\n",
    "        self.match_set = match_set\n",
    "\n",
    "    def get_ref_sys(self):\n",
    "\n",
    "        ref_only = self.ref_ann - len(self.match_set)\n",
    "        sys_only = self.sys_n - len(self.match_set)\n",
    "\n",
    "        return ref_only, sys_only, len(self.match_set), self.match_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Recursively evaluate parse tree, \n",
    "    with check for existence before build\n",
    "       :param sentence: to process\n",
    "       :return class of merged annotations, boolean operated system df \n",
    "    \"\"\"\n",
    "    \n",
    "    class Results(object):\n",
    "        def __init__(self):\n",
    "            self.results = set()\n",
    "            self.system_merges = pd.DataFrame()\n",
    "            \n",
    "    r = Results()\n",
    "    \n",
    "    if 'entity' in analysis_type and corpus != 'casi': \n",
    "        cols_to_keep = ['begin', 'end', 'note_id'] # entity only\n",
    "    elif 'full' in analysis_type: \n",
    "        cols_to_keep = ['cui', 'begin', 'end', 'note_id'] # entity only\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['cui', 'note_id'] # entity only\n",
    "    elif corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap']\n",
    "    \n",
    "    def evaluate(parseTree):\n",
    "        oper = {'&': op.and_, '|': op.or_}\n",
    "        \n",
    "        if parseTree:\n",
    "            leftC = gevent.spawn(evaluate, parseTree.getLeftChild())\n",
    "            rightC = gevent.spawn(evaluate, parseTree.getRightChild())\n",
    "            \n",
    "            if leftC.get() and rightC.get():\n",
    "                query = set()\n",
    "                system_query = pd.DataFrame()\n",
    "                fn = oper[parseTree.getRootVal()]\n",
    "                \n",
    "                if isinstance(leftC.get(), str):\n",
    "                    # get system as leaf node \n",
    "                    left, _ = get_system_matches(leftC.get(), analysis_type, corpus)\n",
    "                    if filter_semtype:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype)\n",
    "                \n",
    "                elif isinstance(leftC.get(), tuple):\n",
    "                    left = leftC.get()[0]\n",
    "                    l_sys = leftC.get()[1]\n",
    "                \n",
    "                if isinstance(rightC.get(), str):\n",
    "                    # get system as leaf node\n",
    "                    right, _ = get_system_matches(rightC.get(), analysis_type, corpus)\n",
    "                    if filter_semtype:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype)\n",
    "                    \n",
    "                elif isinstance(rightC.get(), tuple):\n",
    "                    right = rightC.get()[0]\n",
    "                    r_sys = rightC.get()[1]\n",
    "                    \n",
    "                # create match set based on boolean operation\n",
    "                match_set = fn(left, right)\n",
    "               \n",
    "                if fn == op.or_:\n",
    "                    r.results = r.results.union(match_set)\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        frames = [left_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), tuple):\n",
    "                        frames = [left_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), tuple) and isinstance(rightC.get(), str):\n",
    "                        frames = [l_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), tuple) and isinstance(rightC.get(), tuple):\n",
    "                        frames = [l_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                if fn == op.and_:\n",
    "                    if len(r.results) == 0:\n",
    "                        r.results = match_set\n",
    "                    r.results = r.results.intersection(match_set)\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        df = left_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), tuple):\n",
    "                        df = left_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), tuple) and isinstance(rightC.get(), str):\n",
    "                        df = l_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), tuple) and isinstance(rightC.get(), tuple):\n",
    "                        df = l_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                \n",
    "                # get matched results\n",
    "                query.update(r.results)\n",
    "                \n",
    "                # get combined system results\n",
    "                r.system_merges = df\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    system_query = system_query.append(df)\n",
    "                else:\n",
    "                    print('wtf!')\n",
    "                    \n",
    "                return query, system_query\n",
    "            else:\n",
    "                return parseTree.getRootVal()\n",
    "    \n",
    "    if sentence.n_or > 0 or sentence.n_and > 0:\n",
    "        evaluate(pt)  \n",
    "    \n",
    "    # trivial case\n",
    "    elif sentence.n_or == 0 and sentence.n_and == 0:\n",
    "        r.results, _ = get_system_matches(sentence.sentence, analysis_type, corpus)\n",
    "        if filter_semtype:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        #print('trivial:', sentence.sentence, len(r.results), len(r.system_merges))\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Incoming Boolean sentences are parsed into a binary tree.\n",
    "\n",
    "Test expressions to parse:\n",
    "\n",
    "sentence = '((((A&B)|C)|D)&E)'\n",
    "\n",
    "sentence = '(E&(D|(C|(A&B))))'\n",
    "\n",
    "sentence = '(((A|(B&C))|(D&(E&F)))|(H&I))'\n",
    "\n",
    "\"\"\"\n",
    "# build parse tree from passed sentence\n",
    "# using grammatical rules of Boolean logic\n",
    "def buildParseTree(fpexp):\n",
    "    \"\"\"\n",
    "       Iteratively build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "       :param fpexp: sentence to parse\n",
    "       :return eTree: parse tree representation\n",
    "       Incoming Boolean sentences are parsed into a binary tree.\n",
    "       Test expressions to parse:\n",
    "       sentence = '(A&B)'\n",
    "       sentence = '(A|B)'\n",
    "       sentence = '((A|B)&C)'\n",
    "       \n",
    "    \"\"\"\n",
    "    fplist = fpexp.split()\n",
    "    pStack = Stack()\n",
    "    eTree = BinaryTree('')\n",
    "    pStack.push(eTree)\n",
    "    currentTree = eTree\n",
    "\n",
    "    for i in fplist:\n",
    "\n",
    "        if i == '(':\n",
    "            currentTree.insertLeft('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getLeftChild()\n",
    "        elif i not in ['&', '|', ')']:\n",
    "            currentTree.setRootVal(i)\n",
    "            parent = pStack.pop()\n",
    "            currentTree = parent\n",
    "        elif i in ['&', '|']:\n",
    "            currentTree.setRootVal(i)\n",
    "            currentTree.insertRight('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getRightChild()\n",
    "        elif i == ')':\n",
    "            currentTree = pStack.pop()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return eTree\n",
    "\n",
    "def make_parse_tree(payload):\n",
    "    \"\"\"\n",
    "    Ensure data to create tree are in standard form\n",
    "    :param sentence: sentence to preprocess\n",
    "    :return pt, parse tree graph\n",
    "            sentence, processed sentence to build tree\n",
    "            a: order\n",
    "    \"\"\"\n",
    "    def preprocess_sentence(sentence):\n",
    "        # prepare statement for case when a boolean AND/OR is given\n",
    "        sentence = payload.replace('(', ' ( '). \\\n",
    "            replace(')', ' ) '). \\\n",
    "            replace('&', ' & '). \\\n",
    "            replace('|', ' | '). \\\n",
    "            replace('  ', ' ')\n",
    "        return sentence\n",
    "\n",
    "    sentence = preprocess_sentence(payload)\n",
    "    print(sentence)\n",
    "    \n",
    "    pt = buildParseTree(sentence)\n",
    "    #pt.postorder() \n",
    "    \n",
    "    return pt\n",
    "\n",
    "class Sentence(object):\n",
    "    def __init__(self, sentence):\n",
    "        self = self\n",
    "        self.n_and = sentence.count('&')\n",
    "        self.n_or = sentence.count('|')\n",
    "        self.sentence = sentence\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_docs(corpus):\n",
    "    sql = 'select distinct note_id, sofa from sofas where corpus = %(corpus)s order by note_id'\n",
    "    df = pd.read_sql(sql, params={\"corpus\":corpus}, con=engine)\n",
    "    df.drop_duplicates()\n",
    "    df['len_doc'] = df['sofa'].apply(len)\n",
    "    \n",
    "    subset = df[['note_id', 'len_doc']]\n",
    "    docs = [tuple(x) for x in subset.to_numpy()]\n",
    "    \n",
    "    return docs\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_ann(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    if filter_semtype:\n",
    "        if ',' in semtype:\n",
    "            semtype = semtype.split(',')\n",
    "        else:\n",
    "            semtype = [semtype]\n",
    "        \n",
    "    ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    ann = ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = ann[ann['semtype'].isin(semtype)]\n",
    "        \n",
    "    ann[\"label\"] = 'concept'\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ann = ann[cols_to_keep]\n",
    "    \n",
    "    return ann\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_ann(r):\n",
    "    sys = r.system_merges    \n",
    "    sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "    sys[\"label\"] = 'concept'\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys = sys[cols_to_keep]\n",
    "\n",
    "    return sys\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metrics(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    else:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    # vectorize merges using i-o labeling\n",
    "    if run_type == 'overlap':\n",
    "        if filter_semtype:\n",
    "            TP, TN, FP, FN = vectorized_coocurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            TP, TN, FP, FN = vectorized_coocurences(r, analysis_type, corpus, filter_semtype)\n",
    "\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        \n",
    "        d['TN'] = TN\n",
    "        \n",
    "        # return full metrics\n",
    "        return d\n",
    "\n",
    "    elif run_type == 'exact':\n",
    "        # total by number spans\n",
    "        system_n = len(r.system_merges)\n",
    "        reference_n = get_ref_n(analysis_type, corpus, filter_semtype)\n",
    "\n",
    "        reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, r.results).get_ref_sys()\n",
    "        # get overall TP/TF and various other counts for running confusion matrix metric analysis\n",
    "        return cm_dict(reference_only, system_only, reference_system_match, system_n, reference_n)\n",
    "    \n",
    "def get_merge_data(boolean_expression: str, analysis_type: str, corpus: str, filter_semtype):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    else:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype)\n",
    "    \n",
    "    system_n = len(r.system_merges, r.resu)\n",
    "    reference_n = get_ref_n(analysis_type, corpus, filter_semtype)\n",
    "\n",
    "    reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, r.results).get_ref_sys()\n",
    "\n",
    "    print(cm_dict(reference_only, system_only, reference_system_match, system_n, reference_n))\n",
    "    # get matched data from merge\n",
    "    return r.system_merges # merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all combinations of given list of annotators:\n",
    "def partly_unordered_permutations(lst, k):\n",
    "    elems = set(lst)\n",
    "    for c in combinations(lst, k):\n",
    "        for d in permutations(elems - set(c)):\n",
    "            yield c + d\n",
    "            \n",
    "def expressions(l, n):\n",
    "    for (operations, *operands), operators in product(\n",
    "            combinations(l, n), product(('&', '|'), repeat=n - 1)):\n",
    "        for operation in zip(operators, operands):\n",
    "            operations = [operations, *operation]\n",
    "        yield operations\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "# get list of systems with a semantic type in grouping\n",
    "def get_valid_systems(systems, semtype):\n",
    "    test = []\n",
    "    for sys in systems:\n",
    "        st = system_semtype_check(sys, semtype, corpus)\n",
    "        if st:\n",
    "            test.append(sys)\n",
    "\n",
    "    return test\n",
    "\n",
    "# permute system combinations and evaluate system merges for performance\n",
    "def run_ensemble(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    metrics = pd.DataFrame()\n",
    "    for l in partly_unordered_permutations(systems, 2):\n",
    "        print('processing merge combo:', l)\n",
    "        for i in range(1, len(l)+1):\n",
    "            test = list(expressions(l, i))\n",
    "            for t in test:\n",
    "                if i > 1:\n",
    "                    # format Boolean sentence for parse tree \n",
    "                    t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                if filter_semtype:\n",
    "                    d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "                else:\n",
    "                    d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype)\n",
    "                    \n",
    "                d['merge'] = t\n",
    "                d['n_terms'] = i\n",
    "\n",
    "                frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "                metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# write to file\n",
    "def generate_ensemble_metrics(metrics, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    file_name = corpus + '_all_merge_metrics_'\n",
    "   \n",
    "    # drop exact matches:\n",
    "    metrics = metrics.drop_duplicates()\n",
    "    metrics = metrics.sort_values(by=['n_terms', 'merge'])\n",
    "    #metrics = metrics.drop_duplicates(subset=['TP', 'FN', 'FP', 'n_sys', 'precision', 'recall', 'F', 'TM', 'TP/FN', 'TM', 'n_terms'])\n",
    "\n",
    "    file = file_name + analysis_type\n",
    "    \n",
    "    if run_type == 'overlap':\n",
    "        file += '_overlap_'\n",
    "    \n",
    "    elif run_type == 'exact':\n",
    "        file += '_exact_'\n",
    "    \n",
    "    if filter_semtype:\n",
    "        file += semtype\n",
    "    \n",
    "    geometric_mean(metrics).to_csv(analysisConf.data_dir + file + str(timestamp) + '.csv')\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "# control ensemble run\n",
    "def ensemble_control(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    \n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            metrics = run_ensemble(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "            generate_ensemble_metrics(metrics, analysis_type, corpus, filter_semtype, semtype)\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        metrics = run_ensemble(systems, analysis_type, corpus, filter_semtype)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, filter_semtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Incoming Boolean sentences are parsed into a binary tree.\n",
    "\n",
    "Test expressions to parse:\n",
    "\n",
    "sentence = '((((A&B)|C)|D)&E)'\n",
    "\n",
    "sentence = '(E&(D|(C|(A&B))))'\n",
    "\n",
    "sentence = '(((A|(B&C))|(D&(E&F)))|(H&I))'\n",
    "\n",
    "\"\"\"\n",
    "# build parse tree from passed sentence\n",
    "# using grammatical rules of Boolean logic\n",
    "def buildParseTree(fpexp):\n",
    "    \"\"\"\n",
    "       Iteratively build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "       :param fpexp: sentence to parse\n",
    "       :return eTree: parse tree representation\n",
    "       Incoming Boolean sentences are parsed into a binary tree.\n",
    "       Test expressions to parse:\n",
    "       sentence = '(A&B)'\n",
    "       sentence = '(A|B)'\n",
    "       sentence = '((A|B)&C)'\n",
    "       \n",
    "    \"\"\"\n",
    "    fplist = fpexp.split()\n",
    "    pStack = Stack()\n",
    "    eTree = BinaryTree('')\n",
    "    pStack.push(eTree)\n",
    "    currentTree = eTree\n",
    "\n",
    "    for i in fplist:\n",
    "\n",
    "        if i == '(':\n",
    "            currentTree.insertLeft('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getLeftChild()\n",
    "        elif i not in ['&', '|', ')']:\n",
    "            currentTree.setRootVal(i)\n",
    "            parent = pStack.pop()\n",
    "            currentTree = parent\n",
    "        elif i in ['&', '|']:\n",
    "            currentTree.setRootVal(i)\n",
    "            currentTree.insertRight('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getRightChild()\n",
    "        elif i == ')':\n",
    "            currentTree = pStack.pop()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return eTree\n",
    "\n",
    "def make_parse_tree(payload):\n",
    "    \"\"\"\n",
    "    Ensure data to create tree are in standard form\n",
    "    :param sentence: sentence to preprocess\n",
    "    :return pt, parse tree graph\n",
    "            sentence, processed sentence to build tree\n",
    "            a: order\n",
    "    \"\"\"\n",
    "    def preprocess_sentence(sentence):\n",
    "        # prepare statement for case when a boolean AND/OR is given\n",
    "        sentence = payload.replace('(', ' ( '). \\\n",
    "            replace(')', ' ) '). \\\n",
    "            replace('&', ' & '). \\\n",
    "            replace('|', ' | '). \\\n",
    "            replace('  ', ' ')\n",
    "        return sentence\n",
    "\n",
    "    sentence = preprocess_sentence(payload)\n",
    "    print(sentence)\n",
    "    \n",
    "    pt = buildParseTree(sentence)\n",
    "    #pt.postorder() \n",
    "    \n",
    "    return pt\n",
    "\n",
    "class Sentence(object):\n",
    "    def __init__(self, sentence):\n",
    "        self = self\n",
    "        self.n_and = sentence.count('&')\n",
    "        self.n_or = sentence.count('|')\n",
    "        self.sentence = sentence\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_docs(corpus):\n",
    "    sql = 'select distinct note_id, sofa from sofas where corpus = %(corpus)s order by note_id'\n",
    "    df = pd.read_sql(sql, params={\"corpus\":corpus}, con=engine)\n",
    "    df.drop_duplicates()\n",
    "    df['len_doc'] = df['sofa'].apply(len)\n",
    "    \n",
    "    subset = df[['note_id', 'len_doc']]\n",
    "    docs = [tuple(x) for x in subset.to_numpy()]\n",
    "    \n",
    "    return docs\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_ann(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    if filter_semtype:\n",
    "        if ',' in semtype:\n",
    "            semtype = semtype.split(',')\n",
    "        else:\n",
    "            semtype = [semtype]\n",
    "        \n",
    "    ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    ann = ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = ann[ann['semtype'].isin(semtype)]\n",
    "        \n",
    "    ann[\"label\"] = 'concept'\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ann = ann[cols_to_keep]\n",
    "    \n",
    "    return ann\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_ann(r):\n",
    "    sys = r.system_merges    \n",
    "    sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "    sys[\"label\"] = 'concept'\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys = sys[cols_to_keep]\n",
    "\n",
    "    return sys\n",
    "\n",
    "def get_merge_data(boolean_expression: str, analysis_type: str, corpus: str, filter_semtype):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "\n",
    "    r = process_sentence(pt, sentence, analysis_type, corpus)\n",
    "    \n",
    "    system_n = len(r.system_merges, r.resu)\n",
    "    reference_n = get_ref_n(analysis_type, corpus, filter_semtype)\n",
    "\n",
    "    reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, r.results).get_ref_sys()\n",
    "\n",
    "    print(cm_dict(reference_only, system_only, reference_system_match, system_n, reference_n))\n",
    "    # get matched data from merge\n",
    "    return r.system_merges # merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'] ('analytical_fairview.csv', 'concepts.fairview_all')\n",
      "run_type: overlap\n",
      "None ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
      "processing merge combo: ('biomedicus', 'clamp', 'quick_umls', 'ctakes', 'metamap')\n",
      "biomedicus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clamp\n",
      "quick_umls\n",
      "ctakes\n",
      "metamap\n",
      " ( biomedicus & clamp ) \n",
      " ( biomedicus | clamp ) \n",
      " ( biomedicus & quick_umls ) \n",
      " ( biomedicus | quick_umls ) \n",
      " ( biomedicus & ctakes ) \n",
      " ( biomedicus | ctakes ) \n",
      " ( biomedicus & metamap ) \n",
      " ( biomedicus | metamap ) \n",
      " ( clamp & quick_umls ) \n",
      " ( clamp | quick_umls ) \n",
      " ( clamp & ctakes ) \n",
      " ( clamp | ctakes ) \n",
      " ( clamp & metamap ) \n",
      " ( clamp | metamap ) \n",
      " ( quick_umls & ctakes ) \n",
      " ( quick_umls | ctakes ) \n",
      " ( quick_umls & metamap ) \n",
      " ( quick_umls | metamap ) \n",
      " ( ctakes & metamap ) \n",
      " ( ctakes | metamap ) \n",
      " ( ( biomedicus & clamp ) & quick_umls ) \n",
      " ( ( biomedicus & clamp ) | quick_umls ) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:80: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ( ( biomedicus | clamp ) & quick_umls ) \n",
      " ( ( biomedicus | clamp ) | quick_umls ) \n",
      " ( ( biomedicus & clamp ) & ctakes ) \n",
      " ( ( biomedicus & clamp ) | ctakes ) \n",
      " ( ( biomedicus | clamp ) & ctakes ) \n",
      " ( ( biomedicus | clamp ) | ctakes ) \n",
      " ( ( biomedicus & clamp ) & metamap ) \n",
      " ( ( biomedicus & clamp ) | metamap ) \n",
      " ( ( biomedicus | clamp ) & metamap ) \n",
      " ( ( biomedicus | clamp ) | metamap ) \n",
      " ( ( biomedicus & quick_umls ) & ctakes ) \n",
      " ( ( biomedicus & quick_umls ) | ctakes ) \n",
      " ( ( biomedicus | quick_umls ) & ctakes ) \n",
      " ( ( biomedicus | quick_umls ) | ctakes ) \n",
      " ( ( biomedicus & quick_umls ) & metamap ) \n",
      " ( ( biomedicus & quick_umls ) | metamap ) \n",
      " ( ( biomedicus | quick_umls ) & metamap ) \n",
      " ( ( biomedicus | quick_umls ) | metamap ) \n",
      " ( ( biomedicus & ctakes ) & metamap ) \n",
      " ( ( biomedicus & ctakes ) | metamap ) \n",
      " ( ( biomedicus | ctakes ) & metamap ) \n",
      " ( ( biomedicus | ctakes ) | metamap ) \n",
      " ( ( clamp & quick_umls ) & ctakes ) \n",
      " ( ( clamp & quick_umls ) | ctakes ) \n",
      " ( ( clamp | quick_umls ) & ctakes ) \n",
      " ( ( clamp | quick_umls ) | ctakes ) \n",
      " ( ( clamp & quick_umls ) & metamap ) \n",
      " ( ( clamp & quick_umls ) | metamap ) \n",
      " ( ( clamp | quick_umls ) & metamap ) \n",
      " ( ( clamp | quick_umls ) | metamap ) \n",
      " ( ( clamp & ctakes ) & metamap ) \n",
      " ( ( clamp & ctakes ) | metamap ) \n",
      " ( ( clamp | ctakes ) & metamap ) \n",
      " ( ( clamp | ctakes ) | metamap ) \n",
      " ( ( quick_umls & ctakes ) & metamap ) \n",
      " ( ( quick_umls & ctakes ) | metamap ) \n",
      " ( ( quick_umls | ctakes ) & metamap ) \n",
      " ( ( quick_umls | ctakes ) | metamap ) \n",
      " ( ( ( biomedicus & clamp ) & quick_umls ) & ctakes ) \n",
      " ( ( ( biomedicus & clamp ) & quick_umls ) | ctakes ) \n",
      " ( ( ( biomedicus & clamp ) | quick_umls ) & ctakes ) \n",
      " ( ( ( biomedicus & clamp ) | quick_umls ) | ctakes ) \n",
      " ( ( ( biomedicus | clamp ) & quick_umls ) & ctakes ) \n",
      " ( ( ( biomedicus | clamp ) & quick_umls ) | ctakes ) \n",
      " ( ( ( biomedicus | clamp ) | quick_umls ) & ctakes ) \n",
      " ( ( ( biomedicus | clamp ) | quick_umls ) | ctakes ) \n",
      " ( ( ( biomedicus & clamp ) & quick_umls ) & metamap ) \n",
      " ( ( ( biomedicus & clamp ) & quick_umls ) | metamap ) \n",
      " ( ( ( biomedicus & clamp ) | quick_umls ) & metamap ) \n",
      " ( ( ( biomedicus & clamp ) | quick_umls ) | metamap ) \n",
      " ( ( ( biomedicus | clamp ) & quick_umls ) & metamap ) \n",
      " ( ( ( biomedicus | clamp ) & quick_umls ) | metamap ) \n",
      " ( ( ( biomedicus | clamp ) | quick_umls ) & metamap ) \n",
      " ( ( ( biomedicus | clamp ) | quick_umls ) | metamap ) \n",
      " ( ( ( biomedicus & clamp ) & ctakes ) & metamap ) \n",
      " ( ( ( biomedicus & clamp ) & ctakes ) | metamap ) \n",
      " ( ( ( biomedicus & clamp ) | ctakes ) & metamap ) \n",
      " ( ( ( biomedicus & clamp ) | ctakes ) | metamap ) \n",
      " ( ( ( biomedicus | clamp ) & ctakes ) & metamap ) \n",
      " ( ( ( biomedicus | clamp ) & ctakes ) | metamap ) \n",
      " ( ( ( biomedicus | clamp ) | ctakes ) & metamap ) \n",
      " ( ( ( biomedicus | clamp ) | ctakes ) | metamap ) \n",
      " ( ( ( biomedicus & quick_umls ) & ctakes ) & metamap ) \n",
      " ( ( ( biomedicus & quick_umls ) & ctakes ) | metamap ) \n",
      " ( ( ( biomedicus & quick_umls ) | ctakes ) & metamap ) \n",
      " ( ( ( biomedicus & quick_umls ) | ctakes ) | metamap ) \n",
      " ( ( ( biomedicus | quick_umls ) & ctakes ) & metamap ) \n",
      " ( ( ( biomedicus | quick_umls ) & ctakes ) | metamap ) \n",
      " ( ( ( biomedicus | quick_umls ) | ctakes ) & metamap ) \n",
      " ( ( ( biomedicus | quick_umls ) | ctakes ) | metamap ) \n",
      " ( ( ( clamp & quick_umls ) & ctakes ) & metamap ) \n",
      " ( ( ( clamp & quick_umls ) & ctakes ) | metamap ) \n",
      " ( ( ( clamp & quick_umls ) | ctakes ) & metamap ) \n",
      " ( ( ( clamp & quick_umls ) | ctakes ) | metamap ) \n",
      " ( ( ( clamp | quick_umls ) & ctakes ) & metamap ) \n",
      " ( ( ( clamp | quick_umls ) & ctakes ) | metamap ) \n",
      " ( ( ( clamp | quick_umls ) | ctakes ) & metamap ) \n",
      " ( ( ( clamp | quick_umls ) | ctakes ) | metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) & quick_umls ) & ctakes ) & metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) & quick_umls ) & ctakes ) | metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) & quick_umls ) | ctakes ) & metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) & quick_umls ) | ctakes ) | metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) | quick_umls ) & ctakes ) & metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) | quick_umls ) & ctakes ) | metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) | quick_umls ) | ctakes ) & metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) | quick_umls ) | ctakes ) | metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) & quick_umls ) & ctakes ) & metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) & quick_umls ) & ctakes ) | metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) & quick_umls ) | ctakes ) & metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) & quick_umls ) | ctakes ) | metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) | quick_umls ) & ctakes ) & metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) | quick_umls ) & ctakes ) | metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) | quick_umls ) | ctakes ) & metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) | quick_umls ) | ctakes ) | metamap ) \n",
      "processing merge combo: ('biomedicus', 'clamp', 'quick_umls', 'metamap', 'ctakes')\n",
      " ( metamap & ctakes ) \n",
      " ( metamap | ctakes ) \n",
      " ( ( biomedicus & metamap ) & ctakes ) \n",
      " ( ( biomedicus & metamap ) | ctakes ) \n",
      " ( ( biomedicus | metamap ) & ctakes ) \n",
      " ( ( biomedicus | metamap ) | ctakes ) \n",
      " ( ( clamp & metamap ) & ctakes ) \n",
      " ( ( clamp & metamap ) | ctakes ) \n",
      " ( ( clamp | metamap ) & ctakes ) \n",
      " ( ( clamp | metamap ) | ctakes ) \n",
      " ( ( quick_umls & metamap ) & ctakes ) \n",
      " ( ( quick_umls & metamap ) | ctakes ) \n",
      " ( ( quick_umls | metamap ) & ctakes ) \n",
      " ( ( quick_umls | metamap ) | ctakes ) \n",
      " ( ( ( biomedicus & clamp ) & metamap ) & ctakes ) \n",
      " ( ( ( biomedicus & clamp ) & metamap ) | ctakes ) \n",
      " ( ( ( biomedicus & clamp ) | metamap ) & ctakes ) \n",
      " ( ( ( biomedicus & clamp ) | metamap ) | ctakes ) \n",
      " ( ( ( biomedicus | clamp ) & metamap ) & ctakes ) \n",
      " ( ( ( biomedicus | clamp ) & metamap ) | ctakes ) \n",
      " ( ( ( biomedicus | clamp ) | metamap ) & ctakes ) \n",
      " ( ( ( biomedicus | clamp ) | metamap ) | ctakes ) \n",
      " ( ( ( biomedicus & quick_umls ) & metamap ) & ctakes ) \n",
      " ( ( ( biomedicus & quick_umls ) & metamap ) | ctakes ) \n",
      " ( ( ( biomedicus & quick_umls ) | metamap ) & ctakes ) \n",
      " ( ( ( biomedicus & quick_umls ) | metamap ) | ctakes ) \n",
      " ( ( ( biomedicus | quick_umls ) & metamap ) & ctakes ) \n",
      " ( ( ( biomedicus | quick_umls ) & metamap ) | ctakes ) \n",
      " ( ( ( biomedicus | quick_umls ) | metamap ) & ctakes ) \n",
      " ( ( ( biomedicus | quick_umls ) | metamap ) | ctakes ) \n",
      " ( ( ( clamp & quick_umls ) & metamap ) & ctakes ) \n",
      " ( ( ( clamp & quick_umls ) & metamap ) | ctakes ) \n",
      " ( ( ( clamp & quick_umls ) | metamap ) & ctakes ) \n",
      " ( ( ( clamp & quick_umls ) | metamap ) | ctakes ) \n",
      " ( ( ( clamp | quick_umls ) & metamap ) & ctakes ) \n",
      " ( ( ( clamp | quick_umls ) & metamap ) | ctakes ) \n",
      " ( ( ( clamp | quick_umls ) | metamap ) & ctakes ) \n",
      " ( ( ( clamp | quick_umls ) | metamap ) | ctakes ) \n",
      " ( ( ( ( biomedicus & clamp ) & quick_umls ) & metamap ) & ctakes ) \n",
      " ( ( ( ( biomedicus & clamp ) & quick_umls ) & metamap ) | ctakes ) \n",
      " ( ( ( ( biomedicus & clamp ) & quick_umls ) | metamap ) & ctakes ) \n",
      " ( ( ( ( biomedicus & clamp ) & quick_umls ) | metamap ) | ctakes ) \n",
      " ( ( ( ( biomedicus & clamp ) | quick_umls ) & metamap ) & ctakes ) \n",
      " ( ( ( ( biomedicus & clamp ) | quick_umls ) & metamap ) | ctakes ) \n",
      " ( ( ( ( biomedicus & clamp ) | quick_umls ) | metamap ) & ctakes ) \n",
      " ( ( ( ( biomedicus & clamp ) | quick_umls ) | metamap ) | ctakes ) \n",
      " ( ( ( ( biomedicus | clamp ) & quick_umls ) & metamap ) & ctakes ) \n",
      " ( ( ( ( biomedicus | clamp ) & quick_umls ) & metamap ) | ctakes ) \n",
      " ( ( ( ( biomedicus | clamp ) & quick_umls ) | metamap ) & ctakes ) \n",
      " ( ( ( ( biomedicus | clamp ) & quick_umls ) | metamap ) | ctakes ) \n",
      " ( ( ( ( biomedicus | clamp ) | quick_umls ) & metamap ) & ctakes ) \n",
      " ( ( ( ( biomedicus | clamp ) | quick_umls ) & metamap ) | ctakes ) \n",
      " ( ( ( ( biomedicus | clamp ) | quick_umls ) | metamap ) & ctakes ) \n",
      " ( ( ( ( biomedicus | clamp ) | quick_umls ) | metamap ) | ctakes ) \n",
      "processing merge combo: ('biomedicus', 'clamp', 'ctakes', 'quick_umls', 'metamap')\n",
      " ( ctakes & quick_umls ) \n",
      " ( ctakes | quick_umls ) \n",
      " ( ( biomedicus & ctakes ) & quick_umls ) \n",
      " ( ( biomedicus & ctakes ) | quick_umls ) \n",
      " ( ( biomedicus | ctakes ) & quick_umls ) \n",
      " ( ( biomedicus | ctakes ) | quick_umls ) \n",
      " ( ( clamp & ctakes ) & quick_umls ) \n",
      " ( ( clamp & ctakes ) | quick_umls ) \n",
      " ( ( clamp | ctakes ) & quick_umls ) \n",
      " ( ( clamp | ctakes ) | quick_umls ) \n",
      " ( ( ctakes & quick_umls ) & metamap ) \n",
      " ( ( ctakes & quick_umls ) | metamap ) \n",
      " ( ( ctakes | quick_umls ) & metamap ) \n",
      " ( ( ctakes | quick_umls ) | metamap ) \n",
      " ( ( ( biomedicus & clamp ) & ctakes ) & quick_umls ) \n",
      " ( ( ( biomedicus & clamp ) & ctakes ) | quick_umls ) \n",
      " ( ( ( biomedicus & clamp ) | ctakes ) & quick_umls ) \n",
      " ( ( ( biomedicus & clamp ) | ctakes ) | quick_umls ) \n",
      " ( ( ( biomedicus | clamp ) & ctakes ) & quick_umls ) \n",
      " ( ( ( biomedicus | clamp ) & ctakes ) | quick_umls ) \n",
      " ( ( ( biomedicus | clamp ) | ctakes ) & quick_umls ) \n",
      " ( ( ( biomedicus | clamp ) | ctakes ) | quick_umls ) \n",
      " ( ( ( biomedicus & ctakes ) & quick_umls ) & metamap ) \n",
      " ( ( ( biomedicus & ctakes ) & quick_umls ) | metamap ) \n",
      " ( ( ( biomedicus & ctakes ) | quick_umls ) & metamap ) \n",
      " ( ( ( biomedicus & ctakes ) | quick_umls ) | metamap ) \n",
      " ( ( ( biomedicus | ctakes ) & quick_umls ) & metamap ) \n",
      " ( ( ( biomedicus | ctakes ) & quick_umls ) | metamap ) \n",
      " ( ( ( biomedicus | ctakes ) | quick_umls ) & metamap ) \n",
      " ( ( ( biomedicus | ctakes ) | quick_umls ) | metamap ) \n",
      " ( ( ( clamp & ctakes ) & quick_umls ) & metamap ) \n",
      " ( ( ( clamp & ctakes ) & quick_umls ) | metamap ) \n",
      " ( ( ( clamp & ctakes ) | quick_umls ) & metamap ) \n",
      " ( ( ( clamp & ctakes ) | quick_umls ) | metamap ) \n",
      " ( ( ( clamp | ctakes ) & quick_umls ) & metamap ) \n",
      " ( ( ( clamp | ctakes ) & quick_umls ) | metamap ) \n",
      " ( ( ( clamp | ctakes ) | quick_umls ) & metamap ) \n",
      " ( ( ( clamp | ctakes ) | quick_umls ) | metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) & ctakes ) & quick_umls ) & metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) & ctakes ) & quick_umls ) | metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) & ctakes ) | quick_umls ) & metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) & ctakes ) | quick_umls ) | metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) | ctakes ) & quick_umls ) & metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) | ctakes ) & quick_umls ) | metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) | ctakes ) | quick_umls ) & metamap ) \n",
      " ( ( ( ( biomedicus & clamp ) | ctakes ) | quick_umls ) | metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) & ctakes ) & quick_umls ) & metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) & ctakes ) & quick_umls ) | metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) & ctakes ) | quick_umls ) & metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) & ctakes ) | quick_umls ) | metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) | ctakes ) & quick_umls ) & metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) | ctakes ) & quick_umls ) | metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) | ctakes ) | quick_umls ) & metamap ) \n",
      " ( ( ( ( biomedicus | clamp ) | ctakes ) | quick_umls ) | metamap ) \n",
      "processing merge combo: ('biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls')\n",
      " ( metamap & quick_umls ) \n",
      " ( metamap | quick_umls ) \n",
      " ( ( biomedicus & metamap ) & quick_umls ) \n",
      " ( ( biomedicus & metamap ) | quick_umls ) \n",
      " ( ( biomedicus | metamap ) & quick_umls ) \n",
      " ( ( biomedicus | metamap ) | quick_umls ) \n",
      " ( ( clamp & metamap ) & quick_umls ) \n",
      " ( ( clamp & metamap ) | quick_umls ) \n",
      " ( ( clamp | metamap ) & quick_umls ) \n",
      " ( ( clamp | metamap ) | quick_umls ) \n",
      " ( ( ctakes & metamap ) & quick_umls ) \n",
      " ( ( ctakes & metamap ) | quick_umls ) \n",
      " ( ( ctakes | metamap ) & quick_umls ) \n",
      " ( ( ctakes | metamap ) | quick_umls ) \n",
      " ( ( ( biomedicus & clamp ) & metamap ) & quick_umls ) \n",
      " ( ( ( biomedicus & clamp ) & metamap ) | quick_umls ) \n",
      " ( ( ( biomedicus & clamp ) | metamap ) & quick_umls ) \n",
      " ( ( ( biomedicus & clamp ) | metamap ) | quick_umls ) \n",
      " ( ( ( biomedicus | clamp ) & metamap ) & quick_umls ) \n",
      " ( ( ( biomedicus | clamp ) & metamap ) | quick_umls ) \n",
      " ( ( ( biomedicus | clamp ) | metamap ) & quick_umls ) \n",
      " ( ( ( biomedicus | clamp ) | metamap ) | quick_umls ) \n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "def main():\n",
    "    '''\n",
    "        corpora: i2b2, mipacq, fv017\n",
    "        analyses: entity only (exact span), cui by document, full (aka (entity and cui on exaact span/exact cui)\n",
    "        systems: ctakes, biomedicus, clamp, metamap, quick_umls\n",
    "        \n",
    "        TODO -> Vectorization (entity only) -> done:\n",
    "                add switch for use of TN on single system performance evaluations -> done\n",
    "                add switch for overlap matching versus exact span -> done\n",
    "             -> Other tasks besides concept extraction\n",
    "        \n",
    "    ''' \n",
    "    analysisConf =  AnalysisConfig()\n",
    "    print(analysisConf.systems, analysisConf.corpus_config())\n",
    "    \n",
    "    if (rtype == 1):\n",
    "        generate_metrics(analysis_type, corpus, filter_semtype)\n",
    "    elif (rtype == 2):\n",
    "        print('run_type:', run_type)\n",
    "        if filter_semtype:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, None)\n",
    "    elif (rtype == 3):\n",
    "        t = ['concept_jaccard_score_false']\n",
    "        test_systems(analysis_type, analysisConf.systems, corpus)  \n",
    "        test_count(analysis_type, corpus)\n",
    "        test_ensemble(analysis_type, corpus)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    %prun main()\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = get_sys_data('quick_umls', analysis_type, corpus, filter_semtype)\n",
    "# q = q.sort_values(by=['note_id', 'begin'])\n",
    "# print(q.head(20))\n",
    "\n",
    "# b = get_sys_data('biomedicus', analysis_type, corpus, filter_semtype)\n",
    "# b = b.sort_values(by=['note_id', 'begin'])\n",
    "# print(b.head(20))\n",
    "\n",
    "# df = pd.read_csv('/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/analytical_fairview.csv')\n",
    "\n",
    "# ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "# ref_ann = ref_ann[ref_ann['semtype'] == 'Drug']\n",
    "# #ref_ann.sort_values(by=['file', 'start']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# merge = 'biomedicus' \n",
    "# sys_ann = get_contingency_table(analysis_type, corpus, semtypes[0], merge)  \n",
    "# ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "# #print(len(ref_ann))\n",
    "# ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes).get_system_type('reference'))]\n",
    "# #print(len(ref_ann))\n",
    "\n",
    "# def get_rand_idx(ref_ann, sys_ann):\n",
    "#     r_idx = ref_ann.index.values.tolist() \n",
    "#     s_idx = sys_ann.index.values.tolist()\n",
    "    \n",
    "#     n = int(len(r_idx)/(1.33))\n",
    "#     r = random.sample(r_idx, k=n)\n",
    "#     n = int(len(s_idx)/(1.33))\n",
    "#     s = random.sample(s_idx, k=n)\n",
    "    \n",
    "#     return r, s\n",
    "\n",
    "# metrics = pd.DataFrame()\n",
    "# for i in range(1, 5):\n",
    "#     r, s = get_rand_idx(ref_ann, sys_ann)\n",
    "#     ref = ref_ann.ix[r]\n",
    "#     sys = sys_ann.ix[s]\n",
    "    \n",
    "#     c = get_cooccurences(ref, sys, analysis_type, corpus, False)\n",
    "#     #print(c.ref_n, c.ref_only, c.system_n, c.system_only, c.ref_system_match)\n",
    "    \n",
    "#     d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "    \n",
    "#     frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "#     metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "    \n",
    "# print(geometric_mean(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control filter_semtype in get_sys_data, get_ref_n and generate_metrics. TODO consolidate. \n",
    " \n",
    "# # run single statement\n",
    "# statement = '(ctakes&clamp)'\n",
    "# analysis_type = 'entity'\n",
    "# corpus = 'fairview'\n",
    "# #matches = get_merge_data(statement, analysis_type, corpus)\n",
    "# #print(matches)\n",
    "\n",
    "# import spacy\n",
    "# nlp = spacy.load('en')\n",
    "\n",
    "# sql = \"select distinct note_id, sofa from concepts.sofas where corpus = 'fairview'\"\n",
    "\n",
    "# docs = pd.read_sql(sql, con=engine)\n",
    "\n",
    "# d = {}\n",
    "\n",
    "# for row in docs.itertuples():\n",
    "#     d[row.note_id] = row.sofa\n",
    "    \n",
    "# print(len(d))\n",
    "\n",
    "# test = matches[matches['note_id'] == '0000200926']\n",
    "# print(len(test))\n",
    "\n",
    "# doc = nlp(d['0000200926'])\n",
    "\n",
    "# for row in test.itertuples():\n",
    "#     my_str = [token.text.strip('\\n').lower() for token in doc if token.idx >= (row.begin) and token.idx <= (row.end)]\n",
    "#     if 'diabetes' in my_str:\n",
    "#         print(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTS -> ensemble:\n",
    "# def test_match_consistency(matches, ref_only, ref_n, sys):\n",
    "#     \"\"\"test for reference only/match set consistency:\n",
    "#         params: match, system and reference only sets\"\"\"\n",
    "   \n",
    "#     print('len', len(sys), len(matches), len(matches.union(sys)), len(matches.intersection(sys)))\n",
    "#     assert len(matches.union(ref_only)) == ref_n, 'Reference annotation mismatch union'\n",
    "#     assert len(matches.intersection(sys)) == len(matches), 'System annotation mismatch intersect'\n",
    "#     assert len(matches.union(sys)) == len(sys), 'System annotation mismatch union'\n",
    "#     assert len(matches.intersection(ref_only)) == 0, 'Reference annotation mismatch intersect'\n",
    "\n",
    "# def test_systems(analysis_type, systems, corpus):\n",
    "#     sys = df_to_set(get_sys_data(systems[0], analysis_type, corpus), analysis_type)\n",
    "#     test_match_consistency(*get_system_matches(systems[0], analysis_type, corpus), get_ref_n(analysis_type), sys)\n",
    "#     print('Match consistency:', len(sys),get_ref_n(analysis_type))\n",
    "\n",
    "# def test_metrics(ref, sys_m, match_m):\n",
    "#     test = True\n",
    "#     reference_n = len(ref)\n",
    "#     system_n = len(sys_m)\n",
    "\n",
    "#     print('Test metrics:', type(reference_n), type(system_n), type(match_m))\n",
    "\n",
    "#     reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, match_m).get_ref_sys()\n",
    "#     F, recall, precision, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics()\n",
    "#     F_, recall_, precision_, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics(test)\n",
    "\n",
    "#     assert F[1] == F_, 'F1 issue'\n",
    "#     assert recall[1] == recall_, 'recall issue'\n",
    "#     assert precision[1] == precision_, 'precision issue'\n",
    "#     print(F[1], F_)\n",
    "#     print(recall[1], recall_)\n",
    "#     print(precision[1], precision_)\n",
    "\n",
    "# def test_count(analysis_type, corpus):\n",
    "#     # test match counts:\n",
    "#     ctakes, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     clamp, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "\n",
    "#     print('count:', len(mm.intersection(b9.intersection(clamp.intersection(ctakes)))))\n",
    "    \n",
    "# def test_ensemble(analysis_type, corpus):\n",
    "    \n",
    "#     print('ensemble:')\n",
    "#     # Get mixed system_n\n",
    "#     ref_ann, data = get_metric_data(analysis_type, corpus)\n",
    "\n",
    "#     names = ['ctakes', 'biomedicus', 'metamap', 'clamp']\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['begin', 'end', 'note_id']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['cui', 'note_id']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "#     biomedicus = data[data[\"system\"]=='biomedicus'][cols_to_keep].copy()\n",
    "#     ctakes = data[data[\"system\"]=='ctakes'][cols_to_keep].copy()\n",
    "#     clamp = data[data[\"system\"]=='clamp'][cols_to_keep].copy()\n",
    "#     metamap = data[data[\"system\"]=='metamap'][cols_to_keep].copy()\n",
    "#     quickumls = data[data[\"system\"]=='quick_umls'][cols_to_keep].copy()\n",
    "\n",
    "#     print('systems:', len(biomedicus), len(clamp), len(ctakes), len(metamap), len(quickumls))\n",
    "\n",
    "#     b9 = set()\n",
    "#     cl = set()\n",
    "#     ct = set()\n",
    "#     mm = set()\n",
    "#     qu = set()\n",
    "\n",
    "#     b9 = df_to_set(get_sys_data('biomedicus', analysis_type, corpus), analysis_type)\n",
    "#     print(len(b9))\n",
    "\n",
    "#     ct = df_to_set(get_sys_data('ctakes', analysis_type, corpus), analysis_type)\n",
    "#     print(len(ct))\n",
    "\n",
    "#     cl = df_to_set(get_sys_data('clamp', analysis_type, corpus), analysis_type)\n",
    "#     print(len(cl))\n",
    "\n",
    "#     mm = df_to_set(get_sys_data('metamap', analysis_type, corpus), analysis_type)\n",
    "#     print(len(mm))\n",
    "\n",
    "#     qu = df_to_set(get_sys_data('quick_umls', analysis_type, corpus), analysis_type)\n",
    "#     print(len(qu))\n",
    "    \n",
    "#     print('various merges:')\n",
    "#     print(len(b9), len(cl), len(ct), len(mm), len(qu))\n",
    "#     print(len(mm.intersection(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.union(ct)))))\n",
    "#     print(len(b9.intersection(ct)))\n",
    "\n",
    "#     sys_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('sys_m:', len(sys_m))\n",
    "\n",
    "#     # Get match merges:\n",
    "#     ct, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     cl, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "#     qu, _ = get_system_matches('quick_umls', analysis_type, corpus)\n",
    "\n",
    "#     match_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('match_m:', len(match_m))\n",
    "#     # reference df to set\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['end', 'start','file']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['value','file']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['end', 'start', 'value','file']\n",
    "\n",
    "#     ref = df_to_set(ref_ann[cols_to_keep], analysis_type, 'ref')\n",
    "\n",
    "#     print('ref:', len(ref))\n",
    "\n",
    "#     # test difference:\n",
    "#     print('FP:', len(sys_m - match_m), len(sys_m - ref))\n",
    "#     assert len(sys_m - match_m) == len(sys_m - ref), 'FP mismatch'\n",
    "#     print('FN:', len(ref - match_m), len(ref - sys_m))\n",
    "#     assert len(ref - match_m) == len(ref - sys_m), 'FN mismatch'\n",
    "    \n",
    "#     test_metrics(ref, sys_m, match_m)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
