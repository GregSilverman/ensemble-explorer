{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Copyright (c) 2019 Regents of the University of Minnesota.\n",
    " \n",
    "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    " \n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pymysql\n",
    "import time \n",
    "import functools as ft\n",
    "import glob, os   \n",
    "import operator as op\n",
    "import shelve\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, permutations\n",
    "from sqlalchemy.engine import create_engine\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from scipy import stats  \n",
    "from scipy.stats.mstats import gmean\n",
    "from pythonds.basic.stack import Stack\n",
    "from pythonds.trees.binaryTree import BinaryTree\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from typing import List, Set, Tuple "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cell below contains the configurable parameters to ensure that our ensemble explorer runs properaly on your machine. \n",
    "Please read carfully through steps (1-11) before running the rest of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-1: CHOOSE YOUR CORPUS\n",
    "# TODO: get working with list of corpora\n",
    "#corpora = ['mipacq','i2b2','fairview'] #options for concept extraction include 'fairview', 'mipacq' OR 'i2b2'\n",
    "\n",
    "corpus = 'mipacq'\n",
    "#corpora = ['i2b2','fairview']\n",
    "\n",
    "# STEP-2: CHOOSE YOUR DATA DIRECTORY; this is where output data will be saved on your machine\n",
    "data_directory = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/' \n",
    "\n",
    "# STEP-3: CHOOSE WHICH SYSTEMS YOU'D LIKE TO EVALUATE AGAINST THE CORPUS REFERENCE SET\n",
    "systems = ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "systems = ['clamp', 'quick_umls', 'biomedicus']\n",
    "\n",
    "# STEP-4: CHOOSE TYPE OF RUN\n",
    "rtype = 2      # OPTIONS INCLUDE: 1->Single systems; 2->Ensemble; 3->Tests; 4 -> majority vote \n",
    "               # The Ensemble can include the max system set ['ctakes','biomedicus','clamp','metamap','quick_umls']\n",
    "    \n",
    "# STEP-5: CHOOSE WHAT TYPE OF ANALYSIS YOU'D LIKE TO RUN ON THE CORPUS\n",
    "analysis_type = 'entity' #options include 'entity' OR 'full'\n",
    "\n",
    "# STEP-(6A): ENTER DETAILS FOR ACCESSING MANUAL ANNOTATION DATA\n",
    "database_type = 'mysql+pymysql' # We use mysql+pymql as default\n",
    "database_username = 'gms'\n",
    "database_password = 'nej123' \n",
    "database_url = 'localhost' # HINT: use localhost if you're running database on your local machine\n",
    "database_name = 'concepts' # Enter database name\n",
    "\n",
    "def ref_data(corpus):\n",
    "    return corpus + '_all' # Enter the table within the database where your reference data is stored\n",
    "\n",
    "table_name = ref_data(corpus)\n",
    "\n",
    "# STEP-(6B): ENTER DETAILS FOR ACCESSING SYSTEM ANNOTATION DATA\n",
    "\n",
    "def sys_data(corpus):\n",
    "    return 'analytical_'+corpus+'.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "\n",
    "system_annotation = sys_data(corpus)\n",
    "\n",
    "# STEP-7: CREATE A DB CONNECTION POOL\n",
    "engine_request = str(database_type)+'://'+database_username+':'+database_password+\"@\"+database_url+'/'+database_name\n",
    "engine = create_engine(engine_request, pool_pre_ping=True, pool_size=20, max_overflow=30)\n",
    "\n",
    "# STEP-(8A): FILTER BY SEMTYPE\n",
    "filter_semtype = False\n",
    "\n",
    "# STEP-(8B): IF STEP-(8A) == True -> GET REFERENCE SEMTYPES\n",
    "\n",
    "### Fairview -> ['drug', 'finding', 'anatomy', 'procedure']\n",
    "### i2b2 -> ['test, treatment', 'problem']\n",
    "### MiPACQ -> ['procedures', 'disorders, sign_symptom', 'anatomy', 'chemicals_and_drugs']\n",
    "\n",
    "# semtypes = ['Anatomy']\n",
    "def ref_semtypes(filter_semtype, corpus):\n",
    "    if filter_semtype:\n",
    "        if corpus == 'fairview':\n",
    "            semtypes = ['Drug', 'Finding', 'Anatomy', 'Procedure']\n",
    "        elif corpus == 'i2b2':\n",
    "            semtypes = ['test,treatment', 'problem']\n",
    "        elif corpus == 'mipacq':\n",
    "            semtypes = ['Procedures', 'Disorders,Sign_Symptom', 'Anatomy', 'Chemicals_and_drugs']\n",
    "        \n",
    "        return semtypes\n",
    "\n",
    "semtypes = ref_semtypes(filter_semtype, corpus)\n",
    "\n",
    "# STEP-9: Set data directory/table for source documents for vectorization\n",
    "src_table = 'sofa'\n",
    "\n",
    "# STEP-10: Specificy match type from {'exact', 'overlap'}\n",
    "run_type = 'exact'\n",
    "\n",
    "# STEP-11: Specify expression type for run (TODO: run all at once; make less kludgey)\n",
    "expression_type = 'nested' # type of merge expression: nested ((A&B)|C), paired ((A&B)|(C&D)), nested_with_singleton ((A&B)|((C&D)|E)) \n",
    "# -> NB: len(systems) for pair must be >= 4, and for nested_with_singleton == 5\n",
    "\n",
    "# STEP-12: Specify type of ensemble: merge or vote\n",
    "ensemble_type = 'merge'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "****** TODO \n",
    "-> add 'semtype' to output file name -> done\n",
    "-> filter for case when a system has no equivalent semtypes for a given reference -> done: still need to validate that all semtypes in corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config class for analysis\n",
    "class AnalysisConfig():\n",
    "    \"\"\"\n",
    "    Configuration object:\n",
    "    systems to use\n",
    "    notes by corpus\n",
    "    paths by output, gold and system location\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self = self    \n",
    "        self.systems = systems\n",
    "        self.data_dir = data_directory\n",
    "    \n",
    "    def corpus_config(self): \n",
    "        usys_data = system_annotation\n",
    "        ref_data = database_name+'.'+table_name\n",
    "        return usys_data, ref_data\n",
    "\n",
    "analysisConf =  AnalysisConfig()\n",
    "#usys, ref = analysisConf.corpus_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticTypes(object):\n",
    "    '''\n",
    "    Filter semantic types based on: https://metamap.nlm.nih.gov/SemanticTypesAndGroups.shtml\n",
    "    :params: semtypes list from corpus, system to query\n",
    "    :return: list of equivalent system semtypes \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, semtypes, corpus):\n",
    "        self = self\n",
    "        \n",
    "        sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name FROM concepts.semantic_groups sg join semantic_types st on sg.tui = st.tui where \" + corpus + \"_name in ({})\"\\\n",
    "           .format(', '.join(['%s' for _ in semtypes]))  \n",
    "        \n",
    "        stypes = pd.read_sql(sql, params=[semtypes], con=engine) \n",
    "       \n",
    "        if len(stypes['tui'].tolist()) > 0:\n",
    "            self.biomedicus_types = set(stypes['tui'].tolist())\n",
    "            self.qumls_types = set(stypes['tui'].tolist())\n",
    "        else:\n",
    "            self.biomedicus_types = None\n",
    "            self.qumls_types = None\n",
    "        \n",
    "        if stypes['clamp_name'].dropna(inplace=True) or len(stypes['clamp_name']) == 0:\n",
    "            self.clamp_types = None\n",
    "        else:\n",
    "            self.clamp_types = set(stypes['clamp_name'].tolist()[0].split(','))\n",
    "            \n",
    "        if len(stypes['ctakes_name'].tolist()) > 0:\n",
    "            self.ctakes_types = set(stypes['ctakes_name'].tolist()[0].split(','))\n",
    "        else:\n",
    "            self.ctakes_types = None\n",
    "            \n",
    "        if len(stypes['abbreviation'].tolist()) > 0:\n",
    "            self.metamap_types = set(stypes['abbreviation'].tolist())\n",
    "        else:\n",
    "            self.metamap_types = None\n",
    "            \n",
    "        self.reference_types =  set(semtypes)\n",
    "    \n",
    "    def get_system_type(self, system):  \n",
    "        \n",
    "        if system == 'biomedicus':\n",
    "            semtypes = self.biomedicus_types\n",
    "        elif system == 'ctakes':\n",
    "            semtypes = self.ctakes_types\n",
    "        elif system == 'clamp':\n",
    "            semtypes = self.clamp_types\n",
    "        elif system == 'metamap':\n",
    "            semtypes = self.metamap_types\n",
    "        elif system == 'quick_umls':\n",
    "            semtypes = self.qumls_types\n",
    "        elif system == 'reference':\n",
    "            semtypes = self.reference_types\n",
    "            \n",
    "        return semtypes\n",
    "    \n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('biomedicus'))\n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('quick_umls'))\n",
    "# print(SemanticTypes(['Anatomy'], corpus).get_system_type('clamp'))\n",
    "#print(SemanticTypes(['test,treatment'], 'i2b2').get_system_type('clamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semtypes = ['test,treatment']\n",
    "# semtypes = ['problem']\n",
    "# corpus = 'i2b2'\n",
    "# sys = 'clamp'\n",
    "\n",
    "# is semantic type in particular system\n",
    "def system_semtype_check(sys, semtype, corpus):\n",
    "    st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "    if st:\n",
    "        return sys\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# print(system_semtype_check(sys, semtypes, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for systems\n",
    "class AnnotationSystems():\n",
    "    \"\"\"   \n",
    "    System annotations of interest for UMLS concept extraction\n",
    "    NB: ctakes combines all \"mentions\" annotation types\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"   \n",
    "        \n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\"]\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\"]\n",
    "        self.ctakes_types = [\"ctakes_mentions\"]\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\"]\n",
    "        self.qumls_types = [\"concept_jaccard_score_False\"]\n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "        \n",
    "        elif system == \"quick_umls\":\n",
    "            types = self.qumls_types\n",
    "            \n",
    "        return types, view\n",
    "    \n",
    "annSys = AnnotationSystems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np # access to Numpy from Python layer\n",
    "import math\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"\n",
    "    metrics class:\n",
    "    returns an instance with confusion matrix metrics\n",
    "    \"\"\"\n",
    "    def __init__(self, system_only, gold_only, gold_system_match, system_n, neither = 0): # neither: no sys or manual annotation\n",
    "\n",
    "        self = self    \n",
    "        self.system_only = system_only\n",
    "        self.gold_only = gold_only\n",
    "        self.gold_system_match = gold_system_match\n",
    "        self.system_n = system_n\n",
    "        self.neither = neither\n",
    "        \n",
    "    def get_confusion_metrics(self, corpus = None, test = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        compute confusion matrix measures, as per  \n",
    "        https://stats.stackexchange.com/questions/51296/how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\n",
    "        \"\"\"\n",
    "        cdef:\n",
    "            int TP, FP, FN\n",
    "            double TM\n",
    "\n",
    "        TP = self.gold_system_match\n",
    "        FP = self.system_only\n",
    "        FN = self.gold_only\n",
    "        \n",
    "        TM = TP/math.sqrt(self.system_n) # TigMetric\n",
    "       \n",
    "        if not test:\n",
    "            \n",
    "            if corpus == 'casi':\n",
    "                recall = TP/(TP + FN)\n",
    "                precision = TP/(TP + FP)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "            else:\n",
    "                if self.neither == 0:\n",
    "                    confusion = [[0, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                else:\n",
    "                    confusion = [[self.neither, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                c = np.asarray(confusion)\n",
    "                recall = np.diag(c) / np.sum(c, axis = 1)\n",
    "                precision = np.diag(c) / np.sum(c, axis = 0)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            F = 2*(precision*recall)/(precision + recall)\n",
    "        \n",
    "        # Tignanelli Metric\n",
    "        if FN == 0:\n",
    "            TP_FN_R = TP\n",
    "        elif FN > 0:\n",
    "            TP_FN_R = TP/FN\n",
    " \n",
    "        return F, recall, precision, TP, FP, FN, TP_FN_R, TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_set(df, analysis_type = 'entity', df_type = 'sys', corpus = None):\n",
    "    \n",
    "    # get values for creation of series of type tuple\n",
    "    if 'entity' in analysis_type: \n",
    "        if corpus == 'casi':\n",
    "            arg = df.case, df.overlap\n",
    "        else:    \n",
    "            if df_type == 'sys':\n",
    "                arg = df.begin, df.end, df.note_id\n",
    "            else:\n",
    "                #arg = df.start, df.end, df.file\n",
    "                arg = df.begin, df.end, df.case\n",
    "            \n",
    "    elif 'cui' in analysis_type:\n",
    "        if df_type == 'sys':\n",
    "            arg = df.cui, df.note_id\n",
    "        else:\n",
    "            arg = df.value, df.file\n",
    "    elif 'full' in analysis_type:\n",
    "        if df_type == 'sys':\n",
    "            arg = df.begin, df.end, df.cui, df.note_id\n",
    "        else:\n",
    "            arg = df.start, df.end, df.value, df.file\n",
    "    \n",
    "    return set(list(zip(*arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "\n",
    "from __main__ import df_to_set, engine\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "def get_cooccurences(ref, sys, analysis_type: str, corpus: str):\n",
    "    \"\"\"\n",
    "    get cooccurences between system and reference; exact match; TODO: add relaxed -> done in single system evals during ensemble run\n",
    "    \"\"\"\n",
    "    # cooccurences\n",
    "    class Cooccurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = set()\n",
    "            self.false_negatives = set()\n",
    "            self.corpus = corpus\n",
    "\n",
    "    c = Cooccurences()\n",
    "    \n",
    "    if c.corpus != 'casi':\n",
    "        if 'entity' in analysis_type: \n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            #ref = ref[['start', 'end', 'file']].drop_duplicates()\n",
    "            ref = ref[['begin', 'end', 'case']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type: \n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            # do not overestimate FP\n",
    "            sys = sys[~sys['cui'].isnull()] \n",
    "            ref = ref[['value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "        elif 'full' in analysis_type: \n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            sys = sys[~sys['cui'].isnull()]\n",
    "            ref = ref[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "\n",
    "        # matches via inner join\n",
    "        tp = pd.merge(sys, ref, how = 'inner', left_on=['begin','end','note_id'], right_on = ['begin','end','case']) \n",
    "        \n",
    "        # reference-only via left outer join\n",
    "        fn = pd.merge(ref, sys, how = 'left', left_on=['begin','end','case'], right_on = ['begin','end','note_id'], indicator=True) \n",
    "        fn = fn[fn[\"_merge\"] != \"both\"]\n",
    "\n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'case']\n",
    "        else:\n",
    "            cols_to_keep = ['start', 'end', 'value', 'file']\n",
    "\n",
    "        tp = tp[cols_to_keep]\n",
    "        fn = fn[cols_to_keep]\n",
    "\n",
    "        # use for metrics \n",
    "        c.matches = c.matches.union(df_to_set(tp, analysis_type, 'ref'))\n",
    "        c.false_negatives = c.false_negatives.union(df_to_set(fn, analysis_type, 'ref'))\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches) # fp\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        c.ref_only = len(c.false_negatives)\n",
    "        \n",
    "    else:\n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where overlap = 1 and `system` = %(sys.name)s\"  \n",
    "        tp = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where (overlap = 0 or overlap is null) and `system` = %(sys.name)s\"  \n",
    "        fn = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        c.matches = df_to_set(tp, 'entity', 'sys', 'casi')\n",
    "        c.fn = df_to_set(fn, 'entity', 'sys', 'casi')\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(tp) + len(fn)\n",
    "        c.ref_n = len(tp) + len(fn)\n",
    "        c.ref_only = len(fn)\n",
    "        \n",
    "    # sanity check\n",
    "    if len(ref) - c.ref_system_match < 0:\n",
    "        print('Error: ref_system_match > len(ref)!')\n",
    "    if len(ref) != c.ref_system_match + c.ref_only:\n",
    "        print('Error: ref count mismatch!', len(ref), c.ref_system_match, c.ref_only)\n",
    "   \n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vector(doc: str, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.begin, a.end) for a in ann if a.label == lab]\n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v\n",
    "\n",
    "# test confusion matrix elements for vectorized annotation set; includes TN\n",
    "# https://kawahara.ca/how-to-compute-truefalse-positives-and-truefalse-negatives-in-python-for-binary-classification-problems/\n",
    "def confused(sys1, ann1):\n",
    "    TP = np.sum(np.logical_and(ann1 == 1, sys1 == 1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(ann1 == 0, sys1 == 0))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(ann1 == 0, sys1 == 1))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(ann1 == 1, sys1 == 0))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def vectorized_cooccurences(r: object, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> np.int64:\n",
    "    docs = get_docs(corpus)\n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    sys = get_sys_ann(r)\n",
    "    cvals = []\n",
    "    labels = [\"concept\"]\n",
    "\n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        s1 = list(sys.loc[sys[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        ann1 = label_vector(docs[n][1], a1, labels)\n",
    "        sys1 = label_vector(docs[n][1], s1, labels)\n",
    "\n",
    "        TP, TN, FP, FN = confused(sys1, ann1)\n",
    "        cvals.append([TP, TN, FP, FN])\n",
    "\n",
    "    return np.sum(cvals, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_dict(ref_only: int, system_only: int, ref_system_match: int, system_n: int, ref_n: int) -> dict:\n",
    "    \"\"\"\n",
    "    Generate dictionary of confusion matrix params and measures\n",
    "    :params: ref_only, system_only, reference_system_match -> sets\n",
    "    matches, system_n, reference_n -> counts\n",
    "    :return: dictionary object\n",
    "    \"\"\"\n",
    "\n",
    "    if ref_only + ref_system_match != ref_n:\n",
    "        print('ERROR!')\n",
    "\n",
    "    # get evaluation metrics\n",
    "    F, recall, precision, TP, FP, FN, TP_FN_R, TM  = Metrics(system_only, ref_only, ref_system_match, system_n).get_confusion_metrics()\n",
    "\n",
    "    d = {\n",
    "         'F': F[1], \n",
    "         'precision': precision[1], \n",
    "         'recall': recall[1], \n",
    "         'TP': TP, \n",
    "         'FN': FN, \n",
    "         'FP': FP, \n",
    "         'TP/FN': TP_FN_R,\n",
    "         'n_gold': ref_n, \n",
    "         'n_sys': system_n, \n",
    "         'TM': TM\n",
    "    }\n",
    "    \n",
    "    if system_n - FP != TP:\n",
    "        print('inconsistent system n!')\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metric_data(analysis_type: str, corpus: str):\n",
    "   \n",
    "    usys_file, ref_table = AnalysisConfig().corpus_config()\n",
    "    systems = AnalysisConfig().systems\n",
    "    \n",
    "    sys_ann = pd.read_csv(analysisConf.data_dir + usys_file, dtype={'note_id': str})\n",
    "    \n",
    "    sql = \"SELECT * FROM \" + ref_table  \n",
    "    \n",
    "    ref_ann = pd.read_sql(sql, con=engine)\n",
    "    sys_ann = sys_ann.drop_duplicates()\n",
    "    \n",
    "    return ref_ann, sys_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of rank averages\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(analysis_type: str, corpus: str, filter_semtype, single_sys = None):\n",
    "    start = time.time()\n",
    "\n",
    "    systems = AnalysisConfig().systems\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    ref_ann, sys_ann = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    for sys in systems:\n",
    "        \n",
    "        if filter_semtype:\n",
    "            st = SemanticTypes(semtypes, corpus).get_system_type(sys)\n",
    "            ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes, corpus).get_system_type('reference'))]\n",
    "            \n",
    "        types, _ = AnnotationSystems().get_system_type(sys) # system types for iterable\n",
    "        for t in types:\n",
    "            print(t)\n",
    "\n",
    "            if filter_semtype:\n",
    "                system_annotations = sys_ann[sys_ann['semtypes'].isin(st)].copy()\n",
    "            else:\n",
    "                system_annotations = sys_ann.copy()\n",
    "\n",
    "            system = system_annotations[system_annotations['type'] == str(t)]\n",
    "\n",
    "            if sys == 'quick_umls':\n",
    "                system = system[system.score.astype(float) >= .8]\n",
    "\n",
    "            if sys == 'metamap':\n",
    "                system = system[system.score.abs().astype(int) >= 800]\n",
    "\n",
    "            system = system.drop_duplicates()\n",
    "            system.name = sys\n",
    "\n",
    "            c = get_cooccurences(ref_ann, system, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            if corpus == 'casi':\n",
    "                if sys == 'biomedicus':\n",
    "                    t = 'biomedicus.v2.Acronym'\n",
    "            \n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "            d['system'] = sys\n",
    "            d['type'] = t\n",
    "                \n",
    "            data = pd.DataFrame(d,  index=[0])\n",
    "            metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "            metrics.drop_duplicates(keep='last', inplace=True)\n",
    "        else:\n",
    "            print(\"NO EXACT MATCHES FOR\", t)\n",
    "        elapsed = (time.time() - start)\n",
    "        print(\"elapsed:\", sys, elapsed)\n",
    "     \n",
    "    elapsed = (time.time() - start)\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    if single_sys is None:\n",
    "        file_name = 'metrics_'\n",
    "    \n",
    "    metrics.to_csv(analysisConf.data_dir + corpus + '_' + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "    \n",
    "    print(\"total elapsed time:\", elapsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_n(analysis_type: str, corpus: str, filter_semtype) -> int:\n",
    "    \n",
    "    ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes, corpus).get_system_type('reference'))]\n",
    "            \n",
    "    if corpus == 'casi':\n",
    "        return len(ref_ann)\n",
    "        \n",
    "    else:\n",
    "        # do not overestimate fn\n",
    "        if 'entity' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'file']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type:\n",
    "            ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        elif 'full' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "        return ref_n\n",
    "    \n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_data(system: str, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> pd.DataFrame:\n",
    "   \n",
    "    _, data = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    out = data[data['system'] == system].copy()\n",
    "    \n",
    "    if filter_semtype:\n",
    "        st = SemanticTypes([semtype], corpus).get_system_type(system)\n",
    "    \n",
    "    if corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap'] \n",
    "        out = out[cols_to_keep].drop_duplicates()\n",
    "        return out\n",
    "        \n",
    "    else:\n",
    "        if filter_semtype:\n",
    "            out = out[out['semtypes'].isin(st)].copy()\n",
    "            \n",
    "        else:\n",
    "            out = out[out['system']== system].copy()\n",
    "        \n",
    "        if system == 'quick_umls':\n",
    "            out = out[(out.score.astype(float) >= 0.8) & (out[\"type\"] == 'concept_jaccard_score_False')]\n",
    "            # fix for leading spacxe on semantic type field\n",
    "            out = out.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) \n",
    "        \n",
    "        if system == 'metamap':\n",
    "            out = out[out.score.abs().astype(int) >= 800]\n",
    "            \n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "        elif 'cui' in analysis_type:\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "        elif 'full' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "        #out = out[cols_to_keep]\n",
    "\n",
    "        return out.drop_duplicates()\n",
    "\n",
    "# read in system/reference matches from file\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_system_matches(system: str, analysis_type: str, corpus: str):\n",
    "   \n",
    "    if corpus == 'casi':\n",
    "        \n",
    "        sql = \"select `case`, overlap from test.amia_2019_cases where overlap = 1 and `system` = %(system)s\"  \n",
    "        data_matches = df_to_set(pd.read_sql(sql, params={\"system\":system}, con=engine), 'entity', 'sys', 'casi')\n",
    "        \n",
    "        sql = \"select `case`, overlap from test.amia_2019_cases where (overlap = 0 or overlap is null) and `system` = %(system)s\"  \n",
    "        data_fn = df_to_set(pd.read_sql(sql, params={\"system\":system}, con=engine), 'entity', 'sys', 'casi')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        dir_test = analysisConf.data_dir + 'single_system_out/'\n",
    "\n",
    "        file = dir_test + system + '_' + analysis_type + '_' + corpus + '_matches.txt'\n",
    "        data_matches = set(literal_eval(line.strip()) for line in open(file))\n",
    "\n",
    "        file = dir_test + system + '_' + analysis_type + '_' + corpus + '_ref_only.txt'\n",
    "        data_fn = set(literal_eval(line.strip()) for line in open(file)) \n",
    "\n",
    "    return data_matches, data_fn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GENERATE merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTotals(object):\n",
    "    \"\"\" \n",
    "    returns an instance with merged match set numbers using either union or intersection of elements in set \n",
    "    \"\"\"\n",
    "    def __init__(self, ref_n, sys_n, match_set):\n",
    "\n",
    "        self = self    \n",
    "        self.ref_ann = ref_n\n",
    "        self.sys_n = sys_n\n",
    "        self.match_set = match_set\n",
    "\n",
    "    def get_ref_sys(self):\n",
    "\n",
    "        ref_only = self.ref_ann - len(self.match_set)\n",
    "        sys_only = self.sys_n - len(self.match_set)\n",
    "\n",
    "        return ref_only, sys_only, len(self.match_set), self.match_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Recursively evaluate parse tree, \n",
    "    with check for existence before build\n",
    "       :param sentence: to process\n",
    "       :return class of merged annotations, boolean operated system df \n",
    "    \"\"\"\n",
    "    \n",
    "    class Results(object):\n",
    "        def __init__(self):\n",
    "            self.results = set()\n",
    "            self.system_merges = pd.DataFrame()\n",
    "            \n",
    "    r = Results()\n",
    "    \n",
    "    if 'entity' in analysis_type and corpus != 'casi': \n",
    "        cols_to_keep = ['begin', 'end', 'note_id'] # entity only\n",
    "    elif 'full' in analysis_type: \n",
    "        cols_to_keep = ['cui', 'begin', 'end', 'note_id'] # entity only\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['cui', 'note_id'] # entity only\n",
    "    elif corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap']\n",
    "    \n",
    "    def evaluate(parseTree):\n",
    "        oper = {'&': op.and_, '|': op.or_}\n",
    "        \n",
    "        if parseTree:\n",
    "            leftC = gevent.spawn(evaluate, parseTree.getLeftChild())\n",
    "            rightC = gevent.spawn(evaluate, parseTree.getRightChild())\n",
    "            \n",
    "            if leftC.get() is not None and rightC.get() is not None:\n",
    "                system_query = pd.DataFrame()\n",
    "                fn = oper[parseTree.getRootVal()]\n",
    "                \n",
    "                if isinstance(leftC.get(), str):\n",
    "                    # get system as leaf node \n",
    "                    if filter_semtype:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype)\n",
    "                \n",
    "                elif isinstance(leftC.get(), pd.DataFrame):\n",
    "                    l_sys = leftC.get()\n",
    "                \n",
    "                if isinstance(rightC.get(), str):\n",
    "                    # get system as leaf node\n",
    "                    if filter_semtype:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype)\n",
    "                    \n",
    "                elif isinstance(rightC.get(), pd.DataFrame):\n",
    "                    r_sys = rightC.get()\n",
    "                    \n",
    "                if fn == op.or_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        frames = [left_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [left_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        frames = [l_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [l_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                if fn == op.and_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        df = left_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        df = left_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        df = l_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        df = l_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                \n",
    "                # get combined system results\n",
    "                r.system_merges = df\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    system_query = system_query.append(df)\n",
    "                else:\n",
    "                    print('wtf!')\n",
    "                    \n",
    "                return system_query\n",
    "            else:\n",
    "                return parseTree.getRootVal()\n",
    "    \n",
    "    if sentence.n_or > 0 or sentence.n_and > 0:\n",
    "        evaluate(pt)  \n",
    "    \n",
    "    # trivial case\n",
    "    elif sentence.n_or == 0 and sentence.n_and == 0:\n",
    "        r.results, _ = get_system_matches(sentence.sentence, analysis_type, corpus)\n",
    "        if filter_semtype:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        #print('trivial:', sentence.sentence, len(r.results), len(r.system_merges))\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Incoming Boolean sentences are parsed into a binary tree.\n",
    "\n",
    "Test expressions to parse:\n",
    "\n",
    "sentence = '((((A&B)|C)|D)&E)'\n",
    "\n",
    "sentence = '(E&(D|(C|(A&B))))'\n",
    "\n",
    "sentence = '(((A|(B&C))|(D&(E&F)))|(H&I))'\n",
    "\n",
    "\"\"\"\n",
    "# build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "def buildParseTree(fpexp):\n",
    "    \"\"\"\n",
    "       Iteratively build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "       :param fpexp: sentence to parse\n",
    "       :return eTree: parse tree representation\n",
    "       Incoming Boolean sentences are parsed into a binary tree.\n",
    "       Test expressions to parse:\n",
    "       sentence = '(A&B)'\n",
    "       sentence = '(A|B)'\n",
    "       sentence = '((A|B)&C)'\n",
    "       \n",
    "    \"\"\"\n",
    "    fplist = fpexp.split()\n",
    "    pStack = Stack()\n",
    "    eTree = BinaryTree('')\n",
    "    pStack.push(eTree)\n",
    "    currentTree = eTree\n",
    "\n",
    "    for i in fplist:\n",
    "\n",
    "        if i == '(':\n",
    "            currentTree.insertLeft('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getLeftChild()\n",
    "        elif i not in ['&', '|', ')']:\n",
    "            currentTree.setRootVal(i)\n",
    "            parent = pStack.pop()\n",
    "            currentTree = parent\n",
    "        elif i in ['&', '|']:\n",
    "            currentTree.setRootVal(i)\n",
    "            currentTree.insertRight('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getRightChild()\n",
    "        elif i == ')':\n",
    "            currentTree = pStack.pop()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return eTree\n",
    "\n",
    "def make_parse_tree(payload):\n",
    "    \"\"\"\n",
    "    Ensure data to create tree are in correct form\n",
    "    :param sentence: sentence to preprocess\n",
    "    :return pt, parse tree graph\n",
    "            sentence, processed sentence to build tree\n",
    "            a: order\n",
    "    \"\"\"\n",
    "    def preprocess_sentence(sentence):\n",
    "        # prepare statement for case when a boolean AND/OR is given\n",
    "        sentence = payload.replace('(', ' ( '). \\\n",
    "            replace(')', ' ) '). \\\n",
    "            replace('&', ' & '). \\\n",
    "            replace('|', ' | '). \\\n",
    "            replace('  ', ' ')\n",
    "        return sentence\n",
    "\n",
    "    sentence = preprocess_sentence(payload)\n",
    "    print(sentence)\n",
    "    \n",
    "    pt = buildParseTree(sentence)\n",
    "    #pt.postorder() \n",
    "    \n",
    "    return pt\n",
    "\n",
    "class Sentence(object):\n",
    "    '''\n",
    "    Details about boolean expression -> number operators and expression\n",
    "    '''\n",
    "    def __init__(self, sentence):\n",
    "        self = self\n",
    "        self.n_and = sentence.count('&')\n",
    "        self.n_or = sentence.count('|')\n",
    "        self.sentence = sentence\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_docs(corpus):\n",
    "    sql = 'select distinct note_id, sofa from sofas where corpus = %(corpus)s order by note_id'\n",
    "    df = pd.read_sql(sql, params={\"corpus\":corpus}, con=engine)\n",
    "    df.drop_duplicates()\n",
    "    df['len_doc'] = df['sofa'].apply(len)\n",
    "    \n",
    "    subset = df[['note_id', 'len_doc']]\n",
    "    docs = [tuple(x) for x in subset.to_numpy()]\n",
    "    \n",
    "    return docs\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_ann(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    if filter_semtype:\n",
    "        if ',' in semtype:\n",
    "            semtype = semtype.split(',')\n",
    "        else:\n",
    "            semtype = [semtype]\n",
    "        \n",
    "    ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    ann = ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = ann[ann['semtype'].isin(semtype)]\n",
    "        \n",
    "    ann[\"label\"] = 'concept'\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ann = ann[cols_to_keep]\n",
    "    \n",
    "    return ann\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_ann(r):\n",
    "    sys = r.system_merges    \n",
    "    sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "    sys[\"label\"] = 'concept'\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys = sys[cols_to_keep]\n",
    "\n",
    "    return sys\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metrics(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    else:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    # vectorize merges using i-o labeling\n",
    "    if run_type == 'overlap':\n",
    "        if filter_semtype:\n",
    "            TP, TN, FP, FN = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            TP, TN, FP, FN = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        \n",
    "        d['TN'] = TN\n",
    "        \n",
    "        # return full metrics\n",
    "        return d\n",
    "\n",
    "    elif run_type == 'exact':\n",
    "        # total by number spans\n",
    "        #system_n = len(r.system_merges)\n",
    "        \n",
    "        #reference_n = get_ref_n(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        # -> remove use of txt files here and handle case for semantic type\n",
    "        \n",
    "        if filter_semtype:\n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else: \n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "            \n",
    "        # -> \n",
    "\n",
    "        #reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, r.results).get_ref_sys()\n",
    "        # get overall TP/TF and various other counts for running confusion matrix metric analysis\n",
    "        return d #cm_dict(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all combinations of given list of annotators:\n",
    "def partly_unordered_permutations(lst, k):\n",
    "    elems = set(lst)\n",
    "    for c in combinations(lst, k):\n",
    "        for d in permutations(elems - set(c)):\n",
    "            yield c + d\n",
    "            \n",
    "def expressions(l, n):\n",
    "    for (operations, *operands), operators in product(\n",
    "            combinations(l, n), product(('&', '|'), repeat=n - 1)):\n",
    "        for operation in zip(operators, operands):\n",
    "            operations = [operations, *operation]\n",
    "        yield operations\n",
    "\n",
    "# get list of systems with a semantic type in grouping\n",
    "def get_valid_systems(systems, semtype):\n",
    "    test = []\n",
    "    for sys in systems:\n",
    "        st = system_semtype_check(sys, semtype, corpus)\n",
    "        if st:\n",
    "            test.append(sys)\n",
    "\n",
    "    return test\n",
    "\n",
    "# permute system combinations and evaluate system merges for performance\n",
    "def run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type, semtype = None):\n",
    "    metrics = pd.DataFrame()\n",
    "    \n",
    "    if expression_type == 'nested':\n",
    "        for l in partly_unordered_permutations(systems, 2):\n",
    "            print('processing merge combo:', l)\n",
    "            for i in range(1, len(l)+1):\n",
    "                test = list(expressions(l, i))\n",
    "                for t in test:\n",
    "                    if i > 1:\n",
    "                        # format Boolean sentence for parse tree \n",
    "                        t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                    if filter_semtype:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype)\n",
    "\n",
    "                    d['merge'] = t\n",
    "                    d['n_terms'] = i\n",
    "\n",
    "                    frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "                    metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                    \n",
    "    elif expression_type == 'nested_with_singleton' and len(systems) == 5:\n",
    "        # form (((a&b)|c)&(d|e))\n",
    "        \n",
    "        nested = list(expressions(systems, 3))\n",
    "        test = list(expressions(systems, 2))\n",
    "        to_do_terms = []\n",
    "    \n",
    "        for n in nested:\n",
    "            # format Boolean sentence for parse tree \n",
    "            n = '(' + \" \".join(str(x) for x in n).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "            for t in test:\n",
    "                t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                new_and = '(' + n +'&'+ t + ')'\n",
    "                new_or = '(' + n +'|'+ t + ')'\n",
    "\n",
    "                if new_and.count('biomedicus') != 2 and new_and.count('clamp') != 2 and new_and.count('ctakes') != 2 and new_and.count('metamap') != 2 and new_and.count('quick_umls') != 2:\n",
    "\n",
    "                    if new_and.count('&') != 4 and new_or.count('|') != 4:\n",
    "                        #print(new_and)\n",
    "                        #print(new_or)\n",
    "                        to_do_terms.append(new_or)\n",
    "                        to_do_terms.append(new_and)\n",
    "        \n",
    "        print('nested_with_singleton', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                        \n",
    "    elif expression_type == 'paired':\n",
    "        m = list(expressions(systems, 2))\n",
    "        test = list(expressions(m, 2))\n",
    "\n",
    "        to_do_terms = []\n",
    "        for t in test:\n",
    "            # format Boolean sentence for parse tree \n",
    "            t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "            if t.count('biomedicus') != 2 and t.count('clamp') != 2 and t.count('ctakes') != 2 and t.count('metamap') != 2 and t.count('quick_umls') != 2:\n",
    "                if t.count('&') != 3 and t.count('|') != 3:\n",
    "                    to_do_terms.append(t)\n",
    "                    if len(systems) == 5:\n",
    "                        for i in systems:\n",
    "                            if i not in t:\n",
    "                                #print('('+t+'&'+i+')')\n",
    "                                #print('('+t+'|'+i+')')\n",
    "                                new_and = '('+t+'&'+i+')'\n",
    "                                new_or = '('+t+'|'+i+')'\n",
    "                                to_do_terms.append(new_and)\n",
    "                                to_do_terms.append(new_or)\n",
    "                            \n",
    "        print('paired', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "        \n",
    "    return metrics\n",
    "\n",
    "# write to file\n",
    "def generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype = None):\n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    file_name = corpus + '_all_'\n",
    "   \n",
    "    # drop exact matches:\n",
    "    metrics = metrics.drop_duplicates()\n",
    "    \n",
    "    if ensemble_type == 'merge':\n",
    "        metrics = metrics.sort_values(by=['n_terms', 'merge'])\n",
    "        file_name += 'merge_'\n",
    "    elif ensemble_type == 'vote':\n",
    "        file_name += 'vote_'\n",
    "    \n",
    "    #metrics = metrics.drop_duplicates(subset=['TP', 'FN', 'FP', 'n_sys', 'precision', 'recall', 'F', 'TM', 'TP/FN', 'TM', 'n_terms'])\n",
    "\n",
    "    file = file_name + analysis_type + '_' + run_type +'_'\n",
    "    \n",
    "    if filter_semtype:\n",
    "        file += semtype\n",
    "        \n",
    "    \n",
    "    geometric_mean(metrics).to_csv(analysisConf.data_dir + file + str(timestamp) + '.csv')\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "# control ensemble run\n",
    "def ensemble_control(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            metrics = run_ensemble(test, analysis_type, corpus, filter_semtype, expression_type, semtype)\n",
    "            if (expression_type == 'nested_with_singleton' and len(test) == 5) or expression_type in ['nested', 'paired']:\n",
    "                generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "    else:\n",
    "        metrics = run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad hoc query\n",
    "def get_merge_data(boolean_expression: str, analysis_type: str, corpus: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "\n",
    "    r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    \n",
    "    system_n = len(r.system_merges)\n",
    "    reference_n = get_ref_n(analysis_type, corpus, filter_semtype)\n",
    "\n",
    "    reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, r.results).get_ref_sys()\n",
    "\n",
    "    print('cm', cm_dict(reference_only, system_only, reference_system_match, system_n, reference_n))\n",
    "    # get matched data from merge\n",
    "    return r.system_merges # merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority vote for overlap\n",
    "def vectorized_annotations(ann):\n",
    "    \n",
    "    docs = get_docs(corpus)\n",
    "    labels = [\"concept\"]\n",
    "    out= []\n",
    "    \n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        a = label_vector(docs[n][1], a1, labels)\n",
    "        out.append(a)\n",
    "\n",
    "    return out\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def majority_ensemble(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    d = {}\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys_test = []\n",
    "    \n",
    "    for system in systems:\n",
    "        sys_ann = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        df = sys_ann.copy()\n",
    "        df['label'] = 'concept'\n",
    "        df = df.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "        sys = df[df['system']==system][cols_to_keep].copy()\n",
    "        test = vectorized_annotations(sys)\n",
    "        d[system] = flatten_list(test) \n",
    "        sys_test.append(d[system])\n",
    "\n",
    "    output = sum(np.array(sys_test))\n",
    "    \n",
    "    n = int(len(systems) / 2)\n",
    "    #print(n)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        vote = np.where(output > n, 1, 0)\n",
    "    else:\n",
    "        vote = np.where(output > n, 1, \n",
    "         (np.where(output == n, random.choice(0, 1), 0)))\n",
    "        \n",
    "    return vote\n",
    "\n",
    "def reference(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    #ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "\n",
    "    df = ref_ann.copy()\n",
    "    df = df.drop_duplicates(subset=['begin','end','case'])\n",
    "    df['label'] = 'concept'\n",
    "    #cases = set(df['case'].to_list())\n",
    "    #df = df1.rename(index=str, columns={\"file\": \"case\", \"start\": \"begin\"})\n",
    "\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ref = df[cols_to_keep].copy()\n",
    "    test = vectorized_annotations(ref)\n",
    "    ref =  np.asarray(flatten_list(test), dtype=np.int32) \n",
    "\n",
    "    return ref\n",
    "\n",
    "def majority_vote_out(ref, vote, corpus):    \n",
    "    TP, TN, FP, FN = confused(ref, vote)\n",
    "    print(TP, TN, FP, FN)\n",
    "    system_n = TP + FP\n",
    "    reference_n = TP + FN\n",
    "\n",
    "    d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "\n",
    "    d['TN'] = TN\n",
    "    d['corpus'] = corpus\n",
    "    print(d)\n",
    "    \n",
    "    metrics = pd.DataFrame(d, index=[0])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# control ensemble run\n",
    "def majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            ref = reference(analysis_type, corpus, filter_semtype, semtype)\n",
    "            vote = majority_ensemble(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "            metrics = majority_vote_out(ref, vote, corpus)\n",
    "            metrics['systems'] = ','.join(test)\n",
    "            generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "            print(metrics)\n",
    "    else:\n",
    "        # ref = reference()\n",
    "        ref = reference(analysis_type, corpus, filter_semtype)\n",
    "        vote = majority_ensemble(systems, analysis_type, corpus, filter_semtype)\n",
    "        metrics = majority_vote_out(ref, vote, corpus)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)\n",
    "        metrics['systems'] = ','.join(test)\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clamp', 'quick_umls', 'biomedicus'] ('analytical_mipacq.csv', 'concepts.mipacq_all')\n",
      "run_type: exact\n",
      "None ['clamp', 'quick_umls', 'biomedicus']\n",
      "processing merge combo: ('clamp', 'quick_umls', 'biomedicus')\n",
      "clamp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick_umls\n",
      "biomedicus\n",
      " ( clamp & quick_umls ) \n",
      " ( clamp | quick_umls ) \n",
      " ( clamp & biomedicus ) \n",
      " ( clamp | biomedicus ) \n",
      " ( quick_umls & biomedicus ) \n",
      " ( quick_umls | biomedicus ) \n",
      " ( ( clamp & quick_umls ) & biomedicus ) \n",
      " ( ( clamp & quick_umls ) | biomedicus ) \n",
      " ( ( clamp | quick_umls ) & biomedicus ) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ( ( clamp | quick_umls ) | biomedicus ) \n",
      "processing merge combo: ('clamp', 'biomedicus', 'quick_umls')\n",
      " ( biomedicus & quick_umls ) \n",
      " ( biomedicus | quick_umls ) \n",
      " ( ( clamp & biomedicus ) & quick_umls ) \n",
      " ( ( clamp & biomedicus ) | quick_umls ) \n",
      " ( ( clamp | biomedicus ) & quick_umls ) \n",
      " ( ( clamp | biomedicus ) | quick_umls ) \n",
      "processing merge combo: ('quick_umls', 'biomedicus', 'clamp')\n",
      " ( quick_umls & clamp ) \n",
      " ( quick_umls | clamp ) \n",
      " ( biomedicus & clamp ) \n",
      " ( biomedicus | clamp ) \n",
      " ( ( quick_umls & biomedicus ) & clamp ) \n",
      " ( ( quick_umls & biomedicus ) | clamp ) \n",
      " ( ( quick_umls | biomedicus ) & clamp ) \n",
      " ( ( quick_umls | biomedicus ) | clamp ) \n",
      "           F  precision    recall     TP     FN     FP     TP/FN  n_gold  \\\n",
      "2   0.595794   0.493869  0.750729  12607   4186  12920  3.011706   16793   \n",
      "0   0.396942   0.394988  0.398916   6699  10094  10261  0.663662   16793   \n",
      "1   0.547866   0.423347  0.776157  13034   3759  17754  3.467412   16793   \n",
      "33  0.454404   0.723806  0.331150   5561  11232   2122  0.495103   16793   \n",
      "20  0.611953   0.545065  0.697553  11714   5079   9777  2.306360   16793   \n",
      "34  0.532783   0.394926  0.818496  13745   3048  21059  4.509514   16793   \n",
      "21  0.539628   0.399925  0.829334  13927   2866  20897  4.859386   16793   \n",
      "5   0.454404   0.723806  0.331150   5561  11232   2122  0.495103   16793   \n",
      "3   0.459959   0.704199  0.341511   5735  11058   2409  0.518629   16793   \n",
      "6   0.532783   0.394926  0.818496  13745   3048  21059  4.509514   16793   \n",
      "4   0.496409   0.353449  0.833562  13998   2795  25606  5.008229   16793   \n",
      "7   0.611953   0.545065  0.697553  11714   5079   9777  2.306360   16793   \n",
      "31  0.459959   0.704199  0.341511   5735  11058   2409  0.518629   16793   \n",
      "8   0.539628   0.399925  0.829334  13927   2866  20897  4.859386   16793   \n",
      "32  0.496409   0.353449  0.833562  13998   2795  25606  5.008229   16793   \n",
      "22  0.440412   0.743176  0.312928   5255  11538   1816  0.455452   16793   \n",
      "23  0.553607   0.424841  0.794379  13340   3453  18060  3.863307   16793   \n",
      "9   0.440412   0.743176  0.312928   5255  11538   1816  0.455452   16793   \n",
      "10  0.603185   0.491992  0.779313  13087   3706  13513  3.531301   16793   \n",
      "24  0.619661   0.540418  0.726136  12194   4599  10370  2.651446   16793   \n",
      "25  0.487621   0.338965  0.868517  14585   2208  28443  6.605525   16793   \n",
      "11  0.618058   0.543818  0.715774  12020   4773  10083  2.518332   16793   \n",
      "12  0.487621   0.338965  0.868517  14585   2208  28443  6.605525   16793   \n",
      "35  0.440412   0.743176  0.312928   5255  11538   1816  0.455452   16793   \n",
      "36  0.546281   0.419312  0.783541  13158   3635  18222  3.619807   16793   \n",
      "37  0.472895   0.689927  0.359733   6041  10752   2715  0.561849   16793   \n",
      "38  0.487621   0.338965  0.868517  14585   2208  28443  6.605525   16793   \n",
      "\n",
      "    n_sys         TM                            merge  n_terms  F1 rank  \\\n",
      "2   25527  78.906333                       biomedicus        1      6.0   \n",
      "0   16960  51.439537                            clamp        1     27.0   \n",
      "1   30788  74.282580                       quick_umls        1      8.0   \n",
      "33   7683  63.443550               (biomedicus&clamp)        2     22.5   \n",
      "20  21491  79.905543          (biomedicus&quick_umls)        2      3.5   \n",
      "34  34804  73.676700               (biomedicus|clamp)        2     12.5   \n",
      "21  34824  74.630826          (biomedicus|quick_umls)        2     10.5   \n",
      "5    7683  63.443550               (clamp&biomedicus)        2     22.5   \n",
      "3    8144  63.549851               (clamp&quick_umls)        2     20.5   \n",
      "6   34804  73.676700               (clamp|biomedicus)        2     12.5   \n",
      "4   39604  70.339044               (clamp|quick_umls)        2     14.5   \n",
      "7   21491  79.905543          (quick_umls&biomedicus)        2      3.5   \n",
      "31   8144  63.549851               (quick_umls&clamp)        2     20.5   \n",
      "8   34824  74.630826          (quick_umls|biomedicus)        2     10.5   \n",
      "32  39604  70.339044               (quick_umls|clamp)        2     14.5   \n",
      "22   7071  62.493134  ((clamp&biomedicus)&quick_umls)        3     25.0   \n",
      "23  31400  75.281975  ((clamp&biomedicus)|quick_umls)        3      7.0   \n",
      "9    7071  62.493134  ((clamp&quick_umls)&biomedicus)        3     25.0   \n",
      "10  26600  80.241545  ((clamp&quick_umls)|biomedicus)        3      5.0   \n",
      "24  22564  81.177962  ((clamp|biomedicus)&quick_umls)        3      1.0   \n",
      "25  43028  70.312227  ((clamp|biomedicus)|quick_umls)        3     17.0   \n",
      "11  22103  80.849782  ((clamp|quick_umls)&biomedicus)        3      2.0   \n",
      "12  43028  70.312227  ((clamp|quick_umls)|biomedicus)        3     17.0   \n",
      "35   7071  62.493134  ((quick_umls&biomedicus)&clamp)        3     25.0   \n",
      "36  31380  74.278549  ((quick_umls&biomedicus)|clamp)        3      9.0   \n",
      "37   8756  64.558876  ((quick_umls|biomedicus)&clamp)        3     19.0   \n",
      "38  43028  70.312227  ((quick_umls|biomedicus)|clamp)        3     17.0   \n",
      "\n",
      "    TP/FN rank  TM rank      Gmean  \n",
      "2         14.0      6.0   8.743725  \n",
      "0         19.0     27.0  23.096014  \n",
      "1         13.0     10.0  10.961594  \n",
      "33        23.5     22.5  22.939080  \n",
      "20        17.5      4.5   8.002580  \n",
      "34         8.5     12.5  10.530998  \n",
      "21         6.5      8.5   7.723878  \n",
      "5         23.5     22.5  22.939080  \n",
      "3         21.5     20.5  20.938570  \n",
      "6          8.5     12.5  10.530998  \n",
      "4          4.5     14.5   8.620275  \n",
      "7         17.5      4.5   8.002580  \n",
      "31        21.5     20.5  20.938570  \n",
      "8          6.5      8.5   7.723878  \n",
      "32         4.5     14.5   8.620275  \n",
      "22        26.0     25.0  25.439606  \n",
      "23        10.0      7.0   8.202446  \n",
      "9         26.0     25.0  25.439606  \n",
      "10        12.0      3.0   5.879675  \n",
      "24        15.0      1.0   3.332017  \n",
      "25         2.0     17.0   6.567103  \n",
      "11        16.0      2.0   5.039684  \n",
      "12         2.0     17.0   6.567103  \n",
      "35        26.0     25.0  25.439606  \n",
      "36        11.0     11.0  10.757450  \n",
      "37        20.0     19.0  19.438118  \n",
      "38         2.0     17.0   6.567103  \n",
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         4184471 function calls (4015445 primitive calls) in 5.443 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "     1315    0.420    0.000    0.420    0.000 {built-in method numpy.concatenate}\n",
       "      418    0.308    0.001    0.586    0.001 blocks.py:3131(_merge_blocks)\n",
       "    50379    0.259    0.000    0.259    0.000 {built-in method builtins.compile}\n",
       "        1    0.255    0.255    0.257    0.257 {method 'read' of 'pandas._libs.parsers.TextReader' objects}\n",
       "     1016    0.221    0.000    0.221    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "       54    0.194    0.004    0.209    0.004 <ipython-input-738-cbcab9c60c9a>:1(df_to_set)\n",
       "      432    0.194    0.000    0.195    0.000 {method 'factorize' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "       81    0.167    0.002    0.167    0.002 {method 'recv_into' of '_socket.socket' objects}\n",
       "      144    0.146    0.001    0.147    0.001 {method 'factorize' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "      112    0.144    0.001    0.144    0.001 {method 'factorize' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
       "999166/999164    0.127    0.000    0.182    0.000 {built-in method builtins.isinstance}\n",
       "201516/50379    0.125    0.000    0.177    0.000 ast.py:64(_convert)\n",
       "      199    0.107    0.001    0.108    0.001 {method 'factorize' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "     2089    0.097    0.000    0.108    0.000 {pandas._libs.lib.infer_dtype}\n",
       "     6316    0.092    0.000    0.092    0.000 {built-in method numpy.empty}\n",
       "      498    0.088    0.000    0.088    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
       "    34947    0.062    0.000    0.062    0.000 {method 'settimeout' of '_socket.socket' objects}\n",
       "       95    0.056    0.001    0.056    0.001 {pandas._libs.hashtable.duplicated_int64}\n",
       "   216/24    0.055    0.000    1.749    0.073 <ipython-input-1040-49f2f221cb4b>:26(evaluate)\n",
       "    17457    0.054    0.000    0.169    0.000 connections.py:1195(_read_row_from_packet)\n",
       "      176    0.053    0.000    0.053    0.000 {pandas._libs.algos.take_2d_axis1_object_object}\n",
       "    50379    0.050    0.000    0.503    0.000 ast.py:38(literal_eval)\n",
       "       27    0.049    0.002    1.574    0.058 {_cython_magic_af801d0a94e7688199f12837375f785e.get_cooccurences}\n",
       "     4116    0.048    0.000    0.053    0.000 generic.py:5069(__setattr__)\n",
       "       45    0.041    0.001    0.054    0.001 {pandas._libs.join.inner_join}\n",
       "        7    0.040    0.006    0.040    0.006 {pandas._libs.ops.scalar_compare}\n",
       "    17470    0.039    0.000    0.339    0.000 connections.py:648(_read_packet)\n",
       "   140780    0.038    0.000    0.052    0.000 generic.py:7(_check)\n",
       "    34940    0.037    0.000    0.282    0.000 connections.py:687(_read_bytes)\n",
       "   201277    0.033    0.000    0.043    0.000 strings.py:1519(<lambda>)\n",
       "      361    0.030    0.000    0.030    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
       "       27    0.029    0.001    0.036    0.001 {pandas._libs.join.left_outer_join}\n",
       "    69852    0.029    0.000    0.033    0.000 protocol.py:63(read)\n",
       "        1    0.028    0.028    5.411    5.411 <ipython-input-1042-648145736ddf>:26(run_ensemble)\n",
       "    32343    0.028    0.000    0.360    0.000 <ipython-input-1038-eb2ea29a5c5f>:85(<genexpr>)\n",
       "13959/13584    0.027    0.000    0.033    0.000 {built-in method numpy.array}\n",
       "    69852    0.026    0.000    0.095    0.000 protocol.py:168(read_length_coded_string)\n",
       "      125    0.026    0.000    0.031    0.000 managers.py:1841(_stack_arrays)\n",
       "     6005    0.025    0.000    0.025    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "   217973    0.025    0.000    0.027    0.000 {built-in method builtins.getattr}\n",
       "       96    0.025    0.000    0.055    0.001 sorting.py:20(get_group_index)\n",
       "     2467    0.024    0.000    0.418    0.000 algorithms.py:1544(take_nd)\n",
       "      322    0.023    0.000    0.023    0.000 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
       "    35496    0.023    0.000    0.098    0.000 base.py:75(is_dtype)\n",
       "    21303    0.023    0.000    0.050    0.000 dtypes.py:68(find)\n",
       "187484/172953    0.023    0.000    0.030    0.000 {built-in method builtins.len}\n",
       "      394    0.023    0.000    0.023    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
       "       72    0.023    0.000    0.027    0.000 merge.py:1701(_get_join_keys)\n",
       "1732/1351    0.022    0.000    0.144    0.000 base.py:253(__new__)\n",
       "       72    0.022    0.000    0.506    0.007 merge.py:730(_get_join_indexers)\n",
       "       27    0.022    0.001    0.022    0.001 {method 'lookup' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
       "    25497    0.022    0.000    0.046    0.000 common.py:1845(_is_dtype_type)\n",
       "    41813    0.021    0.000    0.022    0.000 {built-in method builtins.hasattr}\n",
       "        1    0.021    0.021    0.373    0.373 connections.py:1182(_read_rowdata_packet)\n",
       "      165    0.020    0.000    0.647    0.004 managers.py:2029(concatenate_block_managers)\n",
       "    12628    0.019    0.000    0.049    0.000 _dtype.py:319(_name_get)\n",
       "    69863    0.019    0.000    0.035    0.000 protocol.py:150(read_length_encoded_integer)\n",
       "        6    0.019    0.003    0.051    0.008 {pandas._libs.lib.map_infer_mask}\n",
       "      942    0.019    0.000    0.238    0.000 concat.py:165(get_reindexed_values)\n",
       "    15144    0.017    0.000    0.033    0.000 {method 'format' of 'str' objects}\n",
       "        2    0.017    0.008    0.017    0.009 {method 'get_labels_groupby' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "    20940    0.017    0.000    0.064    0.000 common.py:1702(is_extension_array_dtype)\n",
       "     1046    0.016    0.000    0.038    0.000 managers.py:186(_rebuild_blknos_and_blklocs)\n",
       "    69863    0.016    0.000    0.016    0.000 protocol.py:117(read_uint8)\n",
       "   116892    0.016    0.000    0.016    0.000 {built-in method builtins.issubclass}\n",
       "    69845    0.015    0.000    0.015    0.000 {method 'decode' of 'bytes' objects}\n",
       "   218110    0.015    0.000    0.015    0.000 {method 'strip' of 'str' objects}\n",
       "      349    0.015    0.000    0.015    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
       "       95    0.014    0.000    0.702    0.007 frame.py:4605(drop_duplicates)\n",
       "    18042    0.014    0.000    0.190    0.000 <ipython-input-1038-eb2ea29a5c5f>:88(<genexpr>)\n",
       "        3    0.014    0.005    0.565    0.188 <ipython-input-1038-eb2ea29a5c5f>:69(get_system_matches)\n",
       "    34940    0.013    0.000    0.180    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
       "      714    0.012    0.000    0.012    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
       "     2693    0.011    0.000    0.011    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
       "     2467    0.011    0.000    0.031    0.000 algorithms.py:1417(_get_take_nd_function)\n",
       "    12682    0.011    0.000    0.029    0.000 numerictypes.py:365(issubdtype)\n",
       "    25364    0.011    0.000    0.017    0.000 numerictypes.py:293(issubclass_)\n",
       "     7723    0.011    0.000    0.024    0.000 common.py:160(is_sparse)\n",
       "    33546    0.011    0.000    0.022    0.000 strings.py:87(g)\n",
       "      288    0.011    0.000    0.362    0.001 merge.py:1617(_factorize_keys)\n",
       "    50379    0.010    0.000    0.269    0.000 ast.py:30(parse)\n",
       "     1978    0.010    0.000    0.033    0.000 cast.py:255(maybe_promote)\n",
       "     1742    0.010    0.000    0.010    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "      648    0.010    0.000    0.049    0.000 concat.py:261(get_empty_dtype_and_na)\n",
       "      152    0.010    0.000    0.010    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
       "      287    0.008    0.000    0.008    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "     1016    0.008    0.000    0.017    0.000 {pandas._libs.algos.ensure_object}\n",
       "    11915    0.008    0.000    0.019    0.000 common.py:1981(pandas_dtype)\n",
       "     6340    0.008    0.000    0.025    0.000 dtypes.py:973(is_dtype)\n",
       "     3681    0.008    0.000    0.020    0.000 blocks.py:78(__init__)\n",
       "    95236    0.008    0.000    0.008    0.000 {method 'append' of 'list' objects}\n",
       "     2023    0.007    0.000    0.049    0.000 blocks.py:3034(get_block_type)\n",
       "      275    0.007    0.000    0.010    0.000 indexing.py:2575(maybe_convert_indices)\n",
       "      320    0.007    0.000    0.010    0.000 sorting.py:55(maybe_lift)\n",
       "    16942    0.007    0.000    0.023    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
       "       18    0.007    0.000    0.521    0.029 frame.py:6858(merge)\n",
       "        3    0.007    0.002    1.262    0.421 <ipython-input-1038-eb2ea29a5c5f>:27(get_sys_data)\n",
       "      918    0.007    0.000    0.011    0.000 concat.py:117(needs_filling)\n",
       "      293    0.007    0.000    0.012    0.000 concat.py:22(get_mgr_concatenation_plan)\n",
       "        7    0.007    0.001    0.007    0.001 {built-in method io.open}\n",
       "     1100    0.006    0.000    0.967    0.001 frame.py:2893(__getitem__)\n",
       "     3681    0.006    0.000    0.071    0.000 blocks.py:3080(make_block)\n",
       "     3429    0.006    0.000    0.006    0.000 {built-in method numpy.arange}\n",
       "    15220    0.006    0.000    0.048    0.000 common.py:434(is_datetime64tz_dtype)\n",
       "     2124    0.006    0.000    0.014    0.000 base.py:504(_simple_new)\n",
       "     3856    0.006    0.000    0.015    0.000 managers.py:139(shape)\n",
       "        3    0.006    0.002    0.028    0.009 {pandas._libs.lib.map_infer}\n",
       "      146    0.006    0.000    0.006    0.000 {pandas._libs.algos.take_2d_axis1_float64_float64}\n",
       "1342/1341    0.006    0.000    0.045    0.000 series.py:152(__init__)\n",
       "     2758    0.006    0.000    0.016    0.000 _dtype.py:46(__str__)\n",
       "      246    0.005    0.000    0.132    0.001 managers.py:1241(_slice_take_blocks_ax0)\n",
       "        1    0.005    0.005    0.011    0.011 managers.py:772(_interleave)\n",
       "     6999    0.005    0.000    0.020    0.000 common.py:131(is_object_dtype)\n",
       "    17458    0.005    0.000    0.009    0.000 connections.py:1137(_check_packet_is_eof)\n",
       "     5565    0.005    0.000    0.020    0.000 dtypes.py:827(is_dtype)\n",
       "      320    0.005    0.000    0.383    0.001 algorithms.py:559(factorize)\n",
       "      225    0.005    0.000    0.051    0.000 managers.py:1019(set)\n",
       "    17470    0.005    0.000    0.009    0.000 protocol.py:214(check_error)\n",
       "    17471    0.005    0.000    0.005    0.000 {built-in method _struct.unpack}\n",
       "      275    0.005    0.000    0.220    0.001 managers.py:1329(take)\n",
       "        5    0.005    0.001    0.005    0.001 {pandas._libs.lib.maybe_convert_objects}\n",
       "       72    0.005    0.000    1.124    0.016 merge.py:541(get_result)\n",
       "       72    0.005    0.000    0.484    0.007 merge.py:1104(_get_join_indexers)\n",
       "     8653    0.005    0.000    0.017    0.000 common.py:1809(_get_dtype)\n",
       "        1    0.005    0.005    0.005    0.005 __init__.py:131(lmap)\n",
       "      196    0.005    0.000    0.005    0.000 {built-in method posix.stat}\n",
       "    10060    0.004    0.000    0.029    0.000 common.py:572(is_categorical_dtype)\n",
       "        1    0.004    0.004    0.996    0.996 <ipython-input-1035-ee20452e93e4>:1(get_metric_data)\n",
       "    13262    0.004    0.000    0.006    0.000 base.py:652(__len__)\n",
       "      548    0.004    0.000    0.006    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
       "    18968    0.004    0.000    0.006    0.000 common.py:119(<lambda>)\n",
       "      928    0.004    0.000    0.015    0.000 managers.py:963(iget)\n",
       "    17470    0.004    0.000    0.004    0.000 protocol.py:211(is_error_packet)\n",
       "      914    0.004    0.000    0.082    0.000 managers.py:97(__init__)\n",
       "      697    0.004    0.000    0.046    0.000 missing.py:183(_isna_ndarraylike)\n",
       "    17470    0.004    0.000    0.004    0.000 protocol.py:56(__init__)\n",
       "     3660    0.004    0.000    0.033    0.000 common.py:1578(is_bool_dtype)\n",
       "       72    0.004    0.000    1.393    0.019 merge.py:37(merge)\n",
       "     2289    0.004    0.000    0.004    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
       "     3708    0.004    0.000    0.008    0.000 blocks.py:199(mgr_locs)\n",
       "     1760    0.004    0.000    0.016    0.000 common.py:222(asarray_tuplesafe)\n",
       "      780    0.004    0.000    0.057    0.000 construction.py:537(sanitize_array)\n",
       "      548    0.004    0.000    0.078    0.000 base.py:2715(get_indexer)\n",
       "10387/10015    0.004    0.000    0.032    0.000 numeric.py:469(asarray)\n",
       "     4264    0.004    0.000    0.016    0.000 common.py:403(is_datetime64_dtype)\n",
       "     1066    0.004    0.000    0.052    0.000 concat.py:137(is_na)\n",
       "       27    0.004    0.000    3.591    0.133 <ipython-input-1040-49f2f221cb4b>:1(process_sentence)\n",
       "     2970    0.004    0.000    0.006    0.000 base.py:3918(__contains__)\n",
       "    18968    0.004    0.000    0.004    0.000 common.py:117(classes)\n",
       "       26    0.004    0.000    0.004    0.000 managers.py:2004(<listcomp>)\n",
       "     6238    0.004    0.000    0.004    0.000 {built-in method _abc._abc_instancecheck}\n",
       "     8664    0.004    0.000    0.009    0.000 integer.py:80(construct_from_string)\n",
       "     7900    0.004    0.000    0.029    0.000 common.py:536(is_interval_dtype)\n",
       "     1559    0.003    0.000    0.025    0.000 base.py:4051(equals)\n",
       "    17460    0.003    0.000    0.003    0.000 protocol.py:190(is_eof_packet)\n",
       "      187    0.003    0.000    0.035    0.000 {pandas._libs.lib.clean_index_list}\n",
       "     2124    0.003    0.000    0.003    0.000 generic.py:127(__init__)\n",
       "     1341    0.003    0.000    0.015    0.000 managers.py:1443(__init__)\n",
       "     4542    0.003    0.000    0.005    0.000 {pandas._libs.lib.is_scalar}\n",
       "      731    0.003    0.000    0.164    0.000 blocks.py:1217(take_nd)\n",
       "     4053    0.003    0.000    0.010    0.000 inference.py:253(is_list_like)\n",
       "      191    0.003    0.000    0.062    0.000 categorical.py:317(__init__)\n",
       "      777    0.003    0.000    0.011    0.000 managers.py:306(_verify_integrity)\n",
       "      782    0.003    0.000    0.150    0.000 frame.py:378(__init__)\n",
       "     2866    0.003    0.000    0.029    0.000 blocks.py:312(ftype)\n",
       "        1    0.003    0.003    0.302    0.302 parsers.py:403(_read)\n",
       "       95    0.003    0.000    0.551    0.006 frame.py:4639(duplicated)\n",
       "  749/188    0.003    0.000    0.028    0.000 <frozen importlib._bootstrap>:978(_find_and_load)\n",
       "     4569    0.003    0.000    0.078    0.000 base.py:5318(ensure_index)\n",
       "     3226    0.003    0.000    0.005    0.000 dtypes.py:672(construct_from_string)\n",
       "      517    0.003    0.000    0.006    0.000 base.py:1658(is_unique)\n",
       "     1464    0.003    0.000    0.006    0.000 dtypes.py:786(construct_from_string)\n",
       "     4546    0.003    0.000    0.022    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
       "     5565    0.003    0.000    0.023    0.000 common.py:503(is_period_dtype)\n",
       "     4221    0.003    0.000    0.012    0.000 common.py:472(is_timedelta64_dtype)\n",
       "     2220    0.003    0.000    0.054    0.000 missing.py:105(_isna_new)\n",
       "      429    0.003    0.000    0.017    0.000 concat.py:20(get_dtype_kinds)\n",
       "    12144    0.003    0.000    0.003    0.000 {method 'get' of 'dict' objects}\n",
       "     1148    0.003    0.000    0.047    0.000 generic.py:3056(_get_item_cache)\n",
       "        9    0.003    0.000    0.003    0.000 {method 'factorize' of 'pandas._libs.hashtable.Float64HashTable' objects}\n",
       "    11568    0.003    0.000    0.010    0.000 managers.py:141(<genexpr>)\n",
       "2151/1988    0.003    0.000    0.013    0.000 generic.py:5053(__getattr__)\n",
       "     4777    0.003    0.000    0.007    0.000 base.py:3608(values)\n",
       "      948    0.003    0.000    0.004    0.000 concat.py:425(combine_concat_plans)\n",
       "     4929    0.003    0.000    0.003    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "     3546    0.003    0.000    0.003    0.000 generic.py:349(_get_axis_number)\n",
       "     6529    0.003    0.000    0.003    0.000 common.py:127(<lambda>)\n",
       "     1187    0.002    0.000    0.010    0.000 blocks.py:2626(__init__)\n",
       "       27    0.002    0.000    0.002    0.000 {pandas._libs.algos.take_2d_axis0_int8_float64}\n",
       "      903    0.002    0.000    0.022    0.000 managers.py:934(get)\n",
       "      274    0.002    0.000    0.822    0.003 generic.py:3323(_take)\n",
       "      108    0.002    0.000    0.051    0.000 managers.py:1696(form_blocks)\n",
       "      648    0.002    0.000    0.481    0.001 concat.py:230(concatenate_join_units)\n",
       "      568    0.002    0.000    0.005    0.000 cast.py:1193(construct_1d_object_array_from_listlike)\n",
       "      717    0.002    0.000    0.010    0.000 base.py:566(_shallow_copy)\n",
       "     3019    0.002    0.000    0.006    0.000 common.py:1545(is_float_dtype)\n",
       "     1494    0.002    0.000    0.007    0.000 blocks.py:128(_consolidate_key)\n",
       "     1453    0.002    0.000    0.004    0.000 base.py:3940(__getitem__)\n",
       "      942    0.002    0.000    0.033    0.000 managers.py:599(_consolidate_check)\n",
       "       95    0.002    0.000    0.002    0.000 {built-in method _operator.inv}\n",
       "      320    0.002    0.000    0.327    0.001 algorithms.py:434(_factorize_array)\n",
       "     1343    0.002    0.000    0.003    0.000 series.py:354(_set_axis)\n",
       "     3399    0.002    0.000    0.002    0.000 {pandas._libs.algos.ensure_int64}\n",
       "     2148    0.002    0.000    0.017    0.000 blocks.py:225(make_block_same_class)\n",
       "     6918    0.002    0.000    0.003    0.000 managers.py:143(ndim)\n",
       "    12629    0.002    0.000    0.002    0.000 blocks.py:195(mgr_locs)\n",
       "     2704    0.002    0.000    0.003    0.000 generic.py:363(_get_axis_name)\n",
       "     1776    0.002    0.000    0.003    0.000 series.py:392(name)\n",
       "      188    0.002    0.000    0.014    0.000 <frozen importlib._bootstrap>:882(_find_spec)\n",
       "     1643    0.002    0.000    0.002    0.000 _internal.py:886(npy_ctypes_check)\n",
       "      374    0.002    0.000    0.243    0.001 managers.py:1198(reindex_indexer)\n",
       "       99    0.002    0.000    0.003    0.000 function_base.py:4220(delete)\n",
       "     6238    0.002    0.000    0.006    0.000 abc.py:137(__instancecheck__)\n",
       "      196    0.002    0.000    0.009    0.000 <frozen importlib._bootstrap_external>:1356(find_spec)\n",
       "      132    0.002    0.000    0.003    0.000 base.py:1587(is_monotonic_increasing)\n",
       "     4546    0.002    0.000    0.020    0.000 _methods.py:42(_any)\n",
       "      919    0.002    0.000    0.008    0.000 missing.py:360(array_equivalent)\n",
       "3376/3375    0.002    0.000    0.059    0.000 {built-in method builtins.all}\n",
       "     2163    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "       27    0.002    0.000    0.002    0.000 {pandas._libs.algos.take_2d_axis0_int8_int8}\n",
       "      249    0.002    0.000    0.199    0.001 managers.py:318(apply)\n",
       "      903    0.002    0.000    0.019    0.000 frame.py:3342(_box_item_values)\n",
       "     1704    0.002    0.000    0.051    0.000 concat.py:379(<genexpr>)\n",
       "      410    0.002    0.000    0.003    0.000 numeric.py:676(require)\n",
       "      749    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "        1    0.002    0.002    0.560    0.560 sql.py:317(read_sql)\n",
       "       93    0.002    0.000    0.032    0.000 concat.py:237(__init__)\n",
       "     2349    0.002    0.000    0.002    0.000 dtypes.py:452(construct_from_string)\n",
       "      434    0.002    0.000    0.021    0.000 generic.py:1657(_get_label_or_level_values)\n",
       "     1464    0.002    0.000    0.004    0.000 dtypes.py:929(construct_from_string)\n",
       "        1    0.002    0.002    0.002    0.002 result.py:1192(<listcomp>)\n",
       "     2353    0.002    0.000    0.006    0.000 common.py:923(is_signed_integer_dtype)\n",
       "      710    0.002    0.000    0.055    0.000 concat.py:367(is_uniform_join_units)\n",
       "     2203    0.002    0.000    0.006    0.000 base.py:2650(get_loc)\n",
       "      799    0.002    0.000    0.003    0.000 blocks.py:3100(_extend_blocks)\n",
       "      700    0.002    0.000    0.014    0.000 algorithms.py:38(_ensure_data)\n",
       "     3036    0.002    0.000    0.014    0.000 common.py:262(is_categorical)\n",
       "      928    0.002    0.000    0.014    0.000 frame.py:3349(_box_col_values)\n",
       "     2377    0.002    0.000    0.005    0.000 {pandas._libs.lib.values_from_object}\n",
       "     7527    0.002    0.000    0.002    0.000 blocks.py:308(dtype)\n",
       "     2188    0.002    0.000    0.003    0.000 __init__.py:221(iteritems)\n",
       "     3681    0.002    0.000    0.002    0.000 blocks.py:89(_check_ndim)\n",
       "       93    0.002    0.000    0.381    0.004 concat.py:383(get_result)\n",
       "       72    0.002    0.000    0.004    0.000 merge.py:647(_maybe_add_join_keys)\n",
       "     1930    0.002    0.000    0.002    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "     2405    0.002    0.000    0.005    0.000 generic.py:377(_get_axis)\n",
       "       99    0.002    0.000    0.002    0.000 socket.py:337(send)\n",
       "  749/188    0.002    0.000    0.024    0.000 <frozen importlib._bootstrap>:948(_find_and_load_unlocked)\n",
       "      145    0.002    0.000    0.083    0.001 indexing.py:1271(_convert_to_indexer)\n",
       "      132    0.001    0.000    0.597    0.005 managers.py:1887(_consolidate)\n",
       "      558    0.001    0.000    0.010    0.000 cast.py:953(maybe_cast_to_datetime)\n",
       "      596    0.001    0.000    0.004    0.000 generic.py:1546(_is_label_reference)\n",
       "        1    0.001    0.001    0.001    0.001 {pandas._libs.lib.to_object_array_tuples}\n",
       "     1763    0.001    0.000    0.006    0.000 common.py:868(is_integer_dtype)\n",
       "      321    0.001    0.000    0.157    0.000 concat.py:101(_concat_compat)\n",
       "      284    0.001    0.000    0.003    0.000 cast.py:832(maybe_castable)\n",
       "      320    0.001    0.000    0.037    0.000 algorithms.py:132(_reconstruct_data)\n",
       "      471    0.001    0.000    0.006    0.000 common.py:93(is_bool_indexer)\n",
       "       86    0.001    0.000    0.003    0.000 index_tricks.py:316(__getitem__)\n",
       "      942    0.001    0.000    0.030    0.000 managers.py:600(<listcomp>)\n",
       "     1960    0.001    0.000    0.003    0.000 common.py:746(is_dtype_equal)\n",
       "     2224    0.001    0.000    0.019    0.000 common.py:1078(is_datetime64_any_dtype)\n",
       "       27    0.001    0.000    0.003    0.000 <ipython-input-1034-996dcf9791ab>:1(cm_dict)\n",
       "      320    0.001    0.000    0.038    0.000 base.py:784(take)\n",
       "      225    0.001    0.000    0.011    0.000 frame.py:3565(_sanitize_column)\n",
       "     3205    0.001    0.000    0.002    0.000 managers.py:308(<genexpr>)\n",
       "      645    0.001    0.000    0.002    0.000 base.py:643(_engine)\n",
       "      753    0.001    0.000    0.021    0.000 construction.py:684(_try_cast)\n",
       "     2451    0.001    0.000    0.003    0.000 {built-in method builtins.max}\n",
       "      304    0.001    0.000    0.004    0.000 fromnumeric.py:69(_wrapreduction)\n",
       "     1040    0.001    0.000    0.002    0.000 numerictypes.py:578(_can_coerce_all)\n",
       "       86    0.001    0.000    0.035    0.000 managers.py:1134(insert)\n",
       "      702    0.001    0.000    0.003    0.000 generic.py:1513(_is_level_reference)\n",
       "      145    0.001    0.000    0.074    0.001 indexing.py:1108(_get_listlike_indexer)\n",
       "      578    0.001    0.000    0.002    0.000 cast.py:341(infer_dtype_from_scalar)\n",
       "     1443    0.001    0.000    0.001    0.000 {method 'match' of 're.Pattern' objects}\n",
       "      713    0.001    0.000    0.002    0.000 shape_base.py:83(atleast_2d)\n",
       "     1369    0.001    0.000    0.007    0.000 base.py:963(_ndarray_values)\n",
       "      520    0.001    0.000    0.004    0.000 numerictypes.py:602(find_common_type)\n",
       "     6529    0.001    0.000    0.001    0.000 common.py:122(classes_and_not_datetimelike)\n",
       "       72    0.001    0.000    0.260    0.004 merge.py:777(_get_merge_keys)\n",
       "     2997    0.001    0.000    0.002    0.000 generic.py:450(ndim)\n",
       "     3273    0.001    0.000    0.002    0.000 inference.py:438(is_hashable)\n",
       "      918    0.001    0.000    0.013    0.000 concat.py:126(dtype)\n",
       "     1587    0.001    0.000    0.002    0.000 series.py:399(name)\n",
       "      468    0.001    0.000    0.008    0.000 cast.py:1151(construct_1d_arraylike_from_scalar)\n",
       "     4868    0.001    0.000    0.001    0.000 {method 'startswith' of 'str' objects}\n",
       "      914    0.001    0.000    0.002    0.000 managers.py:98(<listcomp>)\n",
       "      434    0.001    0.000    0.002    0.000 generic.py:1607(_check_label_or_level_ambiguity)\n",
       "      520    0.001    0.000    0.001    0.000 numerictypes.py:654(<listcomp>)\n",
       "      213    0.001    0.000    0.001    0.000 blocks.py:3145(<listcomp>)\n",
       "     6468    0.001    0.000    0.002    0.000 {built-in method builtins.hash}\n",
       "     1509    0.001    0.000    0.006    0.000 common.py:1784(_is_dtype)\n",
       "      548    0.001    0.000    0.003    0.000 base.py:4459(_maybe_promote)\n",
       "       72    0.001    0.000    0.021    0.000 base.py:2357(intersection)\n",
       "      245    0.001    0.000    0.001    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "      256    0.001    0.000    0.026    0.000 base.py:3089(reindex)\n",
       "      749    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "     1137    0.001    0.000    0.002    0.000 base.py:547(_get_attributes_dict)\n",
       "      620    0.001    0.000    0.655    0.001 generic.py:5122(_protect_consolidate)\n",
       "     1767    0.001    0.000    0.003    0.000 common.py:980(is_unsigned_integer_dtype)\n",
       "     3108    0.001    0.000    0.001    0.000 {method 'rpartition' of 'str' objects}\n",
       "      280    0.001    0.000    0.004    0.000 numeric.py:34(__new__)\n",
       "      289    0.001    0.000    0.006    0.000 base.py:1117(__iter__)\n",
       "     2185    0.001    0.000    0.001    0.000 base.py:633(_reset_identity)\n",
       "      318    0.001    0.000    0.385    0.001 frame.py:4666(f)\n",
       "     1429    0.001    0.000    0.002    0.000 managers.py:1549(internal_values)\n",
       "       72    0.001    0.000    0.265    0.004 merge.py:474(__init__)\n",
       "     1160    0.001    0.000    0.604    0.001 managers.py:927(_consolidate_inplace)\n",
       "     1121    0.001    0.000    0.003    0.000 {built-in method builtins.sum}\n",
       "       30    0.001    0.000    0.001    0.000 {built-in method numpy.putmask}\n",
       "      100    0.001    0.000    0.145    0.001 generic.py:4113(reindex)\n",
       "      145    0.001    0.000    0.003    0.000 indexing.py:1209(_validate_read_indexer)\n",
       "     1059    0.001    0.000    0.001    0.000 range.py:510(__len__)\n",
       "       99    0.001    0.000    0.023    0.000 base.py:4939(drop)\n",
       "      225    0.001    0.000    0.068    0.000 frame.py:3356(__setitem__)\n",
       "      499    0.001    0.000    0.003    0.000 indexing.py:2450(convert_to_index_sliceable)\n",
       "      438    0.001    0.000    0.002    0.000 numeric.py:2656(seterr)\n",
       "      749    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "      928    0.001    0.000    0.002    0.000 generic.py:3070(_set_as_cached)\n",
       "     3631    0.001    0.000    0.001    0.000 managers.py:206(items)\n",
       "      262    0.001    0.000    0.021    0.000 base.py:584(_shallow_copy_with_infer)\n",
       "     2220    0.001    0.000    0.055    0.000 missing.py:25(isna)\n",
       "     1559    0.001    0.000    0.001    0.000 base.py:613(is_)\n",
       "      991    0.001    0.000    0.001    0.000 generic.py:5036(__finalize__)\n",
       "      492    0.001    0.000    0.006    0.000 cast.py:846(maybe_infer_to_datetimelike)\n",
       "      156    0.001    0.000    0.004    0.000 base.py:786(array)\n",
       "       99    0.001    0.000    0.171    0.002 generic.py:3787(_drop_axis)\n",
       "     1785    0.001    0.000    0.004    0.000 {built-in method builtins.any}\n",
       "      648    0.001    0.000    0.238    0.000 concat.py:240(<listcomp>)\n",
       "      418    0.001    0.000    0.022    0.000 frame.py:742(iteritems)\n",
       "      107    0.001    0.000    0.144    0.001 construction.py:170(init_dict)\n",
       "      620    0.001    0.000    0.653    0.001 generic.py:5135(f)\n",
       "      438    0.001    0.000    0.001    0.000 numeric.py:2758(geterr)\n",
       "      749    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "       99    0.001    0.000    0.080    0.001 generic.py:4469(_reindex_with_indexers)\n",
       "       31    0.001    0.000    0.001    0.000 numeric.py:2551(array_equal)\n",
       "     2197    0.001    0.000    0.001    0.000 {built-in method __new__ of type object at 0x105424778}\n",
       "     4670    0.001    0.000    0.001    0.000 {method 'items' of 'dict' objects}\n",
       "     3292    0.001    0.000    0.001    0.000 format.py:301(len)\n",
       "       27    0.001    0.000    0.194    0.007 merge.py:598(_indicator_post_merge)\n",
       "      957    0.001    0.000    0.010    0.000 common.py:1643(is_extension_type)\n",
       "      380    0.001    0.000    0.077    0.000 algorithms.py:217(_get_data_algo)\n",
       "     2516    0.001    0.000    0.001    0.000 blocks.py:304(shape)\n",
       "      188    0.001    0.000    0.010    0.000 <frozen importlib._bootstrap_external>:1240(_get_spec)\n",
       "      225    0.001    0.000    0.065    0.000 frame.py:3433(_set_item)\n",
       "      548    0.001    0.000    0.007    0.000 base.py:1669(is_boolean)\n",
       "        2    0.001    0.000    0.001    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
       "     1083    0.001    0.000    0.001    0.000 sparse.py:196(construct_from_string)\n",
       "     3854    0.001    0.000    0.001    0.000 {pandas._libs.lib.is_float}\n",
       "     3211    0.001    0.000    0.001    0.000 managers.py:1488(_block)\n",
       "     1838    0.001    0.000    0.002    0.000 base.py:3663(get_values)\n",
       "      980    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:56(_path_join)\n",
       "     1296    0.001    0.000    0.001    0.000 concat.py:391(<genexpr>)\n",
       "      129    0.001    0.000    0.165    0.001 frame.py:2952(_getitem_bool_array)\n",
       "     1242    0.001    0.000    0.001    0.000 managers.py:1522(dtype)\n",
       "     1137    0.001    0.000    0.001    0.000 base.py:551(<dictcomp>)\n",
       "     1429    0.001    0.000    0.002    0.000 series.py:476(_values)\n",
       "      675    0.001    0.000    0.001    0.000 generic.py:144(_init_mgr)\n",
       "     1450    0.001    0.000    0.001    0.000 common.py:144(cast_scalar_indexer)\n",
       "      225    0.001    0.000    0.052    0.000 generic.py:3171(_set_item)\n",
       "      232    0.001    0.000    0.004    0.000 {built-in method builtins.sorted}\n",
       "     2328    0.001    0.000    0.001    0.000 {built-in method builtins.iter}\n",
       "     1776    0.001    0.000    0.001    0.000 concat.py:376(<genexpr>)\n",
       "      749    0.001    0.000    0.005    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "        1    0.001    0.001    0.015    0.015 frame.py:1430(from_records)\n",
       "     1750    0.001    0.000    0.001    0.000 frame.py:474(axes)\n",
       "      620    0.001    0.000    0.621    0.001 managers.py:911(consolidate)\n",
       "       56    0.001    0.000    0.010    0.000 generic.py:5948(fillna)\n",
       "     1494    0.001    0.000    0.007    0.000 managers.py:1893(<lambda>)\n",
       "      432    0.001    0.000    0.001    0.000 {method 'clear' of 'dict' objects}\n",
       "      874    0.001    0.000    0.001    0.000 blocks.py:332(iget)\n",
       "      246    0.001    0.000    0.001    0.000 managers.py:2015(_preprocess_slice_or_indexer)\n",
       "     1192    0.001    0.000    0.001    0.000 generic.py:1576(<genexpr>)\n",
       "      156    0.001    0.000    0.001    0.000 numpy_.py:35(__init__)\n",
       "      133    0.001    0.000    0.189    0.001 generic.py:5699(copy)\n",
       "      327    0.001    0.000    0.173    0.001 blocks.py:749(copy)\n",
       "     5205    0.001    0.000    0.001    0.000 {pandas._libs.lib.is_integer}\n",
       "      225    0.001    0.000    0.001    0.000 base.py:3926(contains)\n",
       "     1121    0.001    0.000    0.004    0.000 inference.py:304(is_array_like)\n",
       "       72    0.001    0.000    0.004    0.000 merge.py:889(_maybe_coerce_merge_keys)\n",
       "     1704    0.001    0.000    0.002    0.000 numeric.py:541(asanyarray)\n",
       "      108    0.001    0.000    0.047    0.000 construction.py:254(_homogenize)\n",
       "       58    0.001    0.000    0.007    0.000 blocks.py:536(_astype)\n",
       "     1361    0.001    0.000    0.001    0.000 common.py:316(apply_if_callable)\n",
       "       72    0.001    0.000    0.514    0.007 merge.py:737(_get_join_info)\n",
       "      879    0.001    0.000    0.002    0.000 frame.py:937(__len__)\n",
       "       27    0.001    0.000    0.001    0.000 {built-in method _operator.add}\n",
       "      651    0.001    0.000    0.001    0.000 {pandas._libs.internals.get_blkno_placements}\n",
       "      413    0.001    0.000    0.023    0.000 frame.py:4685(<genexpr>)\n",
       "      883    0.001    0.000    0.004    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "      130    0.001    0.000    0.079    0.001 managers.py:1233(<listcomp>)\n",
       "      749    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "     1236    0.001    0.000    0.001    0.000 base.py:1237(_get_names)\n",
       "      992    0.001    0.000    0.006    0.000 common.py:605(is_string_dtype)\n",
       "      735    0.001    0.000    0.005    0.000 base.py:646(<lambda>)\n",
       "     1343    0.001    0.000    0.001    0.000 series.py:382(_set_subtyp)\n",
       "  561/187    0.001    0.000    0.023    0.000 {built-in method builtins.__import__}\n",
       "      979    0.001    0.000    0.007    0.000 blocks.py:175(get_values)\n",
       "      145    0.001    0.000    0.002    0.000 indexing.py:256(_convert_scalar_indexer)\n",
       "      646    0.001    0.000    0.002    0.000 common.py:1472(is_numeric_dtype)\n",
       "      218    0.001    0.000    0.010    0.000 numeric.py:67(_shallow_copy)\n",
       "     1723    0.001    0.000    0.002    0.000 managers.py:591(is_consolidated)\n",
       "     1523    0.001    0.000    0.001    0.000 {built-in method pandas._libs.missing.checknull}\n",
       "      620    0.001    0.000    0.655    0.001 generic.py:5132(_consolidate_inplace)\n",
       "     1498    0.001    0.000    0.001    0.000 {built-in method _thread.allocate_lock}\n",
       "     1242    0.001    0.000    0.002    0.000 series.py:406(dtype)\n",
       "      533    0.001    0.000    0.001    0.000 managers.py:174(_is_single_block)\n",
       "      320    0.001    0.000    0.383    0.001 _decorators.py:146(wrapper)\n",
       "      162    0.001    0.000    0.002    0.000 blocks.py:2933(__init__)\n",
       "      992    0.001    0.000    0.003    0.000 common.py:634(condition)\n",
       "      434    0.001    0.000    0.012    0.000 generic.py:3461(xs)\n",
       "       35    0.001    0.000    0.009    0.000 base.py:2254(union)\n",
       "      156    0.001    0.000    0.002    0.000 numpy_.py:127(__init__)\n",
       "      471    0.001    0.000    0.001    0.000 generic.py:381(_get_block_manager_axis)\n",
       "      928    0.001    0.000    0.001    0.000 inference.py:121(is_iterator)\n",
       "      980    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:58(<listcomp>)\n",
       "       27    0.001    0.000    0.001    0.000 base.py:221(_inner_indexer)\n",
       "      648    0.001    0.000    0.002    0.000 concat.py:388(is_uniform_reindex)\n",
       "      410    0.001    0.000    0.001    0.000 numeric.py:748(<setcomp>)\n",
       "       72    0.001    0.000    0.007    0.000 concat.py:486(_concat_index_asobject)\n",
       "       27    0.001    0.000    0.096    0.004 merge.py:574(_indicator_pre_merge)\n",
       "       72    0.000    0.000    0.236    0.003 generic.py:1729(_drop_labels_or_levels)\n",
       "       86    0.000    0.000    0.004    0.000 managers.py:2008(_fast_count_smallints)\n",
       "      780    0.000    0.000    0.002    0.000 arrays.py:7(extract_array)\n",
       "     3292    0.000    0.000    0.001    0.000 __init__.py:291(strlen)\n",
       "      832    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
       "       99    0.000    0.000    0.146    0.001 frame.py:3794(reindex)\n",
       "       58    0.000    0.000    0.000    0.000 blocks.py:335(set)\n",
       "     1139    0.000    0.000    0.000    0.000 concat.py:104(__init__)\n",
       "      434    0.000    0.000    0.001    0.000 common.py:1198(is_datetime_or_timedelta_dtype)\n",
       "      246    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_bool_array}\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:1830(__init__)\n",
       "       86    0.000    0.000    0.025    0.000 base.py:4919(insert)\n",
       "      795    0.000    0.000    0.010    0.000 base.py:1729(inferred_type)\n",
       "      135    0.000    0.000    0.189    0.001 managers.py:710(copy)\n",
       "     1087    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
       "      191    0.000    0.000    0.002    0.000 dtypes.py:521(update_dtype)\n",
       "      101    0.000    0.000    0.001    0.000 generic.py:297(_construct_axes_from_arguments)\n",
       "      108    0.000    0.000    0.058    0.001 managers.py:1663(create_block_manager_from_arrays)\n",
       "      213    0.000    0.000    0.263    0.001 shape_base.py:229(vstack)\n",
       "      218    0.000    0.000    0.007    0.000 dtypes.py:244(_from_values_or_dtype)\n",
       "     1494    0.000    0.000    0.000    0.000 base.py:676(dtype)\n",
       "      108    0.000    0.000    0.015    0.000 base.py:3988(append)\n",
       "       99    0.000    0.000    0.184    0.002 generic.py:3759(drop)\n",
       "       85    0.000    0.000    0.012    0.000 dtypes.py:485(validate_categories)\n",
       "       93    0.000    0.000    0.011    0.000 concat.py:440(_get_new_axes)\n",
       "       83    0.000    0.000    0.010    0.000 managers.py:1810(_multi_blockify)\n",
       "       27    0.000    0.000    5.186    0.192 <ipython-input-1041-adf066fa4b64>:132(get_metrics)\n",
       "      432    0.000    0.000    0.005    0.000 common.py:1431(needs_i8_conversion)\n",
       "       35    0.000    0.000    0.049    0.001 ops.py:1660(wrapper)\n",
       "       95    0.000    0.000    0.013    0.000 generic.py:1439(__neg__)\n",
       "      648    0.000    0.000    0.001    0.000 missing.py:530(clean_reindex_fill_method)\n",
       "      196    0.000    0.000    0.004    0.000 fromnumeric.py:2664(prod)\n",
       "       27    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
       "      156    0.000    0.000    0.013    0.000 series.py:669(__array__)\n",
       "      420    0.000    0.000    0.001    0.000 managers.py:1546(external_values)\n",
       "      749    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "      883    0.000    0.000    0.004    0.000 _methods.py:45(_all)\n",
       "      430    0.000    0.000    0.001    0.000 generic.py:3149(_clear_item_cache)\n",
       "       27    0.000    0.000    0.047    0.002 categorical.py:2560(_get_codes_for_values)\n",
       "       93    0.000    0.000    0.414    0.004 concat.py:24(concat)\n",
       "       99    0.000    0.000    0.087    0.001 frame.py:3754(_reindex_columns)\n",
       "      270    0.000    0.000    0.004    0.000 base.py:700(view)\n",
       "      145    0.000    0.000    0.001    0.000 base.py:2849(_convert_scalar_indexer)\n",
       "     1440    0.000    0.000    0.000    0.000 concat.py:381(<genexpr>)\n",
       "      301    0.000    0.000    0.004    0.000 common.py:702(is_datetimelike)\n",
       "       54    0.000    0.000    0.002    0.000 cast.py:597(astype_nansafe)\n",
       "       93    0.000    0.000    0.002    0.000 concat.py:84(_get_frame_result_type)\n",
       "     1157    0.000    0.000    0.000    0.000 blocks.py:191(fill_value)\n",
       "       99    0.000    0.000    0.087    0.001 frame.py:3729(_reindex_axes)\n",
       "      415    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "       27    0.000    0.000    0.001    0.000 <ipython-input-1041-adf066fa4b64>:14(buildParseTree)\n",
       "      221    0.000    0.000    0.001    0.000 generic.py:3175(_set_is_copy)\n",
       "       28    0.000    0.000    0.001    0.000 base.py:3752(_try_convert_to_int_index)\n",
       "      813    0.000    0.000    0.000    0.000 managers.py:706(nblocks)\n",
       "       95    0.000    0.000    0.008    0.000 series.py:730(__array_wrap__)\n",
       "     1127    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
       "     1084    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\n",
       "       58    0.000    0.000    0.012    0.000 generic.py:5581(astype)\n",
       "      219    0.000    0.000    0.000    0.000 numeric.py:3054(__init__)\n",
       "     2144    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
       "       27    0.000    0.000    0.001    0.000 categorical.py:597(from_codes)\n",
       "       97    0.000    0.000    0.000    0.000 sorting.py:47(_int64_cut_off)\n",
       "       27    0.000    0.000    0.001    0.000 expressions.py:71(_can_use_numexpr)\n",
       "     2250    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
       "     1407    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
       "      246    0.000    0.000    0.001    0.000 blocks.py:2633(is_bool)\n",
       "      243    0.000    0.000    0.001    0.000 format.py:1019(base_formatter)\n",
       "       72    0.000    0.000    0.011    0.000 generic.py:3840(_update_inplace)\n",
       "      108    0.000    0.000    0.125    0.001 construction.py:43(arrays_to_mgr)\n",
       "      162    0.000    0.000    0.001    0.000 blocks.py:1549(__init__)\n",
       "     1960    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
       "      129    0.000    0.000    0.007    0.000 indexing.py:2475(check_bool_indexer)\n",
       "      145    0.000    0.000    0.002    0.000 base.py:2965(_convert_listlike_indexer)\n",
       "     2250    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
       "      570    0.000    0.000    0.001    0.000 generic.py:1895(<genexpr>)\n",
       "      108    0.000    0.000    0.002    0.000 categorical.py:464(copy)\n",
       "       95    0.000    0.000    0.005    0.000 base.py:2445(difference)\n",
       "       82    0.000    0.000    0.003    0.000 iostream.py:382(write)\n",
       "      172    0.000    0.000    0.001    0.000 function_base.py:4641(append)\n",
       "      166    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
       "      438    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
       "      188    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:873(_find_spec_legacy)\n",
       "      812    0.000    0.000    0.000    0.000 concat.py:450(_next_or_none)\n",
       "       99    0.000    0.000    0.002    0.000 iostream.py:195(schedule)\n",
       "     1800    0.000    0.000    0.000    0.000 base.py:3632(_values)\n",
       "       27    0.000    0.000    0.001    0.000 categorical.py:56(f)\n",
       "      520    0.000    0.000    0.000    0.000 _validators.py:221(validate_bool_kwarg)\n",
       "      213    0.000    0.000    0.002    0.000 fromnumeric.py:942(argsort)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'writelines' of '_io._IOBase' objects}\n",
       "      980    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "        1    0.000    0.000    0.016    0.016 sql.py:136(_wrap_result)\n",
       "      166    0.000    0.000    0.001    0.000 codecs.py:319(decode)\n",
       "      213    0.000    0.000    0.001    0.000 shape_base.py:283(<listcomp>)\n",
       "      324    0.000    0.000    0.002    0.000 generic.py:1844(__contains__)\n",
       "      490    0.000    0.000    0.001    0.000 managers.py:1844(_asarray_compat)\n",
       "     1947    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
       "      108    0.000    0.000    0.014    0.000 base.py:4017(_concat)\n",
       "       99    0.000    0.000    0.005    0.000 base.py:4909(delete)\n",
       "      749    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "       72    0.000    0.000    0.002    0.000 merge.py:614(_maybe_restore_index_levels)\n",
       "      141    0.000    0.000    0.002    0.000 frame.py:3585(reindexer)\n",
       "      165    0.000    0.000    0.013    0.000 managers.py:2041(<listcomp>)\n",
       "      218    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_int8}\n",
       "      304    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
       "     1445    0.000    0.000    0.000    0.000 blocks.py:165(internal_values)\n",
       "      624    0.000    0.000    0.000    0.000 blocks.py:255(__len__)\n",
       "      145    0.000    0.000    0.048    0.000 base.py:4447(get_indexer_for)\n",
       "      219    0.000    0.000    0.002    0.000 numeric.py:3058(__enter__)\n",
       "       72    0.000    0.000    0.026    0.000 managers.py:1959(items_overlap_with_suffix)\n",
       "       99    0.000    0.000    0.000    0.000 {built-in method numpy.copyto}\n",
       "       99    0.000    0.000    0.184    0.002 frame.py:3819(drop)\n",
       "      420    0.000    0.000    0.001    0.000 series.py:434(values)\n",
       "      497    0.000    0.000    0.001    0.000 cast.py:1218(construct_1d_ndarray_preserving_na)\n",
       "       86    0.000    0.000    0.016    0.000 base.py:3830(_coerce_scalar_to_index)\n",
       "      348    0.000    0.000    0.000    0.000 {method 'add' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "      321    0.000    0.000    0.001    0.000 concat.py:126(<listcomp>)\n",
       "      918    0.000    0.000    0.001    0.000 format.py:1401(just)\n",
       "      186    0.000    0.000    0.017    0.000 generic.py:5140(_consolidate)\n",
       "      103    0.000    0.000    0.001    0.000 managers.py:1556(get_values)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.writers.write_csv_rows}\n",
       "       93    0.000    0.000    0.006    0.000 concat.py:475(_get_concat_axis)\n",
       "       27    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_int8_int8}\n",
       "      642    0.000    0.000    0.000    0.000 concat.py:120(is_nonempty)\n",
       "       27    0.000    0.000    0.007    0.000 ops.py:1536(wrapper)\n",
       "      217    0.000    0.000    0.017    0.000 base.py:802(_assert_take_fillable)\n",
       "      162    0.000    0.000    0.001    0.000 blocks.py:1679(__init__)\n",
       "      200    0.000    0.000    0.003    0.000 generic.py:4341(<genexpr>)\n",
       "       57    0.000    0.000    0.004    0.000 api.py:128(_union_indexes)\n",
       "     1084    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
       "      648    0.000    0.000    0.000    0.000 concat.py:136(<genexpr>)\n",
       "      490    0.000    0.000    0.000    0.000 generic.py:426(_info_axis)\n",
       "       56    0.000    0.000    0.006    0.000 blocks.py:364(fillna)\n",
       "      188    0.000    0.000    0.011    0.000 <frozen importlib._bootstrap_external>:1272(find_spec)\n",
       "      219    0.000    0.000    0.001    0.000 numeric.py:3063(__exit__)\n",
       "  561/187    0.000    0.000    0.023    0.000 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "      188    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "      752    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:859(__exit__)\n",
       "      321    0.000    0.000    0.001    0.000 concat.py:151(<listcomp>)\n",
       "      100    0.000    0.000    0.000    0.000 _validators.py:230(validate_axis_style_args)\n",
       "       36    0.000    0.000    0.029    0.001 frame.py:6558(append)\n",
       "       93    0.000    0.000    0.000    0.000 api.py:73(_get_distinct_objs)\n",
       "      233    0.000    0.000    0.000    0.000 {pandas._libs.lib.array_equivalent_object}\n",
       "      125    0.000    0.000    0.001    0.000 ops.py:43(get_op_result_name)\n",
       "      213    0.000    0.000    0.000    0.000 shape_base.py:220(_warn_for_nonsequence)\n",
       "       93    0.000    0.000    0.005    0.000 concat.py:464(_get_comb_axis)\n",
       "       59    0.000    0.000    0.001    0.000 range.py:69(__new__)\n",
       "      213    0.000    0.000    0.001    0.000 fromnumeric.py:54(_wrapfunc)\n",
       "      978    0.000    0.000    0.001    0.000 {built-in method builtins.next}\n",
       "      752    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:855(__enter__)\n",
       "      172    0.000    0.000    0.001    0.000 fromnumeric.py:1583(ravel)\n",
       "     1124    0.000    0.000    0.000    0.000 numeric.py:113(is_all_dates)\n",
       "        6    0.000    0.000    0.000    0.000 {pandas._libs.algos.rank_1d_float64}\n",
       "      952    0.000    0.000    0.001    0.000 format.py:1392(<genexpr>)\n",
       "       56    0.000    0.000    0.010    0.000 series.py:3831(fillna)\n",
       "      202    0.000    0.000    0.001    0.000 base.py:2590(_assert_can_do_setop)\n",
       "     1181    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "      190    0.000    0.000    0.002    0.000 generic.py:1848(empty)\n",
       "      129    0.000    0.000    0.000    0.000 generic.py:1814(__hash__)\n",
       "      320    0.000    0.000    0.002    0.000 algorithms.py:163(_ensure_arraylike)\n",
       "       54    0.000    0.000    0.005    0.000 base.py:2354(_wrap_setop_result)\n",
       "       93    0.000    0.000    0.001    0.000 concat.py:309(<listcomp>)\n",
       "       61    0.000    0.000    0.000    0.000 range.py:136(_simple_new)\n",
       "       99    0.000    0.000    0.001    0.000 generic.py:4378(_needs_reindex_multi)\n",
       "      582    0.000    0.000    0.000    0.000 frame.py:361(_constructor)\n",
       "      270    0.000    0.000    0.004    0.000 managers.py:729(<lambda>)\n",
       "     1389    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "      196    0.000    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:74(_path_stat)\n",
       "      156    0.000    0.000    0.000    0.000 common.py:1118(is_datetime64_ns_dtype)\n",
       "     1498    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "     1727    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
       "     1053    0.000    0.000    0.000    0.000 format.py:1418(_is_number)\n",
       "       93    0.000    0.000    0.001    0.000 generic.py:337(_from_axes)\n",
       "      162    0.000    0.000    0.002    0.000 generic.py:1578(_is_label_or_level_reference)\n",
       "       27    0.000    0.000    0.002    0.000 ops.py:1502(na_op)\n",
       "       93    0.000    0.000    0.004    0.000 api.py:87(_get_combined_index)\n",
       "     1159    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
       "       18    0.000    0.000    0.000    0.000 function_base.py:1149(diff)\n",
       "      361    0.000    0.000    0.001    0.000 common.py:1513(is_string_like_dtype)\n",
       "      218    0.000    0.000    0.001    0.000 cast.py:552(coerce_indexer_dtype)\n",
       "     1019    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "       58    0.000    0.000    0.001    0.000 base.py:5408(default_index)\n",
       "       62    0.000    0.000    0.018    0.000 blocks.py:323(concat_same_type)\n",
       "      876    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
       "      193    0.000    0.000    0.001    0.000 indexing.py:2689(is_list_like_indexer)\n",
       "      163    0.000    0.000    0.002    0.000 base.py:3975(_can_hold_identifiers_and_holds_name)\n",
       "       68    0.000    0.000    0.010    0.000 construction.py:284(extract_index)\n",
       "      187    0.000    0.000    0.001    0.000 frame.py:491(shape)\n",
       "      106    0.000    0.000    0.000    0.000 common.py:212(dict_keys_to_ordered_list)\n",
       "       78    0.000    0.000    0.000    0.000 copy.py:66(copy)\n",
       "       58    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
       "       99    0.000    0.000    0.001    0.000 common.py:246(index_labels_to_array)\n",
       "       93    0.000    0.000    0.005    0.000 api.py:44(_get_objs_combined_axis)\n",
       "        9    0.000    0.000    0.003    0.000 format.py:1045(get_result_as_array)\n",
       "      143    0.000    0.000    0.000    0.000 config.py:78(_get_single_key)\n",
       "       81    0.000    0.000    0.000    0.000 blocks.py:1971(_can_hold_element)\n",
       "     1167    0.000    0.000    0.000    0.000 base.py:1396(nlevels)\n",
       "      225    0.000    0.000    0.000    0.000 frame.py:3416(_ensure_valid_index)\n",
       "      785    0.000    0.000    0.000    0.000 categorical.py:441(dtype)\n",
       "      156    0.000    0.000    0.008    0.000 numpy_.py:170(__array__)\n",
       "      196    0.000    0.000    0.000    0.000 managers.py:291(__len__)\n",
       "      280    0.000    0.000    0.000    0.000 base.py:3806(_coerce_to_ndarray)\n",
       "        9    0.000    0.000    0.002    0.000 format.py:1060(format_values_with)\n",
       "       34    0.000    0.000    0.014    0.000 {built-in method builtins.print}\n",
       "      721    0.000    0.000    0.000    0.000 numerictypes.py:587(<listcomp>)\n",
       "       72    0.000    0.000    0.000    0.000 sorting.py:124(is_int64_overflow_possible)\n",
       "       99    0.000    0.000    0.000    0.000 threading.py:1080(is_alive)\n",
       "        7    0.000    0.000    0.000    0.000 {method 'sendall' of '_socket.socket' objects}\n",
       "       86    0.000    0.000    0.000    0.000 inference.py:381(is_dict_like)\n",
       "       54    0.000    0.000    0.000    0.000 twodim_base.py:216(diag)\n",
       "      156    0.000    0.000    0.000    0.000 common.py:1167(is_timedelta64_ns_dtype)\n",
       "       56    0.000    0.000    0.000    0.000 _validators.py:325(validate_fillna_kwargs)\n",
       "      338    0.000    0.000    0.000    0.000 base.py:475(<genexpr>)\n",
       "       27    0.000    0.000    0.003    0.000 blocks.py:927(putmask)\n",
       "       81    0.000    0.000    0.167    0.002 socket.py:575(readinto)\n",
       "      648    0.000    0.000    0.000    0.000 missing.py:71(clean_fill_method)\n",
       "       87    0.000    0.000    0.013    0.000 dtypes.py:328(_finalize)\n",
       "      197    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1203(_path_importer_cache)\n",
       "      216    0.000    0.000    0.000    0.000 merge.py:1731(_should_fill)\n",
       "      288    0.000    0.000    0.000    0.000 common.py:273(maybe_make_list)\n",
       "       72    0.000    0.000    0.000    0.000 merge.py:1704(<lambda>)\n",
       "      175    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "      145    0.000    0.000    0.002    0.000 base.py:1672(is_integer)\n",
       "      145    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "       34    0.000    0.000    0.001    0.000 format.py:1407(<listcomp>)\n",
       "      165    0.000    0.000    0.001    0.000 base.py:1681(is_object)\n",
       "       72    0.000    0.000    0.000    0.000 generic.py:3115(_maybe_update_cacher)\n",
       "       55    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
       "      596    0.000    0.000    0.000    0.000 generic.py:1567(<listcomp>)\n",
       "       27    0.000    0.000    0.003    0.000 algorithms.py:1450(take)\n",
       "      434    0.000    0.000    0.000    0.000 generic.py:1693(<listcomp>)\n",
       "      256    0.000    0.000    0.000    0.000 base.py:5381(_ensure_has_len)\n",
       "      648    0.000    0.000    0.000    0.000 concat.py:137(<genexpr>)\n",
       "      100    0.000    0.000    0.156    0.002 _decorators.py:195(wrapper)\n",
       "       50    0.000    0.000    0.000    0.000 api.py:262(<setcomp>)\n",
       "       99    0.000    0.000    0.001    0.000 numeric.py:175(ones)\n",
       "       48    0.000    0.000    0.000    0.000 printing.py:59(<listcomp>)\n",
       "      416    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "      297    0.000    0.000    0.000    0.000 generic.py:3205(_check_setitem_copy)\n",
       "       27    0.000    0.000    0.005    0.000 categorical.py:1801(take_nd)\n",
       "       58    0.000    0.000    0.008    0.000 managers.py:530(astype)\n",
       "       27    0.000    0.000    0.001    0.000 categorical.py:2490(__init__)\n",
       "        1    0.000    0.000    0.010    0.010 format.py:503(_to_str_columns)\n",
       "       27    0.000    0.000    0.003    0.000 ops.py:1512(safe_na_op)\n",
       "      103    0.000    0.000    0.001    0.000 series.py:490(get_values)\n",
       "       27    0.000    0.000    0.003    0.000 <ipython-input-1041-adf066fa4b64>:54(make_parse_tree)\n",
       "      766    0.000    0.000    0.000    0.000 dtypes.py:555(categories)\n",
       "       29    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_object_object}\n",
       "      285    0.000    0.000    0.000    0.000 series.py:338(_constructor)\n",
       "       54    0.000    0.000    0.000    0.000 fromnumeric.py:1395(diagonal)\n",
       "      361    0.000    0.000    0.000    0.000 common.py:1542(<lambda>)\n",
       "       27    0.000    0.000    0.009    0.000 categorical.py:2517(_delegate_method)\n",
       "      188    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}\n",
       "       93    0.000    0.000    0.000    0.000 api.py:67(<listcomp>)\n",
       "        1    0.000    0.000    0.015    0.015 <ipython-input-1041-adf066fa4b64>:101(get_ref_ann)\n",
       "       56    0.000    0.000    0.007    0.000 managers.py:524(fillna)\n",
       "      284    0.000    0.000    0.000    0.000 config.py:561(_get_deprecated_option)\n",
       "       18    0.000    0.000    0.001    0.000 indexing.py:960(_getitem_lowerdim)\n",
       "      196    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:36(_relax_case)\n",
       "       26    0.000    0.000    0.009    0.000 managers.py:1988(_transform_index)\n",
       "      144    0.000    0.000    0.000    0.000 merge.py:1738(_any)\n",
       "      162    0.000    0.000    0.000    0.000 categorical.py:140(_maybe_to_categorical)\n",
       "      145    0.000    0.000    0.000    0.000 indexing.py:2676(is_nested_tuple)\n",
       "      100    0.000    0.000    0.000    0.000 common.py:199(count_not_none)\n",
       "       34    0.000    0.000    0.002    0.000 format.py:1384(_make_fixed_width)\n",
       "      253    0.000    0.000    0.000    0.000 inference.py:406(<genexpr>)\n",
       "      102    0.000    0.000    0.000    0.000 inference.py:470(is_sequence)\n",
       "       17    0.000    0.000    0.005    0.000 format.py:848(format_array)\n",
       "      141    0.000    0.000    0.000    0.000 config.py:546(_get_root)\n",
       "      186    0.000    0.000    0.001    0.000 concat.py:92(<genexpr>)\n",
       "      103    0.000    0.000    0.000    0.000 blocks.py:184(to_dense)\n",
       "      135    0.000    0.000    0.005    0.000 managers.py:730(<listcomp>)\n",
       "       99    0.000    0.000    0.000    0.000 {built-in method numpy.can_cast}\n",
       "      145    0.000    0.000    0.002    0.000 base.py:2999(_convert_arr_indexer)\n",
       "      108    0.000    0.000    0.000    0.000 base.py:4012(<setcomp>)\n",
       "       58    0.000    0.000    0.000    0.000 base.py:1736(is_all_dates)\n",
       "      410    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
       "       58    0.000    0.000    0.007    0.000 blocks.py:532(astype)\n",
       "       81    0.000    0.000    0.001    0.000 blocks.py:2051(should_store)\n",
       "      188    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "       22    0.000    0.000    0.002    0.000 range.py:272(_shallow_copy)\n",
       "      448    0.000    0.000    0.000    0.000 format.py:541(<genexpr>)\n",
       "       27    0.000    0.000    0.001    0.000 expressions.py:63(_evaluate_standard)\n",
       "       54    0.000    0.000    0.001    0.000 fromnumeric.py:1966(sum)\n",
       "      141    0.000    0.000    0.001    0.000 config.py:96(_get_option)\n",
       "       36    0.000    0.000    0.001    0.000 concat.py:481(_concat_index_same_dtype)\n",
       "       24    0.000    0.000    0.000    0.000 format.py:1422(<listcomp>)\n",
       "       25    0.000    0.000    0.001    0.000 frame.py:2829(_ixs)\n",
       "       54    0.000    0.000    0.001    0.000 blocks.py:709(_try_coerce_args)\n",
       "      216    0.000    0.000    0.001    0.000 merge.py:799(<lambda>)\n",
       "       82    0.000    0.000    0.000    0.000 iostream.py:307(_is_master_process)\n",
       "       57    0.000    0.000    0.000    0.000 api.py:205(_sanitize_and_check)\n",
       "      298    0.000    0.000    0.000    0.000 missing.py:259(notna)\n",
       "       50    0.000    0.000    0.000    0.000 api.py:243(_get_consensus_names)\n",
       "      192    0.000    0.000    0.000    0.000 _config.py:49(getter)\n",
       "       86    0.000    0.000    0.000    0.000 {built-in method numpy.bincount}\n",
       "       27    0.000    0.000    0.007    0.000 categorical.py:857(rename_categories)\n",
       "       36    0.000    0.000    0.001    0.000 base.py:1272(set_names)\n",
       "       72    0.000    0.000    0.000    0.000 merge.py:1011(_validate_specification)\n",
       "       27    0.000    0.000    0.001    0.000 sorting.py:407(safe_sort)\n",
       "       36    0.000    0.000    0.002    0.000 numeric.py:110(_concat_same_dtype)\n",
       "      135    0.000    0.000    0.000    0.000 managers.py:1098(<genexpr>)\n",
       "      213    0.000    0.000    0.000    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
       "       31    0.000    0.000    0.000    0.000 categorical.py:668(_get_codes)\n",
       "      880    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "       25    0.000    0.000    0.000    0.000 printing.py:55(<listcomp>)\n",
       "       72    0.000    0.000    0.007    0.000 base.py:4025(_concat_same_dtype)\n",
       "       27    0.000    0.000    0.001    0.000 indexing.py:2619(validate_indices)\n",
       "       54    0.000    0.000    0.000    0.000 blocks.py:1577(iget)\n",
       "      108    0.000    0.000    0.000    0.000 dtypes.py:120(__str__)\n",
       "      115    0.000    0.000    0.000    0.000 base.py:658(__array__)\n",
       "       72    0.000    0.000    0.002    0.000 generic.py:1765(<listcomp>)\n",
       "      118    0.000    0.000    0.000    0.000 range.py:89(ensure_int)\n",
       "      188    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:792(find_spec)\n",
       "       15    0.000    0.000    0.000    0.000 format.py:1427(<listcomp>)\n",
       "       27    0.000    0.000    0.011    0.000 <ipython-input-1040-49f2f221cb4b>:11(__init__)\n",
       "       27    0.000    0.000    0.006    0.000 categorical.py:425(categories)\n",
       "      101    0.000    0.000    0.000    0.000 generic.py:334(<dictcomp>)\n",
       "      420    0.000    0.000    0.000    0.000 blocks.py:161(external_values)\n",
       "      192    0.000    0.000    0.000    0.000 _config.py:140(get)\n",
       "       16    0.000    0.000    0.007    0.000 format.py:702(_format_col)\n",
       "      213    0.000    0.000    0.000    0.000 blocks.py:3146(<listcomp>)\n",
       "      169    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
       "       33    0.000    0.000    0.001    0.000 accessor.py:167(__get__)\n",
       "       90    0.000    0.000    0.000    0.000 ops.py:66(_maybe_match_name)\n",
       "       95    0.000    0.000    0.000    0.000 base.py:978(empty)\n",
       "      202    0.000    0.000    0.000    0.000 base.py:2249(_validate_sort_keyword)\n",
       "      140    0.000    0.000    0.000    0.000 series.py:591(__len__)\n",
       "       48    0.000    0.000    0.000    0.000 <ipython-input-1042-648145736ddf>:8(expressions)\n",
       "       60    0.000    0.000    0.000    0.000 dtypes.py:465(validate_ordered)\n",
       "       27    0.000    0.000    0.000    0.000 categorical.py:2596(_recode_for_categories)\n",
       "       42    0.000    0.000    0.027    0.001 managers.py:1796(_simple_blockify)\n",
       "      434    0.000    0.000    0.000    0.000 generic.py:1627(<listcomp>)\n",
       "       36    0.000    0.000    0.004    0.000 concat.py:531(_concat_indexes)\n",
       "      117    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
       "       99    0.000    0.000    0.000    0.000 base.py:143(__setattr__)\n",
       "      199    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "       55    0.000    0.000    0.001    0.000 cast.py:1123(cast_scalar_to_array)\n",
       "      520    0.000    0.000    0.000    0.000 numerictypes.py:655(<listcomp>)\n",
       "      189    0.000    0.000    0.000    0.000 categorical.py:1920(__len__)\n",
       "      186    0.000    0.000    0.001    0.000 concat.py:93(<genexpr>)\n",
       "      439    0.000    0.000    0.000    0.000 managers.py:1814(<lambda>)\n",
       "      145    0.000    0.000    0.001    0.000 _methods.py:34(_sum)\n",
       "      132    0.000    0.000    0.003    0.000 base.py:1580(is_monotonic)\n",
       "       93    0.000    0.000    0.000    0.000 common.py:162(_not_none)\n",
       "        6    0.000    0.000    0.003    0.000 strings.py:1854(_wrap_result)\n",
       "        9    0.000    0.000    0.001    0.000 format.py:1078(<listcomp>)\n",
       "       95    0.000    0.000    0.000    0.000 base.py:759(size)\n",
       "       27    0.000    0.000    0.005    0.000 blocks.py:1765(take_nd)\n",
       "        4    0.000    0.000    0.001    0.000 printing.py:15(adjoin)\n",
       "       56    0.000    0.000    0.001    0.000 base.py:1806(hasnans)\n",
       "      112    0.000    0.000    0.000    0.000 managers.py:1045(value_getitem)\n",
       "      494    0.000    0.000    0.000    0.000 dtypes.py:562(ordered)\n",
       "       54    0.000    0.000    0.000    0.000 {method 'diagonal' of 'numpy.ndarray' objects}\n",
       "       72    0.000    0.000    0.000    0.000 concat.py:503(<listcomp>)\n",
       "       87    0.000    0.000    0.013    0.000 dtypes.py:225(__init__)\n",
       "       81    0.000    0.000    0.000    0.000 blocks.py:1571(shape)\n",
       "       93    0.000    0.000    0.000    0.000 concat.py:434(_get_result_dim)\n",
       "      145    0.000    0.000    0.000    0.000 base.py:3035(_convert_list_indexer)\n",
       "      249    0.000    0.000    0.000    0.000 managers.py:376(<dictcomp>)\n",
       "      144    0.000    0.000    0.000    0.000 merge.py:1742(validate_operand)\n",
       "       99    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
       "      100    0.000    0.000    0.002    0.000 base.py:4071(identical)\n",
       "       72    0.000    0.000    0.001    0.000 generic.py:1775(<listcomp>)\n",
       "      106    0.000    0.000    0.000    0.000 construction.py:210(<listcomp>)\n",
       "      120    0.000    0.000    0.000    0.000 <ipython-input-1042-648145736ddf>:37(<genexpr>)\n",
       "       27    0.000    0.000    0.002    0.000 ops.py:1166(dispatch_to_index_op)\n",
       "      216    0.000    0.000    0.000    0.000 merge.py:800(<lambda>)\n",
       "       99    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "      447    0.000    0.000    0.000    0.000 format.py:1423(<genexpr>)\n",
       "       27    0.000    0.000    0.002    0.000 expressions.py:96(_evaluate_numexpr)\n",
       "       54    0.000    0.000    0.001    0.000 fromnumeric.py:2083(any)\n",
       "      162    0.000    0.000    0.000    0.000 blocks.py:1683(_maybe_coerce_values)\n",
       "       27    0.000    0.000    0.000    0.000 <ipython-input-1041-adf066fa4b64>:83(__init__)\n",
       "      244    0.000    0.000    0.000    0.000 common.py:183(_any_not_none)\n",
       "       72    0.000    0.000    0.000    0.000 concat.py:496(<listcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 format.py:1140(<listcomp>)\n",
       "       27    0.000    0.000    0.002    0.000 expressions.py:192(evaluate)\n",
       "       33    0.000    0.000    0.000    0.000 format.py:356(_get_formatter)\n",
       "        1    0.000    0.000    0.001    0.001 csvs.py:290(_save_chunk)\n",
       "       99    0.000    0.000    0.000    0.000 threading.py:1038(_wait_for_tstate_lock)\n",
       "      279    0.000    0.000    0.000    0.000 common.py:164(<genexpr>)\n",
       "      108    0.000    0.000    0.000    0.000 managers.py:1974(lrenamer)\n",
       "       29    0.000    0.000    0.000    0.000 construction.py:509(sanitize_index)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'close' of 'pandas._libs.parsers.TextReader' objects}\n",
       "        2    0.000    0.000    0.006    0.003 {_cython_magic_38d1145b1a6902525e6166a88bdde578.geometric_mean}\n",
       "       81    0.000    0.000    0.000    0.000 cast.py:473(maybe_infer_dtype_type)\n",
       "       72    0.000    0.000    0.001    0.000 generic.py:1778(<listcomp>)\n",
       "       93    0.000    0.000    0.000    0.000 concat.py:507(<listcomp>)\n",
       "       81    0.000    0.000    0.000    0.000 {method '_checkReadable' of '_io._IOBase' objects}\n",
       "       43    0.000    0.000    0.000    0.000 printing.py:156(pprint_thing)\n",
       "       36    0.000    0.000    0.000    0.000 base.py:1240(_set_names)\n",
       "       18    0.000    0.000    0.003    0.000 indexing.py:1485(__getitem__)\n",
       "        1    0.000    0.000    0.373    0.373 connections.py:1149(_read_result_packet)\n",
       "      694    0.000    0.000    0.000    0.000 {method 'ljust' of 'str' objects}\n",
       "       73    0.000    0.000    0.000    0.000 printing.py:50(justify)\n",
       "       82    0.000    0.000    0.000    0.000 iostream.py:320(_schedule_flush)\n",
       "      186    0.000    0.000    0.000    0.000 concat.py:97(<genexpr>)\n",
       "       40    0.000    0.000    0.000    0.000 range.py:330(equals)\n",
       "      108    0.000    0.000    0.000    0.000 blocks.py:1910(_ftype)\n",
       "        1    0.000    0.000    0.032    0.032 <ipython-input-1042-648145736ddf>:129(generate_ensemble_metrics)\n",
       "      300    0.000    0.000    0.000    0.000 common.py:201(<genexpr>)\n",
       "      125    0.000    0.000    0.000    0.000 managers.py:1850(_shape_compat)\n",
       "       54    0.000    0.000    0.002    0.000 blocks.py:213(make_block)\n",
       "      205    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
       "       12    0.000    0.000    0.000    0.000 concat.py:396(trim_join_unit)\n",
       "       16    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
       "       27    0.000    0.000    0.000    0.000 ops.py:101(maybe_upcast_for_op)\n",
       "      7/6    0.000    0.000    0.085    0.014 strings.py:62(_map)\n",
       "       43    0.000    0.000    0.000    0.000 printing.py:185(as_escaped_unicode)\n",
       "      170    0.000    0.000    0.000    0.000 concat.py:510(<genexpr>)\n",
       "        7    0.000    0.000    0.000    0.000 connections.py:744(_execute_command)\n",
       "       32    0.000    0.000    0.001    0.000 common.py:1320(is_datetimelike_v_numeric)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _warnings.warn}\n",
       "       27    0.000    0.000    0.002    0.000 ops.py:1468(_construct_result)\n",
       "      143    0.000    0.000    0.000    0.000 config.py:528(_select_options)\n",
       "      141    0.000    0.000    0.000    0.000 config.py:602(_warn_if_deprecated)\n",
       "        8    0.000    0.000    0.040    0.005 ops.py:1615(na_op)\n",
       "       86    0.000    0.000    0.000    0.000 base.py:4683(_maybe_cast_indexer)\n",
       "       58    0.000    0.000    0.000    0.000 blocks.py:146(is_categorical_astype)\n",
       "      420    0.000    0.000    0.000    0.000 format.py:1424(<genexpr>)\n",
       "        6    0.000    0.000    0.000    0.000 common.py:120(_stringify_path)\n",
       "       54    0.000    0.000    0.001    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "       27    0.000    0.000    0.009    0.000 accessor.py:90(f)\n",
       "       27    0.000    0.000    0.000    0.000 blocks.py:1592(set)\n",
       "      228    0.000    0.000    0.000    0.000 managers.py:1578(_consolidate_inplace)\n",
       "       36    0.000    0.000    0.000    0.000 binaryTree.py:22(insertLeft)\n",
       "       27    0.000    0.000    0.000    0.000 <ipython-input-1041-adf066fa4b64>:62(preprocess_sentence)\n",
       "      252    0.000    0.000    0.000    0.000 format.py:1107(<genexpr>)\n",
       "       99    0.000    0.000    0.000    0.000 binaryTree.py:17(__init__)\n",
       "       27    0.000    0.000    0.001    0.000 {built-in method _operator.ne}\n",
       "       71    0.000    0.000    0.001    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "      141    0.000    0.000    0.001    0.000 config.py:226(__call__)\n",
       "       36    0.000    0.000    0.001    0.000 base.py:1346(rename)\n",
       "      114    0.000    0.000    0.000    0.000 managers.py:1513(index)\n",
       "       24    0.000    0.000    0.001    0.000 format.py:1421(_cond)\n",
       "       27    0.000    0.000    0.000    0.000 expressions.py:173(_bool_arith_check)\n",
       "       10    0.000    0.000    0.088    0.009 <ipython-input-1038-eb2ea29a5c5f>:52(<lambda>)\n",
       "      216    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "       57    0.000    0.000    0.000    0.000 api.py:226(<setcomp>)\n",
       "       36    0.000    0.000    0.000    0.000 indexing.py:2056(_validate_key)\n",
       "       81    0.000    0.000    0.000    0.000 socket.py:614(readable)\n",
       "      143    0.000    0.000    0.000    0.000 config.py:589(_translate_key)\n",
       "       99    0.000    0.000    0.000    0.000 base.py:3072(_can_reindex)\n",
       "       20    0.000    0.000    0.000    0.000 range.py:180(_int64index)\n",
       "       18    0.000    0.000    0.000    0.000 indexing.py:217(_has_valid_tuple)\n",
       "      145    0.000    0.000    0.000    0.000 indexing.py:937(_convert_for_reindex)\n",
       "       18    0.000    0.000    0.002    0.000 indexing.py:2205(_getitem_axis)\n",
       "       31    0.000    0.000    0.000    0.000 blocks.py:2011(should_store)\n",
       "        1    0.000    0.000    0.030    0.030 {pandas._libs.reduction.reduce}\n",
       "       27    0.000    0.000    0.001    0.000 blocks.py:391(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 protocol.py:283(__init__)\n",
       "      188    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:719(find_spec)\n",
       "      186    0.000    0.000    0.000    0.000 concat.py:383(<genexpr>)\n",
       "        9    0.000    0.000    0.000    0.000 format.py:1430(<listcomp>)\n",
       "       99    0.000    0.000    0.000    0.000 stack.py:14(push)\n",
       "       27    0.000    0.000    0.000    0.000 {method 'map_locations' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
       "       18    0.000    0.000    0.000    0.000 indexing.py:2089(_is_scalar_access)\n",
       "       12    0.000    0.000    0.000    0.000 parse.py:109(_coerce_args)\n",
       "      156    0.000    0.000    0.000    0.000 common.py:1195(<lambda>)\n",
       "       72    0.000    0.000    0.000    0.000 base.py:100(_reset_cache)\n",
       "       28    0.000    0.000    0.000    0.000 ops.py:1447(_align_method_SERIES)\n",
       "        2    0.000    0.000    0.007    0.003 managers.py:159(rename_axis)\n",
       "       99    0.000    0.000    0.000    0.000 binaryTree.py:53(setRootVal)\n",
       "        1    0.000    0.000    0.105    0.105 apply.py:228(apply_standard)\n",
       "       27    0.000    0.000    0.000    0.000 common.py:784(is_dtype_union_equal)\n",
       "       36    0.000    0.000    0.000    0.000 concat.py:483(<listcomp>)\n",
       "       18    0.000    0.000    0.003    0.000 indexing.py:2141(_getitem_tuple)\n",
       "       72    0.000    0.000    0.000    0.000 managers.py:1979(rrenamer)\n",
       "      189    0.000    0.000    0.000    0.000 format.py:1139(<lambda>)\n",
       "       96    0.000    0.000    0.000    0.000 binaryTree.py:56(getRootVal)\n",
       "       99    0.000    0.000    0.000    0.000 stack.py:17(pop)\n",
       "       54    0.000    0.000    0.000    0.000 categorical.py:434(ordered)\n",
       "       36    0.000    0.000    0.000    0.000 binaryTree.py:34(insertRight)\n",
       "       27    0.000    0.000    0.000    0.000 expressions.py:163(_has_bool_dtype)\n",
       "        1    0.000    0.000    0.059    0.059 apply.py:262(apply_series_generator)\n",
       "      172    0.000    0.000    0.000    0.000 fromnumeric.py:2847(ndim)\n",
       "       73    0.000    0.000    0.000    0.000 format.py:304(justify)\n",
       "       81    0.000    0.000    0.000    0.000 {method '_checkClosed' of '_io._IOBase' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "       58    0.000    0.000    0.000    0.000 inspect.py:72(isclass)\n",
       "       36    0.000    0.000    0.000    0.000 function_base.py:258(iterable)\n",
       "       27    0.000    0.000    0.000    0.000 categorical.py:2497(_validate)\n",
       "       56    0.000    0.000    0.000    0.000 categorical.py:394(categories)\n",
       "        1    0.000    0.000    5.443    5.443 <ipython-input-1042-648145736ddf>:156(ensemble_control)\n",
       "       54    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}\n",
       "        5    0.000    0.000    0.000    0.000 blocks.py:1982(to_native_types)\n",
       "       27    0.000    0.000    0.000    0.000 format.py:945(_format)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:1343(_handle_dbapi_exception)\n",
       "      298    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
       "       71    0.000    0.000    0.000    0.000 _methods.py:26(_amax)\n",
       "      108    0.000    0.000    0.000    0.000 dtypes.py:117(__unicode__)\n",
       "      108    0.000    0.000    0.000    0.000 categorical.py:452(_constructor)\n",
       "        6    0.000    0.000    0.001    0.000 generic.py:8324(ranker)\n",
       "       21    0.000    0.000    0.001    0.000 range.py:176(_data)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:931(_format_strings)\n",
       "       54    0.000    0.000    0.000    0.000 categorical.py:496(ndim)\n",
       "        1    0.000    0.000    0.001    0.001 sorting.py:189(lexsort_indexer)\n",
       "        1    0.000    0.000    0.009    0.009 generic.py:960(rename)\n",
       "       18    0.000    0.000    0.000    0.000 indexing.py:229(_is_nested_tuple_indexer)\n",
       "       62    0.000    0.000    0.000    0.000 managers.py:2058(<listcomp>)\n",
       "       17    0.000    0.000    0.005    0.000 format.py:927(get_result)\n",
       "      115    0.000    0.000    0.000    0.000 printing.py:62(_join_unicode)\n",
       "       31    0.000    0.000    0.000    0.000 common.py:1752(is_complex_dtype)\n",
       "        7    0.000    0.000    0.040    0.006 ops.py:1591(_comp_method_OBJECT_ARRAY)\n",
       "       12    0.000    0.000    0.000    0.000 base.py:1096(tolist)\n",
       "       10    0.000    0.000    0.000    0.000 protocol.py:180(read_struct)\n",
       "        2    0.000    0.000    0.539    0.270 base.py:1163(_execute_context)\n",
       "       82    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
       "       54    0.000    0.000    0.000    0.000 _methods.py:30(_amin)\n",
       "       59    0.000    0.000    0.000    0.000 common.py:175(_all_none)\n",
       "       18    0.000    0.000    0.000    0.000 format.py:338(_get_adjustment)\n",
       "        1    0.000    0.000    0.257    0.257 parsers.py:1993(read)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:1213(_get_descriptions)\n",
       "      132    0.000    0.000    0.000    0.000 binaryTree.py:47(getRightChild)\n",
       "        1    0.000    0.000    5.443    5.443 <ipython-input-1045-197799a2f9a3>:2(main)\n",
       "       28    0.000    0.000    0.001    0.000 base.py:1785(_isnan)\n",
       "       13    0.000    0.000    0.001    0.000 generic.py:178(_validate_dtype)\n",
       "       27    0.000    0.000    0.000    0.000 blocks.py:1589(should_store)\n",
       "        2    0.000    0.000    0.000    0.000 _methods.py:58(_mean)\n",
       "       59    0.000    0.000    0.000    0.000 range.py:165(_validate_dtype)\n",
       "       32    0.000    0.000    0.000    0.000 indexing.py:2116(_validate_integer)\n",
       "        7    0.000    0.000    0.000    0.000 connections.py:710(_write_bytes)\n",
       "       27    0.000    0.000    0.000    0.000 stack.py:8(__init__)\n",
       "      132    0.000    0.000    0.000    0.000 binaryTree.py:50(getLeftChild)\n",
       "        1    0.000    0.000    5.443    5.443 {built-in method builtins.exec}\n",
       "        6    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "       99    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
       "        6    0.000    0.000    0.088    0.015 strings.py:2723(strip)\n",
       "       54    0.000    0.000    0.000    0.000 indexing.py:1487(<genexpr>)\n",
       "       27    0.000    0.000    0.000    0.000 blocks.py:1706(fill_value)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:651(<listcomp>)\n",
       "       17    0.000    0.000    0.000    0.000 format.py:912(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 apply.py:325(<genexpr>)\n",
       "      101    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "        2    0.000    0.000    0.018    0.009 sorting.py:366(compress_group_index)\n",
       "       54    0.000    0.000    0.000    0.000 base.py:540(_constructor)\n",
       "        6    0.000    0.000    0.000    0.000 strings.py:1795(__init__)\n",
       "       62    0.000    0.000    0.000    0.000 blocks.py:327(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 format.py:739(_get_formatted_column_labels)\n",
       "        1    0.000    0.000    0.006    0.006 construction.py:429(_list_to_arrays)\n",
       "      148    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
       "       96    0.000    0.000    0.000    0.000 timeout.py:260(_start_new_or_dummy)\n",
       "        2    0.000    0.000    0.001    0.001 generic.py:3155(_slice)\n",
       "        6    0.000    0.000    0.001    0.000 api.py:154(_unique_indices)\n",
       "       54    0.000    0.000    0.000    0.000 {method 'append' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "        4    0.000    0.000    0.000    0.000 protocol.py:237(_parse_field_descriptor)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:748(_checkout)\n",
       "        1    0.000    0.000    0.008    0.008 csvs.py:130(save)\n",
       "       27    0.000    0.000    0.000    0.000 <ipython-input-1040-49f2f221cb4b>:10(Results)\n",
       "        6    0.000    0.000    0.000    0.000 _bootlocale.py:33(getpreferredencoding)\n",
       "       39    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "       72    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {pandas._libs.lib.fast_unique_multiple_list}\n",
       "       54    0.000    0.000    0.000    0.000 indexing.py:230(<genexpr>)\n",
       "       16    0.000    0.000    0.000    0.000 managers.py:1552(formatting_values)\n",
       "        1    0.000    0.000    0.001    0.001 format.py:642(_join_multiline)\n",
       "        9    0.000    0.000    0.003    0.000 format.py:1128(_format_strings)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:3600(_reduce)\n",
       "       36    0.000    0.000    0.000    0.000 concat.py:523(_maybe_check_integrity)\n",
       "        5    0.000    0.000    0.001    0.000 connections.py:393(_read_ok_packet)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:123(_join)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:69(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 csvs.py:30(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 csvs.py:191(_save_header)\n",
       "        6    0.000    0.000    0.000    0.000 parse.py:361(urlparse)\n",
       "       96    0.000    0.000    0.000    0.000 timeout.py:56(stop)\n",
       "        6    0.000    0.000    0.085    0.014 strings.py:57(_na_map)\n",
       "        9    0.000    0.000    0.001    0.000 format.py:1412(_trim_zeros)\n",
       "        1    0.000    0.000    0.302    0.302 parsers.py:536(parser_f)\n",
       "        6    0.000    0.000    0.000    0.000 parse.py:409(urlsplit)\n",
       "       33    0.000    0.000    0.000    0.000 base.py:138(_freeze)\n",
       "        6    0.000    0.000    0.000    0.000 strings.py:1805(_validate)\n",
       "        6    0.000    0.000    0.001    0.000 generic.py:8282(rank)\n",
       "       36    0.000    0.000    0.000    0.000 indexing.py:2695(is_label_like)\n",
       "        1    0.000    0.000    0.298    0.298 parsers.py:1137(read)\n",
       "       12    0.000    0.000    0.000    0.000 apipkg.py:133(__makeattr)\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:35(_formatwarnmsg_impl)\n",
       "       20    0.000    0.000    0.000    0.000 common.py:279(is_null_slice)\n",
       "        1    0.000    0.000    0.002    0.002 frame.py:4695(sort_values)\n",
       "       12    0.000    0.000    0.000    0.000 api.py:168(conv)\n",
       "        4    0.000    0.000    0.001    0.000 format.py:307(adjoin)\n",
       "        1    0.000    0.000    0.011    0.011 format.py:582(to_string)\n",
       "        2    0.000    0.000    0.000    0.000 stats.py:256(gmean)\n",
       "       57    0.000    0.000    0.000    0.000 managers.py:1572(is_consolidated)\n",
       "       18    0.000    0.000    0.000    0.000 format.py:298(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:1553(_binify)\n",
       "        4    0.000    0.000    0.005    0.001 construction.py:495(convert)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:3466(apply)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:956(_clean_options)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1352(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 queue.py:135(get)\n",
       "        1    0.000    0.000    0.004    0.004 apply.py:336(wrap_results_for_axis)\n",
       "        4    0.000    0.000    0.000    0.000 <ipython-input-1042-648145736ddf>:2(partly_unordered_permutations)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:998(_format_with_header)\n",
       "        1    0.000    0.000    0.011    0.011 frame.py:678(to_string)\n",
       "        9    0.000    0.000    0.000    0.000 format.py:992(__init__)\n",
       "        1    0.000    0.000    0.006    0.006 common.py:314(_get_handle)\n",
       "        1    0.000    0.000    0.000    0.000 schema.py:3753(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:481(checkout)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:845(_reset)\n",
       "        2    0.000    0.000    0.000    0.000 queue.py:92(put)\n",
       "        3    0.000    0.000    0.001    0.000 base.py:2223(do_rollback)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:335(notify)\n",
       "       78    0.000    0.000    0.000    0.000 base.py:704(ndim)\n",
       "        2    0.000    0.000    0.000    0.000 nanops.py:203(_get_values)\n",
       "        1    0.000    0.000    0.008    0.008 generic.py:2882(to_csv)\n",
       "       27    0.000    0.000    0.000    0.000 blocks.py:477(_maybe_downcast)\n",
       "        2    0.000    0.000    0.000    0.000 blocks.py:730(to_native_types)\n",
       "        3    0.000    0.000    0.011    0.004 managers.py:736(as_array)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:769(<listcomp>)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:94(_expand_user)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:900(_get_options_with_defaults)\n",
       "        1    0.000    0.000    0.000    0.000 exc.py:390(instance)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:645(_finalize_fairy)\n",
       "        2    0.000    0.000    0.000    0.000 default.py:862(_init_statement)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _operator.and_}\n",
       "        6    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:1815(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 algorithms.py:835(rank)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:5457(dtypes)\n",
       "       16    0.000    0.000    0.001    0.000 indexing.py:143(_get_loc)\n",
       "        2    0.000    0.000    0.001    0.001 managers.py:684(get_slice)\n",
       "        3    0.000    0.000    0.000    0.000 common.py:260(_infer_compression)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:507(checkin)\n",
       "        1    0.000    0.000    0.000    0.000 sorting.py:339(get_group_index_sorter)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1050(_format_native_types)\n",
       "        1    0.000    0.000    0.011    0.011 frame.py:614(__unicode__)\n",
       "       27    0.000    0.000    0.000    0.000 format.py:943(<lambda>)\n",
       "        7    0.000    0.000    0.000    0.000 format.py:1138(_format_strings)\n",
       "        1    0.000    0.000    0.011    0.011 construction.py:382(to_arrays)\n",
       "        3    0.000    0.000    0.001    0.000 connections.py:422(rollback)\n",
       "        1    0.000    0.000    0.001    0.001 csvs.py:272(_save)\n",
       "        1    0.000    0.000    0.105    0.105 apply.py:109(get_result)\n",
       "        7    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method now}\n",
       "        1    0.000    0.000    0.001    0.001 ops.py:1817(wrapper)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:1010(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 managers.py:147(set_axis)\n",
       "       27    0.000    0.000    0.000    0.000 blocks.py:2941(_holder)\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:813(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1502(_maybe_dedup_names)\n",
       "        1    0.000    0.000    0.515    0.515 sql.py:1055(read_query)\n",
       "        2    0.000    0.000    0.539    0.269 connections.py:508(query)\n",
       "        2    0.000    0.000    0.539    0.269 connections.py:1073(read)\n",
       "        2    0.000    0.000    0.539    0.270 base.py:1138(_execute_text)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:2223(_contextual_connect)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:215(__init__)\n",
       "        1    0.000    0.000    0.043    0.043 base.py:2312(has_table)\n",
       "        1    0.000    0.000    0.000    0.000 pymysql.py:64(is_disconnect)\n",
       "       27    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
       "        1    0.000    0.000    0.000    0.000 sorting.py:387(_reorder_by_uniques)\n",
       "        6    0.000    0.000    0.000    0.000 generic.py:277(_construct_axes_dict)\n",
       "        3    0.000    0.000    0.011    0.004 generic.py:5250(values)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:381(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 format.py:535(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:179(get_filepath_or_buffer)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:869(close)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'unpack_from' of 'Struct' objects}\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
       "       27    0.000    0.000    0.000    0.000 missing.py:534(fill_zeros)\n",
       "        6    0.000    0.000    0.085    0.014 strings.py:1504(str_strip)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:76(_is_url)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:271(_init_dict)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _csv.writer}\n",
       "       16    0.000    0.000    0.000    0.000 series.py:483(_formatting_values)\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:1120(_make_engine)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1180(_is_potential_multi_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1926(close)\n",
       "        1    0.000    0.000    0.000    0.000 err.py:100(raise_mysql_exception)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:532(ping)\n",
       "        2    0.000    0.000    0.000    0.000 cursors.py:116(_escape_args)\n",
       "        8    0.000    0.000    0.000    0.000 protocol.py:264(get_column_length)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:77(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 attr.py:267(__bool__)\n",
       "        8    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:419(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.where}\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.groupsort_indexer}\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1024(to_native_types)\n",
       "       30    0.000    0.000    0.000    0.000 base.py:5398(<genexpr>)\n",
       "        1    0.000    0.000    0.105    0.105 frame.py:6310(apply)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:11018(logical_func)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:648(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:801(_get_formatted_index)\n",
       "        9    0.000    0.000    0.000    0.000 format.py:1004(_value_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:544(UnicodeWriter)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'writerow' of '_csv.writer' objects}\n",
       "        1    0.000    0.000    0.000    0.000 sql.py:972(__init__)\n",
       "        2    0.000    0.000    0.539    0.269 connections.py:720(_read_query_result)\n",
       "        2    0.000    0.000    0.539    0.269 cursors.py:151(execute)\n",
       "       11    0.000    0.000    0.000    0.000 protocol.py:186(is_ok_packet)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:729(_rollback_impl)\n",
       "        1    0.000    0.000    0.043    0.043 base.py:2133(run_callable)\n",
       "        2    0.000    0.000    0.000    0.000 log.py:59(_should_log_info)\n",
       "        2    0.000    0.000    0.000    0.000 impl.py:111(_do_get)\n",
       "        5    0.000    0.000    0.000    0.000 result.py:560(_merge_cols_by_none)\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:20(_showwarnmsg_impl)\n",
       "        1    0.000    0.000    0.000    0.000 console.py:47(get_console_size)\n",
       "       27    0.000    0.000    0.000    0.000 dtypes.py:234(_from_categorical_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 cast.py:1072(find_common_type)\n",
       "        8    0.000    0.000    0.000    0.000 base.py:2238(_get_reconciled_name_object)\n",
       "        6    0.000    0.000    0.000    0.000 generic.py:279(<dictcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 api.py:174(<listcomp>)\n",
       "        2    0.000    0.000    0.001    0.001 indexing.py:2170(_get_slice_axis)\n",
       "       16    0.000    0.000    0.000    0.000 blocks.py:171(formatting_values)\n",
       "       27    0.000    0.000    0.000    0.000 blocks.py:721(_try_coerce_result)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:225(get_dtypes)\n",
       "       27    0.000    0.000    0.000    0.000 managers.py:1035(value_getitem)\n",
       "        1    0.000    0.000    0.000    0.000 sql.py:115(_parse_date_columns)\n",
       "        1    0.000    0.000    0.000    0.000 sql.py:508(pandasSQL_builder)\n",
       "        2    0.000    0.000    0.539    0.269 cursors.py:324(_query)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:308(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 langhelpers.py:852(__get__)\n",
       "        1    0.000    0.000    0.000    0.000 exc.py:462(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:483(_cached_result_processor)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:295(__get__)\n",
       "        2    0.000    0.000    0.539    0.270 base.py:922(execute)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:345(connect)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:831(_checkin)\n",
       "        5    0.000    0.000    0.000    0.000 result.py:461(_colnames_from_description)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:588(_key_fallback)\n",
       "        1    0.000    0.000    0.002    0.002 result.py:1195(fetchall)\n",
       "        2    0.000    0.000    0.539    0.269 default.py:551(do_execute)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:16(frame_apply)\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:96(_showwarnmsg)\n",
       "        4    0.000    0.000    0.000    0.000 printing.py:36(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 console.py:149(in_ipython_frontend)\n",
       "        1    0.000    0.000    0.000    0.000 sorting.py:177(indexer_from_factorized)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:5393(_trim_front)\n",
       "        1    0.000    0.000    0.009    0.009 frame.py:3942(rename)\n",
       "        2    0.000    0.000    0.000    0.000 indexing.py:264(_convert_slice_indexer)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:226(<listcomp>)\n",
       "        1    0.000    0.000    0.005    0.005 construction.py:484(_convert_object_array)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1936(_set_noconvert_columns)\n",
       "        1    0.000    0.000    0.043    0.043 sql.py:1197(has_table)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:1053(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 cursors.py:40(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 cursors.py:135(mogrify)\n",
       "        1    0.000    0.000    0.000    0.000 cursors.py:341(_do_get_result)\n",
       "        5    0.000    0.000    0.000    0.000 protocol.py:77(read_all)\n",
       "        6    0.000    0.000    0.000    0.000 protocol.py:86(advance)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:122(read_uint16)\n",
       "        4    0.000    0.000    0.000    0.000 protocol.py:233(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 protocol.py:297(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 compat.py:123(reraise)\n",
       "        1    0.000    0.000    0.000    0.000 exc.py:328(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:261(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:183(execution_options)\n",
       "        2    0.000    0.000    0.000    0.000 log.py:56(_should_log_debug)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:366(_return_conn)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:441(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:869(_soft_close)\n",
       "        2    0.000    0.000    0.000    0.000 default.py:1002(_use_server_side_cursor)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:1174(should_autocommit_text)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:323(series_generator)\n",
       "       20    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
       "        6    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 weakref.py:395(__getitem__)\n",
       "        2    0.000    0.000    0.000    0.000 linecache.py:37(getlines)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 config.py:170(get_default_val)\n",
       "       24    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_float64}\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2897(_convert_slice_indexer)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:4698(_validate_indexer)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:606(_info_repr)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:431(_chk_truncate)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:789(show_row_idx_names)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1329(_validate_parse_dates_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1814(_do_date_conversions)\n",
       "        1    0.000    0.000    0.000    0.000 sql.py:45(_is_sqlalchemy_connectable)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:481(cursor)\n",
       "        4    0.000    0.000    0.000    0.000 cursors.py:89(_nextset)\n",
       "        4    0.000    0.000    0.000    0.000 cursors.py:106(nextset)\n",
       "        4    0.000    0.000    0.000    0.000 protocol.py:253(description)\n",
       "        2    0.000    0.000    0.000    0.000 _collections.py:140(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 schema.py:4027(_bind_to)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1327(_safe_close_cursor)\n",
       "        1    0.000    0.000    0.497    0.497 base.py:2149(execute)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:580(get_connection)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:714(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:740(_init_metadata)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:947(should_autocommit)\n",
       "        2    0.000    0.000    0.000    0.000 default.py:1034(create_cursor)\n",
       "        4    0.000    0.000    0.000    0.000 default.py:1051(get_result_processor)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:1092(get_result_proxy)\n",
       "        2    0.000    0.000    0.000    0.000 mysqldb.py:120(do_ping)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:36(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 apply.py:89(columns)\n",
       "        1    0.000    0.000    0.011    0.011 apply.py:97(values)\n",
       "        1    0.000    0.000    0.004    0.004 apply.py:302(wrap_results)\n",
       "        2    0.000    0.000    0.000    0.000 <ipython-input-1025-01a4bf55ac48>:14(corpus_config)\n",
       "        3    0.000    0.000    0.000    0.000 <ipython-input-1025-01a4bf55ac48>:9(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 re.py:271(_compile)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:1619(isEnabledFor)\n",
       "        6    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 _methods.py:48(_count_reduce_items)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:227(itervalues)\n",
       "        1    0.000    0.000    0.011    0.011 base.py:48(__str__)\n",
       "        2    0.000    0.000    0.000    0.000 nanops.py:337(nanany)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:983(format)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:5399(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:4710(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:3110(_is_view)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:627(is_view)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:816(<listcomp>)\n",
       "        1    0.000    0.000    0.005    0.005 construction.py:501(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:3735(reindex)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:4209(isnull)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:347(_validate_integer)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:897(close)\n",
       "        6    0.000    0.000    0.000    0.000 parsers.py:1195(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 cursors.py:51(close)\n",
       "        9    0.000    0.000    0.000    0.000 cursors.py:71(_get_db)\n",
       "        1    0.000    0.000    0.000    0.000 deprecations.py:117(warned)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:116(_for_class)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:364(invalidated)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:865(_autorollback)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:987(close)\n",
       "        2    0.000    0.000    0.000    0.000 impl.py:102(_do_return_conn)\n",
       "        2    0.000    0.000    0.000    0.000 queue.py:195(_full)\n",
       "        2    0.000    0.000    0.000    0.000 queue.py:199(_put)\n",
       "        2    0.000    0.000    0.000    0.000 queue.py:203(_get)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:334(_merge_cursor_description)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2057(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2260(is_disconnect)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:101(dtypes)\n",
       "        1    0.000    0.000    5.443    5.443 <string>:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:186(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 warnings.py:117(_formatwarnmsg)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:180(search)\n",
       "        2    0.000    0.000    0.000    0.000 linecache.py:15(getline)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _struct.unpack_from}\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:83(clear_cache)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'timestamp' of 'datetime.datetime' objects}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:125(lrange)\n",
       "        1    0.000    0.000    0.000    0.000 console.py:90(in_interactive_session)\n",
       "        1    0.000    0.000    0.000    0.000 inference.py:160(is_file_like)\n",
       "        2    0.000    0.000    0.000    0.000 function.py:40(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1787(na_op)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:464(f)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:457(_get_rename_function)\n",
       "        2    0.000    0.000    0.000    0.000 nanops.py:270(_na_ok_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:637(_set_axis)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:1818(__iter__)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:1904(__array__)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:5337(get_values)\n",
       "        2    0.000    0.000    0.000    0.000 range.py:184(_get_data_as_items)\n",
       "        2    0.000    0.000    0.001    0.001 indexing.py:148(_slice)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:604(is_mixed_type)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1884(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1868(_interleaved_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:781(has_index_names)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1536(_make_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2066(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3195(_process_date_conversion)\n",
       "        1    0.000    0.000    0.497    0.497 sql.py:988(execute)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:1069(__del__)\n",
       "        1    0.000    0.000    0.000    0.000 cursors.py:299(fetchall)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:94(rewind)\n",
       "        1    0.000    0.000    0.000    0.000 exc.py:24(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:59(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 compat.py:378(raise_from_cause)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:119(_for_instance)\n",
       "        2    0.000    0.000    0.000    0.000 attr.py:255(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:169(_clone)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:180(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:355(closed)\n",
       "        1    0.000    0.000    0.043    0.043 base.py:1591(run_callable)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:2259(_wrap_pool_connect)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:3425(_escape_identifier)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:3464(quote_identifier)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:949(cursor)\n",
       "        2    0.000    0.000    0.000    0.000 queue.py:191(_empty)\n",
       "        1    0.000    0.000    0.002    0.002 result.py:1178(process_rows)\n",
       "        2    0.000    0.000    0.000    0.000 default.py:943(no_parameters)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2054(_quote_free_identifiers)\n",
       "        2    0.000    0.000    0.000    0.000 pymysql.py:76(_extract_error_code)\n",
       "        8    0.000    0.000    0.000    0.000 csvs.py:112(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:93(index)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:105(agg_axis)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "       12    0.000    0.000    0.000    0.000 parse.py:98(_noop)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:394(_checknetloc)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method sqlalchemy.cutils._distill_params}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'put' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 cast.py:1097(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 cast.py:1105(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 cast.py:1107(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1832(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:4077(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:7600(_get_agg_axis)\n",
       "        2    0.000    0.000    0.000    0.000 blocks.py:136(is_view)\n",
       "        2    0.000    0.000    0.000    0.000 indexing.py:2700(need_slice)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.internals.slice_len}\n",
       "        1    0.000    0.000    0.000    0.000 format.py:785(has_column_names)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:795(show_col_idx_names)\n",
       "        3    0.000    0.000    0.000    0.000 format.py:1434(_has_names)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:112(_validate_header_arg)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:163(is_s3_url)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:171(is_gcs_url)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:939(_check_file_or_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1162(_create_index)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1176(_is_index_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1274(_validate_usecols_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1423(_has_complex_date_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2064(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3157(_make_date_converter)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3278(_clean_na_values)\n",
       "        1    0.000    0.000    0.000    0.000 sql.py:490(_engine_builder)\n",
       "        2    0.000    0.000    0.000    0.000 cursors.py:127(<dictcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 cursors.py:332(_clear_result)\n",
       "        1    0.000    0.000    0.000    0.000 cursors.py:355(_show_warnings)\n",
       "        2    0.000    0.000    0.000    0.000 _collections.py:145(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 _collections.py:151(union)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:56(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:62(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:4322(_string_or_unprintable)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:370(connection)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:709(in_transaction)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:715(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:875(is_valid)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:958(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:263(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:266(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:760(keys)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:1161(_fetchall_impl)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:477(set_connection_execution_options)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:1108(_setup_crud_result_proxy)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:332(result_columns)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'with_traceback' of 'BaseException' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method '_is_owned' of '_thread.RLock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:698(get_ipython)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:275(u)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(is_platform_windows)\n",
       "        2    0.000    0.000    0.000    0.000 config.py:578(_get_registered_option)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:1100(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:1112(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 nanops.py:180(_get_fill_value)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:3867(_has_complex_internals)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:7083(isnull)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:351(should_show_dimensions)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:377(_validate_names)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:1530(_maybe_make_multi_index_columns)\n",
       "        1    0.000    0.000    0.000    0.000 sql.py:74(_convert_params)\n",
       "        1    0.000    0.000    0.000    0.000 sql.py:85(_process_parse_dates_argument)\n",
       "        1    0.000    0.000    0.000    0.000 cursors.py:76(_check_executed)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:208(is_load_local_packet)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:4139(__new__)\n",
       "        5    0.000    0.000    0.000    0.000 base.py:155(_root)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:177(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:479(_still_open_and_connection_is_valid)\n",
       "        1    0.000    0.000    0.000    0.000 result.py:864(_cursor_description)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:1089(handle_dbapi_exception)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:328(result_index)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "def main():\n",
    "    '''\n",
    "        corpora: i2b2, mipacq, fv017\n",
    "        analyses: entity only (exact span), cui by document, full (aka (entity and cui on exaact span/exact cui)\n",
    "        systems: ctakes, biomedicus, clamp, metamap, quick_umls\n",
    "        \n",
    "        TODO -> Vectorization (entity only) -> done:\n",
    "                add switch for use of TN on single system performance evaluations -> done\n",
    "                add switch for overlap matching versus exact span -> done\n",
    "             -> Other tasks besides concept extraction\n",
    "        \n",
    "    ''' \n",
    "    analysisConf =  AnalysisConfig()\n",
    "    print(analysisConf.systems, analysisConf.corpus_config())\n",
    "    \n",
    "    if (rtype == 1):\n",
    "        generate_metrics(analysis_type, corpus, filter_semtype)\n",
    "    elif (rtype == 2):\n",
    "        print('run_type:', run_type)\n",
    "        # TODO -> list of corpora!\n",
    "#         for corpus in corpora: \n",
    "#             table_name = ref_data(corpus)\n",
    "#             system_annotation = sys_data(corpus)\n",
    "#             semtypes = ref_semtypes(filter_semtype, corpus)\n",
    "#             analysisConf =  AnalysisConfig()\n",
    "#             usys, ref = analysisConf.corpus_config(system_annotation, table_name)\n",
    "#             print('Using:', usys, ref)\n",
    "        if filter_semtype:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype)\n",
    "    elif (rtype == 3):\n",
    "        t = ['concept_jaccard_score_false']\n",
    "        test_systems(analysis_type, analysisConf.systems, corpus)  \n",
    "        test_count(analysis_type, corpus)\n",
    "        test_ensemble(analysis_type, corpus)\n",
    "    elif (rtype == 4):\n",
    "        majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    %prun main()\n",
    "#    pass\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': 0.5294468932176879, 'precision': 0.5066949706074461, 'recall': 0.5543381170725897, 'TP': 9309, 'FN': 7484, 'FP': 9063, 'TP/FN': 1.2438535542490647, 'n_gold': 16793, 'n_sys': 18372, 'TM': 68.67913425040182}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "def majority_exact(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "   \n",
    "    cols_to_keep = ['begin', 'end', 'note_id', 'system']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for system in systems:\n",
    "        sys = get_sys_data(system, analysis_type, corpus, False)\n",
    "        sys = sys[sys['system'] == system][cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        frames = [df, sys]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def majority_exact_vote():\n",
    "    sys = majority_exact(systems, analysis_type, corpus, filter_semtype)\n",
    "    sys['span'] = list(zip(sys.begin, sys.end, sys.note_id.astype(str)))\n",
    "    sys['count'] = df.groupby(['span'])['span'].transform('count')\n",
    "\n",
    "    n = int(len(systems) / 2)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        sys = sys[sys['count'] > n]\n",
    "    else:\n",
    "        # https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "        for i in sys.index:\n",
    "            if sys.at[i, 'count'] == n:\n",
    "                sys.at[i, 'count'] = random.choice([1,len(systems)])\n",
    "        sys = sys[sys['count'] > n]\n",
    "\n",
    "    sys = sys.drop_duplicates(subset=['span', 'begin', 'end', 'note_id'])\n",
    "    ref = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "\n",
    "    c = get_cooccurences(ref, sys, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "        # get dictionary of confusion matrix metrics\n",
    "        print(cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n))\n",
    "\n",
    "majority_exact_vote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>note_id</th>\n",
       "      <th>system</th>\n",
       "      <th>span</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128521</th>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>527982345</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(96, 100, 527982345)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128526</th>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "      <td>527982345</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(236, 240, 527982345)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128548</th>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "      <td>4130154172-4</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(79, 83, 4130154172-4)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128551</th>\n",
       "      <td>208</td>\n",
       "      <td>216</td>\n",
       "      <td>4130154172-4</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(208, 216, 4130154172-4)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128555</th>\n",
       "      <td>332</td>\n",
       "      <td>336</td>\n",
       "      <td>4130154172-4</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(332, 336, 4130154172-4)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128557</th>\n",
       "      <td>793</td>\n",
       "      <td>800</td>\n",
       "      <td>4130154172-4</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(793, 800, 4130154172-4)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128558</th>\n",
       "      <td>838</td>\n",
       "      <td>854</td>\n",
       "      <td>4130154172-4</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(838, 854, 4130154172-4)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128560</th>\n",
       "      <td>1005</td>\n",
       "      <td>1010</td>\n",
       "      <td>4130154172-4</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(1005, 1010, 4130154172-4)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128565</th>\n",
       "      <td>1032</td>\n",
       "      <td>1036</td>\n",
       "      <td>4130154172-4</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(1032, 1036, 4130154172-4)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128569</th>\n",
       "      <td>1057</td>\n",
       "      <td>1060</td>\n",
       "      <td>4130154172-4</td>\n",
       "      <td>clamp</td>\n",
       "      <td>(1057, 1060, 4130154172-4)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        begin   end       note_id system                        span  count\n",
       "128521     96   100     527982345  clamp        (96, 100, 527982345)    4.0\n",
       "128526    236   240     527982345  clamp       (236, 240, 527982345)    1.0\n",
       "128548     79    83  4130154172-4  clamp      (79, 83, 4130154172-4)    4.0\n",
       "128551    208   216  4130154172-4  clamp    (208, 216, 4130154172-4)    1.0\n",
       "128555    332   336  4130154172-4  clamp    (332, 336, 4130154172-4)    1.0\n",
       "128557    793   800  4130154172-4  clamp    (793, 800, 4130154172-4)    4.0\n",
       "128558    838   854  4130154172-4  clamp    (838, 854, 4130154172-4)    4.0\n",
       "128560   1005  1010  4130154172-4  clamp  (1005, 1010, 4130154172-4)    1.0\n",
       "128565   1032  1036  4130154172-4  clamp  (1032, 1036, 4130154172-4)    4.0\n",
       "128569   1057  1060  4130154172-4  clamp  (1057, 1060, 4130154172-4)    1.0"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ( ( ctakes & clamp ) | ( biomedicus & metamap ) \n",
      "cm {'F': nan, 'precision': 0.0, 'recall': 0.0, 'TP': 0, 'FN': 16793, 'FP': 16903, 'TP/FN': 0.0, 'n_gold': 16793, 'n_sys': 16903, 'TM': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# control filter_semtype in get_sys_data, get_ref_n and generate_metrics. TODO consolidate. \n",
    " \n",
    "# # run single ad hoc statement\n",
    "statement = '((ctakes&clamp)|(biomedicus&metamap)'\n",
    "analysis_type = 'entity'\n",
    "corpus = 'fairview'\n",
    "matches = get_merge_data(statement, analysis_type, corpus, False)\n",
    "# print(matches)\n",
    "\n",
    "# import spacy\n",
    "# nlp = spacy.load('en')\n",
    "\n",
    "# sql = \"select distinct note_id, sofa from concepts.sofas where corpus = 'fairview'\"\n",
    "\n",
    "# docs = pd.read_sql(sql, con=engine)\n",
    "\n",
    "# d = {}\n",
    "\n",
    "# for row in docs.itertuples():\n",
    "#     d[row.note_id] = row.sofa\n",
    "    \n",
    "# print(len(d))\n",
    "\n",
    "# test = matches[matches['note_id'] == '0000200926']\n",
    "# print(len(test))\n",
    "\n",
    "# doc = nlp(d['0000200926'])\n",
    "\n",
    "# for row in test.itertuples():\n",
    "#     my_str = [token.text.strip('\\n').lower() for token in doc if token.idx >= (row.begin) and token.idx <= (row.end)]\n",
    "#     if 'diabetes' in my_str:\n",
    "#         print(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTS -> ensemble:\n",
    "# def test_match_consistency(matches, ref_only, ref_n, sys):\n",
    "#     \"\"\"test for reference only/match set consistency:\n",
    "#         params: match, system and reference only sets\"\"\"\n",
    "   \n",
    "#     print('len', len(sys), len(matches), len(matches.union(sys)), len(matches.intersection(sys)))\n",
    "#     assert len(matches.union(ref_only)) == ref_n, 'Reference annotation mismatch union'\n",
    "#     assert len(matches.intersection(sys)) == len(matches), 'System annotation mismatch intersect'\n",
    "#     assert len(matches.union(sys)) == len(sys), 'System annotation mismatch union'\n",
    "#     assert len(matches.intersection(ref_only)) == 0, 'Reference annotation mismatch intersect'\n",
    "\n",
    "# def test_systems(analysis_type, systems, corpus):\n",
    "#     sys = df_to_set(get_sys_data(systems[0], analysis_type, corpus), analysis_type)\n",
    "#     test_match_consistency(*get_system_matches(systems[0], analysis_type, corpus), get_ref_n(analysis_type), sys)\n",
    "#     print('Match consistency:', len(sys),get_ref_n(analysis_type))\n",
    "\n",
    "# def test_metrics(ref, sys_m, match_m):\n",
    "#     test = True\n",
    "#     reference_n = len(ref)\n",
    "#     system_n = len(sys_m)\n",
    "\n",
    "#     print('Test metrics:', type(reference_n), type(system_n), type(match_m))\n",
    "\n",
    "#     reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, match_m).get_ref_sys()\n",
    "#     F, recall, precision, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics()\n",
    "#     F_, recall_, precision_, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics(test)\n",
    "\n",
    "#     assert F[1] == F_, 'F1 issue'\n",
    "#     assert recall[1] == recall_, 'recall issue'\n",
    "#     assert precision[1] == precision_, 'precision issue'\n",
    "#     print(F[1], F_)\n",
    "#     print(recall[1], recall_)\n",
    "#     print(precision[1], precision_)\n",
    "\n",
    "# def test_count(analysis_type, corpus):\n",
    "#     # test match counts:\n",
    "#     ctakes, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     clamp, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "\n",
    "#     print('count:', len(mm.intersection(b9.intersection(clamp.intersection(ctakes)))))\n",
    "    \n",
    "# def test_ensemble(analysis_type, corpus):\n",
    "    \n",
    "#     print('ensemble:')\n",
    "#     # Get mixed system_n\n",
    "#     ref_ann, data = get_metric_data(analysis_type, corpus)\n",
    "\n",
    "#     names = ['ctakes', 'biomedicus', 'metamap', 'clamp']\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['begin', 'end', 'note_id']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['cui', 'note_id']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "#     biomedicus = data[data[\"system\"]=='biomedicus'][cols_to_keep].copy()\n",
    "#     ctakes = data[data[\"system\"]=='ctakes'][cols_to_keep].copy()\n",
    "#     clamp = data[data[\"system\"]=='clamp'][cols_to_keep].copy()\n",
    "#     metamap = data[data[\"system\"]=='metamap'][cols_to_keep].copy()\n",
    "#     quickumls = data[data[\"system\"]=='quick_umls'][cols_to_keep].copy()\n",
    "\n",
    "#     print('systems:', len(biomedicus), len(clamp), len(ctakes), len(metamap), len(quickumls))\n",
    "\n",
    "#     b9 = set()\n",
    "#     cl = set()\n",
    "#     ct = set()\n",
    "#     mm = set()\n",
    "#     qu = set()\n",
    "\n",
    "#     b9 = df_to_set(get_sys_data('biomedicus', analysis_type, corpus), analysis_type)\n",
    "#     print(len(b9))\n",
    "\n",
    "#     ct = df_to_set(get_sys_data('ctakes', analysis_type, corpus), analysis_type)\n",
    "#     print(len(ct))\n",
    "\n",
    "#     cl = df_to_set(get_sys_data('clamp', analysis_type, corpus), analysis_type)\n",
    "#     print(len(cl))\n",
    "\n",
    "#     mm = df_to_set(get_sys_data('metamap', analysis_type, corpus), analysis_type)\n",
    "#     print(len(mm))\n",
    "\n",
    "#     qu = df_to_set(get_sys_data('quick_umls', analysis_type, corpus), analysis_type)\n",
    "#     print(len(qu))\n",
    "    \n",
    "#     print('various merges:')\n",
    "#     print(len(b9), len(cl), len(ct), len(mm), len(qu))\n",
    "#     print(len(mm.intersection(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.union(ct)))))\n",
    "#     print(len(b9.intersection(ct)))\n",
    "\n",
    "#     sys_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('sys_m:', len(sys_m))\n",
    "\n",
    "#     # Get match merges:\n",
    "#     ct, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     cl, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "#     qu, _ = get_system_matches('quick_umls', analysis_type, corpus)\n",
    "\n",
    "#     match_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('match_m:', len(match_m))\n",
    "#     # reference df to set\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['end', 'start','file']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['value','file']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['end', 'start', 'value','file']\n",
    "\n",
    "#     ref = df_to_set(ref_ann[cols_to_keep], analysis_type, 'ref')\n",
    "\n",
    "#     print('ref:', len(ref))\n",
    "\n",
    "#     # test difference:\n",
    "#     print('FP:', len(sys_m - match_m), len(sys_m - ref))\n",
    "#     assert len(sys_m - match_m) == len(sys_m - ref), 'FP mismatch'\n",
    "#     print('FN:', len(ref - match_m), len(ref - sys_m))\n",
    "#     assert len(ref - match_m) == len(ref - sys_m), 'FN mismatch'\n",
    "    \n",
    "#     test_metrics(ref, sys_m, match_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
