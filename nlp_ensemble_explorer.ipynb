{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Copyright (c) 2019 Regents of the University of Minnesota.\n",
    " \n",
    "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    " \n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pymysql\n",
    "import time \n",
    "import functools as ft\n",
    "import glob, os   \n",
    "import operator as op\n",
    "import shelve\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, permutations\n",
    "from sqlalchemy.engine import create_engine\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from scipy import stats  \n",
    "from scipy.stats.mstats import gmean\n",
    "from pythonds.basic.stack import Stack\n",
    "from pythonds.trees.binaryTree import BinaryTree\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from typing import List, Set, Tuple \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cell below contains the configurable parameters to ensure that our ensemble explorer runs properaly on your machine. \n",
    "Please read carfully through steps (1-11) before running the rest of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-1: CHOOSE YOUR CORPUS\n",
    "# TODO: get working with list of corpora\n",
    "#corpora = ['mipacq','i2b2','fairview'] #options for concept extraction include 'fairview', 'mipacq' OR 'i2b2'\n",
    "\n",
    "#corpus = 'ray_test'\n",
    "corpus = 'mipacq'\n",
    "#corpus = 'i2b2'\n",
    "#corpora = ['i2b2','fairview']\n",
    "\n",
    "# STEP-2: CHOOSE YOUR DATA DIRECTORY; this is where output data will be saved on your machine\n",
    "data_directory = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/' \n",
    "\n",
    "# STEP-3: CHOOSE WHICH SYSTEMS YOU'D LIKE TO EVALUATE AGAINST THE CORPUS REFERENCE SET\n",
    "#systems = ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "systems = ['clamp', 'quick_umls', 'metamap']\n",
    "#systems = ['biomedicus']\n",
    "#systems = ['ray_test']\n",
    "\n",
    "# STEP-4: CHOOSE TYPE OF RUN\n",
    "rtype = 2      # OPTIONS INCLUDE: 1->Single systems; 2->Ensemble; 3->Tests; 4 -> majority vote \n",
    "               # The Ensemble can include the max system set ['ctakes','biomedicus','clamp','metamap','quick_umls']\n",
    "    \n",
    "# STEP-5: CHOOSE WHAT TYPE OF ANALYSIS YOU'D LIKE TO RUN ON THE CORPUS\n",
    "analysis_type = 'full' #options include 'entity', 'cui' OR 'full'\n",
    "\n",
    "# STEP-(6A): ENTER DETAILS FOR ACCESSING MANUAL ANNOTATION DATA\n",
    "database_type = 'mysql+pymysql' # We use mysql+pymql as default\n",
    "database_username = 'gms'\n",
    "database_password = 'nej123' \n",
    "database_url = 'localhost' # HINT: use localhost if you're running database on your local machine\n",
    "#database_name = 'clinical_trial' # Enter database name\n",
    "database_name = 'concepts' # Enter database name\n",
    "\n",
    "def ref_data(corpus):\n",
    "    return corpus + '_all' # Enter the table within the database where your reference data is stored\n",
    "\n",
    "table_name = ref_data(corpus)\n",
    "\n",
    "# STEP-(6B): ENTER DETAILS FOR ACCESSING SYSTEM ANNOTATION DATA\n",
    "\n",
    "def sys_data(corpus, analysis_type):\n",
    "    if analysis_type == 'entity':\n",
    "        return 'analytical_'+corpus+'.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "    elif analysis_type in ('cui', 'full'):\n",
    "        return 'analytical_'+corpus+'_cui.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "        \n",
    "system_annotation = sys_data(corpus, analysis_type)\n",
    "\n",
    "# STEP-7: CREATE A DB CONNECTION POOL\n",
    "engine_request = str(database_type)+'://'+database_username+':'+database_password+\"@\"+database_url+'/'+database_name\n",
    "engine = create_engine(engine_request, pool_pre_ping=True, pool_size=20, max_overflow=30)\n",
    "\n",
    "# STEP-(8A): FILTER BY SEMTYPE\n",
    "filter_semtype = True\n",
    "\n",
    "# STEP-(8B): IF STEP-(8A) == True -> GET REFERENCE SEMTYPES\n",
    "\n",
    "### Fairview -> ['drug', 'finding', 'anatomy', 'procedure']\n",
    "### i2b2 -> ['test, treatment', 'problem']\n",
    "### MiPACQ -> ['procedures', 'disorders, sign_symptom', 'anatomy', 'chemicals_and_drugs']\n",
    "\n",
    "# semtypes = ['Anatomy']\n",
    "def ref_semtypes(filter_semtype, corpus):\n",
    "    if filter_semtype:\n",
    "        if corpus == 'fairview':\n",
    "            semtypes = ['Drug', 'Finding', 'Anatomy', 'Procedure']\n",
    "        elif corpus == 'i2b2':\n",
    "            semtypes = ['test,treatment', 'problem']\n",
    "        elif corpus == 'mipacq':\n",
    "            semtypes = ['Procedures', 'Disorders,Sign_Symptom', 'Anatomy', 'Chemicals_and_drugs']\n",
    "            #semtypes = ['Anatomy']\n",
    "        elif corpus == 'clinical_trial':\n",
    "            semtypes = ['drug,drug::drug_name,drug::drug_dose,dietary_supplement::dietary_supplement_name,dietary_supplement::dietary_supplement_dose']#,\n",
    "                        ##'temporal_measurement,qualifier,measurement',\n",
    "                        #'device',\n",
    "                        #'condition,observation',\n",
    "                        #'demographics::age,demographics::sex,demographics::race_ethnicity,demographics::bmi,demographics::weight',#,b9\n",
    "                        ##'diet']#,qu\n",
    "                        #'measurement,qualifier']#,b9 and qu\n",
    "                        #'procedure,observation']\n",
    "\n",
    "#             semtypes = ['condition',\n",
    "#                         'qualifier',\n",
    "#                         'drug::drug_name',\n",
    "#                         'temporal_measurement',\n",
    "#                         'observation',\n",
    "#                         'demographics::age',\n",
    "#                         'demographics::weight',\n",
    "#                         'measurement',\n",
    "#                         'demographics::BMI',\n",
    "#                         'diet',\n",
    "#                         'procedure',\n",
    "#                         'device',\n",
    "#                         'demographics::gender',\n",
    "#                         'negation',\n",
    "#                         'dietary_supplement::dietary_supplement_name',\n",
    "#                         'dietary_supplement::dietary_supplement_dose',\n",
    "#                         'demographics::race_ethnicity',\n",
    "#                         'drug::drug_dose',\n",
    "#                         'drug'\n",
    "#                         ]\n",
    "        \n",
    "        return semtypes\n",
    "\n",
    "semtypes = ref_semtypes(filter_semtype, corpus)\n",
    "\n",
    "# STEP-9: Set data directory/table for source documents for vectorization\n",
    "src_table = 'sofa'\n",
    "\n",
    "# STEP-10: Specificy match type from {'exact', 'overlap', 'cui' -> kludge for majority}\n",
    "run_type = 'overlap'\n",
    "\n",
    "# STEP-11: Specify expression type for run (TODO: run all at once; make less kludgey)\n",
    "expression_type = 'nested' #'nested_with_singleton' # type of merge expression: nested ((A&B)|C), paired ((A&B)|(C&D)), nested_with_singleton ((A&B)|((C&D)|E)) \n",
    "# -> NB: len(systems) for pair must be >= 4, and for nested_with_singleton == 5; single-> skip merges\n",
    "\n",
    "# STEP-12: Specify type of ensemble: merge or vote\n",
    "ensemble_type = 'merge'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "****** TODO \n",
    "-> add 'semtype' to output file name -> done\n",
    "-> filter for case when a system has no equivalent semtypes for a given reference -> done: still need to validate that all semtypes in corpus!\n",
    "-> case when system annotations empty from semtype filter; print as 0\n",
    "-> trim whitespace on CSV import -> done for semtypes\n",
    "-> eliminate rtype = 1 for expression_type = 'single'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config class for analysis\n",
    "class AnalysisConfig():\n",
    "    \"\"\"\n",
    "    Configuration object:\n",
    "    systems to use\n",
    "    notes by corpus\n",
    "    paths by output, gold and system location\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self = self    \n",
    "        self.systems = systems\n",
    "        self.data_dir = data_directory\n",
    "    \n",
    "    def corpus_config(self): \n",
    "        usys_data = system_annotation\n",
    "        ref_data = database_name+'.'+table_name\n",
    "        return usys_data, ref_data\n",
    "\n",
    "analysisConf =  AnalysisConfig()\n",
    "#usys, ref = analysisConf.corpus_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticTypes(object):\n",
    "    '''\n",
    "    Filter semantic types based on: https://metamap.nlm.nih.gov/SemanticTypesAndGroups.shtml\n",
    "    :params: semtypes list from corpus, system to query\n",
    "    :return: list of equivalent system semtypes \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, semtypes, corpus):\n",
    "        self = self\n",
    "        \n",
    "#         sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name FROM clinical_trial.semantic_groups sg join semantic_types st on sg.tui = st.tui where \" + corpus + \"_name in ({})\"\\\n",
    "#            .format(', '.join(['%s' for _ in semtypes]))  \n",
    "        sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name FROM concepts.semantic_groups sg join semantic_types st on sg.tui = st.tui where \" + corpus + \"_name in ({})\"\\\n",
    "           .format(', '.join(['%s' for _ in semtypes]))  \n",
    "        \n",
    "        stypes = pd.read_sql(sql, params=[semtypes], con=engine) \n",
    "       \n",
    "        if len(stypes['tui'].tolist()) > 0:\n",
    "            self.biomedicus_types = set(stypes['tui'].tolist())\n",
    "            self.qumls_types = set(stypes['tui'].tolist())\n",
    "        else:\n",
    "            self.biomedicus_types = None\n",
    "            self.qumls_types = None\n",
    "        \n",
    "        if stypes['clamp_name'].dropna(inplace=True) or len(stypes['clamp_name']) == 0:\n",
    "            self.clamp_types = None\n",
    "        else:\n",
    "            self.clamp_types = set(stypes['clamp_name'].tolist()[0].split(','))\n",
    "         \n",
    "        if stypes['ctakes_name'].dropna(inplace=True) or len(stypes['ctakes_name']) == 0:\n",
    "            self.ctakes_types = None\n",
    "        else:\n",
    "            self.ctakes_types = set(stypes['ctakes_name'].tolist()[0].split(','))\n",
    "            \n",
    "        if len(stypes['abbreviation'].tolist()) > 0:\n",
    "            self.metamap_types = set(stypes['abbreviation'].tolist())\n",
    "        else:\n",
    "            self.metamap_types = None\n",
    "        \n",
    "        self.reference_types =  set(semtypes)\n",
    "    \n",
    "    def get_system_type(self, system):  \n",
    "        \n",
    "        if system == 'biomedicus':\n",
    "            semtypes = self.biomedicus_types\n",
    "        elif system == 'ctakes':\n",
    "            semtypes = self.ctakes_types\n",
    "        elif system == 'clamp':\n",
    "            semtypes = self.clamp_types\n",
    "        elif system == 'metamap':\n",
    "            semtypes = self.metamap_types\n",
    "        elif system == 'quick_umls':\n",
    "            semtypes = self.qumls_types\n",
    "        elif system == 'reference':\n",
    "            semtypes = self.reference_types\n",
    "            \n",
    "        return semtypes\n",
    "    \n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('biomedicus'))\n",
    "#print(SemanticTypes(['Drug'], corpus).get_system_type('quick_umls'))\n",
    "#print(SemanticTypes(['drug'], corpus).get_system_type('clamp'))\n",
    "#print(SemanticTypes(['Anatomy'], 'mipacq').get_system_type('ctakes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semtypes = ['test,treatment']\n",
    "#semtypes = 'drug,drug::drug_name,drug::drug_dose,dietary_supplement::dietary_supplement_name,dietary_supplement::dietary_supplement_dose'\n",
    "#corpus = 'clinical_trial'\n",
    "#sys = 'clamp'\n",
    "\n",
    "# is semantic type in particular system\n",
    "def system_semtype_check(sys, semtype, corpus):\n",
    "    st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "    if st:\n",
    "        return sys\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#print(system_semtype_check(sys, semtypes, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for systems\n",
    "class AnnotationSystems():\n",
    "    \"\"\"   \n",
    "    System annotations of interest for UMLS concept extraction\n",
    "    NB: ctakes combines all \"mentions\" annotation types\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"   \n",
    "        \n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\"]\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\"]\n",
    "        self.ctakes_types = [\"ctakes_mentions\"]\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\"]\n",
    "        self.qumls_types = [\"concept_jaccard_score_False\"]\n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "        \n",
    "        elif system == \"quick_umls\":\n",
    "            types = self.qumls_types\n",
    "            \n",
    "        return types, view\n",
    "    \n",
    "annSys = AnnotationSystems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np # access to Numpy from Python layer\n",
    "import math\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"\n",
    "    metrics class:\n",
    "    returns an instance with confusion matrix metrics\n",
    "    \"\"\"\n",
    "    def __init__(self, system_only, gold_only, gold_system_match, system_n, neither = 0): # neither: no sys or manual annotation\n",
    "\n",
    "        self = self    \n",
    "        self.system_only = system_only\n",
    "        self.gold_only = gold_only\n",
    "        self.gold_system_match = gold_system_match\n",
    "        self.system_n = system_n\n",
    "        self.neither = neither\n",
    "        \n",
    "    def get_confusion_metrics(self, corpus = None, test = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        compute confusion matrix measures, as per  \n",
    "        https://stats.stackexchange.com/questions/51296/how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\n",
    "        \"\"\"\n",
    "        cdef:\n",
    "            int TP, FP, FN\n",
    "            double TM\n",
    "\n",
    "        TP = self.gold_system_match\n",
    "        FP = self.system_only\n",
    "        FN = self.gold_only\n",
    "        \n",
    "        TM = TP/math.sqrt(self.system_n) # TigMetric\n",
    "       \n",
    "        if not test:\n",
    "            \n",
    "            if corpus == 'casi':\n",
    "                recall = TP/(TP + FN)\n",
    "                precision = TP/(TP + FP)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "            else:\n",
    "                if self.neither == 0:\n",
    "                    confusion = [[0, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                else:\n",
    "                    confusion = [[self.neither, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                c = np.asarray(confusion)\n",
    "                recall = np.diag(c) / np.sum(c, axis = 1)\n",
    "                precision = np.diag(c) / np.sum(c, axis = 0)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            F = 2*(precision*recall)/(precision + recall)\n",
    "        \n",
    "        # Tignanelli Metric\n",
    "        if FN == 0:\n",
    "            TP_FN_R = TP\n",
    "        elif FN > 0:\n",
    "            TP_FN_R = TP/FN\n",
    " \n",
    "        return F, recall, precision, TP, FP, FN, TP_FN_R, TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_set(df, analysis_type = 'entity', df_type = 'sys', corpus = None):\n",
    "    \n",
    "    # get values for creation of series of type tuple\n",
    "    if 'entity' in analysis_type: \n",
    "        if corpus == 'casi':\n",
    "            arg = df.case, df.overlap\n",
    "        else:    \n",
    "            arg = df.begin, df.end, df.case\n",
    "            \n",
    "    elif 'cui' in analysis_type:\n",
    "        arg = df.value, df.case\n",
    "    elif 'full' in analysis_type:\n",
    "        arg = df.begin, df.end, df.value, df.case\n",
    "    \n",
    "    return set(list(zip(*arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython \n",
    "\n",
    "from __main__ import df_to_set, engine\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "def get_cooccurences(ref, sys, analysis_type: str, corpus: str):\n",
    "    \"\"\"\n",
    "    get cooccurences between system and reference; exact match; TODO: add relaxed -> done in single system evals during ensemble run\n",
    "    \"\"\"\n",
    "    # cooccurences\n",
    "    class Cooccurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = set()\n",
    "            self.false_negatives = set()\n",
    "            self.corpus = corpus\n",
    "\n",
    "    c = Cooccurences()\n",
    "    \n",
    "    if c.corpus != 'casi':\n",
    "        if analysis_type in ['cui', 'full']:\n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\", \"cui\": \"value\"})\n",
    "            # do not overestimate FP\n",
    "            sys = sys[~sys['value'].isnull()] \n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "        \n",
    "        if 'entity' in analysis_type: \n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "            cols_to_keep = ['begin', 'end', 'case']\n",
    "        elif 'cui' in analysis_type: \n",
    "            cols_to_keep = ['value', 'case']\n",
    "        elif 'full' in analysis_type: \n",
    "            cols_to_keep = ['begin', 'end', 'value', 'case']\n",
    "        \n",
    "        sys = sys[cols_to_keep].drop_duplicates()\n",
    "        ref = ref[cols_to_keep].drop_duplicates()\n",
    "        # matches via inner join\n",
    "        tp = pd.merge(sys, ref, how = 'inner', left_on=cols_to_keep, right_on = cols_to_keep) \n",
    "        # reference-only via left outer join\n",
    "        fn = pd.merge(ref, sys, how = 'left', left_on=cols_to_keep, right_on = cols_to_keep, indicator=True) \n",
    "        fn = fn[fn[\"_merge\"] == 'left_only']\n",
    "\n",
    "        tp = tp[cols_to_keep]\n",
    "        fn = fn[cols_to_keep]\n",
    "\n",
    "        # use for metrics \n",
    "        c.matches = c.matches.union(df_to_set(tp, analysis_type, 'ref'))\n",
    "        c.false_negatives = c.false_negatives.union(df_to_set(fn, analysis_type, 'ref'))\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches) # fp\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        c.ref_only = len(c.false_negatives)\n",
    "        \n",
    "    else:\n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where overlap = 1 and `system` = %(sys.name)s\"  \n",
    "        tp = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where (overlap = 0 or overlap is null) and `system` = %(sys.name)s\"  \n",
    "        fn = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        c.matches = df_to_set(tp, 'entity', 'sys', 'casi')\n",
    "        c.fn = df_to_set(fn, 'entity', 'sys', 'casi')\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(tp) + len(fn)\n",
    "        c.ref_n = len(tp) + len(fn)\n",
    "        c.ref_only = len(fn)\n",
    "        \n",
    "    # sanity check\n",
    "    if len(ref) - c.ref_system_match < 0:\n",
    "        print('Error: ref_system_match > len(ref)!')\n",
    "    if len(ref) != c.ref_system_match + c.ref_only:\n",
    "        print('Error: ref count mismatch!', len(ref), c.ref_system_match, c.ref_only)\n",
    "   \n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vector(doc: str, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.begin, a.end) for a in ann if a.label == lab]\n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v\n",
    "\n",
    "# test confusion matrix elements for vectorized annotation set; includes TN\n",
    "# https://kawahara.ca/how-to-compute-truefalse-positives-and-truefalse-negatives-in-python-for-binary-classification-problems/\n",
    "# def confused(sys1, ann1):\n",
    "#     TP = np.sum(np.logical_and(ann1 == 1, sys1 == 1))\n",
    "\n",
    "#     # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "#     TN = np.sum(np.logical_and(ann1 == 0, sys1 == 0))\n",
    "\n",
    "#     # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "#     FP = np.sum(np.logical_and(ann1 == 0, sys1 == 1))\n",
    "\n",
    "#     # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "#     FN = np.sum(np.logical_and(ann1 == 1, sys1 == 0))\n",
    "    \n",
    "#     return TP, TN, FP, FN\n",
    "\n",
    "def confused(sys1, ann1):\n",
    "    TP = np.sum(np.logical_and(ann1 > 0, sys1 == ann1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(ann1 == 0, sys1 == ann1))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(sys1 > 0, sys1 != ann1))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(ann1 > 0, sys1 == 0))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def vectorized_cooccurences(r: object, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> np.int64:\n",
    "    docs = get_docs(corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    sys = get_sys_ann(analysis_type, r)\n",
    "    \n",
    "    cvals = []\n",
    "    if analysis_type == 'entity':\n",
    "        labels = [\"concept\"]\n",
    "    elif analysis_type == 'full':\n",
    "        labels = list(set(ann[\"value\"].tolist()))\n",
    "    \n",
    "    sys2 = list()\n",
    "    ann2 = list()\n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        s1 = list(sys.loc[sys[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        ann1 = label_vector(docs[n][1], a1, labels)\n",
    "        sys1 = label_vector(docs[n][1], s1, labels)\n",
    "        \n",
    "        TP, TN, FP, FN = confused(sys1, ann1)\n",
    "        cvals.append([TP, TN, FP, FN])\n",
    "        sys2.append(list(sys1))\n",
    "        ann2.append(list(ann1))\n",
    "\n",
    "    a2 = [item for sublist in ann2 for item in sublist]\n",
    "    s2 = [item for sublist in sys2 for item in sublist]\n",
    "    report = classification_report(a2, s2, output_dict=True)\n",
    "    macro_precision =  report['macro avg']['precision'] \n",
    "    macro_recall = report['macro avg']['recall']    \n",
    "    macro_f1 = report['macro avg']['f1-score']\n",
    "    \n",
    "    return (np.sum(cvals, axis=0), (macro_precision, macro_recall, macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_dict(ref_only: int, system_only: int, ref_system_match: int, system_n: int, ref_n: int) -> dict:\n",
    "    \"\"\"\n",
    "    Generate dictionary of confusion matrix params and measures\n",
    "    :params: ref_only, system_only, reference_system_match -> sets\n",
    "    matches, system_n, reference_n -> counts\n",
    "    :return: dictionary object\n",
    "    \"\"\"\n",
    "\n",
    "    if ref_only + ref_system_match != ref_n:\n",
    "        print('ERROR!')\n",
    "        \n",
    "    # get evaluation metrics\n",
    "    F, recall, precision, TP, FP, FN, TP_FN_R, TM  = Metrics(system_only, ref_only, ref_system_match, system_n).get_confusion_metrics()\n",
    "\n",
    "    d = {\n",
    "         'F1': F[1], \n",
    "         'precision': precision[1], \n",
    "         'recall': recall[1], \n",
    "         'TP': TP, \n",
    "         'FN': FN, \n",
    "         'FP': FP, \n",
    "         'TP/FN': TP_FN_R,\n",
    "         'n_gold': ref_n, \n",
    "         'n_sys': system_n, \n",
    "         'TM': TM\n",
    "    }\n",
    "    \n",
    "    if system_n - FP != TP:\n",
    "        print('inconsistent system n!')\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metric_data(analysis_type: str, corpus: str):\n",
    "   \n",
    "    usys_file, ref_table = AnalysisConfig().corpus_config()\n",
    "    systems = AnalysisConfig().systems\n",
    "    \n",
    "    sys_ann = pd.read_csv(analysisConf.data_dir + usys_file, dtype={'note_id': str})\n",
    "    \n",
    "    sql = \"SELECT * FROM \" + ref_table #+ \" where semtype in('Anatomy', 'Chemicals_and_drugs')\" \n",
    "    \n",
    "    ref_ann = pd.read_sql(sql, con=engine)\n",
    "    sys_ann = sys_ann.drop_duplicates()\n",
    "    \n",
    "    return ref_ann, sys_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of rank averages\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F1'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(analysis_type: str, corpus: str, filter_semtype, semtype = None):\n",
    "    start = time.time()\n",
    "\n",
    "    systems = AnalysisConfig().systems\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    __, sys_ann = get_metric_data(analysis_type, corpus)\n",
    "    c = None\n",
    "    \n",
    "    for sys in systems:\n",
    "       \n",
    "        if filter_semtype and semtype:\n",
    "            ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        system_annotations = sys_ann[sys_ann['system'] == sys].copy()\n",
    "\n",
    "        if filter_semtype:\n",
    "            st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "\n",
    "            if st: \n",
    "                system_annotations = sys_ann[sys_ann['semtypes'].isin(st)].copy()\n",
    "        else:\n",
    "            system_annotations = sys_ann.copy()\n",
    "\n",
    "        if (filter_semtype and st) or filter_semtype is False:\n",
    "            system = system_annotations.copy()\n",
    "\n",
    "            if sys == 'quick_umls':\n",
    "                system = system[system.score.astype(float) >= .8]\n",
    "\n",
    "            if sys == 'metamap':\n",
    "                system = system.fillna(0)\n",
    "                system = system[system.score.abs().astype(int) >= 800]\n",
    "\n",
    "            system = system.drop_duplicates()\n",
    "\n",
    "            ref_ann = ref_ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "            c = get_cooccurences(ref_ann, system, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "            \n",
    "            if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "                # get dictionary of confusion matrix metrics\n",
    "                d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "                d['system'] = sys\n",
    "\n",
    "                data = pd.DataFrame(d,  index=[0])\n",
    "                metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "                metrics.drop_duplicates(keep='last', inplace=True)\n",
    "            else:\n",
    "                print(\"NO EXACT MATCHES FOR\", sys)\n",
    "            elapsed = (time.time() - start)\n",
    "            print(\"elapsed:\", sys, elapsed)\n",
    "   \n",
    "    if c:\n",
    "        elapsed = (time.time() - start)\n",
    "        print(geometric_mean(metrics))\n",
    "\n",
    "        now = datetime.now()\n",
    "        timestamp = datetime.timestamp(now)\n",
    "\n",
    "        file_name = 'metrics_'\n",
    "\n",
    "        metrics.to_csv(analysisConf.data_dir + corpus + '_' + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "\n",
    "        print(\"total elapsed time:\", elapsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_n(analysis_type: str, corpus: str, filter_semtype: str) -> int:\n",
    "    \n",
    "    ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes, corpus).get_system_type('reference'))]\n",
    "            \n",
    "    if corpus == 'casi':\n",
    "        return len(ref_ann)\n",
    "        \n",
    "    else:\n",
    "        # do not overestimate fn\n",
    "        if 'entity' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'file']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type:\n",
    "            ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        elif 'full' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "        return ref_n\n",
    "    \n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_data(system: str, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> pd.DataFrame:\n",
    "   \n",
    "    _, data = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    out = data[data['system'] == system].copy()\n",
    "    \n",
    "    if filter_semtype:\n",
    "        st = SemanticTypes([semtype], corpus).get_system_type(system)\n",
    "        print(system, 'st', st)\n",
    "    \n",
    "    if corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap'] \n",
    "        out = out[cols_to_keep].drop_duplicates()\n",
    "        return out\n",
    "        \n",
    "    else:\n",
    "        if filter_semtype:\n",
    "            out = out[out['semtypes'].isin(st)].copy()\n",
    "            \n",
    "        else:\n",
    "            out = out[out['system']== system].copy()\n",
    "        \n",
    "        if system == 'quick_umls':\n",
    "            out = out[(out.score.astype(float) >= 0.8) & (out[\"type\"] == 'concept_jaccard_score_False')]\n",
    "            # fix for leading space on semantic type field\n",
    "            out = out.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) \n",
    "            out['semtypes'] = out['semtypes'].str.strip()\n",
    "        \n",
    "        if system == 'metamap':\n",
    "            out = out[out.score.abs().astype(int) >= 800]\n",
    "            \n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "        elif 'cui' in analysis_type:\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "        elif 'full' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "        out = out[cols_to_keep]\n",
    "        \n",
    "        return out.drop_duplicates()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GENERATE merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTotals(object):\n",
    "    \"\"\" \n",
    "    returns an instance with merged match set numbers using either union or intersection of elements in set \n",
    "    \"\"\"\n",
    "    def __init__(self, ref_n, sys_n, match_set):\n",
    "\n",
    "        self = self    \n",
    "        self.ref_ann = ref_n\n",
    "        self.sys_n = sys_n\n",
    "        self.match_set = match_set\n",
    "\n",
    "    def get_ref_sys(self):\n",
    "\n",
    "        ref_only = self.ref_ann - len(self.match_set)\n",
    "        sys_only = self.sys_n - len(self.match_set)\n",
    "\n",
    "        return ref_only, sys_only, len(self.match_set), self.match_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Recursively evaluate parse tree, \n",
    "    with check for existence before build\n",
    "       :param sentence: to process\n",
    "       :return class of merged annotations, boolean operated system df \n",
    "    \"\"\"\n",
    "    \n",
    "    class Results(object):\n",
    "        def __init__(self):\n",
    "            self.results = set()\n",
    "            self.system_merges = pd.DataFrame()\n",
    "            \n",
    "    r = Results()\n",
    "    \n",
    "    if 'entity' in analysis_type and corpus != 'casi': \n",
    "        cols_to_keep = ['begin', 'end', 'note_id'] # entity only\n",
    "    elif 'full' in analysis_type: \n",
    "        cols_to_keep = ['cui', 'begin', 'end', 'note_id'] # entity only\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['cui', 'note_id'] # entity only\n",
    "    elif corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap']\n",
    "    \n",
    "    def evaluate(parseTree):\n",
    "        oper = {'&': op.and_, '|': op.or_}\n",
    "        \n",
    "        if parseTree:\n",
    "            leftC = gevent.spawn(evaluate, parseTree.getLeftChild())\n",
    "            rightC = gevent.spawn(evaluate, parseTree.getRightChild())\n",
    "            \n",
    "            if leftC.get() is not None and rightC.get() is not None:\n",
    "                system_query = pd.DataFrame()\n",
    "                fn = oper[parseTree.getRootVal()]\n",
    "                \n",
    "                if isinstance(leftC.get(), str):\n",
    "                    # get system as leaf node \n",
    "                    if filter_semtype:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype)\n",
    "                \n",
    "                elif isinstance(leftC.get(), pd.DataFrame):\n",
    "                    l_sys = leftC.get()\n",
    "                \n",
    "                if isinstance(rightC.get(), str):\n",
    "                    # get system as leaf node\n",
    "                    if filter_semtype:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype)\n",
    "                    \n",
    "                elif isinstance(rightC.get(), pd.DataFrame):\n",
    "                    r_sys = rightC.get()\n",
    "                    \n",
    "                if fn == op.or_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        frames = [left_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [left_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        frames = [l_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [l_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                if fn == op.and_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        df = left_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        df = left_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        df = l_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        df = l_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                \n",
    "                # get combined system results\n",
    "                r.system_merges = df\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    system_query = system_query.append(df)\n",
    "                else:\n",
    "                    print('wtf!')\n",
    "                    \n",
    "                return system_query\n",
    "            else:\n",
    "                return parseTree.getRootVal()\n",
    "    \n",
    "    if sentence.n_or > 0 or sentence.n_and > 0:\n",
    "        evaluate(pt)  \n",
    "    \n",
    "    # trivial case\n",
    "    elif sentence.n_or == 0 and sentence.n_and == 0:\n",
    "        \n",
    "        if filter_semtype:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Incoming Boolean sentences are parsed into a binary tree.\n",
    "\n",
    "Test expressions to parse:\n",
    "\n",
    "sentence = '((((A&B)|C)|D)&E)'\n",
    "\n",
    "sentence = '(E&(D|(C|(A&B))))'\n",
    "\n",
    "sentence = '(((A|(B&C))|(D&(E&F)))|(H&I))'\n",
    "\n",
    "\"\"\"\n",
    "# build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "def buildParseTree(fpexp):\n",
    "    \"\"\"\n",
    "       Iteratively build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "       :param fpexp: sentence to parse\n",
    "       :return eTree: parse tree representation\n",
    "       Incoming Boolean sentences are parsed into a binary tree.\n",
    "       Test expressions to parse:\n",
    "       sentence = '(A&B)'\n",
    "       sentence = '(A|B)'\n",
    "       sentence = '((A|B)&C)'\n",
    "       \n",
    "    \"\"\"\n",
    "    fplist = fpexp.split()\n",
    "    pStack = Stack()\n",
    "    eTree = BinaryTree('')\n",
    "    pStack.push(eTree)\n",
    "    currentTree = eTree\n",
    "\n",
    "    for i in fplist:\n",
    "\n",
    "        if i == '(':\n",
    "            currentTree.insertLeft('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getLeftChild()\n",
    "        elif i not in ['&', '|', ')']:\n",
    "            currentTree.setRootVal(i)\n",
    "            parent = pStack.pop()\n",
    "            currentTree = parent\n",
    "        elif i in ['&', '|']:\n",
    "            currentTree.setRootVal(i)\n",
    "            currentTree.insertRight('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getRightChild()\n",
    "        elif i == ')':\n",
    "            currentTree = pStack.pop()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return eTree\n",
    "\n",
    "def make_parse_tree(payload):\n",
    "    \"\"\"\n",
    "    Ensure data to create tree are in correct form\n",
    "    :param sentence: sentence to preprocess\n",
    "    :return pt, parse tree graph\n",
    "            sentence, processed sentence to build tree\n",
    "            a: order\n",
    "    \"\"\"\n",
    "    def preprocess_sentence(sentence):\n",
    "        # prepare statement for case when a boolean AND/OR is given\n",
    "        sentence = payload.replace('(', ' ( '). \\\n",
    "            replace(')', ' ) '). \\\n",
    "            replace('&', ' & '). \\\n",
    "            replace('|', ' | '). \\\n",
    "            replace('  ', ' ')\n",
    "        return sentence\n",
    "\n",
    "    sentence = preprocess_sentence(payload)\n",
    "    print('Processing sentence:', sentence)\n",
    "    \n",
    "    pt = buildParseTree(sentence)\n",
    "    #pt.postorder() \n",
    "    \n",
    "    return pt\n",
    "\n",
    "class Sentence(object):\n",
    "    '''\n",
    "    Details about boolean expression -> number operators and expression\n",
    "    '''\n",
    "    def __init__(self, sentence):\n",
    "        self = self\n",
    "        self.n_and = sentence.count('&')\n",
    "        self.n_or = sentence.count('|')\n",
    "        self.sentence = sentence\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_docs(corpus):\n",
    "    \n",
    "    # KLUDGE!!!\n",
    "    if corpus == 'ray_test':\n",
    "        corpus = 'fairview'\n",
    "        \n",
    "    sql = 'select distinct note_id, sofa from sofas where corpus = %(corpus)s order by note_id'\n",
    "    df = pd.read_sql(sql, params={\"corpus\":corpus}, con=engine)\n",
    "    df.drop_duplicates()\n",
    "    df['len_doc'] = df['sofa'].apply(len)\n",
    "    \n",
    "    subset = df[['note_id', 'len_doc']]\n",
    "    docs = [tuple(x) for x in subset.to_numpy()]\n",
    "    \n",
    "    return docs\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_ann(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    if filter_semtype:\n",
    "        if ',' in semtype:\n",
    "            semtype = semtype.split(',')\n",
    "        else:\n",
    "            semtype = [semtype]\n",
    "        \n",
    "    ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    ann = ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = ann[ann['semtype'].isin(semtype)]\n",
    "    if analysis_type == 'entity':   \n",
    "        ann[\"label\"] = 'concept'\n",
    "    elif analysis_type in ['cui','full']:\n",
    "        ann[\"label\"] = ann[\"value\"]\n",
    "    \n",
    "    \n",
    "    if analysis_type == 'entity':\n",
    "        cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    elif analysis_type == 'cui':\n",
    "        cols_to_keep = ['value', 'case', 'label']\n",
    "    elif analysis_type == 'full':\n",
    "        cols_to_keep = ['begin', 'end', 'value', 'case', 'label']\n",
    "    ann = ann[cols_to_keep]\n",
    "    \n",
    "    return ann\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_ann(analysis_type, r):\n",
    "    sys = r.system_merges   \n",
    "    \n",
    "    sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "    if analysis_type == 'entity':\n",
    "        sys[\"label\"] = 'concept'\n",
    "    elif analysis_type in ['cui','full']:\n",
    "        sys[\"label\"] = sys[\"cui\"]\n",
    "    \n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys = sys[cols_to_keep]\n",
    "    return sys\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metrics(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    else:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    # vectorize merges using i-o labeling\n",
    "    if run_type == 'overlap':\n",
    "        if filter_semtype:\n",
    "             ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        print(((TP, TN, FP, FN),(p,r,f1)))\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        \n",
    "        d['TN'] = TN\n",
    "        d['macro_p'] = p\n",
    "        d['macro_r'] = r\n",
    "        d['macro_f1'] = f1\n",
    "        \n",
    "        # return full metrics\n",
    "        return d\n",
    "\n",
    "    elif run_type == 'exact':\n",
    "        # total by number spans\n",
    "        \n",
    "        if filter_semtype:\n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else: \n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "        else:\n",
    "            d = None\n",
    "            \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_valid_systems(['biomedicus'], 'Anatomy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all combinations of given list of annotators:\n",
    "def partly_unordered_permutations(lst, k):\n",
    "    elems = set(lst)\n",
    "    for c in combinations(lst, k):\n",
    "        for d in permutations(elems - set(c)):\n",
    "            yield c + d\n",
    "            \n",
    "def expressions(l, n):\n",
    "    for (operations, *operands), operators in product(\n",
    "            combinations(l, n), product(('&', '|'), repeat=n - 1)):\n",
    "        for operation in zip(operators, operands):\n",
    "            operations = [operations, *operation]\n",
    "        yield operations\n",
    "\n",
    "# get list of systems with a semantic type in grouping\n",
    "def get_valid_systems(systems, semtype):\n",
    "    test = []\n",
    "    for sys in systems:\n",
    "        st = system_semtype_check(sys, semtype, corpus)\n",
    "        if st:\n",
    "            test.append(sys)\n",
    "\n",
    "    return test\n",
    "\n",
    "# permute system combinations and evaluate system merges for performance\n",
    "def run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type, semtype = None):\n",
    "    metrics = pd.DataFrame()\n",
    "    \n",
    "    # pass single system to evaluate\n",
    "    if expression_type == 'single':\n",
    "        for system in systems:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(system, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(system, analysis_type, corpus, run_type, filter_semtype)\n",
    "            d['merge'] = system\n",
    "            d['n_terms'] = 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "    \n",
    "    elif expression_type == 'nested':\n",
    "        for l in partly_unordered_permutations(systems, 2):\n",
    "            print('processing merge combo:', l)\n",
    "            for i in range(1, len(l)+1):\n",
    "                test = list(expressions(l, i))\n",
    "                for t in test:\n",
    "                    if i > 1:\n",
    "                        # format Boolean sentence for parse tree \n",
    "                        t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                    if filter_semtype:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype)\n",
    "\n",
    "                    d['merge'] = t\n",
    "                    d['n_terms'] = i\n",
    "\n",
    "                    frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "                    metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                    \n",
    "    elif expression_type == 'nested_with_singleton' and len(systems) == 5:\n",
    "        # form (((a&b)|c)&(d|e))\n",
    "        \n",
    "        nested = list(expressions(systems, 3))\n",
    "        test = list(expressions(systems, 2))\n",
    "        to_do_terms = []\n",
    "    \n",
    "        for n in nested:\n",
    "            # format Boolean sentence for parse tree \n",
    "            n = '(' + \" \".join(str(x) for x in n).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "            for t in test:\n",
    "                t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                new_and = '(' + n +'&'+ t + ')'\n",
    "                new_or = '(' + n +'|'+ t + ')'\n",
    "\n",
    "                if new_and.count('biomedicus') != 2 and new_and.count('clamp') != 2 and new_and.count('ctakes') != 2 and new_and.count('metamap') != 2 and new_and.count('quick_umls') != 2:\n",
    "\n",
    "                    if new_and.count('&') != 4 and new_or.count('|') != 4:\n",
    "                        #print(new_and)\n",
    "                        #print(new_or)\n",
    "                        to_do_terms.append(new_or)\n",
    "                        to_do_terms.append(new_and)\n",
    "        \n",
    "        print('nested_with_singleton', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                        \n",
    "    elif expression_type == 'paired':\n",
    "        m = list(expressions(systems, 2))\n",
    "        test = list(expressions(m, 2))\n",
    "\n",
    "        to_do_terms = []\n",
    "        for t in test:\n",
    "            # format Boolean sentence for parse tree \n",
    "            t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "            if t.count('biomedicus') != 2 and t.count('clamp') != 2 and t.count('ctakes') != 2 and t.count('metamap') != 2 and t.count('quick_umls') != 2:\n",
    "                if t.count('&') != 3 and t.count('|') != 3:\n",
    "                    to_do_terms.append(t)\n",
    "                    if len(systems) == 5:\n",
    "                        for i in systems:\n",
    "                            if i not in t:\n",
    "                                #print('('+t+'&'+i+')')\n",
    "                                #print('('+t+'|'+i+')')\n",
    "                                new_and = '('+t+'&'+i+')'\n",
    "                                new_or = '('+t+'|'+i+')'\n",
    "                                to_do_terms.append(new_and)\n",
    "                                to_do_terms.append(new_or)\n",
    "                            \n",
    "        print('paired', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "        \n",
    "    return metrics\n",
    "\n",
    "# write to file\n",
    "def generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype = None):\n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    file_name = corpus + '_all_'\n",
    "   \n",
    "    # drop exact matches:\n",
    "    metrics = metrics.drop_duplicates()\n",
    "    \n",
    "    if ensemble_type == 'merge':\n",
    "        metrics = metrics.sort_values(by=['n_terms', 'merge'])\n",
    "        file_name += 'merge_'\n",
    "    elif ensemble_type == 'vote':\n",
    "        file_name += 'vote_'\n",
    "    \n",
    "    #metrics = metrics.drop_duplicates(subset=['TP', 'FN', 'FP', 'n_sys', 'precision', 'recall', 'F', 'TM', 'TP/FN', 'TM', 'n_terms'])\n",
    "\n",
    "    file = file_name + analysis_type + '_' + run_type +'_'\n",
    "    \n",
    "    if filter_semtype:\n",
    "        file += semtype\n",
    "        \n",
    "    \n",
    "    geometric_mean(metrics).to_csv(analysisConf.data_dir + file + str(timestamp) + '.csv')\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "# control ensemble run\n",
    "def ensemble_control(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSTEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            metrics = run_ensemble(test, analysis_type, corpus, filter_semtype, expression_type, semtype)\n",
    "            if (expression_type == 'nested_with_singleton' and len(test) == 5) or expression_type in ['nested', 'paired', 'single']:\n",
    "                generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "    else:\n",
    "        metrics = run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad hoc query\n",
    "def get_merge_data(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "\n",
    "    r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    if run_type == 'overlap':\n",
    "        if filter_semtype:\n",
    "            TP, TN, FP, FN = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            TP, TN, FP, FN = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        print(d)\n",
    "        \n",
    "    elif run_type == 'exact':\n",
    "        c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "\n",
    "            print('cm', d)\n",
    "    \n",
    "    # get matched data from merge\n",
    "    return r.system_merges # merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority vote \n",
    "def vectorized_annotations(ann):\n",
    "    \n",
    "    docs = get_docs(corpus)\n",
    "    labels = [\"concept\"]\n",
    "    out= []\n",
    "    \n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        a = label_vector(docs[n][1], a1, labels)\n",
    "        out.append(a)\n",
    "\n",
    "    return out\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def get_reference_vector(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    df = ref_ann.copy()\n",
    "    df = df.drop_duplicates(subset=['begin','end','case'])\n",
    "    df['label'] = 'concept'\n",
    "\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ref = df[cols_to_keep].copy()\n",
    "    test = vectorized_annotations(ref)\n",
    "    ref =  np.asarray(flatten_list(test), dtype=np.int32) \n",
    "\n",
    "    return ref\n",
    "\n",
    "def majority_overlap_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    d = {}\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys_test = []\n",
    "    \n",
    "    for system in systems:\n",
    "        sys_ann = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        df = sys_ann.copy()\n",
    "        df['label'] = 'concept'\n",
    "        df = df.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "        sys = df[df['system']==system][cols_to_keep].copy()\n",
    "        test = vectorized_annotations(sys)\n",
    "        d[system] = flatten_list(test) \n",
    "        sys_test.append(d[system])\n",
    "\n",
    "    output = sum(np.array(sys_test))\n",
    "    \n",
    "    n = int(len(systems) / 2)\n",
    "    #print(n)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        vote = np.where(output > n, 1, 0)\n",
    "    else:\n",
    "        vote = np.where(output > n, 1, \n",
    "         (np.where(output == n, random.randint(0, 1), 0)))\n",
    "        \n",
    "    return vote\n",
    "\n",
    "def majority_overlap_vote_out(ref, vote, corpus):    \n",
    "    TP, TN, FP, FN = confused(ref, vote)\n",
    "    print(TP, TN, FP, FN)\n",
    "    system_n = TP + FP\n",
    "    reference_n = TP + FN\n",
    "\n",
    "    d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "\n",
    "    d['TN'] = TN\n",
    "    d['corpus'] = corpus\n",
    "    print(d)\n",
    "    \n",
    "    metrics = pd.DataFrame(d, index=[0])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# control vote run\n",
    "def majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            \n",
    "            if run_type == 'overlap':\n",
    "                ref = get_reference_vector(analysis_type, corpus, filter_semtype, semtype)\n",
    "                vote = majority_overlap_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                metrics = majority_overlap_vote_out(ref, vote, corpus)\n",
    "                #generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "            elif run_type == 'exact':\n",
    "                sys = majority_exact_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                d = majority_exact_vote_out(sys, filter_semtype, semtype)\n",
    "                metrics = pd.DataFrame(d, index=[0])\n",
    "            elif run_type == 'cui':\n",
    "                sys = majority_cui_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                d = majority_cui_vote_out(sys, filter_semtype, semtype)\n",
    "                metrics = pd.DataFrame(d, index=[0])\n",
    "           \n",
    "            metrics['systems'] = ','.join(test)\n",
    "            generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "                \n",
    "    else:\n",
    "        if run_type == 'overlap':\n",
    "            ref = get_reference_vector(analysis_type, corpus, filter_semtype)\n",
    "            vote = majority_overlap_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            metrics = majority_overlap_vote_out(ref, vote, corpus)\n",
    "            \n",
    "        elif run_type == 'exact':\n",
    "            sys = majority_exact_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            d = majority_exact_vote_out(sys, filter_semtype)\n",
    "            metrics = pd.DataFrame(d, index=[0])\n",
    "            \n",
    "        elif run_type == 'cui':\n",
    "            sys = majority_cui_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            d = majority_cui_vote_out(sys, filter_semtype)\n",
    "            metrics = pd.DataFrame(d, index=[0])\n",
    "            \n",
    "        metrics['systems'] = ','.join(systems)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "def majority_cui_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "   \n",
    "    cols_to_keep = ['cui', 'note_id', 'system']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for system in systems:\n",
    "        if filter_semtype:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        sys = sys[sys['system'] == system][cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        frames = [df, sys]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def majority_cui_vote_out(sys, filter_semtype, semtype = None):\n",
    "    \n",
    "    sys = sys.astype(str)\n",
    "    sys['value_cui'] = list(zip(sys.cui, sys.note_id.astype(str)))\n",
    "    sys['count'] = sys.groupby(['value_cui'])['value_cui'].transform('count')\n",
    "\n",
    "    n = int(len(systems) / 2)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        sys = sys[sys['count'] > n]\n",
    "    else:\n",
    "        # https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "        for i in sys.index:\n",
    "            if sys.at[i, 'count'] == n:\n",
    "                sys.at[i, 'count'] = random.choice([1,len(systems)])\n",
    "        sys = sys[sys['count'] > n]\n",
    "\n",
    "    sys = sys.drop_duplicates(subset=['value_cui', 'cui', 'note_id'])\n",
    "    ref = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    c = get_cooccurences(ref, sys, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "        # get dictionary of confusion matrix metrics\n",
    "        print(cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n))\n",
    "        return cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "    \n",
    "\n",
    "def majority_exact_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "   \n",
    "    cols_to_keep = ['begin', 'end', 'note_id', 'system']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for system in systems:\n",
    "        if filter_semtype:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        sys = sys[sys['system'] == system][cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        frames = [df, sys]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "    return df\n",
    "        \n",
    "def majority_exact_vote_out(sys, filter_semtype, semtype = None):\n",
    "    sys['span'] = list(zip(sys.begin, sys.end, sys.note_id.astype(str)))\n",
    "    sys['count'] = sys.groupby(['span'])['span'].transform('count')\n",
    "\n",
    "    n = int(len(systems) / 2)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        sys = sys[sys['count'] > n]\n",
    "    else:\n",
    "        # https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "        for i in sys.index:\n",
    "            if sys.at[i, 'count'] == n:\n",
    "                sys.at[i, 'count'] = random.choice([1,len(systems)])\n",
    "        sys = sys[sys['count'] > n]\n",
    "\n",
    "    sys = sys.drop_duplicates(subset=['span', 'begin', 'end', 'note_id'])\n",
    "    ref = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    c = get_cooccurences(ref, sys, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "        # get dictionary of confusion matrix metrics\n",
    "        print(cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n))\n",
    "        return cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "    \n",
    "#ensemble_type = 'vote'        \n",
    "#filter_semtype = False\n",
    "#majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clamp', 'quick_umls', 'metamap'] ('analytical_mipacq_cui.csv', 'concepts.mipacq_all')\n",
      "run_type: overlap\n",
      "['Procedures', 'Disorders,Sign_Symptom', 'Anatomy', 'Chemicals_and_drugs'] ['clamp', 'quick_umls', 'metamap']\n",
      "SYSTEMS FOR SEMTYPE Procedures ARE ['clamp', 'quick_umls', 'metamap']\n",
      "processing merge combo: ('clamp', 'quick_umls', 'metamap')\n",
      "Processing sentence: clamp\n",
      "clamp st {'treatment', 'test'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((8940, 738455, 5412, 20744), (0.3260093648459863, 0.3143663286536675, 0.2960812017949108))\n",
      "Processing sentence: quick_umls\n",
      "quick_umls st {'T058', 'T065', 'T063', 'T062', 'T059', 'T061', 'T060'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((16043, 733271, 12528, 11709), (0.41325955155928124, 0.44930011137762316, 0.4058336653984477))\n",
      "Processing sentence: metamap\n",
      "metamap st {'resa', 'lbpr', 'hlca', 'mbrt', 'edac', 'topp', 'diap'}\n",
      "((13623, 734173, 10655, 15100), (0.3802130350390937, 0.3807467158313623, 0.34954959570752087))\n",
      "Processing sentence:  ( clamp & quick_umls ) \n",
      "((7701, 739788, 3346, 22716), (0.2840569349877598, 0.2610973054261405, 0.2534176342089102))\n",
      "Processing sentence:  ( clamp | quick_umls ) \n",
      "((16896, 732210, 13783, 10662), (0.4455741779083751, 0.49005101425128145, 0.4376912714187596))\n",
      "Processing sentence:  ( clamp & metamap ) \n",
      "((6989, 739671, 3505, 23386), (0.2698066837553322, 0.23428829282069, 0.23052584450235533))\n",
      "Processing sentence:  ( clamp | metamap ) \n",
      "((15340, 733106, 12092, 13013), (0.42646026683244226, 0.45026880281905163, 0.4048207866639047))\n",
      "Processing sentence:  ( quick_umls & metamap ) \n",
      "((11216, 737487, 6715, 18133), (0.3417696053650576, 0.32588889475555305, 0.30882469584208894))\n",
      "Processing sentence:  ( quick_umls | metamap ) \n",
      "((18087, 730449, 15576, 9439), (0.4475541059028931, 0.4946994984051905, 0.4393857301824285))\n",
      "Processing sentence:  ( ( clamp & quick_umls ) & metamap ) \n",
      "((6337, 740165, 2657, 24392), (0.24858615118344393, 0.2152984856310451, 0.21213917476242264))\n",
      "Processing sentence:  ( ( clamp & quick_umls ) | metamap ) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((14912, 733825, 11207, 13607), (0.410722117683036, 0.42310421453992525, 0.38562227424588313))\n",
      "Processing sentence:  ( ( clamp | quick_umls ) & metamap ) \n",
      "((11770, 737022, 7356, 17403), (0.35904893326351683, 0.3439112982341235, 0.32568002287886955))\n",
      "Processing sentence:  ( ( clamp | quick_umls ) | metamap ) \n",
      "((18437, 729812, 16288, 9014), (0.4605856435918469, 0.5182290416481075, 0.4551647215416176))\n",
      "processing merge combo: ('clamp', 'metamap', 'quick_umls')\n",
      "Processing sentence:  ( metamap & quick_umls ) \n",
      "((11216, 737487, 6715, 18133), (0.3417696053650576, 0.32588889475555305, 0.30882469584208894))\n",
      "Processing sentence:  ( metamap | quick_umls ) \n",
      "((18087, 730449, 15576, 9439), (0.4475541059028931, 0.4946994984051905, 0.4393857301824285))\n",
      "Processing sentence:  ( ( clamp & metamap ) & quick_umls ) \n",
      "((6337, 740165, 2657, 24392), (0.24858615118344393, 0.2152984856310451, 0.21213917476242264))\n",
      "Processing sentence:  ( ( clamp & metamap ) | quick_umls ) \n",
      "((16505, 732917, 12943, 11186), (0.42947658604136624, 0.46505566700193124, 0.4205469746105027))\n",
      "Processing sentence:  ( ( clamp | metamap ) & quick_umls ) \n",
      "((12524, 737110, 7357, 16560), (0.3728570385797985, 0.369679389253481, 0.3464650144606873))\n",
      "Processing sentence:  ( ( clamp | metamap ) | quick_umls ) \n",
      "((18437, 729812, 16288, 9014), (0.4605856435918469, 0.5182290416481075, 0.4551647215416176))\n",
      "processing merge combo: ('quick_umls', 'metamap', 'clamp')\n",
      "Processing sentence:  ( quick_umls & clamp ) \n",
      "((7701, 739788, 3346, 22716), (0.2840569349877598, 0.2610973054261405, 0.2534176342089102))\n",
      "Processing sentence:  ( quick_umls | clamp ) \n",
      "((16896, 732210, 13783, 10662), (0.4455741779083751, 0.49005101425128145, 0.4376912714187596))\n",
      "Processing sentence:  ( metamap & clamp ) \n",
      "((6989, 739671, 3505, 23386), (0.2698066837553322, 0.23428829282069, 0.23052584450235533))\n",
      "Processing sentence:  ( metamap | clamp ) \n",
      "((15340, 733106, 12092, 13013), (0.42646026683244226, 0.45026880281905163, 0.4048207866639047))\n",
      "Processing sentence:  ( ( quick_umls & metamap ) & clamp ) \n",
      "((6337, 740165, 2657, 24392), (0.24858615118344393, 0.2152984856310451, 0.21213917476242264))\n",
      "Processing sentence:  ( ( quick_umls & metamap ) | clamp ) \n",
      "((13574, 735835, 9075, 15067), (0.40860020761156385, 0.4165847576763906, 0.3835024321435826))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) & clamp ) \n",
      "((8353, 739294, 4194, 21710), (0.3036218322991992, 0.28008711261578545, 0.2709656214155486))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) | clamp ) \n",
      "((18437, 729812, 16288, 9014), (0.4605856435918469, 0.5182290416481075, 0.4551647215416176))\n",
      "          F1  precision    recall     TP     FN     FP     TP/FN  n_gold  \\\n",
      "0   0.406031   0.622910  0.301172   8940  20744   5412  0.430968   29684   \n",
      "2   0.514066   0.561125  0.474289  13623  15100  10655  0.902185   28723   \n",
      "1   0.569678   0.561513  0.578084  16043  11709  12528  1.370143   27752   \n",
      "5   0.342020   0.666000  0.230091   6989  23386   3505  0.298854   30375   \n",
      "3   0.371455   0.697112  0.253181   7701  22716   3346  0.339012   30417   \n",
      "6   0.549969   0.559201  0.541036  15340  13013  12092  1.178821   28353   \n",
      "4   0.580250   0.550735  0.613107  16896  10662  13783  1.584693   27558   \n",
      "33  0.342020   0.666000  0.230091   6989  23386   3505  0.298854   30375   \n",
      "20  0.474450   0.625509  0.382160  11216  18133   6715  0.618541   29349   \n",
      "34  0.549969   0.559201  0.541036  15340  13013  12092  1.178821   28353   \n",
      "21  0.591185   0.537296  0.657088  18087   9439  15576  1.916199   27526   \n",
      "31  0.371455   0.697112  0.253181   7701  22716   3346  0.339012   30417   \n",
      "7   0.474450   0.625509  0.382160  11216  18133   6715  0.618541   29349   \n",
      "32  0.580250   0.550735  0.613107  16896  10662  13783  1.584693   27558   \n",
      "8   0.591185   0.537296  0.657088  18087   9439  15576  1.916199   27526   \n",
      "22  0.319059   0.704581  0.206222   6337  24392   2657  0.259798   30729   \n",
      "23  0.577714   0.560479  0.596042  16505  11186  12943  1.475505   27691   \n",
      "9   0.319059   0.704581  0.206222   6337  24392   2657  0.259798   30729   \n",
      "10  0.545847   0.570925  0.522879  14912  13607  11207  1.095907   28519   \n",
      "24  0.511549   0.629948  0.430615  12524  16560   7357  0.756280   29084   \n",
      "25  0.593058   0.530943  0.671633  18437   9014  16288  2.045374   27451   \n",
      "11  0.487381   0.615393  0.403455  11770  17403   7356  0.676320   29173   \n",
      "12  0.593058   0.530943  0.671633  18437   9014  16288  2.045374   27451   \n",
      "35  0.319059   0.704581  0.206222   6337  24392   2657  0.259798   30729   \n",
      "36  0.529304   0.599320  0.473936  13574  15067   9075  0.900909   28641   \n",
      "37  0.392068   0.665737  0.277850   8353  21710   4194  0.384754   30063   \n",
      "38  0.593058   0.530943  0.671633  18437   9014  16288  2.045374   27451   \n",
      "\n",
      "    n_sys         TM      TN   macro_p   macro_r  macro_f1  \\\n",
      "0   14352  74.624478  738455  0.326009  0.314366  0.296081   \n",
      "2   24278  87.431173  734173  0.380213  0.380747  0.349550   \n",
      "1   28571  94.912380  733271  0.413260  0.449300  0.405834   \n",
      "5   10494  68.225152  739671  0.269807  0.234288  0.230526   \n",
      "3   11047  73.269790  739788  0.284057  0.261097  0.253418   \n",
      "6   27432  92.618261  733106  0.426460  0.450269  0.404821   \n",
      "4   30679  96.463563  732210  0.445574  0.490051  0.437691   \n",
      "33  10494  68.225152  739671  0.269807  0.234288  0.230526   \n",
      "20  17931  83.759822  737487  0.341770  0.325889  0.308825   \n",
      "34  27432  92.618261  733106  0.426460  0.450269  0.404821   \n",
      "21  33663  98.580299  730449  0.447554  0.494699  0.439386   \n",
      "31  11047  73.269790  739788  0.284057  0.261097  0.253418   \n",
      "7   17931  83.759822  737487  0.341770  0.325889  0.308825   \n",
      "32  30679  96.463563  732210  0.445574  0.490051  0.437691   \n",
      "8   33663  98.580299  730449  0.447554  0.494699  0.439386   \n",
      "22   8994  66.820122  740165  0.248586  0.215298  0.212139   \n",
      "23  29448  96.180632  732917  0.429477  0.465056  0.420547   \n",
      "9    8994  66.820122  740165  0.248586  0.215298  0.212139   \n",
      "10  26119  92.269384  733825  0.410722  0.423104  0.385622   \n",
      "24  19881  88.822695  737110  0.372857  0.369679  0.346465   \n",
      "25  34725  98.939367  729812  0.460586  0.518229  0.455165   \n",
      "11  19126  85.106825  737022  0.359049  0.343911  0.325680   \n",
      "12  34725  98.939367  729812  0.460586  0.518229  0.455165   \n",
      "35   8994  66.820122  740165  0.248586  0.215298  0.212139   \n",
      "36  22649  90.195180  735835  0.408600  0.416585  0.383502   \n",
      "37  12547  74.571440  739294  0.303622  0.280087  0.270966   \n",
      "38  34725  98.939367  729812  0.460586  0.518229  0.455165   \n",
      "\n",
      "                           merge  n_terms  F1 rank  TP/FN rank  TM rank  \\\n",
      "0                          clamp        1     19.0        19.0     19.0   \n",
      "2                        metamap        1     14.0        13.0     15.0   \n",
      "1                     quick_umls        1      9.0         9.0      9.0   \n",
      "5                (clamp&metamap)        2     23.5        23.5     23.5   \n",
      "3             (clamp&quick_umls)        2     21.5        21.5     21.5   \n",
      "6                (clamp|metamap)        2     10.5        10.5     10.5   \n",
      "4             (clamp|quick_umls)        2      6.5         6.5      6.5   \n",
      "33               (metamap&clamp)        2     23.5        23.5     23.5   \n",
      "20          (metamap&quick_umls)        2     17.5        17.5     17.5   \n",
      "34               (metamap|clamp)        2     10.5        10.5     10.5   \n",
      "21          (metamap|quick_umls)        2      4.5         4.5      4.5   \n",
      "31            (quick_umls&clamp)        2     21.5        21.5     21.5   \n",
      "7           (quick_umls&metamap)        2     17.5        17.5     17.5   \n",
      "32            (quick_umls|clamp)        2      6.5         6.5      6.5   \n",
      "8           (quick_umls|metamap)        2      4.5         4.5      4.5   \n",
      "22  ((clamp&metamap)&quick_umls)        3     26.0        26.0     26.0   \n",
      "23  ((clamp&metamap)|quick_umls)        3      8.0         8.0      8.0   \n",
      "9   ((clamp&quick_umls)&metamap)        3     26.0        26.0     26.0   \n",
      "10  ((clamp&quick_umls)|metamap)        3     12.0        12.0     12.0   \n",
      "24  ((clamp|metamap)&quick_umls)        3     15.0        15.0     14.0   \n",
      "25  ((clamp|metamap)|quick_umls)        3      2.0         2.0      2.0   \n",
      "11  ((clamp|quick_umls)&metamap)        3     16.0        16.0     16.0   \n",
      "12  ((clamp|quick_umls)|metamap)        3      2.0         2.0      2.0   \n",
      "35  ((quick_umls&metamap)&clamp)        3     26.0        26.0     26.0   \n",
      "36  ((quick_umls&metamap)|clamp)        3     13.0        14.0     13.0   \n",
      "37  ((quick_umls|metamap)&clamp)        3     20.0        20.0     20.0   \n",
      "38  ((quick_umls|metamap)|clamp)        3      2.0         2.0      2.0   \n",
      "\n",
      "        Gmean  \n",
      "0   19.000000  \n",
      "2   13.968209  \n",
      "1    9.000000  \n",
      "5   23.500000  \n",
      "3   21.500000  \n",
      "6   10.500000  \n",
      "4    6.500000  \n",
      "33  23.500000  \n",
      "20  17.500000  \n",
      "34  10.500000  \n",
      "21   4.500000  \n",
      "31  21.500000  \n",
      "7   17.500000  \n",
      "32   6.500000  \n",
      "8    4.500000  \n",
      "22  26.000000  \n",
      "23   8.000000  \n",
      "9   26.000000  \n",
      "10  12.000000  \n",
      "24  14.547028  \n",
      "25   2.000000  \n",
      "11  16.000000  \n",
      "12   2.000000  \n",
      "35  26.000000  \n",
      "36  13.435309  \n",
      "37  20.000000  \n",
      "38   2.000000  \n",
      "SYSTEMS FOR SEMTYPE Disorders,Sign_Symptom ARE ['clamp', 'quick_umls', 'metamap']\n",
      "processing merge combo: ('clamp', 'quick_umls', 'metamap')\n",
      "Processing sentence: clamp\n",
      "clamp st {'labvalue', 'problem'}\n",
      "((17645, 696833, 7280, 51793), (0.29161753842435284, 0.25108467219640057, 0.24770716057519254))\n",
      "Processing sentence: quick_umls\n",
      "quick_umls st {'T047', 'T033', 'T190', 'T048', 'T184', 'T020', 'T049', 'T191', 'T050', 'T037', 'T019', 'T046'}\n",
      "((41035, 687682, 21785, 23049), (0.46781450801618435, 0.49427954047049255, 0.4511517838809138))\n",
      "Processing sentence: metamap\n",
      "metamap st {'anab', 'dsyn', 'cgab', 'fndg', 'sosy', 'mobd', 'inpo', 'neop', 'acab', 'comd', 'patf', 'emod'}\n",
      "((33166, 690558, 17781, 32046), (0.4493074699687818, 0.43545522721815244, 0.4139795364472951))\n",
      "Processing sentence:  ( clamp & quick_umls ) \n",
      "((15518, 697363, 5122, 55548), (0.258596930353092, 0.2158110134221161, 0.2165444166779177))\n",
      "Processing sentence:  ( clamp | quick_umls ) \n",
      "((42476, 687364, 22230, 21481), (0.49611826676336035, 0.5199795609561652, 0.47659655796115064))\n",
      "Processing sentence:  ( clamp & metamap ) \n",
      "((14062, 697576, 4653, 57260), (0.2667394313331508, 0.2046605601258736, 0.21153967449134164))\n",
      "Processing sentence:  ( clamp | metamap ) \n",
      "((36467, 690022, 19512, 27550), (0.46682763583328346, 0.47802432897881925, 0.44417210087536796))\n",
      "Processing sentence:  ( quick_umls & metamap ) \n",
      "((28838, 693991, 12267, 38455), (0.39958209567338315, 0.3734832417852661, 0.36040643227455027))\n",
      "Processing sentence:  ( quick_umls | metamap ) \n",
      "((44581, 684564, 25484, 18922), (0.5181730858465075, 0.5469287946574786, 0.5007482444411623))\n",
      "Processing sentence:  ( ( clamp & quick_umls ) & metamap ) \n",
      "((12784, 697705, 3901, 59161), (0.24225475314441763, 0.18372377074166238, 0.19092619412524192))\n",
      "Processing sentence:  ( ( clamp & quick_umls ) | metamap ) \n",
      "((35793, 690270, 18712, 28776), (0.46090160165139354, 0.4654570425644624, 0.43516819840746745))\n",
      "Processing sentence:  ( ( clamp | quick_umls ) & metamap ) \n",
      "((29931, 693869, 12528, 37223), (0.4214817749321616, 0.3911812444598799, 0.37848933767842646))\n",
      "Processing sentence:  ( ( clamp | quick_umls ) | metamap ) \n",
      "((45085, 684360, 25979, 18127), (0.5244511130959211, 0.5565058462478717, 0.5082151024618413))\n",
      "processing merge combo: ('clamp', 'metamap', 'quick_umls')\n",
      "Processing sentence:  ( metamap & quick_umls ) \n",
      "((28838, 693991, 12267, 38455), (0.39958209567338315, 0.3734832417852661, 0.36040643227455027))\n",
      "Processing sentence:  ( metamap | quick_umls ) \n",
      "((44581, 684564, 25484, 18922), (0.5181730858465075, 0.5469287946574786, 0.5007482444411623))\n",
      "Processing sentence:  ( ( clamp & metamap ) & quick_umls ) \n",
      "((12784, 697705, 3901, 59161), (0.24225475314441763, 0.18372377074166238, 0.19092619412524192))\n",
      "Processing sentence:  ( ( clamp & metamap ) | quick_umls ) \n",
      "((41955, 687588, 21711, 22297), (0.4896503613097761, 0.5097728044656255, 0.46859279780620994))\n",
      "Processing sentence:  ( ( clamp | metamap ) & quick_umls ) \n",
      "((31555, 693663, 13369, 34964), (0.4117460435366662, 0.4053759387058367, 0.3829379476609478))\n",
      "Processing sentence:  ( ( clamp | metamap ) | quick_umls ) \n",
      "((45085, 684360, 25979, 18127), (0.5244511130959211, 0.5565058462478717, 0.5082151024618413))\n",
      "processing merge combo: ('quick_umls', 'metamap', 'clamp')\n",
      "Processing sentence:  ( quick_umls & clamp ) \n",
      "((15518, 697363, 5122, 55548), (0.258596930353092, 0.2158110134221161, 0.2165444166779177))\n",
      "Processing sentence:  ( quick_umls | clamp ) \n",
      "((42476, 687364, 22230, 21481), (0.49611826676336035, 0.5199795609561652, 0.47659655796115064))\n",
      "Processing sentence:  ( metamap & clamp ) \n",
      "((14062, 697576, 4653, 57260), (0.2667394313331508, 0.2046605601258736, 0.21153967449134164))\n",
      "Processing sentence:  ( metamap | clamp ) \n",
      "((36467, 690022, 19512, 27550), (0.46682763583328346, 0.47802432897881925, 0.44417210087536796))\n",
      "Processing sentence:  ( ( quick_umls & metamap ) & clamp ) \n",
      "((12784, 697705, 3901, 59161), (0.24225475314441763, 0.18372377074166238, 0.19092619412524192))\n",
      "Processing sentence:  ( ( quick_umls & metamap ) | clamp ) \n",
      "((33339, 693273, 14486, 32453), (0.44041391030603294, 0.43625432385846286, 0.4107489318905533))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) & clamp ) \n",
      "((16796, 697234, 5874, 53647), (0.2830972462512855, 0.2367070571013363, 0.237037818688464))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) | clamp ) \n",
      "((45085, 684360, 25979, 18127), (0.5244511130959211, 0.5565058462478717, 0.5082151024618413))\n",
      "          F1  precision    recall     TP     FN     FP     TP/FN  n_gold  \\\n",
      "0   0.373981   0.707924  0.254112  17645  51793   7280  0.340683   69438   \n",
      "2   0.571045   0.650990  0.508587  33166  32046  17781  1.034950   65212   \n",
      "1   0.646709   0.653216  0.640331  41035  23049  21785  1.780338   64084   \n",
      "5   0.312360   0.751376  0.197162  14062  57260   4653  0.245582   71322   \n",
      "3   0.338429   0.751841  0.218360  15518  55548   5122  0.279362   71066   \n",
      "6   0.607804   0.651441  0.569646  36467  27550  19512  1.323666   64017   \n",
      "4   0.660268   0.656446  0.664134  42476  21481  22230  1.977375   63957   \n",
      "33  0.312360   0.751376  0.197162  14062  57260   4653  0.245582   71322   \n",
      "20  0.532076   0.701569  0.428544  28838  38455  12267  0.749915   67293   \n",
      "34  0.607804   0.651441  0.569646  36467  27550  19512  1.323666   64017   \n",
      "21  0.667540   0.636281  0.702030  44581  18922  25484  2.356041   63503   \n",
      "31  0.338429   0.751841  0.218360  15518  55548   5122  0.279362   71066   \n",
      "7   0.532076   0.701569  0.428544  28838  38455  12267  0.749915   67293   \n",
      "32  0.660268   0.656446  0.664134  42476  21481  22230  1.977375   63957   \n",
      "8   0.667540   0.636281  0.702030  44581  18922  25484  2.356041   63503   \n",
      "22  0.288480   0.766197  0.177691  12784  59161   3901  0.216088   71945   \n",
      "23  0.655967   0.658986  0.652976  41955  22297  21711  1.881643   64252   \n",
      "9   0.288480   0.766197  0.177691  12784  59161   3901  0.216088   71945   \n",
      "10  0.601189   0.656692  0.554337  35793  28776  18712  1.243849   64569   \n",
      "24  0.566298   0.702409  0.474376  31555  34964  13369  0.902500   66519   \n",
      "25  0.671527   0.634428  0.713235  45085  18127  25979  2.487174   63212   \n",
      "11  0.546121   0.704939  0.445707  29931  37223  12528  0.804100   67154   \n",
      "12  0.671527   0.634428  0.713235  45085  18127  25979  2.487174   63212   \n",
      "35  0.288480   0.766197  0.177691  12784  59161   3901  0.216088   71945   \n",
      "36  0.586866   0.697104  0.506733  33339  32453  14486  1.027301   65792   \n",
      "37  0.360766   0.740891  0.238434  16796  53647   5874  0.313084   70443   \n",
      "38  0.671527   0.634428  0.713235  45085  18127  25979  2.487174   63212   \n",
      "\n",
      "    n_sys          TM      TN   macro_p   macro_r  macro_f1  \\\n",
      "0   24925  111.764551  696833  0.291618  0.251085  0.247707   \n",
      "2   50947  146.937886  690558  0.449307  0.435455  0.413980   \n",
      "1   62820  163.721408  687682  0.467815  0.494280  0.451152   \n",
      "5   18715  102.790310  697576  0.266739  0.204661  0.211540   \n",
      "3   20640  108.014212  697363  0.258597  0.215811  0.216544   \n",
      "6   55979  154.130103  690022  0.466828  0.478024  0.444172   \n",
      "4   64706  166.982645  687364  0.496118  0.519980  0.476597   \n",
      "33  18715  102.790310  697576  0.266739  0.204661  0.211540   \n",
      "20  41105  142.238712  693991  0.399582  0.373483  0.360406   \n",
      "34  55979  154.130103  690022  0.466828  0.478024  0.444172   \n",
      "21  70065  168.422164  684564  0.518173  0.546929  0.500748   \n",
      "31  20640  108.014212  697363  0.258597  0.215811  0.216544   \n",
      "7   41105  142.238712  693991  0.399582  0.373483  0.360406   \n",
      "32  64706  166.982645  687364  0.496118  0.519980  0.476597   \n",
      "8   70065  168.422164  684564  0.518173  0.546929  0.500748   \n",
      "22  16685   98.970020  697705  0.242255  0.183724  0.190926   \n",
      "23  63666  166.276143  687588  0.489650  0.509773  0.468593   \n",
      "9   16685   98.970020  697705  0.242255  0.183724  0.190926   \n",
      "10  54505  153.313334  690270  0.460902  0.465457  0.435168   \n",
      "24  44924  148.877468  693663  0.411746  0.405376  0.382938   \n",
      "25  71064  169.124782  684360  0.524451  0.556506  0.508215   \n",
      "11  42459  145.256758  693869  0.421482  0.391181  0.378489   \n",
      "12  71064  169.124782  684360  0.524451  0.556506  0.508215   \n",
      "35  16685   98.970020  697705  0.242255  0.183724  0.190926   \n",
      "36  47825  152.449175  693273  0.440414  0.436254  0.410749   \n",
      "37  22670  111.552705  697234  0.283097  0.236707  0.237038   \n",
      "38  71064  169.124782  684360  0.524451  0.556506  0.508215   \n",
      "\n",
      "                           merge  n_terms  F1 rank  TP/FN rank  TM rank  \\\n",
      "0                          clamp        1     19.0        19.0     19.0   \n",
      "2                        metamap        1     14.0        13.0     15.0   \n",
      "1                     quick_umls        1      9.0         9.0      9.0   \n",
      "5                (clamp&metamap)        2     23.5        23.5     23.5   \n",
      "3             (clamp&quick_umls)        2     21.5        21.5     21.5   \n",
      "6                (clamp|metamap)        2     10.5        10.5     10.5   \n",
      "4             (clamp|quick_umls)        2      6.5         6.5      6.5   \n",
      "33               (metamap&clamp)        2     23.5        23.5     23.5   \n",
      "20          (metamap&quick_umls)        2     17.5        17.5     17.5   \n",
      "34               (metamap|clamp)        2     10.5        10.5     10.5   \n",
      "21          (metamap|quick_umls)        2      4.5         4.5      4.5   \n",
      "31            (quick_umls&clamp)        2     21.5        21.5     21.5   \n",
      "7           (quick_umls&metamap)        2     17.5        17.5     17.5   \n",
      "32            (quick_umls|clamp)        2      6.5         6.5      6.5   \n",
      "8           (quick_umls|metamap)        2      4.5         4.5      4.5   \n",
      "22  ((clamp&metamap)&quick_umls)        3     26.0        26.0     26.0   \n",
      "23  ((clamp&metamap)|quick_umls)        3      8.0         8.0      8.0   \n",
      "9   ((clamp&quick_umls)&metamap)        3     26.0        26.0     26.0   \n",
      "10  ((clamp&quick_umls)|metamap)        3     12.0        12.0     12.0   \n",
      "24  ((clamp|metamap)&quick_umls)        3     15.0        15.0     14.0   \n",
      "25  ((clamp|metamap)|quick_umls)        3      2.0         2.0      2.0   \n",
      "11  ((clamp|quick_umls)&metamap)        3     16.0        16.0     16.0   \n",
      "12  ((clamp|quick_umls)|metamap)        3      2.0         2.0      2.0   \n",
      "35  ((quick_umls&metamap)&clamp)        3     26.0        26.0     26.0   \n",
      "36  ((quick_umls&metamap)|clamp)        3     13.0        14.0     13.0   \n",
      "37  ((quick_umls|metamap)&clamp)        3     20.0        20.0     20.0   \n",
      "38  ((quick_umls|metamap)|clamp)        3      2.0         2.0      2.0   \n",
      "\n",
      "        Gmean  \n",
      "0   19.000000  \n",
      "2   13.968209  \n",
      "1    9.000000  \n",
      "5   23.500000  \n",
      "3   21.500000  \n",
      "6   10.500000  \n",
      "4    6.500000  \n",
      "33  23.500000  \n",
      "20  17.500000  \n",
      "34  10.500000  \n",
      "21   4.500000  \n",
      "31  21.500000  \n",
      "7   17.500000  \n",
      "32   6.500000  \n",
      "8    4.500000  \n",
      "22  26.000000  \n",
      "23   8.000000  \n",
      "9   26.000000  \n",
      "10  12.000000  \n",
      "24  14.547028  \n",
      "25   2.000000  \n",
      "11  16.000000  \n",
      "12   2.000000  \n",
      "35  26.000000  \n",
      "36  13.435309  \n",
      "37  20.000000  \n",
      "38   2.000000  \n",
      "SYSTEMS FOR SEMTYPE Anatomy ARE ['quick_umls', 'metamap']\n",
      "processing merge combo: ('quick_umls', 'metamap')\n",
      "Processing sentence: quick_umls\n",
      "quick_umls st {'T022', 'T031', 'T021', 'T029', 'T025', 'T023', 'T024', 'T018', 'T017', 'T030', 'T026'}\n",
      "((12484, 745656, 8336, 7075), (0.3301603561453471, 0.40080727366410734, 0.3329228316863051))\n",
      "Processing sentence: metamap\n",
      "metamap st {'celc', 'bsoj', 'blor', 'bpoc', 'bdsu', 'cell', 'tisu', 'emst', 'anst', 'bdsy', 'ffas'}\n",
      "((5960, 747474, 4398, 15719), (0.286730212312982, 0.2813705246289403, 0.25285392412508767))\n",
      "Processing sentence:  ( quick_umls & metamap ) \n",
      "((4923, 747818, 3363, 17447), (0.22363560165264873, 0.21130672557808633, 0.19250396248760976))\n",
      "Processing sentence:  ( quick_umls | metamap ) \n",
      "((13443, 745364, 9080, 5664), (0.3943229822538638, 0.4663986828142572, 0.3922996738188138))\n",
      "         F1  precision    recall     TP     FN    FP     TP/FN  n_gold  n_sys  \\\n",
      "1  0.372070   0.575401  0.274920   5960  15719  4398  0.379159   21679  10358   \n",
      "0  0.618341   0.599616  0.638274  12484   7075  8336  1.764523   19559  20820   \n",
      "2  0.321177   0.594135  0.220072   4923  17447  3363  0.282169   22370   8286   \n",
      "3  0.645832   0.596857  0.703564  13443   5664  9080  2.373411   19107  22523   \n",
      "\n",
      "          TM      TN   macro_p   macro_r  macro_f1                 merge  \\\n",
      "1  58.560976  747474  0.286730  0.281371  0.252854               metamap   \n",
      "0  86.519380  745656  0.330160  0.400807  0.332923            quick_umls   \n",
      "2  54.082576  747818  0.223636  0.211307  0.192504  (quick_umls&metamap)   \n",
      "3  89.574229  745364  0.394323  0.466399  0.392300  (quick_umls|metamap)   \n",
      "\n",
      "   n_terms  F1 rank  TP/FN rank  TM rank  Gmean  \n",
      "1        1      3.0         3.0      3.0    3.0  \n",
      "0        1      2.0         2.0      2.0    2.0  \n",
      "2        2      4.0         4.0      4.0    4.0  \n",
      "3        2      1.0         1.0      1.0    1.0  \n",
      "SYSTEMS FOR SEMTYPE Chemicals_and_drugs ARE ['clamp', 'quick_umls', 'metamap']\n",
      "processing merge combo: ('clamp', 'quick_umls', 'metamap')\n",
      "Processing sentence: clamp\n",
      "clamp st {'drug'}\n",
      "((6738, 754330, 1439, 11044), (0.39195435551306934, 0.3785915835882612, 0.3689117318032021))\n",
      "Processing sentence: quick_umls\n",
      "quick_umls st {'T126', 'T103', 'T109', 'T123', 'T125', 'T195', 'T121', 'T127', 'T122', 'T104', 'T200', 'T196', 'T116', 'T129', 'T114', 'T192', 'T197', 'T120', 'T130', 'T131'}\n",
      "((11382, 751554, 5717, 4898), (0.6074408162572515, 0.6846922073933646, 0.6218417732473428))\n",
      "Processing sentence: metamap\n",
      "metamap st {'vita', 'bacs', 'imft', 'aapp', 'inch', 'irda', 'enzy', 'phsu', 'clnd', 'chvs', 'chem', 'hops', 'nnon', 'antb', 'horm', 'orch', 'bodm', 'elii', 'chvf', 'rcpt'}\n",
      "((8445, 751393, 5425, 8288), (0.5337833608824323, 0.47525048471052334, 0.471286185866771))\n",
      "Processing sentence:  ( clamp & quick_umls ) \n",
      "((6454, 754478, 1255, 11364), (0.38296971804438973, 0.36067690091634586, 0.3559342009929394))\n",
      "Processing sentence:  ( clamp | quick_umls ) \n",
      "((11583, 751422, 5846, 4700), (0.6136015031752302, 0.6957412027561001, 0.6296771251232282))\n",
      "Processing sentence:  ( clamp & metamap ) \n",
      "((4422, 754674, 868, 13587), (0.30323478520051644, 0.23232787387092937, 0.248221830499468))\n",
      "Processing sentence:  ( clamp | metamap ) \n",
      "((10716, 751066, 5936, 5833), (0.6154768140908871, 0.6159988399013682, 0.5841625449175639))\n",
      "Processing sentence:  ( quick_umls & metamap ) \n",
      "((6603, 753326, 3123, 10499), (0.4559228926475101, 0.39508558684023126, 0.3999140410954623))\n",
      "Processing sentence:  ( quick_umls | metamap ) \n",
      "((13021, 749815, 7669, 3046), (0.6789191634044666, 0.7548801672545783, 0.6856468762669152))\n",
      "Processing sentence:  ( ( clamp & quick_umls ) & metamap ) \n",
      "((4306, 754734, 808, 13703), (0.29778751420257765, 0.22741386458322144, 0.24325152625902471))\n",
      "Processing sentence:  ( ( clamp & quick_umls ) | metamap ) \n",
      "((10584, 751137, 5854, 5976), (0.6137532583139107, 0.6072897254966627, 0.5794161295993236))\n",
      "Processing sentence:  ( ( clamp | quick_umls ) & metamap ) \n",
      "((6719, 753266, 3183, 10383), (0.46137016689440913, 0.39999959612793917, 0.40488434576575427))\n",
      "Processing sentence:  ( ( clamp | quick_umls ) | metamap ) \n",
      "((13106, 749755, 7726, 2964), (0.6800084298548291, 0.7610217061918634, 0.6887848734129479))\n",
      "processing merge combo: ('clamp', 'metamap', 'quick_umls')\n",
      "Processing sentence:  ( metamap & quick_umls ) \n",
      "((6603, 753326, 3123, 10499), (0.4559228926475101, 0.39508558684023126, 0.3999140410954623))\n",
      "Processing sentence:  ( metamap | quick_umls ) \n",
      "((13021, 749815, 7669, 3046), (0.6789191634044666, 0.7548801672545783, 0.6856468762669152))\n",
      "Processing sentence:  ( ( clamp & metamap ) & quick_umls ) \n",
      "((4306, 754734, 808, 13703), (0.29778751420257765, 0.22741386458322144, 0.24325152625902471))\n",
      "Processing sentence:  ( ( clamp & metamap ) | quick_umls ) \n",
      "((11498, 751494, 5777, 4782), (0.6128688136784446, 0.6895888219579301, 0.626794484742558))\n",
      "Processing sentence:  ( ( clamp | metamap ) & quick_umls ) \n",
      "((8751, 753070, 3570, 8160), (0.5387394341552132, 0.5280513328856659, 0.5090709283255919))\n",
      "Processing sentence:  ( ( clamp | metamap ) | quick_umls ) \n",
      "((13106, 749755, 7726, 2964), (0.6800084298548291, 0.7610217061918634, 0.6887848734129479))\n",
      "processing merge combo: ('quick_umls', 'metamap', 'clamp')\n",
      "Processing sentence:  ( quick_umls & clamp ) \n",
      "((6454, 754478, 1255, 11364), (0.38296971804438973, 0.36067690091634586, 0.3559342009929394))\n",
      "Processing sentence:  ( quick_umls | clamp ) \n",
      "((11583, 751422, 5846, 4700), (0.6136015031752302, 0.6957412027561001, 0.6296771251232282))\n",
      "Processing sentence:  ( metamap & clamp ) \n",
      "((4422, 754674, 868, 13587), (0.30323478520051644, 0.23232787387092937, 0.248221830499468))\n",
      "Processing sentence:  ( metamap | clamp ) \n",
      "((10716, 751066, 5936, 5833), (0.6154768140908871, 0.6159988399013682, 0.5841625449175639))\n",
      "Processing sentence:  ( ( quick_umls & metamap ) & clamp ) \n",
      "((4306, 754734, 808, 13703), (0.29778751420257765, 0.22741386458322144, 0.24325152625902471))\n",
      "Processing sentence:  ( ( quick_umls & metamap ) | clamp ) \n",
      "((8999, 752927, 3724, 7901), (0.5455440277756921, 0.5416811573184688, 0.5185258978407662))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) & clamp ) \n",
      "((6570, 754418, 1315, 11248), (0.3884073328633369, 0.36558219742162884, 0.36089569302279617))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) | clamp ) \n",
      "((13106, 749755, 7726, 2964), (0.6800084298548291, 0.7610217061918634, 0.6887848734129479))\n",
      "          F1  precision    recall     TP     FN    FP     TP/FN  n_gold  \\\n",
      "0   0.519126   0.824019  0.378923   6738  11044  1439  0.610105   17782   \n",
      "2   0.551907   0.608868  0.504691   8445   8288  5425  1.018943   16733   \n",
      "1   0.681986   0.665653  0.699140  11382   4898  5717  2.323806   16280   \n",
      "5   0.379587   0.835917  0.245544   4422  13587   868  0.325458   18009   \n",
      "3   0.505661   0.837203  0.362218   6454  11364  1255  0.567934   17818   \n",
      "6   0.645523   0.643526  0.647532  10716   5833  5936  1.837134   16549   \n",
      "4   0.687174   0.664582  0.711355  11583   4700  5846  2.464468   16283   \n",
      "33  0.379587   0.835917  0.245544   4422  13587   868  0.325458   18009   \n",
      "20  0.492247   0.678902  0.386095   6603  10499  3123  0.628917   17102   \n",
      "34  0.645523   0.643526  0.647532  10716   5833  5936  1.837134   16549   \n",
      "21  0.708491   0.629338  0.810419  13021   3046  7669  4.274787   16067   \n",
      "31  0.505661   0.837203  0.362218   6454  11364  1255  0.567934   17818   \n",
      "7   0.492247   0.678902  0.386095   6603  10499  3123  0.628917   17102   \n",
      "32  0.687174   0.664582  0.711355  11583   4700  5846  2.464468   16283   \n",
      "8   0.708491   0.629338  0.810419  13021   3046  7669  4.274787   16067   \n",
      "22  0.372443   0.842002  0.239103   4306  13703   808  0.314238   18009   \n",
      "23  0.685323   0.665586  0.706265  11498   4782  5777  2.404433   16280   \n",
      "9   0.372443   0.842002  0.239103   4306  13703   808  0.314238   18009   \n",
      "10  0.641493   0.643874  0.639130  10584   5976  5854  1.771084   16560   \n",
      "24  0.598727   0.710251  0.517474   8751   8160  3570  1.072426   16911   \n",
      "25  0.710314   0.629128  0.815557  13106   2964  7726  4.421727   16070   \n",
      "11  0.497630   0.678550  0.392878   6719  10383  3183  0.647115   17102   \n",
      "12  0.710314   0.629128  0.815557  13106   2964  7726  4.421727   16070   \n",
      "35  0.372443   0.842002  0.239103   4306  13703   808  0.314238   18009   \n",
      "36  0.607568   0.707302  0.532485   8999   7901  3724  1.138970   16900   \n",
      "37  0.511224   0.833228  0.368728   6570  11248  1315  0.584104   17818   \n",
      "38  0.710314   0.629128  0.815557  13106   2964  7726  4.421727   16070   \n",
      "\n",
      "    n_sys         TM      TN   macro_p   macro_r  macro_f1  \\\n",
      "0    8177  74.513336  754330  0.391954  0.378592  0.368912   \n",
      "2   13870  71.706979  751393  0.533783  0.475250  0.471286   \n",
      "1   17099  87.042875  751554  0.607441  0.684692  0.621842   \n",
      "5    5290  60.798225  754674  0.303235  0.232328  0.248222   \n",
      "3    7709  73.507210  754478  0.382970  0.360677  0.355934   \n",
      "6   16652  83.042326  751066  0.615477  0.615999  0.584163   \n",
      "4   17429  87.737412  751422  0.613602  0.695741  0.629677   \n",
      "33   5290  60.798225  754674  0.303235  0.232328  0.248222   \n",
      "20   9726  66.953636  753326  0.455923  0.395086  0.399914   \n",
      "34  16652  83.042326  751066  0.615477  0.615999  0.584163   \n",
      "21  20690  90.524075  749815  0.678919  0.754880  0.685647   \n",
      "31   7709  73.507210  754478  0.382970  0.360677  0.355934   \n",
      "7    9726  66.953636  753326  0.455923  0.395086  0.399914   \n",
      "32  17429  87.737412  751422  0.613602  0.695741  0.629677   \n",
      "8   20690  90.524075  749815  0.678919  0.754880  0.685647   \n",
      "22   5114  60.213471  754734  0.297788  0.227414  0.243252   \n",
      "23  17275  87.480907  751494  0.612869  0.689589  0.626794   \n",
      "9    5114  60.213471  754734  0.297788  0.227414  0.243252   \n",
      "10  16438  82.551571  751137  0.613753  0.607290  0.579416   \n",
      "24  12321  78.837838  753070  0.538739  0.528051  0.509071   \n",
      "25  20832  90.803937  749755  0.680008  0.761022  0.688785   \n",
      "11   9902  67.521671  753266  0.461370  0.400000  0.404884   \n",
      "12  20832  90.803937  749755  0.680008  0.761022  0.688785   \n",
      "35   5114  60.213471  754734  0.297788  0.227414  0.243252   \n",
      "36  12723  79.781002  752927  0.545544  0.541681  0.518526   \n",
      "37   7885  73.988551  754418  0.388407  0.365582  0.360896   \n",
      "38  20832  90.803937  749755  0.680008  0.761022  0.688785   \n",
      "\n",
      "                           merge  n_terms  F1 rank  TP/FN rank  TM rank  \\\n",
      "0                          clamp        1     16.0        19.0     15.0   \n",
      "2                        metamap        1     15.0        15.0     19.0   \n",
      "1                     quick_umls        1      9.0         9.0      9.0   \n",
      "5                (clamp&metamap)        2     23.5        23.5     23.5   \n",
      "3             (clamp&quick_umls)        2     18.5        21.5     17.5   \n",
      "6                (clamp|metamap)        2     10.5        10.5     10.5   \n",
      "4             (clamp|quick_umls)        2      6.5         6.5      6.5   \n",
      "33               (metamap&clamp)        2     23.5        23.5     23.5   \n",
      "20          (metamap&quick_umls)        2     21.5        17.5     21.5   \n",
      "34               (metamap|clamp)        2     10.5        10.5     10.5   \n",
      "21          (metamap|quick_umls)        2      4.5         4.5      4.5   \n",
      "31            (quick_umls&clamp)        2     18.5        21.5     17.5   \n",
      "7           (quick_umls&metamap)        2     21.5        17.5     21.5   \n",
      "32            (quick_umls|clamp)        2      6.5         6.5      6.5   \n",
      "8           (quick_umls|metamap)        2      4.5         4.5      4.5   \n",
      "22  ((clamp&metamap)&quick_umls)        3     26.0        26.0     26.0   \n",
      "23  ((clamp&metamap)|quick_umls)        3      8.0         8.0      8.0   \n",
      "9   ((clamp&quick_umls)&metamap)        3     26.0        26.0     26.0   \n",
      "10  ((clamp&quick_umls)|metamap)        3     12.0        12.0     12.0   \n",
      "24  ((clamp|metamap)&quick_umls)        3     14.0        14.0     14.0   \n",
      "25  ((clamp|metamap)|quick_umls)        3      2.0         2.0      2.0   \n",
      "11  ((clamp|quick_umls)&metamap)        3     20.0        16.0     20.0   \n",
      "12  ((clamp|quick_umls)|metamap)        3      2.0         2.0      2.0   \n",
      "35  ((quick_umls&metamap)&clamp)        3     26.0        26.0     26.0   \n",
      "36  ((quick_umls&metamap)|clamp)        3     13.0        13.0     13.0   \n",
      "37  ((quick_umls|metamap)&clamp)        3     17.0        20.0     16.0   \n",
      "38  ((quick_umls|metamap)|clamp)        3      2.0         2.0      2.0   \n",
      "\n",
      "        Gmean  \n",
      "0   16.781596  \n",
      "2   16.661687  \n",
      "1    9.000000  \n",
      "5   23.500000  \n",
      "3   19.295369  \n",
      "6   10.500000  \n",
      "4    6.500000  \n",
      "33  23.500000  \n",
      "20  19.620268  \n",
      "34  10.500000  \n",
      "21   4.500000  \n",
      "31  19.295369  \n",
      "7   19.620268  \n",
      "32   6.500000  \n",
      "8    4.500000  \n",
      "22  26.000000  \n",
      "23   8.000000  \n",
      "9   26.000000  \n",
      "10  12.000000  \n",
      "24  14.000000  \n",
      "25   2.000000  \n",
      "11  18.111686  \n",
      "12   2.000000  \n",
      "35  26.000000  \n",
      "36  13.000000  \n",
      "37  17.787567  \n",
      "38   2.000000  \n",
      " done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         282954545 function calls (280384440 primitive calls) in 428.979 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "    64090  135.060    0.002  215.264    0.003 <ipython-input-11-d491bb397590>:1(label_vector)\n",
       " 61620650   75.015    0.000   75.528    0.000 <ipython-input-11-d491bb397590>:8(<listcomp>)\n",
       "     4335   52.633    0.012   52.633    0.012 {method 'sort' of 'numpy.ndarray' objects}\n",
       "750620/621992   26.225    0.000   27.822    0.000 {built-in method numpy.array}\n",
       "    64105   16.585    0.000   16.585    0.000 {pandas._libs.ops.scalar_compare}\n",
       "       85    5.989    0.070  428.025    5.036 <ipython-input-19-90de0edd371d>:150(get_metrics)\n",
       "       85    5.607    0.066  419.144    4.931 <ipython-input-11-d491bb397590>:44(vectorized_cooccurences)\n",
       "27488629/27488579    5.488    0.000    9.361    0.000 {built-in method builtins.isinstance}\n",
       " 61620650    4.450    0.000    4.450    0.000 <ipython-input-11-d491bb397590>:9(<listcomp>)\n",
       "     1020    4.078    0.004    4.078    0.004 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "  64096/1    3.240    0.000  429.009  429.009 {built-in method builtins.exec}\n",
       "    64090    2.609    0.000    6.564    0.000 __init__.py:316(namedtuple)\n",
       "     4335    2.283    0.001   56.723    0.013 arraysetops.py:299(_unique1d)\n",
       "  8533969    2.166    0.000    2.952    0.000 generic.py:7(_check)\n",
       "  1226708    1.783    0.000    4.765    0.000 dtypes.py:68(find)\n",
       "     4335    1.770    0.000    1.770    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
       "     1700    1.703    0.001   41.655    0.025 multiclass.py:174(type_of_target)\n",
       "     1126    1.670    0.001    1.670    0.001 {built-in method numpy.bincount}\n",
       "10407561/8165652    1.632    0.000    2.323    0.000 {built-in method builtins.len}\n",
       "     3956    1.598    0.000    1.598    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "13336082/13336079    1.561    0.000    1.888    0.000 {built-in method builtins.getattr}\n",
       "   288493    1.544    0.000   18.271    0.000 indexing.py:960(_getitem_lowerdim)\n",
       "  1593236    1.541    0.000    3.644    0.000 common.py:1845(_is_dtype_type)\n",
       "   463588    1.495    0.000    1.495    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "   774522    1.416    0.000    2.738    0.000 generic.py:5069(__setattr__)\n",
       "       85    1.336    0.016    1.336    0.016 <ipython-input-11-d491bb397590>:75(<listcomp>)\n",
       "       85    1.334    0.016    1.334    0.016 <ipython-input-11-d491bb397590>:74(<listcomp>)\n",
       "  1437833    1.254    0.000    1.961    0.000 {method 'format' of 'str' objects}\n",
       "       85    1.180    0.014   94.389    1.110 classification.py:1448(classification_report)\n",
       "   132128    1.088    0.000    7.552    0.000 algorithms.py:1544(take_nd)\n",
       "  2240381    1.077    0.000    1.781    0.000 {built-in method builtins.hasattr}\n",
       "   289544    1.075    0.000    3.957    0.000 managers.py:963(iget)\n",
       "      340    1.062    0.003   57.747    0.170 classification.py:882(precision_recall_fscore_support)\n",
       "  1580056    1.005    0.000    4.269    0.000 base.py:75(is_dtype)\n",
       "354089/354088    0.991    0.000   12.705    0.000 series.py:152(__init__)\n",
       "  1173799    0.868    0.000    2.776    0.000 common.py:1981(pandas_dtype)\n",
       "    32045    0.866    0.000    1.929    0.000 <ipython-input-11-d491bb397590>:30(confused)\n",
       "  1161981    0.864    0.000    4.320    0.000 common.py:1702(is_extension_array_dtype)\n",
       "   930236    0.850    0.000    4.040    0.000 common.py:93(is_bool_indexer)\n",
       "   352842    0.821    0.000    7.131    0.000 base.py:1117(__iter__)\n",
       "   535307    0.818    0.000    2.111    0.000 _dtype.py:319(_name_get)\n",
       "   288525    0.817    0.000   10.305    0.000 frame.py:2829(_ixs)\n",
       "   486406    0.797    0.000    1.946    0.000 blocks.py:78(__init__)\n",
       "    66108    0.786    0.000    1.830    0.000 managers.py:186(_rebuild_blknos_and_blklocs)\n",
       "    64113    0.775    0.000   32.733    0.001 ops.py:1660(wrapper)\n",
       "   352583    0.760    0.000   49.776    0.000 indexing.py:1485(__getitem__)\n",
       "  5807109    0.742    0.000    0.742    0.000 {built-in method builtins.issubclass}\n",
       "  1802881    0.697    0.000    2.382    0.000 inference.py:253(is_list_like)\n",
       "  1125323    0.673    0.000    0.957    0.000 generic.py:363(_get_axis_name)\n",
       "  1515716    0.670    0.000    0.670    0.000 common.py:117(classes)\n",
       "   746589    0.666    0.000    0.666    0.000 {built-in method numpy.arange}\n",
       "   354088    0.631    0.000    2.812    0.000 managers.py:1443(__init__)\n",
       "547441/547433    0.618    0.000    1.019    0.000 generic.py:5053(__getattr__)\n",
       "    64090    0.607    0.000   39.976    0.001 frame.py:849(itertuples)\n",
       "   486406    0.581    0.000    0.643    0.000 blocks.py:199(mgr_locs)\n",
       "   486406    0.578    0.000    4.367    0.000 blocks.py:3080(make_block)\n",
       "  1941058    0.575    0.000    0.580    0.000 {built-in method _abc._abc_instancecheck}\n",
       "    64466    0.561    0.000    1.034    0.000 indexing.py:2575(maybe_convert_indices)\n",
       "  2076296    0.557    0.000    0.757    0.000 base.py:652(__len__)\n",
       "  1124980    0.555    0.000    1.763    0.000 generic.py:377(_get_axis)\n",
       "  1219395    0.553    0.000    0.887    0.000 managers.py:1549(internal_values)\n",
       "   418542    0.536    0.000    0.920    0.000 series.py:392(name)\n",
       "  1070630    0.536    0.000    0.785    0.000 numerictypes.py:293(issubclass_)\n",
       "   132128    0.527    0.000    1.561    0.000 algorithms.py:1417(_get_take_nd_function)\n",
       "   288493    0.525    0.000   13.145    0.000 indexing.py:2205(_getitem_axis)\n",
       "   288493    0.500    0.000    4.534    0.000 indexing.py:217(_has_valid_tuple)\n",
       "   354093    0.484    0.000    0.905    0.000 series.py:354(_set_axis)\n",
       "   576986    0.478    0.000    3.666    0.000 indexing.py:2056(_validate_key)\n",
       "   419483    0.475    0.000    0.475    0.000 generic.py:127(__init__)\n",
       "   131666    0.469    0.000    1.820    0.000 cast.py:255(maybe_promote)\n",
       "    64466    0.464    0.000   16.802    0.000 managers.py:1329(take)\n",
       "   535315    0.461    0.000    1.293    0.000 numerictypes.py:365(issubdtype)\n",
       "   288493    0.457    0.000    0.852    0.000 indexing.py:2089(_is_scalar_access)\n",
       "  1941058    0.447    0.000    1.027    0.000 abc.py:137(__instancecheck__)\n",
       "   963694    0.439    0.000    0.439    0.000 {built-in method __new__ of type object at 0x1062ad778}\n",
       "   274205    0.423    0.000    0.423    0.000 {built-in method numpy.empty}\n",
       "   352495    0.416    0.000   25.466    0.000 frame.py:919(<genexpr>)\n",
       "  1158078    0.416    0.000    0.808    0.000 generic.py:450(ndim)\n",
       "    64810    0.411    0.000    0.411    0.000 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
       "   576970    0.410    0.000    1.696    0.000 indexing.py:2116(_validate_integer)\n",
       "   338115    0.409    0.000    0.978    0.000 common.py:160(is_sparse)\n",
       "  1039496    0.409    0.000    1.104    0.000 integer.py:80(construct_from_string)\n",
       "   553727    0.409    0.000    2.441    0.000 common.py:403(is_datetime64_dtype)\n",
       "  1025066    0.403    0.000    3.133    0.000 common.py:434(is_datetime64tz_dtype)\n",
       "    64462    0.381    0.000   19.775    0.000 generic.py:3323(_take)\n",
       "  1219395    0.372    0.000    1.258    0.000 series.py:476(_values)\n",
       "   263190    0.361    0.000    0.892    0.000 managers.py:139(shape)\n",
       "   291847    0.358    0.000    0.565    0.000 base.py:3940(__getitem__)\n",
       "   865666    0.358    0.000    1.617    0.000 indexing.py:2689(is_list_like_indexer)\n",
       "   706515    0.353    0.000    0.596    0.000 managers.py:1522(dtype)\n",
       "  1357054    0.352    0.000    0.471    0.000 managers.py:143(ndim)\n",
       "   289544    0.352    0.000    3.864    0.000 frame.py:3349(_box_col_values)\n",
       "   128994    0.349    0.000    8.714    0.000 blocks.py:1217(take_nd)\n",
       "  1515716    0.346    0.000    0.513    0.000 common.py:119(<lambda>)\n",
       "   353119    0.338    0.000    4.380    0.000 common.py:702(is_datetimelike)\n",
       "   865479    0.337    0.000    0.551    0.000 indexing.py:1487(<genexpr>)\n",
       "    64284    0.334    0.000    0.334    0.000 {pandas._libs.algos.take_2d_axis1_object_object}\n",
       "   226646    0.322    0.000    1.216    0.000 blocks.py:2626(__init__)\n",
       "    66514    0.322    0.000    3.872    0.000 construction.py:537(sanitize_array)\n",
       "   489595    0.320    0.000    1.554    0.000 common.py:472(is_timedelta64_dtype)\n",
       "        1    0.317    0.317    0.319    0.319 {method 'read' of 'pandas._libs.parsers.TextReader' objects}\n",
       "   130889    0.309    0.000    0.614    0.000 dtypes.py:786(construct_from_string)\n",
       "  1991083    0.305    0.000    0.305    0.000 managers.py:1488(_block)\n",
       "   400600    0.298    0.000    1.156    0.000 common.py:131(is_object_dtype)\n",
       "    65399    0.283    0.000    1.033    0.000 frame.py:2893(__getitem__)\n",
       "   288493    0.278    0.000    0.861    0.000 indexing.py:229(_is_nested_tuple_indexer)\n",
       "   419578    0.275    0.000    2.711    0.000 blocks.py:225(make_block_same_class)\n",
       "   491620    0.274    0.000    0.379    0.000 {pandas._libs.lib.is_scalar}\n",
       "   129368    0.267    0.000    0.644    0.000 numeric.py:2656(seterr)\n",
       "   204349    0.265    0.000    0.729    0.000 dtypes.py:973(is_dtype)\n",
       "   866901    0.265    0.000    1.244    0.000 inference.py:304(is_array_like)\n",
       "    64090    0.261    0.000   24.569    0.000 indexing.py:1855(_getitem_axis)\n",
       "   895657    0.260    0.000    0.735    0.000 __init__.py:403(_make)\n",
       "    64577    0.260    0.000    0.619    0.000 cast.py:832(maybe_castable)\n",
       "   133606    0.258    0.000    0.707    0.000 _dtype.py:46(__str__)\n",
       "    68913    0.250    0.000    1.528    0.000 blocks.py:3034(get_block_type)\n",
       "  1460968    0.247    0.000    0.247    0.000 {method 'get' of 'dict' objects}\n",
       "   706515    0.240    0.000    0.836    0.000 series.py:406(dtype)\n",
       "   354344    0.237    0.000    0.420    0.000 series.py:399(name)\n",
       "      377    0.231    0.001    0.231    0.001 {method 'recv_into' of '_socket.socket' objects}\n",
       "   199936    0.230    0.000    0.484    0.000 dtypes.py:672(construct_from_string)\n",
       "    64095    0.226    0.000    0.226    0.000 {built-in method numpy.zeros}\n",
       "   129368    0.222    0.000    0.239    0.000 numeric.py:2758(geterr)\n",
       "   576986    0.216    0.000    0.688    0.000 indexing.py:2695(is_label_like)\n",
       "    65484    0.216    0.000    0.693    0.000 managers.py:306(_verify_integrity)\n",
       "   131117    0.212    0.000    0.234    0.000 base.py:3918(__contains__)\n",
       "   865479    0.212    0.000    0.283    0.000 indexing.py:230(<genexpr>)\n",
       "    64259    0.209    0.000    0.522    0.000 numpy_.py:35(__init__)\n",
       "   130437    0.208    0.000    1.373    0.000 base.py:4051(equals)\n",
       "    66303    0.208    0.000    1.022    0.000 cast.py:953(maybe_cast_to_datetime)\n",
       "    64521    0.208    0.000   13.471    0.000 managers.py:1198(reindex_indexer)\n",
       "   706647    0.207    0.000    0.281    0.000 common.py:316(apply_if_callable)\n",
       "   675471    0.206    0.000    0.827    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
       "    65836    0.206    0.000    4.355    0.000 managers.py:97(__init__)\n",
       "   288493    0.205    0.000   23.013    0.000 indexing.py:2141(_getitem_tuple)\n",
       "   131515    0.205    0.000    1.017    0.000 fromnumeric.py:69(_wrapreduction)\n",
       "    64259    0.201    0.000    1.313    0.000 base.py:786(array)\n",
       "   289544    0.195    0.000    0.562    0.000 generic.py:3070(_set_as_cached)\n",
       "    65394    0.194    0.000    0.817    0.000 frame.py:378(__init__)\n",
       "   971591    0.186    0.000    0.186    0.000 {method 'startswith' of 'str' objects}\n",
       "    65340    0.183    0.000    0.817    0.000 base.py:566(_shallow_copy)\n",
       "    66514    0.182    0.000    2.845    0.000 construction.py:684(_try_cast)\n",
       "   327037    0.181    0.000    0.181    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "   975008    0.180    0.000    0.180    0.000 blocks.py:308(dtype)\n",
       "    67673    0.178    0.000    0.428    0.000 base.py:504(_simple_new)\n",
       "   488280    0.176    0.000    0.363    0.000 base.py:5318(ensure_index)\n",
       "   288485    0.175    0.000   10.479    0.000 indexing.py:143(_get_loc)\n",
       "   289544    0.173    0.000    0.173    0.000 blocks.py:332(iget)\n",
       "   292547    0.173    0.000    0.461    0.000 {built-in method builtins.any}\n",
       "    64412    0.172    0.000    0.172    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "   789570    0.171    0.000    0.531    0.000 managers.py:141(<genexpr>)\n",
       "   486406    0.168    0.000    0.168    0.000 blocks.py:89(_check_ndim)\n",
       "    64255    0.167    0.000    8.870    0.000 managers.py:1233(<listcomp>)\n",
       "   198169    0.167    0.000    0.167    0.000 dtypes.py:452(construct_from_string)\n",
       "    64521    0.163    0.000    1.224    0.000 base.py:784(take)\n",
       "     1117    0.162    0.000    0.162    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "   354093    0.160    0.000    0.160    0.000 series.py:382(_set_subtyp)\n",
       "   128690    0.159    0.000    1.091    0.000 fromnumeric.py:1966(sum)\n",
       "  1219475    0.157    0.000    0.157    0.000 blocks.py:165(internal_values)\n",
       "   130889    0.155    0.000    0.242    0.000 dtypes.py:929(construct_from_string)\n",
       "   420637    0.155    0.000    0.221    0.000 inference.py:438(is_hashable)\n",
       "   462868    0.154    0.000    0.218    0.000 common.py:1809(_get_dtype)\n",
       "   328588    0.153    0.000    1.008    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
       "    64090    0.150    0.000   22.546    0.000 indexing.py:1511(_getbool_axis)\n",
       "   288501    0.149    0.000    0.170    0.000 common.py:279(is_null_slice)\n",
       "471908/343292    0.146    0.000   19.426    0.000 numeric.py:469(asarray)\n",
       "        4    0.144    0.036    0.144    0.036 {built-in method gc.collect}\n",
       "   887818    0.137    0.000    0.137    0.000 blocks.py:195(mgr_locs)\n",
       "   130663    0.132    0.000    0.132    0.000 {method 'match' of 're.Pattern' objects}\n",
       "   290489    0.130    0.000    0.130    0.000 frame.py:474(axes)\n",
       "   278042    0.129    0.000    1.071    0.000 common.py:572(is_categorical_dtype)\n",
       "   262642    0.127    0.000    0.261    0.000 base.py:3608(values)\n",
       "      178    0.127    0.001    0.127    0.001 managers.py:2004(<listcomp>)\n",
       "   133606    0.125    0.000    1.281    0.000 blocks.py:312(ftype)\n",
       "    64297    0.123    0.000    2.734    0.000 indexing.py:2475(check_bool_indexer)\n",
       "   320168    0.121    0.000    0.121    0.000 {method 'item' of 'numpy.generic' objects}\n",
       "   937388    0.121    0.000    0.121    0.000 {pandas._libs.lib.is_integer}\n",
       "    65926    0.119    0.000    1.477    0.000 managers.py:599(_consolidate_check)\n",
       "     4335    0.111    0.000   56.854    0.013 arraysetops.py:151(unique)\n",
       "   291789    0.110    0.000    0.146    0.000 common.py:144(cast_scalar_indexer)\n",
       "   195512    0.109    0.000    0.271    0.000 {pandas._libs.lib.values_from_object}\n",
       "      425    0.108    0.000   31.781    0.075 multiclass.py:42(unique_labels)\n",
       "    64259    0.107    0.000    0.641    0.000 numpy_.py:127(__init__)\n",
       "   228401    0.106    0.000    0.282    0.000 managers.py:291(__len__)\n",
       "    64584    0.106    0.000    0.106    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
       "    64255    0.106    0.000    1.768    0.000 series.py:669(__array__)\n",
       "   328843    0.104    0.000    0.855    0.000 _methods.py:42(_any)\n",
       "      425    0.103    0.000   41.933    0.099 classification.py:44(_check_targets)\n",
       "    64611    0.103    0.000   25.569    0.000 {method 'extend' of 'list' objects}\n",
       "    64192    0.102    0.000    0.102    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
       "   207223    0.097    0.000    0.825    0.000 common.py:536(is_interval_dtype)\n",
       "   129368    0.096    0.000    0.096    0.000 {built-in method numpy.seterrobj}\n",
       "    64090    0.096    0.000    0.096    0.000 {built-in method builtins.repr}\n",
       "     4990    0.094    0.000    0.094    0.000 {built-in method numpy.concatenate}\n",
       "    66688    0.093    0.000    0.172    0.000 {method 'join' of 'str' objects}\n",
       "    71253    0.093    0.000    0.380    0.000 common.py:1578(is_bool_dtype)\n",
       "       85    0.093    0.001    0.093    0.001 classification.py:1562(<dictcomp>)\n",
       "     3095    0.089    0.000    0.105    0.000 {pandas._libs.lib.infer_dtype}\n",
       "   551880    0.087    0.000    0.087    0.000 {built-in method builtins.hash}\n",
       "    65365    0.086    0.000    0.176    0.000 missing.py:360(array_equivalent)\n",
       "    64113    0.086    0.000   17.301    0.000 ops.py:1615(na_op)\n",
       "   129937    0.083    0.000    0.148    0.000 sparse.py:196(construct_from_string)\n",
       "    64105    0.083    0.000   16.752    0.000 ops.py:1591(_comp_method_OBJECT_ARRAY)\n",
       "   130405    0.081    0.000    0.192    0.000 common.py:746(is_dtype_equal)\n",
       "      218    0.078    0.000    0.079    0.000 {method 'factorize' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
       "   352495    0.078    0.000    0.078    0.000 __init__.py:388(<genexpr>)\n",
       "    64347    0.077    0.000    0.202    0.000 managers.py:1556(get_values)\n",
       "    65200    0.076    0.000    0.433    0.000 generic.py:5122(_protect_consolidate)\n",
       "    64192    0.075    0.000    0.261    0.000 base.py:1736(is_all_dates)\n",
       "   706655    0.075    0.000    0.075    0.000 {built-in method builtins.callable}\n",
       "   130437    0.072    0.000    0.092    0.000 base.py:613(is_)\n",
       "    64684    0.071    0.000    0.345    0.000 numeric.py:3063(__exit__)\n",
       "    64153    0.070    0.000    0.173    0.000 ops.py:43(get_op_result_name)\n",
       "   198087    0.070    0.000    0.107    0.000 managers.py:308(<genexpr>)\n",
       "    70456    0.069    0.000    0.166    0.000 common.py:1545(is_float_dtype)\n",
       "   134152    0.069    0.000    0.069    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
       "   135511    0.066    0.000    0.540    0.000 common.py:262(is_categorical)\n",
       "   640902    0.066    0.000    0.066    0.000 {method 'isidentifier' of 'str' objects}\n",
       "    37201    0.064    0.000    0.064    0.000 {method 'settimeout' of '_socket.socket' objects}\n",
       "   131515    0.063    0.000    0.063    0.000 fromnumeric.py:70(<dictcomp>)\n",
       "    65926    0.063    0.000    1.344    0.000 managers.py:600(<listcomp>)\n",
       "   580175    0.063    0.000    0.063    0.000 {method 'add' of 'set' objects}\n",
       "    64383    0.063    0.000    0.121    0.000 generic.py:3175(_set_is_copy)\n",
       "    76033    0.063    0.000    0.230    0.000 dtypes.py:827(is_dtype)\n",
       "    64684    0.062    0.000    0.433    0.000 numeric.py:3058(__enter__)\n",
       "    68889    0.062    0.000    0.162    0.000 missing.py:105(_isna_new)\n",
       "    65529    0.061    0.000    0.061    0.000 {method 'replace' of 'str' objects}\n",
       "   640900    0.061    0.000    0.061    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "    18132    0.060    0.000    0.201    0.000 connections.py:1195(_read_row_from_packet)\n",
       "    65061    0.060    0.000    0.070    0.000 generic.py:144(_init_mgr)\n",
       "    68583    0.060    0.000    0.081    0.000 generic.py:349(_get_axis_number)\n",
       "    65836    0.060    0.000    0.115    0.000 managers.py:98(<listcomp>)\n",
       "   399360    0.059    0.000    0.094    0.000 multiclass.py:101(<genexpr>)\n",
       "   258736    0.058    0.000    0.058    0.000 {built-in method numpy.geterrobj}\n",
       "      220    0.058    0.000    0.059    0.000 {method 'factorize' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "    68857    0.058    0.000    0.151    0.000 common.py:868(is_integer_dtype)\n",
       "    64684    0.058    0.000    0.074    0.000 numeric.py:3054(__init__)\n",
       "   296644    0.057    0.000    0.057    0.000 managers.py:206(items)\n",
       "   424832    0.057    0.000    0.057    0.000 {pandas._libs.lib.is_float}\n",
       "     1870    0.056    0.000    8.469    0.005 fromnumeric.py:1785(shape)\n",
       "    66590    0.055    0.000    0.661    0.000 common.py:1643(is_extension_type)\n",
       "    65200    0.054    0.000    0.341    0.000 generic.py:5135(f)\n",
       "    64098    0.054    0.000    0.349    0.000 base.py:3975(_can_hold_identifiers_and_holds_name)\n",
       "    65873    0.053    0.000    0.112    0.000 base.py:547(_get_attributes_dict)\n",
       "    64259    0.051    0.000    0.094    0.000 common.py:1118(is_datetime64_ns_dtype)\n",
       "   195501    0.051    0.000    0.054    0.000 managers.py:591(is_consolidated)\n",
       "    67886    0.051    0.000    0.082    0.000 __init__.py:221(iteritems)\n",
       "    66202    0.051    0.000    0.129    0.000 cast.py:1218(construct_1d_ndarray_preserving_na)\n",
       "    66380    0.049    0.000    0.157    0.000 {built-in method builtins.sum}\n",
       "   130310    0.048    0.000    0.224    0.000 managers.py:927(_consolidate_inplace)\n",
       "    64993    0.048    0.000    0.125    0.000 generic.py:381(_get_block_manager_axis)\n",
       "   130730    0.048    0.000    0.161    0.000 base.py:3663(get_values)\n",
       "   129941    0.048    0.000    0.048    0.000 {method 'search' of 're.Pattern' objects}\n",
       "   133079    0.047    0.000    0.047    0.000 {pandas._libs.algos.ensure_int64}\n",
       "    65431    0.046    0.000    0.055    0.000 generic.py:5036(__finalize__)\n",
       "    65200    0.046    0.000    0.479    0.000 generic.py:5132(_consolidate_inplace)\n",
       "    64255    0.046    0.000    0.106    0.000 numpy_.py:170(__array__)\n",
       "      657    0.046    0.000    0.114    0.000 blocks.py:3131(_merge_blocks)\n",
       "    64127    0.046    0.000    2.044    0.000 generic.py:178(_validate_dtype)\n",
       "      330    0.046    0.000    0.046    0.000 {method 'factorize' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "      277    0.045    0.000    0.045    0.000 {method 'factorize' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "    65873    0.044    0.000    0.058    0.000 base.py:551(<dictcomp>)\n",
       "    64360    0.043    0.000    0.152    0.000 base.py:802(_assert_take_fillable)\n",
       "   267858    0.043    0.000    0.043    0.000 {method 'items' of 'dict' objects}\n",
       "    79787    0.043    0.000    0.163    0.000 classification.py:1565(<listcomp>)\n",
       "    66514    0.042    0.000    0.203    0.000 arrays.py:7(extract_array)\n",
       "    65686    0.041    0.000    0.105    0.000 generic.py:3056(_get_item_cache)\n",
       "   662/74    0.041    0.000    1.127    0.015 <ipython-input-18-e3f3b2a89fec>:26(evaluate)\n",
       "    18505    0.041    0.000    0.410    0.000 connections.py:648(_read_packet)\n",
       "    67721    0.041    0.000    0.084    0.000 common.py:1784(_is_dtype)\n",
       "   259165    0.039    0.000    0.039    0.000 base.py:3632(_values)\n",
       "   288563    0.039    0.000    0.039    0.000 base.py:704(ndim)\n",
       "    65840    0.038    0.000    0.667    0.000 inference.py:121(is_iterator)\n",
       "    64106    0.038    0.000    0.174    0.000 base.py:1681(is_object)\n",
       "3091/2139    0.037    0.000    0.265    0.000 base.py:253(__new__)\n",
       "    76033    0.037    0.000    0.267    0.000 common.py:503(is_period_dtype)\n",
       "    37010    0.036    0.000    0.347    0.000 connections.py:687(_read_bytes)\n",
       "    89853    0.035    0.000    0.041    0.000 protocol.py:63(read)\n",
       "      404    0.035    0.000    0.045    0.000 managers.py:1841(_stack_arrays)\n",
       "       40    0.033    0.001    0.033    0.001 {method 'factorize' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
       "    64259    0.033    0.000    0.104    0.000 common.py:1167(is_timedelta64_ns_dtype)\n",
       "    89908    0.033    0.000    0.116    0.000 protocol.py:168(read_length_coded_string)\n",
       "    67883    0.033    0.000    0.033    0.000 base.py:633(_reset_identity)\n",
       "    64347    0.032    0.000    0.234    0.000 series.py:490(get_values)\n",
       "   204796    0.032    0.000    0.042    0.000 strings.py:1519(<lambda>)\n",
       "   132643    0.031    0.000    0.031    0.000 blocks.py:304(shape)\n",
       "     1451    0.031    0.000    0.031    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "    64347    0.030    0.000    0.078    0.000 blocks.py:184(to_dense)\n",
       "    68889    0.030    0.000    0.192    0.000 missing.py:25(isna)\n",
       "    65200    0.030    0.000    0.228    0.000 managers.py:911(consolidate)\n",
       "    79718    0.029    0.000    8.357    0.000 numeric.py:541(asanyarray)\n",
       "   130073    0.029    0.000    0.029    0.000 blocks.py:191(fill_value)\n",
       "      127    0.028    0.000    0.028    0.000 {pandas._libs.hashtable.duplicated_int64}\n",
       "       85    0.027    0.000    0.027    0.000 classification.py:1546(<listcomp>)\n",
       "       11    0.027    0.002    1.688    0.153 <ipython-input-16-5027fd525437>:27(get_sys_data)\n",
       "     1020    0.027    0.000    0.075    0.000 arraysetops.py:484(in1d)\n",
       "   130001    0.027    0.000    0.027    0.000 {method 'lower' of 'str' objects}\n",
       "      406    0.027    0.000    0.027    0.000 {built-in method posix.stat}\n",
       "    64550    0.026    0.000    0.052    0.000 generic.py:426(_info_axis)\n",
       "   223201    0.025    0.000    0.025    0.000 {method 'append' of 'list' objects}\n",
       "    64090    0.025    0.000    0.036    0.000 indexing.py:1831(_get_partial_string_timestamp_match_key)\n",
       "    67084    0.023    0.000    0.023    0.000 {built-in method pandas._libs.missing.checknull}\n",
       "      772    0.023    0.000    0.023    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
       "     1388    0.023    0.000    0.099    0.000 concat.py:261(get_empty_dtype_and_na)\n",
       "    90196    0.023    0.000    0.042    0.000 protocol.py:150(read_length_encoded_integer)\n",
       "    77520    0.022    0.000    0.031    0.000 common.py:127(<lambda>)\n",
       "    64090    0.022    0.000    0.022    0.000 {built-in method sys._getframe}\n",
       "       15    0.022    0.001    0.022    0.001 {pandas._libs.hashtable.ismember_object}\n",
       "    65966    0.022    0.000    0.022    0.000 {method 'update' of 'dict' objects}\n",
       "   130062    0.022    0.000    0.022    0.000 {pandas._libs.algos.ensure_platform_int}\n",
       "    64090    0.022    0.000    0.022    0.000 {built-in method sys.intern}\n",
       "    65937    0.020    0.000    0.020    0.000 base.py:676(dtype)\n",
       "       34    0.020    0.001    0.401    0.012 connections.py:1182(_read_rowdata_packet)\n",
       "        8    0.019    0.002    0.019    0.002 {method 'get_labels_groupby' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "       32    0.019    0.001    0.052    0.002 {pandas._libs.lib.map_infer_mask}\n",
       "    90197    0.019    0.000    0.019    0.000 protocol.py:117(read_uint8)\n",
       "    89651    0.019    0.000    0.019    0.000 {method 'decode' of 'bytes' objects}\n",
       "    64754    0.018    0.000    0.018    0.000 frame.py:361(_constructor)\n",
       "     1326    0.018    0.000    0.024    0.000 cast.py:1193(construct_1d_object_array_from_listlike)\n",
       "    68185    0.017    0.000    0.018    0.000 {built-in method builtins.iter}\n",
       "    67418    0.017    0.000    0.017    0.000 {method 'pop' of 'dict' objects}\n",
       "    77520    0.016    0.000    0.016    0.000 common.py:122(classes_and_not_datetimelike)\n",
       "      850    0.016    0.000   15.036    0.018 multiclass.py:24(_unique_multiclass)\n",
       "      547    0.015    0.000    0.015    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
       "      680    0.014    0.000    0.030    0.000 classification.py:838(_prf_divide)\n",
       "      763    0.014    0.000    0.014    0.000 socket.py:337(send)\n",
       "      568    0.014    0.000    0.025    0.000 concat.py:22(get_mgr_concatenation_plan)\n",
       "    37010    0.014    0.000    0.246    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
       "      753    0.013    0.000    0.021    0.000 {built-in method builtins.sorted}\n",
       "     6154    0.013    0.000    0.013    0.000 _internal.py:886(npy_ctypes_check)\n",
       "    66688    0.013    0.000    0.013    0.000 {pandas._libs.algos.ensure_object}\n",
       "      131    0.013    0.000    0.045    0.000 sorting.py:20(get_group_index)\n",
       "    65510    0.012    0.000    0.012    0.000 base.py:1396(nlevels)\n",
       "      680    0.010    0.000   12.228    0.018 label.py:113(_encode_check_unknown)\n",
       "      277    0.010    0.000    0.010    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "   179196    0.010    0.000    0.010    0.000 {method 'strip' of 'str' objects}\n",
       "    64399    0.010    0.000    0.010    0.000 series.py:338(_constructor)\n",
       "    64259    0.010    0.000    0.010    0.000 common.py:1195(<lambda>)\n",
       "      734    0.010    0.000    0.010    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
       "       55    0.010    0.000    0.017    0.000 {pandas._libs.join.inner_join}\n",
       "     9498    0.009    0.000    0.009    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "    25599    0.009    0.000    0.018    0.000 strings.py:87(g)\n",
       "      358    0.008    0.000    0.120    0.000 managers.py:1696(form_blocks)\n",
       "      341    0.008    0.000    0.580    0.002 managers.py:2029(concatenate_block_managers)\n",
       "     2396    0.008    0.000    0.015    0.000 concat.py:117(needs_filling)\n",
       "        6    0.008    0.001    0.008    0.001 {built-in method io.open}\n",
       "     2396    0.008    0.000    0.157    0.000 concat.py:165(get_reindexed_values)\n",
       "      483    0.008    0.000    0.008    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
       "     2778    0.008    0.000    0.083    0.000 concat.py:137(is_na)\n",
       "     1805    0.008    0.000    0.059    0.000 missing.py:183(_isna_ndarraylike)\n",
       "      568    0.008    0.000    0.010    0.000 sorting.py:55(maybe_lift)\n",
       "     4335    0.007    0.000    0.009    0.000 arraysetops.py:138(_unpack_tuple)\n",
       "     1020    0.007    0.000    0.086    0.000 arraysetops.py:745(setdiff1d)\n",
       "     2635    0.007    0.000    0.122    0.000 fromnumeric.py:2083(any)\n",
       "     1173    0.007    0.000    0.050    0.000 concat.py:20(get_dtype_kinds)\n",
       "      568    0.007    0.000    0.312    0.001 algorithms.py:559(factorize)\n",
       "     2034    0.007    0.000    0.009    0.000 concat.py:425(combine_concat_plans)\n",
       "       85    0.007    0.000    0.014    0.000 <ipython-input-12-09d4c6f9a52f>:1(cm_dict)\n",
       "     1870    0.007    0.000   16.656    0.009 validation.py:771(column_or_1d)\n",
       "     2966    0.006    0.000    0.040    0.000 common.py:222(asarray_tuplesafe)\n",
       "     2210    0.006    0.000    0.023    0.000 validation.py:127(_num_samples)\n",
       "      127    0.006    0.000    0.592    0.005 frame.py:4605(drop_duplicates)\n",
       "      359    0.006    0.000    0.089    0.000 {pandas._libs.lib.clean_index_list}\n",
       "     2082    0.006    0.000    8.181    0.004 fromnumeric.py:1583(ravel)\n",
       " 1446/368    0.006    0.000    0.082    0.000 <frozen importlib._bootstrap>:978(_find_and_load)\n",
       "    18534    0.006    0.000    0.006    0.000 {built-in method _struct.unpack}\n",
       "      367    0.006    0.000    0.051    0.000 <frozen importlib._bootstrap>:882(_find_spec)\n",
       "      274    0.005    0.000    0.080    0.000 managers.py:1241(_slice_take_blocks_ax0)\n",
       "      275    0.005    0.000    0.118    0.000 merge.py:1617(_factorize_keys)\n",
       "    18506    0.005    0.000    0.010    0.000 protocol.py:214(check_error)\n",
       "    18166    0.005    0.000    0.009    0.000 connections.py:1137(_check_packet_is_eof)\n",
       "      103    0.005    0.000    0.005    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
       "     1700    0.005    0.000    0.009    0.000 multiclass.py:111(is_multilabel)\n",
       "       55    0.005    0.000    0.008    0.000 merge.py:1701(_get_join_keys)\n",
       "      286    0.005    0.000    0.118    0.000 concat.py:237(__init__)\n",
       "     3120    0.005    0.000    0.014    0.000 blocks.py:128(_consolidate_key)\n",
       "     4357    0.005    0.000    0.088    0.000 concat.py:379(<genexpr>)\n",
       "     1020    0.005    0.000   16.316    0.016 label.py:77(_encode)\n",
       "     2522    0.005    0.000    0.005    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
       "      286    0.005    0.000    0.565    0.002 concat.py:383(get_result)\n",
       "      605    0.005    0.000    0.006    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
       "     1936    0.005    0.000    0.032    0.000 cast.py:1151(construct_1d_arraylike_from_scalar)\n",
       "      644    0.005    0.000    0.010    0.000 base.py:1658(is_unique)\n",
       "       25    0.005    0.000    0.005    0.000 __init__.py:131(lmap)\n",
       "8201/8200    0.005    0.000    0.102    0.000 {built-in method builtins.all}\n",
       "      680    0.004    0.000   16.328    0.024 label.py:239(transform)\n",
       "      396    0.004    0.000    0.036    0.000 <frozen importlib._bootstrap_external>:1356(find_spec)\n",
       "     1388    0.004    0.000    0.333    0.000 concat.py:230(concatenate_join_units)\n",
       "      127    0.004    0.000    0.466    0.004 frame.py:4639(duplicated)\n",
       "        1    0.004    0.004    0.379    0.379 parsers.py:403(_read)\n",
       "        1    0.004    0.004    1.147    1.147 <ipython-input-13-ae69ae0eb560>:1(get_metric_data)\n",
       "    18506    0.004    0.000    0.004    0.000 protocol.py:211(is_error_packet)\n",
       "        4    0.004    0.001  414.633  103.658 <ipython-input-21-d71652308ba2>:26(run_ensemble)\n",
       "       13    0.004    0.000    0.022    0.002 {pandas._libs.lib.map_infer}\n",
       "     1020    0.004    0.000   16.308    0.016 label.py:40(_encode_numpy)\n",
       "    18505    0.004    0.000    0.004    0.000 protocol.py:56(__init__)\n",
       "     1008    0.004    0.000    0.069    0.000 concat.py:101(_concat_compat)\n",
       "        5    0.004    0.001    0.008    0.002 managers.py:772(_interleave)\n",
       "     2184    0.004    0.000    0.026    0.000 cast.py:846(maybe_infer_to_datetimelike)\n",
       "     1936    0.004    0.000    0.006    0.000 cast.py:341(infer_dtype_from_scalar)\n",
       "2577/2071    0.004    0.000    0.004    0.000 {built-in method _abc._abc_subclasscheck}\n",
       "     7219    0.004    0.000    0.009    0.000 {built-in method builtins.max}\n",
       "      925    0.004    0.000    0.007    0.000 numeric.py:676(require)\n",
       "      605    0.004    0.000    0.092    0.000 base.py:2715(get_indexer)\n",
       "      765    0.004    0.000    0.043    0.000 validation.py:220(check_consistent_length)\n",
       "     1579    0.004    0.000    0.097    0.000 concat.py:367(is_uniform_join_units)\n",
       "    18234    0.004    0.000    0.004    0.000 protocol.py:190(is_eof_packet)\n",
       "     1431    0.004    0.000    4.084    0.003 fromnumeric.py:54(_wrapfunc)\n",
       "     1448    0.004    0.000    0.007    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "      730    0.004    0.000    0.004    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
       "      765    0.003    0.000    0.016    0.000 function_base.py:294(average)\n",
       "      568    0.003    0.000    0.218    0.000 algorithms.py:434(_factorize_array)\n",
       "      202    0.003    0.000    0.075    0.000 {built-in method builtins.print}\n",
       "    12920    0.003    0.000    0.006    0.000 format.py:301(len)\n",
       "       55    0.003    0.000    0.146    0.003 merge.py:1104(_get_join_indexers)\n",
       "     3850    0.003    0.000    0.005    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "     1020    0.003    0.000    4.086    0.004 fromnumeric.py:1179(searchsorted)\n",
       "      188    0.003    0.000    0.003    0.000 {method 'sendall' of '_socket.socket' objects}\n",
       "      680    0.003    0.000    0.006    0.000 validation.py:903(check_is_fitted)\n",
       "        1    0.003    0.003    0.006    0.006 {built-in method _socket.getaddrinfo}\n",
       "       85    0.003    0.000    0.481    0.006 <ipython-input-19-90de0edd371d>:136(get_sys_ann)\n",
       "      333    0.003    0.000    0.435    0.001 construction.py:170(init_dict)\n",
       "     3935    0.003    0.000    0.010    0.000 common.py:923(is_signed_integer_dtype)\n",
       " 1444/366    0.003    0.000    0.074    0.000 <frozen importlib._bootstrap>:948(_find_and_load_unlocked)\n",
       "     1190    0.003    0.000    0.025    0.000 algorithms.py:38(_ensure_data)\n",
       "     3398    0.003    0.000    0.004    0.000 range.py:510(__len__)\n",
       "      518    0.003    0.000    0.006    0.000 _methods.py:58(_mean)\n",
       "     1019    0.003    0.000    0.024    0.000 managers.py:934(get)\n",
       "      471    0.003    0.000    0.005    0.000 {built-in method _warnings.warn}\n",
       "     1396    0.003    0.000    0.006    0.000 blocks.py:3100(_extend_blocks)\n",
       "      272    0.003    0.000    0.135    0.000 managers.py:1887(_consolidate)\n",
       "      763    0.003    0.000    0.020    0.000 iostream.py:195(schedule)\n",
       "      373    0.003    0.000    0.188    0.001 managers.py:318(apply)\n",
       "      672    0.003    0.000    0.024    0.000 iostream.py:382(write)\n",
       "     3876    0.002    0.000    0.034    0.000 common.py:1078(is_datetime64_any_dtype)\n",
       "        4    0.002    0.001    0.206    0.051 <ipython-input-19-90de0edd371d>:106(get_ref_ann)\n",
       "      358    0.002    0.000    0.159    0.000 construction.py:254(_homogenize)\n",
       "       85    0.002    0.000    2.852    0.034 <ipython-input-18-e3f3b2a89fec>:1(process_sentence)\n",
       "      532    0.002    0.000    0.002    0.000 {pandas._libs.algos.take_2d_axis1_float64_float64}\n",
       "      411    0.002    0.000    0.003    0.000 blocks.py:3145(<listcomp>)\n",
       "     1171    0.002    0.000    0.007    0.000 numerictypes.py:602(find_common_type)\n",
       "     1275    0.002    0.000   16.502    0.013 multiclass.py:77(<genexpr>)\n",
       "     2396    0.002    0.000    0.018    0.000 concat.py:126(dtype)\n",
       "     1171    0.002    0.000    0.002    0.000 numerictypes.py:654(<listcomp>)\n",
       "       33    0.002    0.000    0.002    0.000 {method 'factorize' of 'pandas._libs.hashtable.Float64HashTable' objects}\n",
       "        8    0.002    0.000    0.002    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
       "       55    0.002    0.000    0.149    0.003 merge.py:730(_get_join_indexers)\n",
       "       25    0.002    0.000    0.732    0.029 sql.py:317(read_sql)\n",
       "      211    0.002    0.000    0.120    0.001 indexing.py:1271(_convert_to_indexer)\n",
       "      172    0.002    0.000    0.051    0.000 managers.py:1019(set)\n",
       "     1019    0.002    0.000    0.021    0.000 frame.py:3342(_box_item_values)\n",
       "     1388    0.002    0.000    0.159    0.000 concat.py:240(<listcomp>)\n",
       "     2342    0.002    0.000    0.003    0.000 numerictypes.py:578(_can_coerce_all)\n",
       "     2416    0.002    0.000    0.007    0.000 base.py:2650(get_loc)\n",
       "     1448    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "       29    0.002    0.000    0.002    0.000 result.py:1192(<listcomp>)\n",
       "     1275    0.002    0.000   15.038    0.012 multiclass.py:98(<genexpr>)\n",
       "    12920    0.002    0.000    0.003    0.000 __init__.py:291(strlen)\n",
       "       89    0.002    0.000    0.290    0.003 generic.py:960(rename)\n",
       "      505    0.002    0.000    0.007    0.000 numeric.py:34(__new__)\n",
       "      106    0.002    0.000    0.004    0.000 index_tricks.py:316(__getitem__)\n",
       "      448    0.002    0.000    0.018    0.000 generic.py:1657(_get_label_or_level_values)\n",
       "     1440    0.002    0.000    0.003    0.000 shape_base.py:83(atleast_2d)\n",
       "     1448    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "      211    0.002    0.000    0.107    0.001 indexing.py:1108(_get_listlike_indexer)\n",
       "     5708    0.002    0.000    0.002    0.000 {method 'rpartition' of 'str' objects}\n",
       "      568    0.002    0.000    0.061    0.000 algorithms.py:132(_reconstruct_data)\n",
       "     2994    0.002    0.000    0.005    0.000 common.py:980(is_unsigned_integer_dtype)\n",
       "        4    0.002    0.000    0.002    0.000 {method 'read' of '_io.FileIO' objects}\n",
       "      367    0.002    0.000    0.039    0.000 <frozen importlib._bootstrap_external>:1240(_get_spec)\n",
       "        4    0.002    0.000    0.002    0.000 {pandas._libs.writers.write_csv_rows}\n",
       "      106    0.002    0.000    0.042    0.000 managers.py:1134(insert)\n",
       "      811    0.002    0.000    0.040    0.000 frame.py:742(iteritems)\n",
       "     4357    0.002    0.000    0.002    0.000 concat.py:376(<genexpr>)\n",
       "      680    0.002    0.000    0.002    0.000 shape_base.py:25(atleast_1d)\n",
       "      668    0.002    0.000    0.005    0.000 generic.py:1546(_is_label_reference)\n",
       "       25    0.002    0.000    0.002    0.000 {pandas._libs.lib.to_object_array_tuples}\n",
       "      560    0.002    0.000    0.315    0.001 frame.py:4666(f)\n",
       "     1020    0.002    0.000    0.003    0.000 format.py:1019(base_formatter)\n",
       "     1984    0.002    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:56(_path_join)\n",
       "     1448    0.001    0.000    0.003    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "     1089    0.001    0.000    0.003    0.000 <frozen importlib._bootstrap>:873(_find_spec_legacy)\n",
       "      178    0.001    0.000    0.244    0.001 managers.py:159(rename_axis)\n",
       "     1734    0.001    0.000    0.004    0.000 common.py:1472(is_numeric_dtype)\n",
       "        2    0.001    0.001    0.001    0.001 {method 'readline' of '_io.BufferedReader' objects}\n",
       "      765    0.001    0.000    0.015    0.000 validation.py:231(<listcomp>)\n",
       "       94    0.001    0.000    0.002    0.000 {built-in method builtins.__build_class__}\n",
       "      340    0.001    0.000    0.017    0.000 label.py:207(fit)\n",
       "      760    0.001    0.000    0.002    0.000 base.py:643(_engine)\n",
       "      253    0.001    0.000    0.026    0.000 managers.py:1810(_multi_blockify)\n",
       "      518    0.001    0.000    0.002    0.000 _methods.py:48(_count_reduce_items)\n",
       "      358    0.001    0.000    0.144    0.000 managers.py:1663(create_block_manager_from_arrays)\n",
       "     2690    0.001    0.000    0.014    0.000 common.py:605(is_string_dtype)\n",
       "      880    0.001    0.000    0.003    0.000 generic.py:1513(_is_level_reference)\n",
       "      286    0.001    0.000    0.034    0.000 concat.py:440(_get_new_axes)\n",
       "      211    0.001    0.000    0.004    0.000 indexing.py:1209(_validate_read_indexer)\n",
       "     2690    0.001    0.000    0.008    0.000 common.py:634(condition)\n",
       "     1446    0.001    0.000    0.010    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "      286    0.001    0.000    0.684    0.002 concat.py:24(concat)\n",
       "     3120    0.001    0.000    0.015    0.000 managers.py:1893(<lambda>)\n",
       "       25    0.001    0.000    0.046    0.002 frame.py:1430(from_records)\n",
       "     2776    0.001    0.000    0.002    0.000 concat.py:391(<genexpr>)\n",
       "     1269    0.001    0.000    0.003    0.000 common.py:1198(is_datetime_or_timedelta_dtype)\n",
       "      302    0.001    0.000    0.035    0.000 base.py:3089(reindex)\n",
       "     2430    0.001    0.000    0.009    0.000 blocks.py:175(get_values)\n",
       "     1822    0.001    0.000    0.008    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "       85    0.001    0.000    0.002    0.000 <ipython-input-19-90de0edd371d>:14(buildParseTree)\n",
       "     1476    0.001    0.000    0.007    0.000 base.py:963(_ndarray_values)\n",
       "      568    0.001    0.000    0.020    0.000 numeric.py:67(_shallow_copy)\n",
       "      358    0.001    0.000    0.387    0.001 construction.py:43(arrays_to_mgr)\n",
       "     1448    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "      340    0.001    0.000    0.006    0.000 shape_base.py:286(hstack)\n",
       "      751    0.001    0.000    0.002    0.000 shape_base.py:220(_warn_for_nonsequence)\n",
       "     2085    0.001    0.000    0.004    0.000 managers.py:1844(_asarray_compat)\n",
       "        4    0.001    0.000    0.001    0.000 {method 'writelines' of '_io._IOBase' objects}\n",
       "     1984    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:58(<listcomp>)\n",
       "       55    0.001    0.000    0.090    0.002 merge.py:777(_get_merge_keys)\n",
       "     1264    0.001    0.000    0.013    0.000 common.py:1431(needs_i8_conversion)\n",
       "      448    0.001    0.000    0.002    0.000 generic.py:1607(_check_label_or_level_ambiguity)\n",
       "       55    0.001    0.000    0.002    0.000 function_base.py:4220(delete)\n",
       "      763    0.001    0.000    0.003    0.000 threading.py:1080(is_alive)\n",
       "      372    0.001    0.000    0.028    0.000 base.py:584(_shallow_copy_with_infer)\n",
       "        4    0.001    0.000    0.003    0.001 <frozen importlib._bootstrap_external>:914(get_data)\n",
       "     1388    0.001    0.000    0.003    0.000 concat.py:388(is_uniform_reindex)\n",
       "     2892    0.001    0.000    0.001    0.000 concat.py:104(__init__)\n",
       "2577/2071    0.001    0.000    0.005    0.000 abc.py:141(__subclasscheck__)\n",
       "     2213    0.001    0.000    0.001    0.000 {built-in method builtins.min}\n",
       "      286    0.001    0.000    0.006    0.000 concat.py:84(_get_frame_result_type)\n",
       "      605    0.001    0.000    0.003    0.000 base.py:4459(_maybe_promote)\n",
       "     2742    0.001    0.000    0.002    0.000 concat.py:450(_next_or_none)\n",
       "      344    0.001    0.000    0.198    0.001 managers.py:710(copy)\n",
       "      925    0.001    0.000    0.001    0.000 numeric.py:748(<setcomp>)\n",
       "     2897    0.001    0.000    0.001    0.000 {built-in method _thread.allocate_lock}\n",
       "      127    0.001    0.000    0.001    0.000 {built-in method _operator.inv}\n",
       "        1    0.001    0.001    0.001    0.001 parsers.py:1830(__init__)\n",
       " 1079/361    0.001    0.000    0.070    0.000 {built-in method builtins.__import__}\n",
       "      592    0.001    0.000    0.055    0.000 algorithms.py:217(_get_data_algo)\n",
       "     1061    0.001    0.000    0.008    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "     3570    0.001    0.000    0.003    0.000 format.py:1401(just)\n",
       "        2    0.001    0.000    0.001    0.001 {method 'readlines' of '_io._IOBase' objects}\n",
       "        4    0.001    0.000    0.002    0.000 generic.py:9415(abs)\n",
       "   624/46    0.001    0.000    0.002    0.000 arrayprint.py:716(recurser)\n",
       "      286    0.001    0.000    0.015    0.000 concat.py:475(_get_concat_axis)\n",
       "      127    0.001    0.000    0.002    0.000 protocol.py:283(__init__)\n",
       "       55    0.001    0.000    0.219    0.004 merge.py:541(get_result)\n",
       "      735    0.001    0.000    0.158    0.000 blocks.py:749(copy)\n",
       "      161    0.001    0.000    0.165    0.001 frame.py:2952(_getitem_bool_array)\n",
       "     3349    0.001    0.000    0.001    0.000 concat.py:381(<genexpr>)\n",
       "      377    0.001    0.000    0.232    0.001 socket.py:575(readinto)\n",
       "       25    0.001    0.000    0.053    0.002 sql.py:136(_wrap_result)\n",
       "       48    0.001    0.000    0.012    0.000 format.py:1045(get_result_as_array)\n",
       "      572    0.001    0.000    0.074    0.000 generic.py:5140(_consolidate)\n",
       "     3738    0.001    0.000    0.003    0.000 format.py:1392(<genexpr>)\n",
       "      672    0.001    0.000    0.001    0.000 iostream.py:307(_is_master_process)\n",
       "      687    0.001    0.000    0.036    0.000 frame.py:4685(<genexpr>)\n",
       "      178    0.001    0.000    0.179    0.001 managers.py:1988(_transform_index)\n",
       "      688    0.001    0.000    0.010    0.000 base.py:700(view)\n",
       "      186    0.001    0.000    0.006    0.000 connections.py:744(_execute_command)\n",
       "      700    0.001    0.000    0.002    0.000 config.py:78(_get_single_key)\n",
       "      568    0.001    0.000    0.313    0.001 _decorators.py:146(wrapper)\n",
       "       55    0.001    0.000    0.016    0.000 base.py:2357(intersection)\n",
       "      605    0.001    0.000    0.008    0.000 base.py:1669(is_boolean)\n",
       "      176    0.001    0.000    0.013    0.000 api.py:128(_union_indexes)\n",
       "       55    0.001    0.000    0.095    0.002 merge.py:474(__init__)\n",
       "       24    0.001    0.000    0.001    0.000 {pandas._libs.algos.rank_1d_float64}\n",
       "       48    0.001    0.000    0.009    0.000 format.py:1060(format_values_with)\n",
       "     1008    0.001    0.000    0.001    0.000 concat.py:126(<listcomp>)\n",
       "      106    0.001    0.000    0.006    0.000 managers.py:2008(_fast_count_smallints)\n",
       "     1988    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "      411    0.001    0.000    0.043    0.000 shape_base.py:229(vstack)\n",
       "      236    0.001    0.000    0.031    0.000 construction.py:284(extract_index)\n",
       "      202    0.001    0.000    0.003    0.000 range.py:69(__new__)\n",
       "      210    0.001    0.000    0.001    0.000 range.py:136(_simple_new)\n",
       "      822    0.001    0.000    0.001    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "      286    0.001    0.000    0.017    0.000 concat.py:464(_get_comb_axis)\n",
       "     5086    0.001    0.000    0.001    0.000 {built-in method _imp.acquire_lock}\n",
       "     6097    0.001    0.000    0.001    0.000 {method 'endswith' of 'str' objects}\n",
       "       74    0.001    0.000    0.001    0.000 numeric.py:2551(array_equal)\n",
       "      340    0.001    0.000    0.003    0.000 shape_base.py:335(<listcomp>)\n",
       "      166    0.001    0.000    0.137    0.001 generic.py:5699(copy)\n",
       "      277    0.001    0.000    0.016    0.000 base.py:1096(tolist)\n",
       "     1636    0.001    0.000    0.001    0.000 base.py:1237(_get_names)\n",
       "     2016    0.001    0.000    0.001    0.000 concat.py:136(<genexpr>)\n",
       "     1446    0.001    0.000    0.003    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "      126    0.001    0.000    0.012    0.000 frame.py:3565(_sanitize_column)\n",
       "      286    0.001    0.000    0.002    0.000 concat.py:309(<listcomp>)\n",
       "      650    0.001    0.000    0.001    0.000 managers.py:1546(external_values)\n",
       "       23    0.001    0.000    0.132    0.006 <ipython-input-4-8a49c4ff8f4c>:8(__init__)\n",
       "     5086    0.001    0.000    0.001    0.000 {built-in method _imp.release_lock}\n",
       "       55    0.001    0.000    0.003    0.000 merge.py:647(_maybe_add_join_keys)\n",
       "     1822    0.001    0.000    0.006    0.000 _methods.py:45(_all)\n",
       "      498    0.001    0.000    0.001    0.000 indexing.py:2450(convert_to_index_sliceable)\n",
       "      903    0.001    0.000    0.001    0.000 {pandas._libs.internals.get_blkno_placements}\n",
       "      211    0.001    0.000    0.002    0.000 indexing.py:256(_convert_scalar_indexer)\n",
       "     4034    0.001    0.000    0.001    0.000 {method 'rstrip' of 'str' objects}\n",
       "     2190    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:859(__exit__)\n",
       "     1008    0.001    0.000    0.004    0.000 concat.py:151(<listcomp>)\n",
       "     3658    0.001    0.000    0.001    0.000 format.py:1418(_is_number)\n",
       "     2016    0.001    0.000    0.001    0.000 concat.py:120(is_nonempty)\n",
       "      832    0.001    0.000    0.001    0.000 managers.py:174(_is_single_block)\n",
       "      201    0.001    0.000    0.004    0.000 base.py:5408(default_index)\n",
       "     2190    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:855(__enter__)\n",
       "      286    0.001    0.000    0.001    0.000 api.py:73(_get_distinct_objs)\n",
       "      763    0.001    0.000    0.001    0.000 threading.py:1038(_wait_for_tstate_lock)\n",
       "      274    0.001    0.000    0.001    0.000 managers.py:2015(_preprocess_slice_or_indexer)\n",
       "     3084    0.001    0.000    0.002    0.000 {built-in method builtins.next}\n",
       "      673    0.001    0.000    0.001    0.000 generic.py:3149(_clear_item_cache)\n",
       "     1336    0.001    0.000    0.002    0.000 generic.py:1576(<genexpr>)\n",
       "      110    0.001    0.000    0.091    0.001 frame.py:6558(append)\n",
       "      286    0.001    0.000    0.014    0.000 api.py:87(_get_combined_index)\n",
       "       45    0.001    0.000    0.001    0.000 blocks.py:2689(set)\n",
       "     1446    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "      170    0.001    0.000    0.002    0.000 twodim_base.py:216(diag)\n",
       "      165    0.001    0.000    0.018    0.000 base.py:3988(append)\n",
       "     1028    0.001    0.000    0.002    0.000 frame.py:937(__len__)\n",
       "      365    0.001    0.000    0.001    0.000 {built-in method pandas._libs.lib.is_bool_array}\n",
       "       55    0.001    0.000    0.001    0.000 base.py:1587(is_monotonic_increasing)\n",
       "      411    0.001    0.000    0.003    0.000 shape_base.py:283(<listcomp>)\n",
       "      763    0.001    0.000    0.001    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "      341    0.001    0.000    0.026    0.000 managers.py:2041(<listcomp>)\n",
       "      726    0.001    0.000    0.001    0.000 six.py:184(find_module)\n",
       "      257    0.001    0.000    0.001    0.000 base.py:2849(_convert_scalar_indexer)\n",
       "       25    0.001    0.000    0.006    0.000 base.py:1343(_handle_dbapi_exception)\n",
       "     3492    0.001    0.000    0.001    0.000 {pandas._libs.lib.is_bool}\n",
       "       55    0.001    0.000    0.004    0.000 merge.py:889(_maybe_coerce_merge_keys)\n",
       "      168    0.001    0.000    0.003    0.000 format.py:1407(<listcomp>)\n",
       "      332    0.001    0.000    0.001    0.000 common.py:212(dict_keys_to_ordered_list)\n",
       "       56    0.001    0.000    0.018    0.000 generic.py:4113(reindex)\n",
       "      126    0.001    0.000    0.206    0.002 frame.py:3433(_set_item)\n",
       "      747    0.001    0.000    0.001    0.000 {pandas._libs.lib.array_equivalent_object}\n",
       "      286    0.001    0.000    0.016    0.000 api.py:44(_get_objs_combined_axis)\n",
       "      576    0.001    0.000    0.002    0.000 frame.py:491(shape)\n",
       "      448    0.001    0.000    0.008    0.000 generic.py:3461(xs)\n",
       "     1388    0.001    0.000    0.001    0.000 blocks.py:255(__len__)\n",
       "      106    0.001    0.000    0.030    0.000 base.py:4919(insert)\n",
       "      277    0.001    0.000    0.001    0.000 protocol.py:180(read_struct)\n",
       "      765    0.001    0.000    0.005    0.000 base.py:646(<lambda>)\n",
       "       55    0.001    0.000    0.032    0.001 generic.py:3787(_drop_axis)\n",
       "      751    0.001    0.000    0.001    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
       "      680    0.001    0.000    0.001    0.000 validation.py:950(<listcomp>)\n",
       "      888    0.001    0.000    0.011    0.000 base.py:1729(inferred_type)\n",
       "      126    0.001    0.000    0.207    0.002 frame.py:3356(__setitem__)\n",
       "      692    0.001    0.000    0.003    0.000 config.py:96(_get_option)\n",
       "        4    0.001    0.000    0.041    0.010 format.py:503(_to_str_columns)\n",
       "       34    0.001    0.000    0.005    0.000 connections.py:1213(_get_descriptions)\n",
       "      255    0.001    0.000    0.002    0.000 classification.py:1589(<listcomp>)\n",
       "      168    0.001    0.000    0.010    0.000 format.py:1384(_make_fixed_width)\n",
       "      367    0.001    0.000    0.040    0.000 <frozen importlib._bootstrap_external>:1272(find_spec)\n",
       "       55    0.001    0.000    0.012    0.000 base.py:4939(drop)\n",
       "       84    0.001    0.000    0.023    0.000 format.py:848(format_array)\n",
       "     1392    0.001    0.000    0.001    0.000 config.py:561(_get_deprecated_option)\n",
       "      150    0.001    0.000    0.001    0.000 <ipython-input-21-d71652308ba2>:8(expressions)\n",
       "      145    0.001    0.000    0.001    0.000 generic.py:297(_construct_axes_from_arguments)\n",
       "      763    0.001    0.000    0.001    0.000 iostream.py:93(_event_pipe)\n",
       "      191    0.001    0.000    0.028    0.000 blocks.py:323(concat_same_type)\n",
       "      154    0.000    0.000    0.001    0.000 api.py:262(<setcomp>)\n",
       "      688    0.000    0.000    0.011    0.000 managers.py:729(<lambda>)\n",
       "      692    0.000    0.000    0.001    0.000 config.py:546(_get_root)\n",
       "      286    0.000    0.000    0.002    0.000 generic.py:337(_from_axes)\n",
       "      411    0.000    0.000    0.003    0.000 fromnumeric.py:942(argsort)\n",
       "      116    0.000    0.000    0.002    0.000 protocol.py:237(_parse_field_descriptor)\n",
       "     1061    0.000    0.000    0.007    0.000 _methods.py:34(_sum)\n",
       "     1070    0.000    0.000    0.003    0.000 missing.py:259(notna)\n",
       "      240    0.000    0.000    0.001    0.000 printing.py:59(<listcomp>)\n",
       "      127    0.000    0.000    0.013    0.000 generic.py:1439(__neg__)\n",
       "       89    0.000    0.000    0.291    0.003 frame.py:3942(rename)\n",
       "       54    0.000    0.000    0.640    0.012 base.py:1163(_execute_context)\n",
       "     2541    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "      165    0.000    0.000    0.017    0.000 base.py:4017(_concat)\n",
       "     2943    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "      518    0.000    0.000    0.007    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
       "      661    0.000    0.000    0.001    0.000 missing.py:530(clean_reindex_fill_method)\n",
       "       55    0.000    0.000    0.070    0.001 generic.py:1729(_drop_labels_or_levels)\n",
       "      117    0.000    0.000    0.001    0.000 format.py:1422(<listcomp>)\n",
       "      363    0.000    0.000    0.001    0.000 __init__.py:23(find_module)\n",
       "       55    0.000    0.000    0.314    0.006 frame.py:6858(merge)\n",
       " 1081/362    0.000    0.000    0.068    0.000 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "     2016    0.000    0.000    0.001    0.000 concat.py:137(<genexpr>)\n",
       "      592    0.000    0.000    0.001    0.000 _config.py:49(getter)\n",
       "     3023    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "      135    0.000    0.000    0.000    0.000 sorting.py:47(_int64_cut_off)\n",
       "      131    0.000    0.000    0.010    0.000 series.py:730(__array_wrap__)\n",
       "       50    0.000    0.000    0.026    0.001 base.py:748(_checkout)\n",
       "      367    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "      115    0.000    0.000    0.009    0.000 range.py:272(_shallow_copy)\n",
       "      127    0.000    0.000    0.006    0.000 base.py:2445(difference)\n",
       "      820    0.000    0.000    0.001    0.000 _validators.py:221(validate_bool_kwarg)\n",
       "      365    0.000    0.000    0.001    0.000 blocks.py:2633(is_bool)\n",
       "      236    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
       "      650    0.000    0.000    0.001    0.000 series.py:434(values)\n",
       "     1780    0.000    0.000    0.001    0.000 format.py:541(<genexpr>)\n",
       "       55    0.000    0.000    0.011    0.000 generic.py:4469(_reindex_with_indexers)\n",
       "      404    0.000    0.000    0.027    0.000 <frozen importlib._bootstrap_external>:74(_path_stat)\n",
       "      101    0.000    0.000    0.007    0.000 generic.py:3840(_update_inplace)\n",
       "      762    0.000    0.000    0.002    0.000 generic.py:1895(<genexpr>)\n",
       "      255    0.000    0.000    0.001    0.000 {method 'any' of 'numpy.generic' objects}\n",
       "      186    0.000    0.000    0.001    0.000 managers.py:147(set_axis)\n",
       "      772    0.000    0.000    0.001    0.000 common.py:1513(is_string_like_dtype)\n",
       "      578    0.000    0.000    0.001    0.000 arrayprint.py:693(_extendLine)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method marshal.loads}\n",
       "      190    0.000    0.000    0.003    0.000 fromnumeric.py:2664(prod)\n",
       "      401    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:1203(_path_importer_cache)\n",
       "      170    0.000    0.000    0.001    0.000 fromnumeric.py:1395(diagonal)\n",
       "       55    0.000    0.000    0.314    0.006 merge.py:37(merge)\n",
       "       46    0.000    0.000    0.004    0.000 {method 'get_value' of 'pandas._libs.index.IndexEngine' objects}\n",
       "       55    0.000    0.000    0.006    0.000 concat.py:486(_concat_index_asobject)\n",
       "      211    0.000    0.000    0.003    0.000 base.py:2965(_convert_listlike_indexer)\n",
       "      127    0.000    0.000    0.015    0.000 connections.py:393(_read_ok_packet)\n",
       "      672    0.000    0.000    0.002    0.000 iostream.py:320(_schedule_flush)\n",
       "      828    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
       "       51    0.000    0.000    0.001    0.000 base.py:69(__init__)\n",
       "      176    0.000    0.000    0.001    0.000 api.py:205(_sanitize_and_check)\n",
       "      144    0.000    0.000    0.001    0.000 _validators.py:230(validate_axis_style_args)\n",
       "      453    0.000    0.000    0.000    0.000 {method 'title' of 'str' objects}\n",
       "       55    0.000    0.000    0.153    0.003 merge.py:737(_get_join_info)\n",
       "      850    0.000    0.000    0.000    0.000 {method 'pop' of 'set' objects}\n",
       "        6    0.000    0.000    0.000    0.000 sre_compile.py:276(_optimize_charset)\n",
       "       45    0.000    0.000    0.000    0.000 {built-in method numpy.putmask}\n",
       "      212    0.000    0.000    0.002    0.000 function_base.py:4641(append)\n",
       "       80    0.000    0.000    0.031    0.000 format.py:702(_format_col)\n",
       "     3480    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "      211    0.000    0.000    0.068    0.000 base.py:4447(get_indexer_for)\n",
       "      126    0.000    0.000    0.048    0.000 generic.py:3171(_set_item)\n",
       "      344    0.000    0.000    0.011    0.000 managers.py:730(<listcomp>)\n",
       "       46    0.000    0.000    0.005    0.000 base.py:4342(get_value)\n",
       "       85    0.000    0.000    0.013    0.000 <ipython-input-19-90de0edd371d>:54(make_parse_tree)\n",
       "      396    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:36(_relax_case)\n",
       "      122    0.000    0.000    0.001    0.000 printing.py:55(<listcomp>)\n",
       "      110    0.000    0.000    0.003    0.000 base.py:1272(set_names)\n",
       "      154    0.000    0.000    0.001    0.000 api.py:243(_get_consensus_names)\n",
       "       69    0.000    0.000    0.001    0.000 format.py:1427(<listcomp>)\n",
       "      404    0.000    0.000    0.000    0.000 range.py:89(ensure_int)\n",
       "      188    0.000    0.000    0.005    0.000 connections.py:710(_write_bytes)\n",
       "       19    0.000    0.000    0.003    0.000 printing.py:15(adjoin)\n",
       "      903    0.000    0.000    0.000    0.000 managers.py:706(nblocks)\n",
       "      286    0.000    0.000    0.001    0.000 api.py:67(<listcomp>)\n",
       "      110    0.000    0.000    0.003    0.000 concat.py:481(_concat_index_same_dtype)\n",
       "     2722    0.000    0.000    0.000    0.000 {method 'ljust' of 'str' objects}\n",
       "       29    0.000    0.000    0.001    0.000 result.py:215(__init__)\n",
       "      440    0.000    0.000    0.002    0.000 generic.py:1844(__contains__)\n",
       "       48    0.000    0.000    0.003    0.000 format.py:1078(<listcomp>)\n",
       "      110    0.000    0.000    0.006    0.000 numeric.py:110(_concat_same_dtype)\n",
       "       25    0.000    0.000    0.001    0.000 schema.py:3753(__init__)\n",
       "      106    0.000    0.000    0.019    0.000 base.py:3830(_coerce_scalar_to_index)\n",
       "      505    0.000    0.000    0.000    0.000 base.py:3806(_coerce_to_ndarray)\n",
       "      572    0.000    0.000    0.002    0.000 concat.py:92(<genexpr>)\n",
       "       54    0.000    0.000    0.001    0.000 default.py:862(_init_statement)\n",
       "      118    0.000    0.000    0.009    0.000 frame.py:3585(reindexer)\n",
       "      254    0.000    0.000    0.002    0.000 generic.py:1848(empty)\n",
       "      389    0.000    0.000    0.001    0.000 protocol.py:122(read_uint16)\n",
       "     1837    0.000    0.000    0.000    0.000 managers.py:1814(<lambda>)\n",
       "      144    0.000    0.000    0.309    0.002 _decorators.py:195(wrapper)\n",
       "      255    0.000    0.000    0.000    0.000 {built-in method numpy.result_type}\n",
       "      720    0.000    0.000    0.000    0.000 base.py:475(<genexpr>)\n",
       "       50    0.000    0.000    0.017    0.000 base.py:481(checkout)\n",
       "      164    0.000    0.000    0.001    0.000 format.py:356(_get_formatter)\n",
       "      568    0.000    0.000    0.002    0.000 algorithms.py:163(_ensure_arraylike)\n",
       "      220    0.000    0.000    0.002    0.000 generic.py:1578(_is_label_or_level_reference)\n",
       "      151    0.000    0.000    0.039    0.000 managers.py:1796(_simple_blockify)\n",
       "        1    0.000    0.000    0.000    0.000 <ipython-input-19-90de0edd371d>:102(<listcomp>)\n",
       "      367    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:792(find_spec)\n",
       "       46    0.000    0.000    0.014    0.000 series.py:865(__getitem__)\n",
       "      367    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}\n",
       "       85    0.000    0.000    0.033    0.000 <ipython-input-18-e3f3b2a89fec>:11(__init__)\n",
       "      170    0.000    0.000    0.000    0.000 {method 'diagonal' of 'numpy.ndarray' objects}\n",
       "       55    0.000    0.000    0.035    0.001 generic.py:3759(drop)\n",
       "      692    0.000    0.000    0.004    0.000 config.py:226(__call__)\n",
       "      165    0.000    0.000    0.001    0.000 printing.py:156(pprint_thing)\n",
       "      377    0.000    0.000    0.000    0.000 {method '_checkReadable' of '_io._IOBase' objects}\n",
       "      592    0.000    0.000    0.000    0.000 _config.py:140(get)\n",
       "       32    0.000    0.000    0.001    0.000 format.py:1140(<listcomp>)\n",
       "      332    0.000    0.000    0.000    0.000 construction.py:210(<listcomp>)\n",
       "     1510    0.000    0.000    0.000    0.000 format.py:1423(<genexpr>)\n",
       "       55    0.000    0.000    0.018    0.000 frame.py:3794(reindex)\n",
       "      161    0.000    0.000    0.000    0.000 generic.py:1814(__hash__)\n",
       "       25    0.000    0.000    0.015    0.001 base.py:2312(has_table)\n",
       "      673    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "       46    0.000    0.000    0.002    0.000 arrayprint.py:480(_array2string)\n",
       "        4    0.000    0.000    0.118    0.030 <ipython-input-21-d71652308ba2>:142(generate_ensemble_metrics)\n",
       "      772    0.000    0.000    0.000    0.000 common.py:1542(<lambda>)\n",
       "       46    0.000    0.000    0.003    0.000 arrayprint.py:518(array2string)\n",
       "      211    0.000    0.000    0.003    0.000 base.py:1672(is_integer)\n",
       "      425    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
       "     1406    0.000    0.000    0.000    0.000 numeric.py:113(is_all_dates)\n",
       "      227    0.000    0.000    0.145    0.001 generic.py:3205(_check_setitem_copy)\n",
       "      692    0.000    0.000    0.001    0.000 config.py:602(_warn_if_deprecated)\n",
       "      572    0.000    0.000    0.002    0.000 concat.py:93(<genexpr>)\n",
       "      101    0.000    0.000    0.004    0.000 generic.py:3115(_maybe_update_cacher)\n",
       "      165    0.000    0.000    0.000    0.000 printing.py:185(as_escaped_unicode)\n",
       "       50    0.000    0.000    0.000    0.000 queue.py:135(get)\n",
       "       85    0.000    0.000    0.000    0.000 <ipython-input-19-90de0edd371d>:83(__init__)\n",
       "      288    0.000    0.000    0.000    0.000 protocol.py:186(is_ok_packet)\n",
       "        1    0.000    0.000  414.797  414.797 <ipython-input-21-d71652308ba2>:169(ensemble_control)\n",
       "      957    0.000    0.000    0.000    0.000 numerictypes.py:587(<listcomp>)\n",
       "      286    0.000    0.000    0.000    0.000 common.py:162(_not_none)\n",
       "       55    0.000    0.000    0.014    0.000 frame.py:3754(_reindex_columns)\n",
       "       76    0.000    0.000    0.012    0.000 base.py:2223(do_rollback)\n",
       "      368    0.000    0.000    0.000    0.000 <ipython-input-21-d71652308ba2>:50(<genexpr>)\n",
       "        8    0.000    0.000    0.022    0.003 <ipython-input-14-6708c31f37df>:7(geometric_mean)\n",
       "      404    0.000    0.000    0.001    0.000 managers.py:1850(_shape_compat)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method posix.listdir}\n",
       "      673    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
       "      286    0.000    0.000    0.000    0.000 concat.py:507(<listcomp>)\n",
       "        4    0.000    0.000    0.005    0.001 csvs.py:290(_save_chunk)\n",
       "      926    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
       "      389    0.000    0.000    0.000    0.000 {built-in method _struct.unpack_from}\n",
       "       25    0.000    0.000    0.009    0.000 construction.py:429(_list_to_arrays)\n",
       "       59    0.000    0.000    0.631    0.011 connections.py:508(query)\n",
       "       55    0.000    0.000    0.001    0.000 merge.py:614(_maybe_restore_index_levels)\n",
       "      700    0.000    0.000    0.000    0.000 config.py:528(_select_options)\n",
       "      110    0.000    0.000    0.001    0.000 base.py:1240(_set_names)\n",
       "       24    0.000    0.000    0.000    0.000 function_base.py:1149(diff)\n",
       "     1068    0.000    0.000    0.000    0.000 format.py:1107(<genexpr>)\n",
       "      286    0.000    0.000    0.000    0.000 concat.py:434(_get_result_dim)\n",
       "      858    0.000    0.000    0.000    0.000 common.py:164(<genexpr>)\n",
       "      110    0.000    0.000    0.010    0.000 concat.py:531(_concat_indexes)\n",
       "       99    0.000    0.000    0.000    0.000 threading.py:335(notify)\n",
       "      117    0.000    0.000    0.002    0.000 format.py:1421(_cond)\n",
       "      362    0.000    0.000    0.002    0.000 printing.py:50(justify)\n",
       "       55    0.000    0.000    0.003    0.000 base.py:4909(delete)\n",
       "       46    0.000    0.000    0.022    0.000 series.py:4221(dropna)\n",
       "       32    0.000    0.000    0.006    0.000 strings.py:1854(_wrap_result)\n",
       "       57    0.000    0.000    0.000    0.000 cursors.py:116(_escape_args)\n",
       "      763    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
       "      225    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "     1171    0.000    0.000    0.000    0.000 numerictypes.py:655(<listcomp>)\n",
       "      661    0.000    0.000    0.000    0.000 missing.py:71(clean_fill_method)\n",
       "      144    0.000    0.000    0.000    0.000 common.py:199(count_not_none)\n",
       "       48    0.000    0.000    0.000    0.000 format.py:1430(<listcomp>)\n",
       "       50    0.000    0.000    0.028    0.001 base.py:2223(_contextual_connect)\n",
       "    36/32    0.000    0.000    0.081    0.003 strings.py:62(_map)\n",
       "       46    0.000    0.000    0.007    0.000 managers.py:1506(get_slice)\n",
       "       50    0.000    0.000    0.000    0.000 queue.py:92(put)\n",
       "      700    0.000    0.000    0.000    0.000 config.py:589(_translate_key)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'close' of 'pandas._libs.parsers.TextReader' objects}\n",
       "      378    0.000    0.000    0.000    0.000 socket.py:614(readable)\n",
       "      110    0.000    0.000    0.003    0.000 base.py:1346(rename)\n",
       "      305    0.000    0.000    0.000    0.000 binaryTree.py:17(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}\n",
       "      178    0.000    0.000    0.001    0.000 common.py:457(_get_rename_function)\n",
       "      126    0.000    0.000    0.000    0.000 base.py:3926(contains)\n",
       "       50    0.000    0.000    0.008    0.000 base.py:845(_reset)\n",
       "       55    0.000    0.000    0.015    0.000 frame.py:3729(_reindex_axes)\n",
       "       50    0.000    0.000    0.009    0.000 base.py:645(_finalize_fairy)\n",
       "       89    0.000    0.000    0.000    0.000 __init__.py:125(lrange)\n",
       "       25    0.000    0.000    0.001    0.000 sql.py:972(__init__)\n",
       "       34    0.000    0.000    0.407    0.012 connections.py:1149(_read_result_packet)\n",
       "       25    0.000    0.000    0.000    0.000 exc.py:390(instance)\n",
       "      363    0.000    0.000    0.000    0.000 {method 'partition' of 'str' objects}\n",
       "       46    0.000    0.000    0.000    0.000 arrayprint.py:411(_get_format_function)\n",
       "       81    0.000    0.000    0.001    0.000 langhelpers.py:852(__get__)\n",
       "      218    0.000    0.000    0.001    0.000 base.py:2590(_assert_can_do_setop)\n",
       "      572    0.000    0.000    0.001    0.000 concat.py:97(<genexpr>)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:2260(is_disconnect)\n",
       "       55    0.000    0.000    0.000    0.000 {built-in method numpy.copyto}\n",
       "      211    0.000    0.000    0.002    0.000 base.py:2999(_convert_arr_indexer)\n",
       "       55    0.000    0.000    0.016    0.000 managers.py:1959(items_overlap_with_suffix)\n",
       "       40    0.000    0.000    0.000    0.000 attr.py:166(update_subclass)\n",
       "       25    0.000    0.000    0.000    0.000 err.py:100(raise_mysql_exception)\n",
       "       50    0.000    0.000    0.001    0.000 base.py:507(checkin)\n",
       "       46    0.000    0.000    0.008    0.000 series.py:975(_get_values)\n",
       "      668    0.000    0.000    0.000    0.000 generic.py:1567(<listcomp>)\n",
       "       59    0.000    0.000    0.629    0.011 connections.py:720(_read_query_result)\n",
       "       54    0.000    0.000    0.640    0.012 base.py:1138(_execute_text)\n",
       "       55    0.000    0.000    0.036    0.001 frame.py:3819(drop)\n",
       "      362    0.000    0.000    0.002    0.000 format.py:304(justify)\n",
       "       99    0.000    0.000    0.007    0.000 construction.py:495(convert)\n",
       "      252    0.000    0.000    0.000    0.000 weakref.py:395(__getitem__)\n",
       "      411    0.000    0.000    0.000    0.000 blocks.py:3146(<listcomp>)\n",
       "       76    0.000    0.000    0.011    0.000 connections.py:422(rollback)\n",
       "      199    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
       "      368    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "       50    0.000    0.000    0.009    0.000 connections.py:532(ping)\n",
       "      305    0.000    0.000    0.000    0.000 stack.py:17(pop)\n",
       "      524    0.000    0.000    0.001    0.000 concat.py:510(<genexpr>)\n",
       "       59    0.000    0.000    0.629    0.011 connections.py:1073(read)\n",
       "      680    0.000    0.000    0.001    0.000 format.py:1139(<lambda>)\n",
       "       25    0.000    0.000    0.015    0.001 construction.py:382(to_arrays)\n",
       "       84    0.000    0.000    0.019    0.000 format.py:927(get_result)\n",
       "       50    0.000    0.000    0.000    0.000 base.py:123(_join)\n",
       "       88    0.000    0.000    0.001    0.000 format.py:338(_get_adjustment)\n",
       "     1380    0.000    0.000    0.000    0.000 format.py:1424(<genexpr>)\n",
       "       51    0.000    0.000    0.001    0.000 base.py:77(__init__)\n",
       "      211    0.000    0.000    0.000    0.000 indexing.py:2676(is_nested_tuple)\n",
       "       25    0.000    0.000    0.685    0.027 sql.py:1055(read_query)\n",
       "      9/3    0.000    0.000    0.000    0.000 sre_parse.py:475(_parse)\n",
       "      140    0.000    0.000    0.000    0.000 result.py:461(_colnames_from_description)\n",
       "      813    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "       55    0.000    0.000    0.000    0.000 sorting.py:124(is_int64_overflow_possible)\n",
       "        4    0.000    0.000    0.005    0.001 sorting.py:189(lexsort_indexer)\n",
       "      127    0.000    0.000    0.000    0.000 base.py:978(empty)\n",
       "      302    0.000    0.000    0.000    0.000 base.py:5381(_ensure_has_len)\n",
       "       59    0.000    0.000    0.631    0.011 cursors.py:324(_query)\n",
       "      152    0.000    0.000    0.000    0.000 protocol.py:86(advance)\n",
       "       46    0.000    0.000    0.008    0.000 series.py:913(_get_with)\n",
       "      110    0.000    0.000    0.000    0.000 binaryTree.py:22(insertLeft)\n",
       "       21    0.000    0.000    0.001    0.000 blocks.py:536(_astype)\n",
       "      448    0.000    0.000    0.000    0.000 generic.py:1693(<listcomp>)\n",
       "       44    0.000    0.000    0.079    0.002 <ipython-input-16-5027fd525437>:53(<lambda>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "       84    0.000    0.000    0.001    0.000 range.py:180(_int64index)\n",
       "      377    0.000    0.000    0.000    0.000 {method '_checkClosed' of '_io._IOBase' objects}\n",
       "       46    0.000    0.000    0.000    0.000 arrayprint.py:358(_get_formatdict)\n",
       "        4    0.000    0.000    0.025    0.006 {pandas._libs.reduction.reduce}\n",
       "      305    0.000    0.000    0.000    0.000 stack.py:14(push)\n",
       "       85    0.000    0.000    0.000    0.000 <ipython-input-19-90de0edd371d>:62(preprocess_sentence)\n",
       "       21    0.000    0.000    0.002    0.000 generic.py:5581(astype)\n",
       "      650    0.000    0.000    0.000    0.000 blocks.py:161(external_values)\n",
       "       59    0.000    0.000    0.001    0.000 cursors.py:135(mogrify)\n",
       "       25    0.000    0.000    0.004    0.000 base.py:729(_rollback_impl)\n",
       "      277    0.000    0.000    0.000    0.000 {method 'unpack_from' of 'Struct' objects}\n",
       "       25    0.000    0.000    0.044    0.002 base.py:2133(run_callable)\n",
       "      123    0.000    0.000    0.000    0.000 range.py:330(equals)\n",
       "      211    0.000    0.000    0.000    0.000 base.py:3035(_convert_list_indexer)\n",
       "      112    0.000    0.000    0.001    0.000 generic.py:4341(<genexpr>)\n",
       "      151    0.000    0.000    0.000    0.000 attr.py:267(__bool__)\n",
       "      145    0.000    0.000    0.000    0.000 generic.py:334(<dictcomp>)\n",
       "        4    0.000    0.000    0.001    0.000 format.py:931(_format_strings)\n",
       "      220    0.000    0.000    0.000    0.000 merge.py:1731(_should_fill)\n",
       "       15    0.000    0.000    0.024    0.002 algorithms.py:370(isin)\n",
       "       25    0.000    0.000    0.006    0.000 sql.py:115(_parse_date_columns)\n",
       "      116    0.000    0.000    0.000    0.000 protocol.py:253(description)\n",
       "       24    0.000    0.000    0.004    0.000 generic.py:8324(ranker)\n",
       "       46    0.000    0.000    0.003    0.000 arrayprint.py:463(wrapper)\n",
       "      110    0.000    0.000    0.000    0.000 function_base.py:258(iterable)\n",
       "       46    0.000    0.000    0.004    0.000 generic.py:3093(_maybe_cache_changed)\n",
       "      176    0.000    0.000    0.000    0.000 api.py:226(<setcomp>)\n",
       "      573    0.000    0.000    0.000    0.000 concat.py:383(<genexpr>)\n",
       "      232    0.000    0.000    0.000    0.000 protocol.py:264(get_column_length)\n",
       "       77    0.000    0.000    0.002    0.000 common.py:1320(is_datetimelike_v_numeric)\n",
       "       55    0.000    0.000    0.000    0.000 generic.py:4378(_needs_reindex_multi)\n",
       "      181    0.000    0.000    0.000    0.000 inference.py:470(is_sequence)\n",
       "       18    0.000    0.000    0.000    0.000 common.py:120(_stringify_path)\n",
       "       15    0.000    0.000    0.026    0.002 series.py:3947(isin)\n",
       "       29    0.000    0.000    0.001    0.000 result.py:441(<listcomp>)\n",
       "        1    0.000    0.000  428.978  428.978 <ipython-input-24-d4627e3a7b63>:2(main)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "      418    0.000    0.000    0.000    0.000 common.py:183(_any_not_none)\n",
       "       25    0.000    0.000    0.000    0.000 result.py:588(_key_fallback)\n",
       "       55    0.000    0.000    0.003    0.000 generic.py:1765(<listcomp>)\n",
       "      202    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "       46    0.000    0.000    0.000    0.000 arrayprint.py:69(_make_options_dict)\n",
       "       50    0.000    0.000    0.009    0.000 base.py:869(close)\n",
       "       46    0.000    0.000    0.017    0.000 missing.py:522(remove_na_arraylike)\n",
       "       46    0.000    0.000    0.000    0.000 blocks.py:266(_slice)\n",
       "       25    0.000    0.000    0.000    0.000 exc.py:462(__init__)\n",
       "       25    0.000    0.000    0.000    0.000 pymysql.py:64(is_disconnect)\n",
       "       48    0.000    0.000    0.003    0.000 format.py:1412(_trim_zeros)\n",
       "       55    0.000    0.000    0.000    0.000 merge.py:1704(<lambda>)\n",
       "       50    0.000    0.000    0.017    0.000 impl.py:111(_do_get)\n",
       "      127    0.000    0.000    0.000    0.000 base.py:759(size)\n",
       "       54    0.000    0.000    0.000    0.000 default.py:1034(create_cursor)\n",
       "       59    0.000    0.000    0.632    0.011 cursors.py:151(execute)\n",
       "      140    0.000    0.000    0.000    0.000 result.py:560(_merge_cols_by_none)\n",
       "      367    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:719(find_spec)\n",
       "       46    0.000    0.000    0.000    0.000 numeric.py:203(_convert_scalar_indexer)\n",
       "      165    0.000    0.000    0.000    0.000 base.py:4012(<setcomp>)\n",
       "       25    0.000    0.000    0.001    0.000 sql.py:508(pandasSQL_builder)\n",
       "       46    0.000    0.000    0.005    0.000 range.py:520(__getitem__)\n",
       "       54    0.000    0.000    0.640    0.012 base.py:922(execute)\n",
       "      170    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}\n",
       "        4    0.000    0.000    0.099    0.025 apply.py:228(apply_standard)\n",
       "      965    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
       "       55    0.000    0.000    0.006    0.000 base.py:4025(_concat_same_dtype)\n",
       "        4    0.000    0.000    0.002    0.000 format.py:651(<listcomp>)\n",
       "       85    0.000    0.000    0.000    0.000 stack.py:8(__init__)\n",
       "       46    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "      260    0.000    0.000    0.001    0.000 series.py:591(__len__)\n",
       "      387    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
       "        4    0.000    0.000    0.057    0.014 apply.py:262(apply_series_generator)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:574(spec_from_file_location)\n",
       "      116    0.000    0.000    0.002    0.000 protocol.py:233(__init__)\n",
       "      111    0.000    0.000    0.000    0.000 type_api.py:483(_cached_result_processor)\n",
       "       55    0.000    0.000    0.001    0.000 common.py:246(index_labels_to_array)\n",
       "      126    0.000    0.000    0.000    0.000 frame.py:3416(_ensure_valid_index)\n",
       "       59    0.000    0.000    0.000    0.000 connections.py:1053(__init__)\n",
       "      455    0.000    0.000    0.000    0.000 printing.py:62(_join_unicode)\n",
       "       88    0.000    0.000    0.001    0.000 range.py:176(_data)\n",
       "        4    0.000    0.000    0.005    0.001 format.py:642(_join_multiline)\n",
       "      220    0.000    0.000    0.001    0.000 merge.py:799(<lambda>)\n",
       "       29    0.000    0.000    0.001    0.000 result.py:740(_init_metadata)\n",
       "      110    0.000    0.000    0.000    0.000 concat.py:483(<listcomp>)\n",
       "       37    0.000    0.000    0.001    0.000 deprecations.py:117(warned)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:183(execution_options)\n",
       "       46    0.000    0.000    0.003    0.000 arrayprint.py:1499(_array_str_implementation)\n",
       "      360    0.000    0.000    0.000    0.000 common.py:464(f)\n",
       "       84    0.000    0.000    0.000    0.000 format.py:912(__init__)\n",
       "       50    0.000    0.000    0.000    0.000 log.py:56(_should_log_debug)\n",
       "      202    0.000    0.000    0.000    0.000 common.py:175(_all_none)\n",
       "       25    0.000    0.000    0.000    0.000 exc.py:328(__init__)\n",
       "       51    0.000    0.000    0.001    0.000 base.py:295(__get__)\n",
       "        8    0.000    0.000    0.004    0.000 categorical.py:317(__init__)\n",
       "      448    0.000    0.000    0.000    0.000 generic.py:1627(<listcomp>)\n",
       "       51    0.000    0.000    0.000    0.000 _collections.py:140(__new__)\n",
       "      432    0.000    0.000    0.000    0.000 common.py:201(<genexpr>)\n",
       "       25    0.000    0.000    0.000    0.000 sql.py:45(_is_sqlalchemy_connectable)\n",
       "       50    0.000    0.000    0.009    0.000 mysqldb.py:120(do_ping)\n",
       "      114    0.000    0.000    0.000    0.000 base.py:658(__array__)\n",
       "       32    0.000    0.000    0.000    0.000 strings.py:1805(_validate)\n",
       "       25    0.000    0.000    0.044    0.002 sql.py:1197(has_table)\n",
       "       55    0.000    0.000    0.000    0.000 numeric.py:175(ones)\n",
       "       29    0.000    0.000    0.000    0.000 default.py:947(should_autocommit)\n",
       "       54    0.000    0.000    0.000    0.000 default.py:1002(_use_server_side_cursor)\n",
       "      220    0.000    0.000    0.000    0.000 common.py:273(maybe_make_list)\n",
       "      152    0.000    0.000    0.000    0.000 base.py:4683(_maybe_cast_indexer)\n",
       "       45    0.000    0.000    0.001    0.000 blocks.py:2736(should_store)\n",
       "        8    0.000    0.000    0.001    0.000 generic.py:5948(fillna)\n",
       "      110    0.000    0.000    0.000    0.000 merge.py:1738(_any)\n",
       "      110    0.000    0.000    0.000    0.000 binaryTree.py:34(insertRight)\n",
       "      404    0.000    0.000    0.000    0.000 binaryTree.py:47(getRightChild)\n",
       "       55    0.000    0.000    0.000    0.000 copy.py:66(copy)\n",
       "       32    0.000    0.000    0.001    0.000 strings.py:1795(__init__)\n",
       "       59    0.000    0.000    0.000    0.000 cursors.py:40(__init__)\n",
       "       50    0.000    0.000    0.009    0.000 base.py:831(_checkin)\n",
       "        1    0.000    0.000    0.000    0.000 hub.py:396(__init__)\n",
       "       85    0.000    0.000    0.000    0.000 <ipython-input-18-e3f3b2a89fec>:10(Results)\n",
       "       54    0.000    0.000    0.000    0.000 {built-in method sqlalchemy.cutils._distill_params}\n",
       "      294    0.000    0.000    0.000    0.000 timeout.py:260(_start_new_or_dummy)\n",
       "       55    0.000    0.000    0.001    0.000 generic.py:1778(<listcomp>)\n",
       "        4    0.000    0.000    0.002    0.001 format.py:739(_get_formatted_column_labels)\n",
       "        4    0.000    0.000    0.047    0.012 frame.py:678(to_string)\n",
       "       34    0.000    0.000    0.000    0.000 protocol.py:308(__init__)\n",
       "       50    0.000    0.000    0.026    0.001 base.py:345(connect)\n",
       "       85    0.000    0.000    0.001    0.000 format.py:945(_format)\n",
       "      118    0.000    0.000    0.000    0.000 cursors.py:89(_nextset)\n",
       "      404    0.000    0.000    0.000    0.000 binaryTree.py:50(getLeftChild)\n",
       "      305    0.000    0.000    0.000    0.000 binaryTree.py:53(setRootVal)\n",
       "       59    0.000    0.000    0.000    0.000 connections.py:481(cursor)\n",
       "       50    0.000    0.000    0.000    0.000 base.py:580(get_connection)\n",
       "      101    0.000    0.000    0.000    0.000 base.py:100(_reset_cache)\n",
       "      191    0.000    0.000    0.000    0.000 blocks.py:327(<listcomp>)\n",
       "      373    0.000    0.000    0.000    0.000 managers.py:376(<dictcomp>)\n",
       "      191    0.000    0.000    0.000    0.000 managers.py:2058(<listcomp>)\n",
       "       29    0.000    0.000    0.001    0.000 result.py:714(__init__)\n",
       "       55    0.000    0.000    0.001    0.000 generic.py:1775(<listcomp>)\n",
       "       48    0.000    0.000    0.012    0.000 format.py:1128(_format_strings)\n",
       "        4    0.000    0.000    0.001    0.000 csvs.py:30(__init__)\n",
       "      102    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "       48    0.000    0.000    0.000    0.000 format.py:992(__init__)\n",
       "       55    0.000    0.000    0.000    0.000 merge.py:1011(_validate_specification)\n",
       "       51    0.000    0.000    0.001    0.000 base.py:116(_for_class)\n",
       "      294    0.000    0.000    0.000    0.000 binaryTree.py:56(getRootVal)\n",
       "        8    0.000    0.000    0.004    0.000 generic.py:3155(_slice)\n",
       "       20    0.000    0.000    0.001    0.000 blocks.py:1982(to_native_types)\n",
       "      127    0.000    0.000    0.000    0.000 protocol.py:297(__getattr__)\n",
       "       25    0.000    0.000    0.007    0.000 result.py:1195(fetchall)\n",
       "      102    0.000    0.000    0.000    0.000 __init__.py:1619(isEnabledFor)\n",
       "       18    0.000    0.000    0.003    0.000 api.py:154(_unique_indices)\n",
       "       16    0.000    0.000    0.000    0.000 blocks.py:335(set)\n",
       "      118    0.000    0.000    0.000    0.000 cursors.py:106(nextset)\n",
       "        4    0.000    0.000    0.017    0.004 csvs.py:130(save)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:597(astype_nansafe)\n",
       "       19    0.000    0.000    0.003    0.000 format.py:307(adjoin)\n",
       "      578    0.000    0.000    0.000    0.000 arrayprint.py:1154(__call__)\n",
       "       24    0.000    0.000    0.004    0.000 generic.py:8282(rank)\n",
       "      218    0.000    0.000    0.000    0.000 base.py:2249(_validate_sort_keyword)\n",
       "       25    0.000    0.000    0.000    0.000 schema.py:4027(_bind_to)\n",
       "       50    0.000    0.000    0.009    0.000 base.py:987(close)\n",
       "        4    0.000    0.000    0.007    0.002 frame.py:4695(sort_values)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:1553(_binify)\n",
       "        5    0.000    0.000    0.002    0.000 series.py:3466(apply)\n",
       "       50    0.000    0.000    0.000    0.000 impl.py:102(_do_return_conn)\n",
       "       57    0.000    0.000    0.632    0.011 default.py:551(do_execute)\n",
       "        4    0.000    0.000    0.046    0.012 format.py:582(to_string)\n",
       "       25    0.000    0.000    0.624    0.025 base.py:2149(execute)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:3752(_try_convert_to_int_index)\n",
       "       55    0.000    0.000    0.000    0.000 concat.py:503(<listcomp>)\n",
       "       25    0.000    0.000    0.000    0.000 compat.py:123(reraise)\n",
       "       14    0.000    0.000    0.000    0.000 <ipython-input-21-d71652308ba2>:2(partly_unordered_permutations)\n",
       "       25    0.000    0.000    0.008    0.000 construction.py:484(_convert_object_array)\n",
       "       51    0.000    0.000    0.000    0.000 log.py:59(_should_log_info)\n",
       "      111    0.000    0.000    0.000    0.000 default.py:1051(get_result_processor)\n",
       "     14/3    0.000    0.000    0.000    0.000 sre_compile.py:71(_compile)\n",
       "        2    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "       55    0.000    0.000    0.000    0.000 {built-in method numpy.can_cast}\n",
       "       16    0.000    0.000    0.001    0.000 dtypes.py:485(validate_categories)\n",
       "        8    0.000    0.000    0.021    0.003 sorting.py:366(compress_group_index)\n",
       "       46    0.000    0.000    0.000    0.000 blocks.py:3183(_safe_reshape)\n",
       "       29    0.000    0.000    0.001    0.000 default.py:1092(get_result_proxy)\n",
       "        4    0.000    0.000    0.003    0.001 <frozen importlib._bootstrap_external>:793(get_code)\n",
       "       46    0.000    0.000    0.004    0.000 series.py:388(_update_inplace)\n",
       "        1    0.000    0.000    0.000    0.000 stringprep.py:6(<module>)\n",
       "       46    0.000    0.000    0.002    0.000 arrayprint.py:707(_formatArray)\n",
       "       80    0.000    0.000    0.000    0.000 managers.py:1552(formatting_values)\n",
       "       50    0.000    0.000    0.000    0.000 base.py:261(__init__)\n",
       "        4    0.000    0.000    0.019    0.005 generic.py:2882(to_csv)\n",
       "      128    0.000    0.000    0.000    0.000 {method 'add' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "      220    0.000    0.000    0.000    0.000 merge.py:800(<lambda>)\n",
       "       34    0.000    0.000    0.000    0.000 cursors.py:341(_do_get_result)\n",
       "        2    0.000    0.000    0.003    0.002 linecache.py:82(updatecache)\n",
       "       79    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
       "      211    0.000    0.000    0.000    0.000 indexing.py:937(_convert_for_reindex)\n",
       "       29    0.000    0.000    0.005    0.000 result.py:869(_soft_close)\n",
       "        4    0.000    0.000    0.000    0.000 csvs.py:191(_save_header)\n",
       "       59    0.000    0.000    0.000    0.000 cursors.py:51(close)\n",
       "       25    0.000    0.000    0.000    0.000 _collections.py:151(union)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:169(_clone)\n",
       "        8    0.000    0.000    0.001    0.000 stats.py:256(gmean)\n",
       "        4    0.000    0.000    0.047    0.012 frame.py:614(__unicode__)\n",
       "       88    0.000    0.000    0.000    0.000 format.py:298(__init__)\n",
       "       25    0.000    0.000    0.008    0.000 construction.py:501(<listcomp>)\n",
       "       54    0.000    0.000    0.000    0.000 base.py:1327(_safe_close_cursor)\n",
       "       50    0.000    0.000    0.000    0.000 base.py:949(cursor)\n",
       "       15    0.000    0.000    0.000    0.000 parse.py:409(urlsplit)\n",
       "        8    0.000    0.000    0.002    0.000 generic.py:5457(dtypes)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'writerow' of '_csv.writer' objects}\n",
       "      270    0.000    0.000    0.000    0.000 cursors.py:71(_get_db)\n",
       "       24    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "       32    0.000    0.000    0.001    0.000 accessor.py:167(__get__)\n",
       "       32    0.000    0.000    0.087    0.003 strings.py:2723(strip)\n",
       "        8    0.000    0.000    0.001    0.000 blocks.py:730(to_native_types)\n",
       "       27    0.000    0.000    0.000    0.000 compiler.py:3425(_escape_identifier)\n",
       "       29    0.000    0.000    0.001    0.000 result.py:334(_merge_cursor_description)\n",
       "       29    0.000    0.000    0.002    0.000 result.py:1178(process_rows)\n",
       "      294    0.000    0.000    0.000    0.000 timeout.py:56(stop)\n",
       "       25    0.000    0.000    0.000    0.000 inference.py:381(is_dict_like)\n",
       "        8    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_object_object}\n",
       "        8    0.000    0.000    0.001    0.000 base.py:998(_format_with_header)\n",
       "       25    0.000    0.000    0.000    0.000 compat.py:378(raise_from_cause)\n",
       "      380    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
       "       36    0.000    0.000    0.000    0.000 base.py:2254(union)\n",
       "      202    0.000    0.000    0.000    0.000 range.py:165(_validate_dtype)\n",
       "       25    0.000    0.000    0.016    0.001 base.py:1591(run_callable)\n",
       "       50    0.000    0.000    0.027    0.001 base.py:2259(_wrap_pool_connect)\n",
       "      212    0.000    0.000    0.000    0.000 fromnumeric.py:2847(ndim)\n",
       "       96    0.000    0.000    0.000    0.000 base.py:143(__setattr__)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:381(__init__)\n",
       "       24    0.000    0.000    0.000    0.000 connections.py:469(escape_string)\n",
       "       50    0.000    0.000    0.000    0.000 base.py:715(__init__)\n",
       "       13    0.000    0.000    0.008    0.001 managers.py:736(as_array)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:769(<listcomp>)\n",
       "      110    0.000    0.000    0.000    0.000 merge.py:1742(validate_operand)\n",
       "       25    0.000    0.000    0.004    0.000 base.py:865(_autorollback)\n",
       "      110    0.000    0.000    0.000    0.000 concat.py:523(_maybe_check_integrity)\n",
       "       25    0.000    0.000    0.000    0.000 sql.py:74(_convert_params)\n",
       "       50    0.000    0.000    0.001    0.000 base.py:366(_return_conn)\n",
       "       84    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "       46    0.000    0.000    0.000    0.000 arrayprint.py:365(<lambda>)\n",
       "       25    0.000    0.000    0.624    0.025 sql.py:988(execute)\n",
       "       25    0.000    0.000    0.000    0.000 exc.py:24(__init__)\n",
       "       29    0.000    0.000    0.001    0.000 default.py:1108(_setup_crud_result_proxy)\n",
       "       36    0.000    0.000    0.000    0.000 apipkg.py:133(__makeattr)\n",
       "       44    0.000    0.000    0.001    0.000 apply.py:325(<genexpr>)\n",
       "       15    0.000    0.000    0.000    0.000 parse.py:361(urlparse)\n",
       "       56    0.000    0.000    0.001    0.000 base.py:4071(identical)\n",
       "       50    0.000    0.000    0.000    0.000 queue.py:195(_full)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:2057(<listcomp>)\n",
       "       25    0.000    0.000    0.000    0.000 connections.py:448(escape)\n",
       "      128    0.000    0.000    0.000    0.000 protocol.py:77(read_all)\n",
       "        4    0.000    0.000    0.005    0.001 csvs.py:272(_save)\n",
       "       46    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
       "        4    0.000    0.000    0.003    0.001 warnings.py:35(_formatwarnmsg_impl)\n",
       "       51    0.000    0.000    0.001    0.000 base.py:119(_for_instance)\n",
       "       46    0.000    0.000    0.000    0.000 arrayprint.py:1149(__init__)\n",
       "       19    0.000    0.000    0.001    0.000 printing.py:36(<listcomp>)\n",
       "       55    0.000    0.000    0.001    0.000 base.py:1580(is_monotonic)\n",
       "        4    0.000    0.000    0.100    0.025 frame.py:6310(apply)\n",
       "       21    0.000    0.000    0.001    0.000 managers.py:530(astype)\n",
       "       80    0.000    0.000    0.000    0.000 series.py:483(_formatting_values)\n",
       "       12    0.000    0.000    0.075    0.006 <ipython-input-5-5ceb2d72714e>:7(system_semtype_check)\n",
       "        4    0.000    0.000    0.002    0.000 ops.py:1817(wrapper)\n",
       "        8    0.000    0.000    0.003    0.000 managers.py:684(get_slice)\n",
       "        5    0.000    0.000    0.001    0.000 series.py:3600(_reduce)\n",
       "       25    0.000    0.000    0.000    0.000 cursors.py:299(fetchall)\n",
       "       40    0.000    0.000    0.000    0.000 attr.py:227(__init__)\n",
       "      188    0.000    0.000    0.000    0.000 weakref.py:435(__contains__)\n",
       "        5    0.000    0.000    0.000    0.000 cast.py:1072(find_common_type)\n",
       "       15    0.000    0.000    0.022    0.001 algorithms.py:407(<lambda>)\n",
       "       24    0.000    0.000    0.002    0.000 algorithms.py:835(rank)\n",
       "       85    0.000    0.000    0.000    0.000 format.py:943(<lambda>)\n",
       "        4    0.000    0.000    0.010    0.002 common.py:314(_get_handle)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _csv.writer}\n",
       "     20/3    0.000    0.000    0.001    0.000 visitors.py:85(_compiler_dispatch)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:479(_still_open_and_connection_is_valid)\n",
       "       49    0.000    0.000    0.000    0.000 queue.py:203(_get)\n",
       "       26    0.000    0.000    0.000    0.000 pymysql.py:76(_extract_error_code)\n",
       "       69    0.000    0.000    0.000    0.000 common.py:1752(is_complex_dtype)\n",
       "       55    0.000    0.000    0.000    0.000 concat.py:496(<listcomp>)\n",
       "       32    0.000    0.000    0.001    0.000 format.py:1138(_format_strings)\n",
       "       27    0.000    0.000    0.000    0.000 compiler.py:3464(quote_identifier)\n",
       "       24    0.000    0.000    0.001    0.000 dtypes.py:328(_finalize)\n",
       "        4    0.000    0.000    0.000    0.000 sorting.py:339(get_group_index_sorter)\n",
       "       32    0.000    0.000    0.081    0.003 strings.py:57(_na_map)\n",
       "       24    0.000    0.000    0.000    0.000 generic.py:277(_construct_axes_dict)\n",
       "       90    0.000    0.000    0.000    0.000 sre_parse.py:233(__next)\n",
       "        2    0.000    0.000    0.002    0.001 tokenize.py:443(open)\n",
       "       18    0.000    0.000    0.000    0.000 {pandas._libs.lib.fast_unique_multiple_list}\n",
       "       36    0.000    0.000    0.001    0.000 api.py:168(conv)\n",
       "       29    0.000    0.000    0.000    0.000 base.py:1174(should_autocommit_text)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:87(<dictcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1404(_fill_cache)\n",
       "       21    0.000    0.000    0.001    0.000 blocks.py:532(astype)\n",
       "      121    0.000    0.000    0.000    0.000 managers.py:1513(index)\n",
       "       50    0.000    0.000    0.000    0.000 queue.py:199(_put)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:2054(_quote_free_identifiers)\n",
       "        4    0.000    0.000    0.099    0.025 apply.py:109(get_result)\n",
       "       32    0.000    0.000    0.081    0.003 strings.py:1504(str_strip)\n",
       "        4    0.000    0.000    0.001    0.000 format.py:801(_get_formatted_index)\n",
       "        1    0.000    0.000    0.008    0.008 connections.py:564(connect)\n",
       "       50    0.000    0.000    0.000    0.000 attr.py:255(__call__)\n",
       "        6    0.000    0.000    0.001    0.000 re.py:271(_compile)\n",
       "       46    0.000    0.000    0.000    0.000 arrayprint.py:74(<dictcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_int8}\n",
       "        8    0.000    0.000    0.004    0.000 indexing.py:2170(_get_slice_axis)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:648(<listcomp>)\n",
       "       25    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
       "        8    0.000    0.000    0.001    0.000 series.py:3831(fillna)\n",
       "        4    0.000    0.000    0.075    0.019 <ipython-input-21-d71652308ba2>:16(get_valid_systems)\n",
       "     17/6    0.000    0.000    0.000    0.000 sre_parse.py:174(getwidth)\n",
       "        4    0.000    0.000    0.000    0.000 sorting.py:387(_reorder_by_uniques)\n",
       "      116    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
       "      134    0.000    0.000    0.000    0.000 sre_parse.py:164(__getitem__)\n",
       "       13    0.000    0.000    0.009    0.001 generic.py:5250(values)\n",
       "        1    0.000    0.000    0.008    0.008 connections.py:183(__init__)\n",
       "       46    0.000    0.000    0.000    0.000 cursors.py:122(<genexpr>)\n",
       "     14/4    0.000    0.000    0.000    0.000 langhelpers.py:273(get_cls_kwargs)\n",
       "       10    0.000    0.000    0.000    0.000 elements.py:717(__getattr__)\n",
       "       50    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "      165    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {pandas._libs.algos.groupsort_indexer}\n",
       "        5    0.000    0.000    0.000    0.000 nanops.py:203(_get_values)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:1010(<listcomp>)\n",
       "      160    0.000    0.000    0.000    0.000 format.py:535(<genexpr>)\n",
       "       27    0.000    0.000    0.000    0.000 common.py:94(_expand_user)\n",
       "       46    0.000    0.000    0.000    0.000 series.py:348(_can_hold_na)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:786(_request_authentication)\n",
       "       59    0.000    0.000    0.000    0.000 cursors.py:332(_clear_result)\n",
       "       50    0.000    0.000    0.000    0.000 base.py:364(invalidated)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:500(__init__)\n",
       "       75    0.000    0.000    0.000    0.000 base.py:958(__getattr__)\n",
       "       29    0.000    0.000    0.000    0.000 result.py:266(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:271(cache_from_source)\n",
       "        1    0.000    0.000    0.007    0.007 socket.py:691(create_connection)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method numpy.where}\n",
       "       24    0.000    0.000    0.000    0.000 dtypes.py:465(validate_ordered)\n",
       "        8    0.000    0.000    0.000    0.000 base.py:1050(_format_native_types)\n",
       "       80    0.000    0.000    0.000    0.000 blocks.py:171(formatting_values)\n",
       "       40    0.000    0.000    0.000    0.000 attr.py:160(_assign_cls_collection)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:1999(visit_select)\n",
       "      106    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method now}\n",
       "       16    0.000    0.000    0.000    0.000 categorical.py:668(_get_codes)\n",
       "        5    0.000    0.000    0.001    0.000 generic.py:11018(logical_func)\n",
       "        8    0.000    0.000    0.001    0.000 managers.py:225(get_dtypes)\n",
       "       25    0.000    0.000    0.000    0.000 langhelpers.py:59(__enter__)\n",
       "       50    0.000    0.000    0.000    0.000 queue.py:191(_empty)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\n",
       "      4/3    0.000    0.000    0.005    0.002 <frozen importlib._bootstrap>:663(_load_unlocked)\n",
       "        8    0.000    0.000    0.000    0.000 dtypes.py:244(_from_values_or_dtype)\n",
       "        8    0.000    0.000    0.001    0.000 ops.py:1815(<lambda>)\n",
       "       48    0.000    0.000    0.000    0.000 format.py:1004(_value_formatter)\n",
       "       24    0.000    0.000    0.000    0.000 connections.py:462(literal)\n",
       "      125    0.000    0.000    0.000    0.000 base.py:155(_root)\n",
       "      102    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "        4    0.000    0.000    0.001    0.000 sorting.py:177(indexer_from_factorized)\n",
       "        1    0.000    0.000    0.319    0.319 parsers.py:1993(read)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:780(visit_label)\n",
       "       25    0.000    0.000    0.000    0.000 result.py:1161(_fetchall_impl)\n",
       "        1    0.000    0.000    0.035    0.035 <ipython-input-19-90de0edd371d>:89(get_docs)\n",
       "        8    0.000    0.000    0.000    0.000 dtypes.py:521(update_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:431(_chk_truncate)\n",
       "       34    0.000    0.000    0.000    0.000 cursors.py:355(_show_warnings)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:1761(_label_select_column)\n",
       "        3    0.000    0.000    0.002    0.001 default.py:342(check_unicode)\n",
       "       90    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_float64}\n",
       "        5    0.000    0.000    0.000    0.000 common.py:163(is_s3_url)\n",
       "        1    0.000    0.000    0.379    0.379 parsers.py:536(parser_f)\n",
       "       59    0.000    0.000    0.000    0.000 connections.py:1069(__del__)\n",
       "       50    0.000    0.000    0.000    0.000 base.py:355(closed)\n",
       "        1    0.000    0.000    0.004    0.004 mysqldb.py:136(_check_unicode_returns)\n",
       "       46    0.000    0.000    0.000    0.000 base.py:697(shape)\n",
       "       24    0.000    0.000    0.000    0.000 generic.py:279(<dictcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 indexing.py:264(_convert_slice_indexer)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:179(get_filepath_or_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:973(_get_server_information)\n",
       "        3    0.000    0.000    0.001    0.000 sre_compile.py:759(compile)\n",
       "      110    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "        4    0.000    0.000    0.000    0.000 console.py:47(get_console_size)\n",
       "        4    0.000    0.000    0.000    0.000 console.py:149(in_ipython_frontend)\n",
       "        1    0.000    0.000    0.373    0.373 parsers.py:1137(read)\n",
       "       24    0.000    0.000    0.000    0.000 converters.py:68(_escape_unicode)\n",
       "        8    0.000    0.000    0.000    0.000 type_api.py:505(_dialect_info)\n",
       "       14    0.000    0.000    0.000    0.000 codecs.py:319(decode)\n",
       "        2    0.000    0.000    0.000    0.000 sre_compile.py:413(<listcomp>)\n",
       "      6/3    0.000    0.000    0.000    0.000 sre_parse.py:417(_parse_sub)\n",
       "       30    0.000    0.000    0.000    0.000 parse.py:109(_coerce_args)\n",
       "       84    0.000    0.000    0.000    0.000 _methods.py:26(_amax)\n",
       "       40    0.000    0.000    0.000    0.000 ops.py:66(_maybe_match_name)\n",
       "        8    0.000    0.000    0.001    0.000 base.py:1024(to_native_types)\n",
       "       55    0.000    0.000    0.000    0.000 base.py:3072(_can_reindex)\n",
       "        8    0.000    0.000    0.000    0.000 construction.py:509(sanitize_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1352(__init__)\n",
       "       25    0.000    0.000    0.000    0.000 protocol.py:94(rewind)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2687(__init__)\n",
       "       23    0.000    0.000    0.000    0.000 default.py:894(<listcomp>)\n",
       "        4    0.000    0.000    0.006    0.002 apply.py:336(wrap_results_for_axis)\n",
       "       46    0.000    0.000    0.000    0.000 weakref.py:408(__setitem__)\n",
       "       24    0.000    0.000    0.001    0.000 dtypes.py:225(__init__)\n",
       "       18    0.000    0.000    0.001    0.000 api.py:174(<listcomp>)\n",
       "       16    0.000    0.000    0.000    0.000 blocks.py:2011(should_store)\n",
       "       46    0.000    0.000    0.000    0.000 managers.py:1568(_can_hold_na)\n",
       "        9    0.000    0.000    0.000    0.000 sqltypes.py:140(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 default.py:331(_check_unicode_returns)\n",
       "       30    0.000    0.000    0.000    0.000 default.py:943(no_parameters)\n",
       "       23    0.000    0.000    0.000    0.000 <ipython-input-4-8a49c4ff8f4c>:42(get_system_type)\n",
       "        4    0.000    0.000    0.000    0.000 apply.py:16(frame_apply)\n",
       "       49    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
       "       19    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "        8    0.000    0.000    0.000    0.000 base.py:2897(_convert_slice_indexer)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:260(_infer_compression)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1926(close)\n",
       "       25    0.000    0.000    0.000    0.000 langhelpers.py:62(__exit__)\n",
       "       25    0.000    0.000    0.000    0.000 elements.py:4322(_string_or_unprintable)\n",
       "        1    0.000    0.000    0.016    0.016 base.py:622(__connect)\n",
       "        5    0.000    0.000    0.000    0.000 types.py:69(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:307(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:523(_compile_bytecode)\n",
       "      4/3    0.000    0.000    0.005    0.002 <frozen importlib._bootstrap_external>:722(exec_module)\n",
       "       75    0.000    0.000    0.000    0.000 sre_parse.py:254(get)\n",
       "       50    0.000    0.000    0.000    0.000 inference.py:406(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 _validators.py:325(validate_fillna_kwargs)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:5393(_trim_front)\n",
       "        8    0.000    0.000    0.000    0.000 managers.py:627(is_view)\n",
       "       25    0.000    0.000    0.004    0.000 base.py:180(__exit__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2157(_setup_select_stack)\n",
       "       29    0.000    0.000    0.000    0.000 result.py:263(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1278(visit_typeclause)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _operator.and_}\n",
       "        4    0.000    0.000    0.003    0.001 warnings.py:20(_showwarnmsg_impl)\n",
       "        8    0.000    0.000    0.001    0.000 base.py:983(format)\n",
       "       36    0.000    0.000    0.000    0.000 base.py:2238(_get_reconciled_name_object)\n",
       "        8    0.000    0.000    0.000    0.000 managers.py:226(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2395(__init__)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:709(in_transaction)\n",
       "        4    0.000    0.000    0.000    0.000 apply.py:36(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:1(<module>)\n",
       "       32    0.000    0.000    0.000    0.000 csvs.py:112(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 csvs.py:4(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
       "       74    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
       "       62    0.000    0.000    0.000    0.000 sre_parse.py:172(append)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:221(makefile)\n",
       "        8    0.000    0.000    0.000    0.000 config.py:170(get_default_val)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:76(_is_url)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:890(_process_auth)\n",
       "        4    0.000    0.000    0.000    0.000 langhelpers.py:1136(constructor_copy)\n",
       "        9    0.000    0.000    0.000    0.000 <string>:1(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 compiler.py:3477(_requires_quotes)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
       "        3    0.000    0.000    0.000    0.000 sre_compile.py:536(_compile_info)\n",
       "        2    0.000    0.000    0.001    0.001 tokenize.py:350(detect_encoding)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:900(_get_options_with_defaults)\n",
       "       51    0.000    0.000    0.000    0.000 _collections.py:145(__init__)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:875(is_valid)\n",
       "       99    0.000    0.000    0.000    0.000 {method '_is_owned' of '_thread.RLock' objects}\n",
       "        4    0.000    0.000    0.000    0.000 warnings.py:419(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 sre_parse.py:919(parse)\n",
       "        4    0.000    0.000    0.003    0.001 linecache.py:37(getlines)\n",
       "        8    0.000    0.000    0.000    0.000 managers.py:524(fillna)\n",
       "       25    0.000    0.000    0.000    0.000 sql.py:490(_engine_builder)\n",
       "       25    0.000    0.000    0.000    0.000 langhelpers.py:56(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:3066(__init__)\n",
       "       28    0.000    0.000    0.000    0.000 elements.py:4139(__new__)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2959(_froms)\n",
       "       42    0.000    0.000    0.000    0.000 base.py:105(_event_descriptors)\n",
       "       31    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:438(_classify_pyc)\n",
       "       13    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
       "       21    0.000    0.000    0.000    0.000 inspect.py:72(isclass)\n",
       "        4    0.000    0.000    0.047    0.012 base.py:48(__str__)\n",
       "       24    0.000    0.000    0.000    0.000 base.py:4698(_validate_indexer)\n",
       "        4    0.000    0.000    0.000    0.000 frame.py:606(_info_repr)\n",
       "        4    0.000    0.000    0.000    0.000 generic.py:637(_set_axis)\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:813(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:956(_clean_options)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1180(_is_potential_multi_index)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:1440(adapt_type)\n",
       "       82    0.000    0.000    0.000    0.000 base.py:370(connection)\n",
       "       25    0.000    0.000    0.000    0.000 default.py:477(set_connection_execution_options)\n",
       "       25    0.000    0.000    0.000    0.000 default.py:1089(handle_dbapi_exception)\n",
       "       10    0.000    0.000    0.000    0.000 enum.py:284(__call__)\n",
       "        3    0.000    0.000    0.000    0.000 enum.py:836(__and__)\n",
       "       32    0.000    0.000    0.000    0.000 base.py:138(_freeze)\n",
       "        4    0.000    0.000    0.001    0.000 frame.py:4710(<listcomp>)\n",
       "       58    0.000    0.000    0.000    0.000 managers.py:1578(_consolidate_inplace)\n",
       "        8    0.000    0.000    0.000    0.000 format.py:781(has_index_names)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:544(UnicodeWriter)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1502(_maybe_dedup_names)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:186(scramble_caching_sha2)\n",
       "       34    0.000    0.000    0.000    0.000 cursors.py:127(<dictcomp>)\n",
       "       34    0.000    0.000    0.000    0.000 protocol.py:208(is_load_local_packet)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3831(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 type_api.py:440(dialect_impl)\n",
       "        3    0.000    0.000    0.000    0.000 <string>:1(select)\n",
       "       23    0.000    0.000    0.000    0.000 <ipython-input-4-8a49c4ff8f4c>:14(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 apply.py:323(series_generator)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'split' of 're.Pattern' objects}\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:51(_r_long)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:369(_get_cached)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1351(_get_spec)\n",
       "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1433(<setcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 sre_compile.py:249(_compile_charset)\n",
       "        1    0.000    0.000    0.006    0.006 socket.py:731(getaddrinfo)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'setsockopt' of '_socket.socket' objects}\n",
       "        5    0.000    0.000    0.000    0.000 _config.py:135(_default)\n",
       "       97    0.000    0.000    0.000    0.000 base.py:5398(<genexpr>)\n",
       "       25    0.000    0.000    0.000    0.000 sql.py:85(_process_parse_dates_argument)\n",
       "        7    0.000    0.000    0.000    0.000 langhelpers.py:253(_inspect_func_args)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2340(literal_column)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2988(_get_display_froms)\n",
       "        1    0.000    0.000    0.005    0.005 default.py:286(initialize)\n",
       "       25    0.000    0.000    0.000    0.000 base.py:177(__enter__)\n",
       "        6    0.000    0.000    0.000    0.000 compiler.py:3529(quote)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1316(visit_cast)\n",
       "        3    0.000    0.000    0.000    0.000 types.py:689(_adapt_string_for_cast)\n",
       "        1    0.000    0.000    0.001    0.001 idna.py:3(<module>)\n",
       "       12    0.000    0.000    0.000    0.000 apply.py:89(columns)\n",
       "        4    0.000    0.000    0.006    0.002 apply.py:302(wrap_results)\n",
       "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:62(_path_split)\n",
       "        2    0.000    0.000    0.000    0.000 sre_compile.py:411(_mk_bitmap)\n",
       "        8    0.000    0.000    0.000    0.000 cast.py:552(coerce_indexer_dtype)\n",
       "        5    0.000    0.000    0.000    0.000 nanops.py:337(nanany)\n",
       "        8    0.000    0.000    0.000    0.000 base.py:1806(hasnans)\n",
       "       21    0.000    0.000    0.000    0.000 blocks.py:146(is_categorical_astype)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:816(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:1120(_make_engine)\n",
       "        1    0.000    0.000    0.008    0.008 __init__.py:88(Connect)\n",
       "       34    0.000    0.000    0.000    0.000 cursors.py:76(_check_executed)\n",
       "        3    0.000    0.000    0.000    0.000 langhelpers.py:897(expire_instance)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:274(__init__)\n",
       "      9/3    0.000    0.000    0.001    0.000 compiler.py:349(process)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2186(_compose_select_body)\n",
       "       25    0.000    0.000    0.000    0.000 result.py:760(keys)\n",
       "       29    0.000    0.000    0.000    0.000 result.py:864(_cursor_description)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:1279(first)\n",
       "        4    0.000    0.000    0.008    0.002 apply.py:97(values)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:318(__exit__)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:576(module_from_spec)\n",
       "        1    0.000    0.000    0.003    0.003 __init__.py:71(search_function)\n",
       "        5    0.000    0.000    0.000    0.000 os.py:673(__getitem__)\n",
       "        3    0.000    0.000    0.001    0.000 sre_compile.py:598(_code)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:563(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 cast.py:1260(maybe_cast_to_integer_array)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:1447(_align_method_SERIES)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:5399(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 generic.py:3110(_is_view)\n",
       "        8    0.000    0.000    0.004    0.000 indexing.py:148(_slice)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:364(fillna)\n",
       "       41    0.000    0.000    0.000    0.000 managers.py:1041(value_getitem)\n",
       "        5    0.000    0.000    0.000    0.000 managers.py:1868(_interleaved_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:271(_init_dict)\n",
       "        7    0.000    0.000    0.000    0.000 elements.py:705(comparator)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:864(anon_label)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3641(_columns_plus_names)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1747(_extend_string)\n",
       "        1    0.000    0.000    0.008    0.008 base.py:2347(initialize)\n",
       "        2    0.000    0.000    0.000    0.000 types.py:510(__init__)\n",
       "       18    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:471(_validate_timestamp_pyc)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:951(path_stats)\n",
       "        5    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "        4    0.000    0.000    0.003    0.001 warnings.py:96(_showwarnmsg)\n",
       "        4    0.000    0.000    0.001    0.000 re.py:180(search)\n",
       "       10    0.000    0.000    0.000    0.000 enum.py:526(__new__)\n",
       "        3    0.000    0.000    0.000    0.000 sre_parse.py:224(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:225(_import_one)\n",
       "       19    0.000    0.000    0.000    0.000 cast.py:1112(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 categorical.py:394(categories)\n",
       "        8    0.000    0.000    0.000    0.000 generic.py:1904(__array__)\n",
       "        8    0.000    0.000    0.000    0.000 generic.py:5337(get_values)\n",
       "        8    0.000    0.000    0.000    0.000 format.py:789(show_row_idx_names)\n",
       "       12    0.000    0.000    0.000    0.000 format.py:1434(_has_names)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:34(scramble_native_password)\n",
       "        9    0.000    0.000    0.000    0.000 cursors.py:280(fetchone)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:361(__init__)\n",
       "       21    0.000    0.000    0.000    0.000 langhelpers.py:1145(<genexpr>)\n",
       "        1    0.000    0.000    0.008    0.008 strategies.py:194(first_connect)\n",
       "        3    0.000    0.000    0.001    0.000 base.py:1287(_cursor_execute)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:834(visit_column)\n",
       "        4    0.000    0.000    0.000    0.000 default.py:409(type_descriptor)\n",
       "       17    0.000    0.000    0.000    0.000 base.py:1753(attr)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2172(get_isolation_level)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2184(_get_server_version_info)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2296(_compat_first)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:300(getregentry)\n",
       "        4    0.000    0.000    0.001    0.000 apply.py:101(dtypes)\n",
       "        4    0.000    0.000    0.000    0.000 apply.py:105(agg_axis)\n",
       "       25    0.000    0.000    0.000    0.000 {method 'with_traceback' of 'BaseException' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:84(_path_is_mode_type)\n",
       "        4    0.000    0.000    0.000    0.000 codecs.py:186(__init__)\n",
       "      4/3    0.000    0.000    0.000    0.000 sre_compile.py:461(_get_literal_prefix)\n",
       "       14    0.000    0.000    0.000    0.000 sre_parse.py:111(__init__)\n",
       "       31    0.000    0.000    0.000    0.000 sre_parse.py:249(match)\n",
       "       17    0.000    0.000    0.000    0.000 sre_parse.py:286(tell)\n",
       "        4    0.000    0.000    0.003    0.001 linecache.py:15(getline)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _hashlib.new}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'timestamp' of 'datetime.datetime' objects}\n",
       "       40    0.000    0.000    0.000    0.000 dtypes.py:555(categories)\n",
       "       32    0.000    0.000    0.000    0.000 dtypes.py:562(ordered)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method pandas._libs.internals.slice_len}\n",
       "       20    0.000    0.000    0.000    0.000 managers.py:1045(value_getitem)\n",
       "        5    0.000    0.000    0.000    0.000 managers.py:1884(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:795(show_col_idx_names)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1936(_set_noconvert_columns)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:304(<dictcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:637(write_packet)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:48(_my_crypt)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3944(_set_table)\n",
       "        7    0.000    0.000    0.000    0.000 type_api.py:60(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:524(adapt)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1542(_truncated_identifier)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1564(_process_anon)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1954(visit_CHAR)\n",
       "       19    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "       59    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:94(__new__)\n",
       "        5    0.000    0.000    0.000    0.000 os.py:751(encode)\n",
       "        8    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 sre_compile.py:416(_bytes_to_codes)\n",
       "        2    0.000    0.000    0.000    0.000 version.py:307(parse)\n",
       "        4    0.000    0.000    0.000    0.000 console.py:90(in_interactive_session)\n",
       "       19    0.000    0.000    0.000    0.000 cast.py:1100(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:1787(na_op)\n",
       "        8    0.000    0.000    0.000    0.000 range.py:184(_get_data_as_items)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3195(_process_date_conversion)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:305(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:54(collate)\n",
       "        3    0.000    0.000    0.001    0.000 elements.py:464(_compiler)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4299(apply_map)\n",
       "       10    0.000    0.000    0.000    0.000 type_api.py:1430(to_instance)\n",
       "        1    0.000    0.000    0.008    0.008 attr.py:279(exec_once)\n",
       "        1    0.000    0.000    0.008    0.008 strategies.py:106(connect)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1261(visit_binary)\n",
       "        1    0.000    0.000    0.001    0.001 base.py:2750(_detect_casing)\n",
       "        1    0.000    0.000    0.002    0.002 base.py:2794(_detect_sql_mode)\n",
       "        4    0.000    0.000    0.000    0.000 apply.py:332(result_columns)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:311(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:994(_gcd_import)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:401(_check_name_wrapper)\n",
       "        8    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
       "        3    0.000    0.000    0.000    0.000 sre_compile.py:492(_get_charset_prefix)\n",
       "        3    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
       "       25    0.000    0.000    0.000    0.000 sre_parse.py:160(__len__)\n",
       "        2    0.000    0.000    0.001    0.001 tokenize.py:374(read_or_stop)\n",
       "        2    0.000    0.000    0.000    0.000 tokenize.py:380(find_cookie)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:412(_real_close)\n",
       "        1    0.000    0.000    0.000    0.000 {function socket.close at 0x107153488}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'put' of 'numpy.ndarray' objects}\n",
       "       10    0.000    0.000    0.000    0.000 cast.py:1105(<genexpr>)\n",
       "        5    0.000    0.000    0.000    0.000 managers.py:604(is_mixed_type)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:171(is_gcs_url)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:3735(reindex)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:4209(isnull)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:925(__getattr__)\n",
       "        3    0.000    0.000    0.001    0.000 elements.py:399(compile)\n",
       "        4    0.000    0.000    0.000    0.000 elements.py:4544(_literal_as_binds)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:94(__getattr__)\n",
       "        1    0.000    0.000    0.008    0.008 default.py:452(connect)\n",
       "        1    0.000    0.000    0.002    0.002 default.py:379(<setcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:1146(_fetchone_impl)\n",
       "        3    0.000    0.000    0.000    0.000 types.py:674(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 mysqldb.py:214(_detect_charset)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:93(_path_isfile)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(normalize_encoding)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:884(__init__)\n",
       "        4    0.000    0.000    0.003    0.001 warnings.py:117(_formatwarnmsg)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:358(remove)\n",
       "        1    0.000    0.000    0.000    0.000 weakref.py:356(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 sre_compile.py:595(isstring)\n",
       "        2    0.000    0.000    0.000    0.000 sre_parse.py:408(_uniq)\n",
       "        3    0.000    0.000    0.000    0.000 sre_parse.py:903(fix_flags)\n",
       "        3    0.000    0.000    0.000    0.000 hashlib.py:139(__hash_new)\n",
       "        5    0.000    0.000    0.000    0.000 parse.py:394(_checknetloc)\n",
       "       15    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
       "        3    0.000    0.000    0.000    0.000 _config.py:130(_convert)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:212(_import_one_of)\n",
       "        1    0.000    0.000    0.000    0.000 hub.py:430(backend)\n",
       "       10    0.000    0.000    0.000    0.000 cast.py:1097(<genexpr>)\n",
       "       10    0.000    0.000    0.000    0.000 cast.py:1107(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 categorical.py:441(dtype)\n",
       "        5    0.000    0.000    0.000    0.000 nanops.py:270(_na_ok_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:785(has_column_names)\n",
       "        4    0.000    0.000    0.000    0.000 series.py:737(__array_prepare__)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:401(_send_autocommit_mode)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:946(_get_auth_plugin_handler)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:730(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:755(unique_list)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:39(<listcomp>)\n",
       "        1    0.000    0.000    0.008    0.008 langhelpers.py:1440(go)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:38(_from_objects)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:1271(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2455(_from_objects)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4184(__new__)\n",
       "        3    0.000    0.000    0.000    0.000 type_api.py:307(_has_column_expression)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:521(_gen_dialect_impl)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2120(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 sqltypes.py:411(__init__)\n",
       "        1    0.000    0.000    0.008    0.008 attr.py:291(__call__)\n",
       "        1    0.000    0.000    0.002    0.002 base.py:914(scalar)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1318(_generate_generic_binary)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:2082(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:3598(format_label)\n",
       "        1    0.000    0.000    0.016    0.016 base.py:425(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2809(_detect_ansiquotes)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:2906(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:34(FrameApply)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
       "        7    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method gc.get_referents}\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\n",
       "       16    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:403(cached)\n",
       "        2    0.000    0.000    0.000    0.000 codecs.py:309(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 sre_compile.py:65(_combine_flags)\n",
       "        4    0.000    0.000    0.000    0.000 sre_compile.py:423(_simple)\n",
       "       12    0.000    0.000    0.000    0.000 sre_parse.py:81(groups)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_sha256}\n",
       "        3    0.000    0.000    0.000    0.000 <ipython-input-3-01a4bf55ac48>:9(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:248(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:245(validate)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:227(itervalues)\n",
       "        2    0.000    0.000    0.000    0.000 version.py:312(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 config.py:578(_get_registered_option)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:1785(_isnan)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:1140(to_numpy)\n",
       "        4    0.000    0.000    0.000    0.000 frame.py:7600(_get_agg_axis)\n",
       "        4    0.000    0.000    0.000    0.000 generic.py:1818(__iter__)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:136(is_view)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:351(should_show_dimensions)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:347(_validate_integer)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:897(close)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:1530(_maybe_make_multi_index_columns)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1814(_do_date_conversions)\n",
       "        2    0.000    0.000    0.000    0.000 charset.py:43(by_name)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:74(_makefile)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:383(autocommit)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:396(__iter__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:733(__missing__)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:681(self_group)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4345(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4340(_select_iterables)\n",
       "        3    0.000    0.000    0.000    0.000 <string>:1(cast)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:410(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 impl.py:142(_inc_overflow)\n",
       "        2    0.000    0.000    0.000    0.000 result.py:1306(scalar)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1778(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2309(_get_default_schema_name)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2902(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:147(encode)\n",
       "        4    0.000    0.000    0.000    0.000 apply.py:328(result_index)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'split' of 'bytes' objects}\n",
       "       25    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "        2    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:109(import_module)\n",
       "        1    0.000    0.000    0.000    0.000 _collections_abc.py:367(__subclasshook__)\n",
       "        2    0.000    0.000    0.001    0.000 re.py:232(compile)\n",
       "        7    0.000    0.000    0.000    0.000 sre_compile.py:453(_get_iscased)\n",
       "        3    0.000    0.000    0.000    0.000 sre_parse.py:84(opengroup)\n",
       "        2    0.000    0.000    0.000    0.000 sre_parse.py:267(getuntil)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:295(_class_escape)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:221(_releaseLock)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:1605(getEffectiveLevel)\n",
       "       30    0.000    0.000    0.000    0.000 parse.py:98(_noop)\n",
       "        4    0.000    0.000    0.000    0.000 socket.py:97(_intenum_converter)\n",
       "        1    0.000    0.000    0.000    0.000 hub.py:426(loop_class)\n",
       "        1    0.000    0.000    0.000    0.000 hub.py:594(start_periodic_monitoring_thread)\n",
       "        2    0.000    0.000    0.000    0.000 version.py:302(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:331(_cmp)\n",
       "        5    0.000    0.000    0.000    0.000 function.py:40(__call__)\n",
       "        5    0.000    0.000    0.000    0.000 nanops.py:180(_get_fill_value)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:3867(_has_complex_internals)\n",
       "        6    0.000    0.000    0.000    0.000 parsers.py:1195(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1536(_make_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2064(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2066(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 converters.py:12(escape_item)\n",
       "        1    0.000    0.000    0.000    0.000 converters.py:47(escape_bool)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:11(int2byte)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:4(byte2int)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:142(read_string)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:1051(module)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:3098(_from_objects)\n",
       "        6    0.000    0.000    0.000    0.000 elements.py:3941(_get_table)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3950(_from_objects)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:270(_type_memos)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:352(__str__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:399(process)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:872(visit_collation)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:890(escape_literal_column)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:901(close)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1350(get_select_precolumns)\n",
       "        1    0.000    0.000    0.000    0.000 pymysql.py:51(supports_server_side_cursors)\n",
       "        2    0.000    0.000    0.000    0.000 <ipython-input-3-01a4bf55ac48>:14(corpus_config)\n",
       "        4    0.000    0.000    0.000    0.000 apply.py:93(index)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:317(FrameRowApply)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:356(FrameColumnApply)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'issuperset' of 'set' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'rsplit' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:424(has_location)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:929(_sanity_check)\n",
       "        3    0.000    0.000    0.000    0.000 sre_parse.py:96(closegroup)\n",
       "        2    0.000    0.000    0.000    0.000 sre_parse.py:101(checklookbehindgroup)\n",
       "        4    0.000    0.000    0.000    0.000 sre_parse.py:168(__setitem__)\n",
       "        2    0.000    0.000    0.000    0.000 sre_parse.py:343(_escape)\n",
       "        2    0.000    0.000    0.000    0.000 __init__.py:212(_acquireLock)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1361(debug)\n",
       "        4    0.000    0.000    0.000    0.000 interactiveshell.py:698(get_ipython)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:416(close)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:91(validate_bool)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:275(u)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(is_platform_windows)\n",
       "        4    0.000    0.000    0.000    0.000 ops.py:1832(<lambda>)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:4077(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:7083(isnull)\n",
       "        8    0.000    0.000    0.000    0.000 indexing.py:2700(need_slice)\n",
       "        9    0.000    0.000    0.000    0.000 managers.py:1572(is_consolidated)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:939(_check_file_or_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1162(_create_index)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1176(_is_index_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1274(_validate_usecols_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1329(_validate_parse_dates_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1423(_has_complex_date_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3157(_make_date_converter)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3278(_clean_na_values)\n",
       "        1    0.000    0.000    0.000    0.000 charset.py:18(encoding)\n",
       "        1    0.000    0.000    0.000    0.000 charset.py:40(by_id)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:101(lenenc_int)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:96(pack_int24)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:389(get_autocommit)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:964(character_set_name)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:60(get_all_data)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:759(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:1068(__getattr__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:751(_select_iterable)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:4062(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4559(_interpret_as_column_or_from)\n",
       "        1    0.000    0.000    0.000    0.000 operators.py:1376(is_comparison)\n",
       "        1    0.000    0.000    0.000    0.000 operators.py:1399(is_boolean)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3002(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3663(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:276(_memoized_attr__exec_once_mutex)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1168(_get_operator_dispatch)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1758(_add_to_result_map)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2080(<listcomp>)\n",
       "        1    0.000    0.000    0.016    0.016 base.py:296(_create_connection)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2367(_warn_for_known_db_issues)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2381(_is_mariadb)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2385(_is_mysql)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:2407(_supports_cast)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:146(Codec)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:292(StreamWriter)\n",
       "        1    0.000    0.000    0.000    0.000 csvs.py:28(CSVFormatter)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:719(create_module)\n",
       "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:909(get_filename)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method greenlet.getcurrent}\n",
       "        3    0.000    0.000    0.000    0.000 _config.py:109(validate_anything)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:51(__lt__)\n",
       "        1    0.000    0.000    0.000    0.000 inference.py:160(is_file_like)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:112(_validate_header_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:377(_validate_names)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:196(is_auth_switch_request)\n",
       "        5    0.000    0.000    0.000    0.000 type_api.py:269(result_processor)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:340(for_modify)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:419(type)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:708(default_from)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:3579(format_collation)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:218(IncrementalEncoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:253(IncrementalDecoder)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:295(StreamReader)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "def main():\n",
    "    '''\n",
    "        corpora: i2b2, mipacq, fv017\n",
    "        analyses: entity only (exact span), cui by document, full (aka (entity and cui on exaact span/exact cui)\n",
    "        systems: ctakes, biomedicus, clamp, metamap, quick_umls\n",
    "        \n",
    "        TODO -> Vectorization (entity only) -> done:\n",
    "                add switch for use of TN on single system performance evaluations -> done\n",
    "                add switch for overlap matching versus exact span -> done\n",
    "             -> Other tasks besides concept extraction\n",
    "        \n",
    "    ''' \n",
    "    analysisConf =  AnalysisConfig()\n",
    "    print(analysisConf.systems, analysisConf.corpus_config())\n",
    "    \n",
    "    if (rtype == 1):\n",
    "        print(semtypes, systems)\n",
    "        if filter_semtype:\n",
    "            for semtype in semtypes:\n",
    "                test = get_valid_systems(systems, semtype)\n",
    "                print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "                generate_metrics(analysis_type, corpus, filter_semtype, semtype)\n",
    "            \n",
    "        else:\n",
    "            generate_metrics(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    elif (rtype == 2):\n",
    "        print('run_type:', run_type)\n",
    "        # TODO -> list of corpora!\n",
    "#         for corpus in corpora: \n",
    "#             table_name = ref_data(corpus)\n",
    "#             system_annotation = sys_data(corpus)\n",
    "#             semtypes = ref_semtypes(filter_semtype, corpus)\n",
    "#             analysisConf =  AnalysisConfig()\n",
    "#             usys, ref = analysisConf.corpus_config(system_annotation, table_name)\n",
    "#             print('Using:', usys, ref)\n",
    "        if filter_semtype:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype)\n",
    "    elif (rtype == 3):\n",
    "        t = ['concept_jaccard_score_false']\n",
    "        test_systems(analysis_type, analysisConf.systems, corpus)  \n",
    "        test_count(analysis_type, corpus)\n",
    "        test_ensemble(analysis_type, corpus)\n",
    "    elif (rtype == 4):\n",
    "        if filter_semtype:\n",
    "            majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            majority_vote(systems, analysis_type, corpus, run_type, filter_semtype)\n",
    "    elif (rtype == 5):\n",
    "        \n",
    "        # control filter_semtype in get_sys_data, get_ref_n and generate_metrics. TODO consolidate. \n",
    "        # # run single ad hoc statement\n",
    "        statement = '((ctakes&biomedicus)|metamap)'\n",
    "\n",
    "        def add_hoc(analysis_type, corpus, statement):\n",
    "            sys = get_merge_data(statement, analysis_type, corpus, run_type, filter_semtype)\n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "            sys['label'] = 'concept'\n",
    "\n",
    "            ref = get_reference_vector(analysis_type, corpus, filter_semtype)\n",
    "            sys = vectorized_annotations(sys)\n",
    "            sys = np.asarray(flatten_list(list(sys)), dtype=np.int32)\n",
    "\n",
    "            return ref, sys\n",
    "\n",
    "        ref, sys = add_hoc(analysis_type, corpus, statement)\n",
    "        \n",
    "        # query by term:\n",
    "        \n",
    "        # import spacy\n",
    "        # nlp = spacy.load('en')\n",
    "\n",
    "        # sql = \"select distinct note_id, sofa from concepts.sofas where corpus = 'fairview'\"\n",
    "\n",
    "        # docs = pd.read_sql(sql, con=engine)\n",
    "\n",
    "        # d = {}\n",
    "\n",
    "        # for row in docs.itertuples():\n",
    "        #     d[row.note_id] = row.sofa\n",
    "\n",
    "        # print(len(d))\n",
    "\n",
    "        # test = matches[matches['note_id'] == '0000200926']\n",
    "        # print(len(test))\n",
    "\n",
    "        # doc = nlp(d['0000200926'])\n",
    "\n",
    "        # for row in test.itertuples():\n",
    "        #     my_str = [token.text.strip('\\n').lower() for token in doc if token.idx >= (row.begin) and token.idx <= (row.end)]\n",
    "        #     if 'diabetes' in my_str:\n",
    "        #         print(my_str)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    %prun main()\n",
    "    print('done!')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tests to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTS -> ensemble:\n",
    "# def test_match_consistency(matches, ref_only, ref_n, sys):\n",
    "#     \"\"\"test for reference only/match set consistency:\n",
    "#         params: match, system and reference only sets\"\"\"\n",
    "   \n",
    "#     print('len', len(sys), len(matches), len(matches.union(sys)), len(matches.intersection(sys)))\n",
    "#     assert len(matches.union(ref_only)) == ref_n, 'Reference annotation mismatch union'\n",
    "#     assert len(matches.intersection(sys)) == len(matches), 'System annotation mismatch intersect'\n",
    "#     assert len(matches.union(sys)) == len(sys), 'System annotation mismatch union'\n",
    "#     assert len(matches.intersection(ref_only)) == 0, 'Reference annotation mismatch intersect'\n",
    "\n",
    "# def test_systems(analysis_type, systems, corpus):\n",
    "#     sys = df_to_set(get_sys_data(systems[0], analysis_type, corpus), analysis_type)\n",
    "#     test_match_consistency(*get_system_matches(systems[0], analysis_type, corpus), get_ref_n(analysis_type), sys)\n",
    "#     print('Match consistency:', len(sys),get_ref_n(analysis_type))\n",
    "\n",
    "# def test_metrics(ref, sys_m, match_m):\n",
    "#     test = True\n",
    "#     reference_n = len(ref)\n",
    "#     system_n = len(sys_m)\n",
    "\n",
    "#     print('Test metrics:', type(reference_n), type(system_n), type(match_m))\n",
    "\n",
    "#     reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, match_m).get_ref_sys()\n",
    "#     F, recall, precision, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics()\n",
    "#     F_, recall_, precision_, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics(test)\n",
    "\n",
    "#     assert F[1] == F_, 'F1 issue'\n",
    "#     assert recall[1] == recall_, 'recall issue'\n",
    "#     assert precision[1] == precision_, 'precision issue'\n",
    "#     print(F[1], F_)\n",
    "#     print(recall[1], recall_)\n",
    "#     print(precision[1], precision_)\n",
    "\n",
    "# def test_count(analysis_type, corpus):\n",
    "#     # test match counts:\n",
    "#     ctakes, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     clamp, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "\n",
    "#     print('count:', len(mm.intersection(b9.intersection(clamp.intersection(ctakes)))))\n",
    "    \n",
    "# def test_ensemble(analysis_type, corpus):\n",
    "    \n",
    "#     print('ensemble:')\n",
    "#     # Get mixed system_n\n",
    "#     ref_ann, data = get_metric_data(analysis_type, corpus)\n",
    "\n",
    "#     names = ['ctakes', 'biomedicus', 'metamap', 'clamp']\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['begin', 'end', 'note_id']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['cui', 'note_id']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "#     biomedicus = data[data[\"system\"]=='biomedicus'][cols_to_keep].copy()\n",
    "#     ctakes = data[data[\"system\"]=='ctakes'][cols_to_keep].copy()\n",
    "#     clamp = data[data[\"system\"]=='clamp'][cols_to_keep].copy()\n",
    "#     metamap = data[data[\"system\"]=='metamap'][cols_to_keep].copy()\n",
    "#     quickumls = data[data[\"system\"]=='quick_umls'][cols_to_keep].copy()\n",
    "\n",
    "#     print('systems:', len(biomedicus), len(clamp), len(ctakes), len(metamap), len(quickumls))\n",
    "\n",
    "#     b9 = set()\n",
    "#     cl = set()\n",
    "#     ct = set()\n",
    "#     mm = set()\n",
    "#     qu = set()\n",
    "\n",
    "#     b9 = df_to_set(get_sys_data('biomedicus', analysis_type, corpus), analysis_type)\n",
    "#     print(len(b9))\n",
    "\n",
    "#     ct = df_to_set(get_sys_data('ctakes', analysis_type, corpus), analysis_type)\n",
    "#     print(len(ct))\n",
    "\n",
    "#     cl = df_to_set(get_sys_data('clamp', analysis_type, corpus), analysis_type)\n",
    "#     print(len(cl))\n",
    "\n",
    "#     mm = df_to_set(get_sys_data('metamap', analysis_type, corpus), analysis_type)\n",
    "#     print(len(mm))\n",
    "\n",
    "#     qu = df_to_set(get_sys_data('quick_umls', analysis_type, corpus), analysis_type)\n",
    "#     print(len(qu))\n",
    "    \n",
    "#     print('various merges:')\n",
    "#     print(len(b9), len(cl), len(ct), len(mm), len(qu))\n",
    "#     print(len(mm.intersection(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.union(ct)))))\n",
    "#     print(len(b9.intersection(ct)))\n",
    "\n",
    "#     sys_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('sys_m:', len(sys_m))\n",
    "\n",
    "#     # Get match merges:\n",
    "#     ct, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     cl, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "#     qu, _ = get_system_matches('quick_umls', analysis_type, corpus)\n",
    "\n",
    "#     match_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('match_m:', len(match_m))\n",
    "#     # reference df to set\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['end', 'start','file']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['value','file']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['end', 'start', 'value','file']\n",
    "\n",
    "#     ref = df_to_set(ref_ann[cols_to_keep], analysis_type, 'ref')\n",
    "\n",
    "#     print('ref:', len(ref))\n",
    "\n",
    "#     # test difference:\n",
    "#     print('FP:', len(sys_m - match_m), len(sys_m - ref))\n",
    "#     assert len(sys_m - match_m) == len(sys_m - ref), 'FP mismatch'\n",
    "#     print('FN:', len(ref - match_m), len(ref - sys_m))\n",
    "#     assert len(ref - match_m) == len(ref - sys_m), 'FN mismatch'\n",
    "    \n",
    "#     test_metrics(ref, sys_m, match_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
