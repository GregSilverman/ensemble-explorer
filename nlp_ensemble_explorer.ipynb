{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Copyright (c) 2019 Regents of the University of Minnesota.\n",
    " \n",
    "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    " \n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time \n",
    "import functools as ft\n",
    "import glob, os, sys   \n",
    "import operator as op\n",
    "import shelve\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "#from pandas.api.types import is_numeric_dtypen()\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, permutations\n",
    "from sqlalchemy.engine import create_engine\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from scipy import stats  \n",
    "from scipy.stats.mstats import gmean\n",
    "from pythonds.basic.stack import Stack\n",
    "from pythonds.trees.binaryTree import BinaryTree\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from typing import List, Set, Tuple \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pythonds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cell below contains the configurable parameters to ensure that our ensemble explorer runs properaly on your machine. \n",
    "Please read carfully through steps (1-11) before running the rest of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-1: CHOOSE YOUR CORPUS\n",
    "# TODO: get working with list of corpora\n",
    "#corpora = ['mipacq','i2b2','fairview'] #options for concept extraction include 'fairview', 'mipacq' OR 'i2b2'\n",
    "\n",
    "# cross-system semantic union merge filter for cross system aggregations using custom system annotations file with corpus name and system name using 'ray_test': \n",
    "# need to add semantic type filrering when reading in sys_data\n",
    "#corpus = 'ray_test'\n",
    "#corpus = 'clinical_trial2'\n",
    "corpus = 'fairview'\n",
    "#corpora = ['i2b2','fairview']\n",
    "\n",
    "# STEP-2: CHOOSE YOUR DATA DIRECTORY; this is where output data will be saved on your machine\n",
    "data_directory = '/mnt/DataResearch/DataStageData/ed_provider_notes/output/' \n",
    "\n",
    "# STEP-3: CHOOSE WHICH SYSTEMS YOU'D LIKE TO EVALUATE AGAINST THE CORPUS REFERENCE SET\n",
    "#systems = ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
    "#systems = ['biomedicus', 'clamp', 'metamap', 'quick_umls']\n",
    "#systems = ['biomedicus', 'quick_umls']\n",
    "#systems = ['biomedicus', 'ctakes', 'quick_umls']\n",
    "systems = ['biomedicus', 'clamp', 'ctakes', 'metamap','quick_umls']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['ctakes', 'quick_umls', 'biomedicus', 'metamap']\n",
    "#systems = ['biomedicus', 'metamap']\n",
    "#systems = ['ray_test']\n",
    "#systems = ['metamap']\n",
    "\n",
    "# STEP-4: CHOOSE TYPE OF RUN\n",
    "rtype = 6      # OPTIONS INCLUDE: 1->Single systems; 2->Ensemble; 3->Tests; 4 -> majority vote \n",
    "               # The Ensemble can include the max system set ['ctakes','biomedicus','clamp','metamap','quick_umls']\n",
    "    \n",
    "# STEP-5: CHOOSE WHAT TYPE OF ANALYSIS YOU'D LIKE TO RUN ON THE CORPUS\n",
    "analysis_type = 'full' #options include 'entity', 'cui' OR 'full'\n",
    "\n",
    "# STEP-(6A): ENTER DETAILS FOR ACCESSING MANUAL ANNOTATION DATA\n",
    "database_type = 'postgresql+psycopg2' # We use mysql+pymql as default\n",
    "database_username = 'gsilver1'\n",
    "database_password = 'nej123' \n",
    "database_url = 'd0pconcourse001' # HINT: use localhost if you're running database on your local machine\n",
    "#database_name = 'clinical_trial' # Enter database name\n",
    "database_name = 'covid-19' # Enter database name\n",
    "\n",
    "def ref_data(corpus):\n",
    "    return corpus + '_all' # Enter the table within the database where your reference data is stored\n",
    "\n",
    "table_name = ref_data(corpus)\n",
    "\n",
    "# STEP-(6B): ENTER DETAILS FOR ACCESSING SYSTEM ANNOTATION DATA\n",
    "\n",
    "def sys_data(corpus, analysis_type):\n",
    "    if analysis_type == 'entity':\n",
    "        return 'analytical_'+corpus+'.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "    elif analysis_type in ('cui', 'full'):\n",
    "        return 'analytical_'+corpus+'_cui.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "        \n",
    "system_annotation = sys_data(corpus, analysis_type)\n",
    "\n",
    "# STEP-7: CREATE A DB CONNECTION POOL\n",
    "engine_request = str(database_type)+'://'+database_username+':'+database_password+\"@\"+database_url+'/'+database_name\n",
    "engine = create_engine(engine_request, pool_pre_ping=True, pool_size=20, max_overflow=30)\n",
    "\n",
    "# STEP-(8A): FILTER BY SEMTYPE\n",
    "filter_semtype = True #False\n",
    "\n",
    "# STEP-(8B): IF STEP-(8A) == True -> GET REFERENCE SEMTYPES\n",
    "\n",
    "def ref_semtypes(filter_semtype, corpus):\n",
    "    if filter_semtype:\n",
    "        if corpus == 'fairview':\n",
    "            semtypes = ['Disorders']\n",
    "        else: pass\n",
    "        \n",
    "        return semtypes\n",
    "\n",
    "semtypes = ref_semtypes(filter_semtype, corpus)\n",
    "\n",
    "# STEP-9: Set data directory/table for source documents for vectorization\n",
    "src_table = 'sofa'\n",
    "\n",
    "# STEP-10: Specificy match type from {'exact', 'overlap', 'cui' -> kludge for majority}\n",
    "run_type = 'overlap'\n",
    "\n",
    "# for clinical trial, measurement/temoral are single system since no overlap for intersect\n",
    "# STEP-11: Specify expression type for run (TODO: run all at once; make less kludgey)\n",
    "expression_type = 'nested' #'nested_with_singleton' # type of merge expression: nested ((A&B)|C), paired ((A&B)|(C&D)), nested_with_singleton ((A&B)|((C&D)|E)) \n",
    "# -> NB: len(systems) for pair must be >= 4, and for nested_with_singleton == 5; single-> skip merges\n",
    "\n",
    "# STEP-12: Specify type of ensemble: merge or vote\n",
    "ensemble_type = 'merge'\n",
    "\n",
    "# STEP-13: run on negation modifier (TODO: negated entity)\n",
    "modification = None #'negation' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****** TODO \n",
    "-> add majority vote to union for analysis_type = 'full'\n",
    "-> case for multiple labels on same/overlapping span/same system; disambiguate (order by score if exists and select random for ties): done!\n",
    "-> port to command line \n",
    "----------------------->\n",
    "-> still need to validate that all semtypes in corpus!\n",
    "-> handle case where intersect merges are empty/any confusion matrix values are 0; specificallly on empty df in evaluate method: done!\n",
    "-> case when system annotations empty from semtype filter; print as 0: done!\n",
    "-> trim whitespace on CSV import -> done for semtypes\n",
    "-> eliminate rtype = 1 for expression_type = 'single'\n",
    "-> cross-system semantic union merge on aggregation\n",
    "-> negation: testing\n",
    "-> other modification, such as 'present'\n",
    "-> clean up configuration process\n",
    "-> allow iteration through all corpora and semtypes\n",
    "-> optimize vecorization (remove confusion?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config class for analysis\n",
    "class AnalysisConfig():\n",
    "    \"\"\"\n",
    "    Configuration object:\n",
    "    systems to use\n",
    "    notes by corpus\n",
    "    paths by output, gold and system location\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self = self    \n",
    "        self.systems = systems\n",
    "        self.data_dir = data_directory\n",
    "    \n",
    "    def corpus_config(self): \n",
    "        usys_data = system_annotation\n",
    "        ref_data = database_name+'.'+table_name\n",
    "        return usys_data, ref_data\n",
    "\n",
    "analysisConf =  AnalysisConfig()\n",
    "#usys, ref = analysisConf.corpus_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticTypes(object):\n",
    "    '''\n",
    "    Filter semantic types based on: https://metamap.nlm.nih.gov/SemanticTypesAndGroups.shtml\n",
    "    :params: semtypes list from corpus, system to query\n",
    "    :return: list of equivalent system semtypes \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, semtypes, corpus):\n",
    "        self = self\n",
    "        \n",
    "#         if corpus == 'clinical_trial2':\n",
    "#             corpus = 'clinical_trial' # kludge!!\n",
    "#         sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name, biomedicus_name FROM clinical_trial.semantic_groups sg join semantic_types st on sg.tui = st.tui where \" + corpus + \"_name in ({})\"\\\n",
    "#             .format(', '.join(['%s' for _ in semtypes]))  \n",
    "        sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name FROM semantic_groups sg join semantic_types st on sg.tui = st.tui where group_name in ({})\"\\\n",
    "           .format(', '.join(['%s' for _ in semtypes]))  \n",
    "        \n",
    "        stypes = pd.read_sql(sql, params=[semtypes], con=engine) \n",
    "       \n",
    "        if len(stypes['tui'].tolist()) > 0:\n",
    "            self.biomedicus_types = set(stypes['tui'].tolist())\n",
    "            self.qumls_types = set(stypes['tui'].tolist())\n",
    "        \n",
    "        else:\n",
    "            self.biomedicus_types = None\n",
    "            self.qumls_types = None\n",
    "        \n",
    "        if stypes['clamp_name'].dropna(inplace=True) or len(stypes['clamp_name']) == 0:\n",
    "            self.clamp_types = None\n",
    "        else:\n",
    "            self.clamp_types = set(stypes['clamp_name'].tolist()[0].split(','))\n",
    "         \n",
    "        if stypes['ctakes_name'].dropna(inplace=True) or len(stypes['ctakes_name']) == 0:\n",
    "            self.ctakes_types = None\n",
    "        else:\n",
    "            self.ctakes_types = set(stypes['ctakes_name'].tolist()[0].split(','))\n",
    " \n",
    "# # # Kludge for b9 temporal\n",
    "#         if stypes['biomedicus_name'].dropna(inplace=True) or len(stypes['biomedicus_name']) > 0:\n",
    "#             self.biomedicus_types.update(set(stypes['biomedicus_name'].tolist()[0].split(',')))\n",
    "#         #else:\n",
    "#         #    self.biomedicus_type = None\n",
    "        \n",
    "        if len(stypes['abbreviation'].tolist()) > 0:\n",
    "            self.metamap_types = set(stypes['abbreviation'].tolist())\n",
    "        else:\n",
    "            self.metamap_types = None\n",
    "        \n",
    "        self.reference_types =  set(semtypes)\n",
    "    \n",
    "    def get_system_type(self, system):  \n",
    "        \n",
    "        if system == 'biomedicus':\n",
    "            semtypes = self.biomedicus_types\n",
    "        elif system == 'ctakes':\n",
    "            semtypes = self.ctakes_types\n",
    "        elif system == 'clamp':\n",
    "            semtypes = self.clamp_types\n",
    "        elif system == 'metamap':\n",
    "            semtypes = self.metamap_types\n",
    "        elif system == 'quick_umls':\n",
    "            semtypes = self.qumls_types\n",
    "        elif system == 'reference':\n",
    "            semtypes = self.reference_types\n",
    "            \n",
    "        return semtypes\n",
    "    \n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('biomedicus'))\n",
    "#print(SemanticTypes(['Drug'], corpus).get_system_type('quick_umls'))\n",
    "#print(SemanticTypes(['drug'], corpus).get_system_type('clamp'))\n",
    "#print(SemanticTypes(['Disorders'], 'fairview').get_system_type('clamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#semtypes = ['test,treatment']\n",
    "#semtypes = 'drug,drug::drug_name,drug::drug_dose,dietary_supplement::dietary_supplement_name,dietary_supplement::dietary_supplement_dose'\n",
    "#semtypes =  'demographics::age,demographics::sex,demographics::race_ethnicity,demographics::bmi,demographics::weight'\n",
    "#corpus = 'clinical_trial'\n",
    "#sys = 'quick_umls'\n",
    "\n",
    "# is semantic type in particular system\n",
    "def system_semtype_check(sys, semtype, corpus):\n",
    "    st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "    if st:\n",
    "        return sys\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#print(system_semtype_check(sys, semtypes, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for systems\n",
    "class AnnotationSystems():\n",
    "    \"\"\"   \n",
    "    System annotations of interest for UMLS concept extraction\n",
    "    NB: ctakes combines all \"mentions\" annotation types\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"   \n",
    "        \n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\"]\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\"]\n",
    "        self.ctakes_types = [\"ctakes_mentions\"]\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\"]\n",
    "        self.qumls_types = [\"concept_jaccard_score_False\"]\n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "        \n",
    "        elif system == \"quick_umls\":\n",
    "            types = self.qumls_types\n",
    "            \n",
    "        return types, view\n",
    "    \n",
    "annSys = AnnotationSystems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython\n",
    "\n",
    "#import numpy as np # access to Numpy from Python layer\n",
    "#import math\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"\n",
    "    metrics class:\n",
    "    returns an instance with confusion matrix metrics\n",
    "    \"\"\"\n",
    "    def __init__(self, system_only, gold_only, gold_system_match, system_n, neither = 0): # neither: no sys or manual annotation\n",
    "\n",
    "        self = self    \n",
    "        self.system_only = system_only\n",
    "        self.gold_only = gold_only\n",
    "        self.gold_system_match = gold_system_match\n",
    "        self.system_n = system_n\n",
    "        self.neither = neither\n",
    "        \n",
    "    def get_confusion_metrics(self, corpus = None, test = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        compute confusion matrix measures, as per  \n",
    "        https://stats.stackexchange.com/questions/51296/how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\n",
    "        \"\"\"\n",
    "#         cdef:\n",
    "#             int TP, FP, FN\n",
    "#             double TM\n",
    "\n",
    "        TP = self.gold_system_match\n",
    "        FP = self.system_only\n",
    "        FN = self.gold_only\n",
    "        \n",
    "        TM = TP/math.sqrt(self.system_n) # TigMetric\n",
    "       \n",
    "        if not test:\n",
    "            \n",
    "            if corpus == 'casi':\n",
    "                recall = TP/(TP + FN)\n",
    "                precision = TP/(TP + FP)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "            else:\n",
    "                if self.neither == 0:\n",
    "                    confusion = [[0, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                else:\n",
    "                    confusion = [[self.neither, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                c = np.asarray(confusion)\n",
    "                \n",
    "                if TP != 0 or FP != 0:\n",
    "                    precision = TP/(TP+FP)\n",
    "                else:\n",
    "                    precision = 0\n",
    "                \n",
    "                if TP != 0 or FN != 0:\n",
    "                    recall = TP/(TP+FN)\n",
    "                else:\n",
    "                    recall = 0\n",
    "                \n",
    "                if precision + recall != 0:\n",
    "                    F = 2*(precision*recall)/(precision + recall)\n",
    "                else:\n",
    "                    F = 0\n",
    "    \n",
    "#                 recall = np.diag(c) / np.sum(c, axis = 1)\n",
    "#                 precision = np.diag(c) / np.sum(c, axis = 0)\n",
    "#                 #print('Yo!', np.mean(precision), np.mean(recall))\n",
    "#                 if np.mean(precision) != 0 and np.mean(recall) != 0:\n",
    "#                     F = 2*(precision*recall)/(precision + recall)\n",
    "#                 else:\n",
    "#                     F = 0\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            F = 2*(precision*recall)/(precision + recall)\n",
    "        \n",
    "        # Tignanelli Metric\n",
    "        if FN == 0:\n",
    "            TP_FN_R = TP\n",
    "        elif FN > 0:\n",
    "            TP_FN_R = TP/FN\n",
    " \n",
    "        return F, recall, precision, TP, FP, FN, TP_FN_R, TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_set(df, analysis_type = 'entity', df_type = 'sys', corpus = None):\n",
    "    \n",
    "    # get values for creation of series of type tuple\n",
    "    if 'entity' in analysis_type: \n",
    "        if corpus == 'casi':\n",
    "            arg = df.case, df.overlap\n",
    "        else:    \n",
    "            arg = df.begin, df.end, df.case\n",
    "            \n",
    "    elif 'cui' in analysis_type:\n",
    "        arg = df.value, df.case\n",
    "    elif 'full' in analysis_type:\n",
    "        arg = df.begin, df.end, df.value, df.case\n",
    "    \n",
    "    return set(list(zip(*arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython \n",
    "\n",
    "from __main__ import df_to_set, engine\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "def get_cooccurences(ref, sys, analysis_type: str, corpus: str):\n",
    "    \"\"\"\n",
    "    get cooccurences between system and reference; exact match; TODO: add relaxed -> done in single system evals during ensemble run\n",
    "    \"\"\"\n",
    "    # cooccurences\n",
    "    class Cooccurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = set()\n",
    "            self.false_negatives = set()\n",
    "            self.corpus = corpus\n",
    "\n",
    "    c = Cooccurences()\n",
    "    \n",
    "    if c.corpus != 'casi':\n",
    "        if analysis_type in ['cui', 'full']:\n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\", \"cui\": \"value\"})\n",
    "            # do not overestimate FP\n",
    "            sys = sys[~sys['value'].isnull()] \n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "        \n",
    "        if 'entity' in analysis_type: \n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "            cols_to_keep = ['begin', 'end', 'case']\n",
    "        elif 'cui' in analysis_type: \n",
    "            cols_to_keep = ['value', 'case']\n",
    "        elif 'full' in analysis_type: \n",
    "            cols_to_keep = ['begin', 'end', 'value', 'case']\n",
    "        \n",
    "        sys = sys[cols_to_keep].drop_duplicates()\n",
    "        ref = ref[cols_to_keep].drop_duplicates()\n",
    "        # matches via inner join\n",
    "        tp = pd.merge(sys, ref, how = 'inner', left_on=cols_to_keep, right_on = cols_to_keep) \n",
    "        # reference-only via left outer join\n",
    "        fn = pd.merge(ref, sys, how = 'left', left_on=cols_to_keep, right_on = cols_to_keep, indicator=True) \n",
    "        fn = fn[fn[\"_merge\"] == 'left_only']\n",
    "\n",
    "        tp = tp[cols_to_keep]\n",
    "        fn = fn[cols_to_keep]\n",
    "\n",
    "        # use for metrics \n",
    "        c.matches = c.matches.union(df_to_set(tp, analysis_type, 'ref'))\n",
    "        c.false_negatives = c.false_negatives.union(df_to_set(fn, analysis_type, 'ref'))\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches) # fp\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        c.ref_only = len(c.false_negatives)\n",
    "        \n",
    "    else:\n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where overlap = 1 and `system` = %(sys.name)s\"  \n",
    "        tp = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where (overlap = 0 or overlap is null) and `system` = %(sys.name)s\"  \n",
    "        fn = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        c.matches = df_to_set(tp, 'entity', 'sys', 'casi')\n",
    "        c.fn = df_to_set(fn, 'entity', 'sys', 'casi')\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(tp) + len(fn)\n",
    "        c.ref_n = len(tp) + len(fn)\n",
    "        c.ref_only = len(fn)\n",
    "        \n",
    "    # sanity check\n",
    "    if len(ref) - c.ref_system_match < 0:\n",
    "        print('Error: ref_system_match > len(ref)!')\n",
    "    if len(ref) != c.ref_system_match + c.ref_only:\n",
    "        print('Error: ref count mismatch!', len(ref), c.ref_system_match, c.ref_only)\n",
    "   \n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vector(doc: str, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.begin, a.end) for a in ann if a.label == lab]\n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v\n",
    "\n",
    "# test confusion matrix elements for vectorized annotation set; includes TN\n",
    "# https://kawahara.ca/how-to-compute-truefalse-positives-and-truefalse-negatives-in-python-for-binary-classification-problems/\n",
    "# def confused(sys1, ann1):\n",
    "#     TP = np.sum(np.logical_and(ann1 == 1, sys1 == 1))\n",
    "\n",
    "#     # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "#     TN = np.sum(np.logical_and(ann1 == 0, sys1 == 0))\n",
    "\n",
    "#     # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "#     FP = np.sum(np.logical_and(ann1 == 0, sys1 == 1))\n",
    "\n",
    "#     # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "#     FN = np.sum(np.logical_and(ann1 == 1, sys1 == 0))\n",
    "    \n",
    "#     return TP, TN, FP, FN\n",
    "\n",
    "def confused(sys1, ann1):\n",
    "    TP = np.sum(np.logical_and(ann1 > 0, sys1 == ann1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(ann1 == 0, sys1 == ann1))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(sys1 > 0, sys1 != ann1))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(ann1 > 0, sys1 == 0))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def vectorized_cooccurences(r: object, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> np.int64:\n",
    "    docs = get_docs(corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    sys = get_sys_ann(analysis_type, r)\n",
    "    \n",
    "    #cvals = []\n",
    "    if analysis_type == 'entity':\n",
    "        labels = [\"concept\"]\n",
    "    elif analysis_type in ['cui', 'full']:\n",
    "        labels = list(set(ann[\"value\"].tolist()))\n",
    "    \n",
    "    sys2 = list()\n",
    "    ann2 = list()\n",
    "    s2 = list()\n",
    "    a2 = list()\n",
    "    \n",
    "    for n in range(len(docs)):\n",
    "        \n",
    "        if analysis_type != 'cui':\n",
    "            a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "            s1 = list(sys.loc[sys[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "            ann1 = label_vector(docs[n][1], a1, labels)\n",
    "            sys1 = label_vector(docs[n][1], s1, labels)\n",
    "\n",
    "            #TP, TN, FP, FN = confused(sys1, ann1)\n",
    "            #cvals.append([TP, TN, FP, FN])\n",
    "            sys2.append(list(sys1))\n",
    "            ann2.append(list(ann1))\n",
    "\n",
    "        else:\n",
    "            a = ann.loc[ann[\"case\"] == docs[n][0]]['label'].tolist()\n",
    "            s = sys.loc[sys[\"case\"] == docs[n][0]]['label'].tolist()\n",
    "            x = [1 if x in a else 0 for x in labels]\n",
    "            y = [1 if x in s else 0 for x in labels]\n",
    "#             x_sparse = sparse.csr_matrix(x)\n",
    "#             y_sparse = sparse.csr_matrix(y)\n",
    "            s2.append(y)\n",
    "            a2.append(x)\n",
    "           \n",
    "            \n",
    "            #a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "            #s1 = list(sys.loc[sys[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "   \n",
    "    if analysis_type != 'cui':\n",
    "        a2 = [item for sublist in ann2 for item in sublist]\n",
    "        s2 = [item for sublist in sys2 for item in sublist]\n",
    "        report = classification_report(a2, s2, output_dict=True)\n",
    "        #print('classification:', report)\n",
    "        macro_precision =  report['macro avg']['precision'] \n",
    "        macro_recall = report['macro avg']['recall']    \n",
    "        macro_f1 = report['macro avg']['f1-score']\n",
    "        TN, FP, FN, TP = confusion_matrix(a2, s2).ravel()\n",
    "        \n",
    "        #return (np.sum(cvals, axis=0), (macro_precision, macro_recall, macro_f1))\n",
    "        return ((TP, TN, FP, FN), (macro_precision, macro_recall, macro_f1))\n",
    "    else:\n",
    "        x_sparse = sparse.csr_matrix(a2)\n",
    "        y_sparse = sparse.csr_matrix(s2)\n",
    "        report = classification_report(x_sparse, y_sparse, output_dict=True)\n",
    "        macro_precision =  report['macro avg']['precision'] \n",
    "        macro_recall = report['macro avg']['recall']    \n",
    "        macro_f1 = report['macro avg']['f1-score']\n",
    "        #print((macro_precision, macro_recall, macro_f1))\n",
    "        return ((0, 0, 0, 0), (macro_precision, macro_recall, macro_f1))\n",
    "                                       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_dict(ref_only: int, system_only: int, ref_system_match: int, system_n: int, ref_n: int) -> dict:\n",
    "    \"\"\"\n",
    "    Generate dictionary of confusion matrix params and measures\n",
    "    :params: ref_only, system_only, reference_system_match -> sets\n",
    "    matches, system_n, reference_n -> counts\n",
    "    :return: dictionary object\n",
    "    \"\"\"\n",
    "\n",
    "    if ref_only + ref_system_match != ref_n:\n",
    "        print('ERROR!')\n",
    "        \n",
    "    # get evaluation metrics\n",
    "    F, recall, precision, TP, FP, FN, TP_FN_R, TM  = Metrics(system_only, ref_only, ref_system_match, system_n).get_confusion_metrics()\n",
    "\n",
    "    d = {\n",
    "#          'F1': F[1], \n",
    "#          'precision': precision[1], \n",
    "#          'recall': recall[1], \n",
    "         'F1': F, \n",
    "         'precision': precision, \n",
    "         'recall': recall, \n",
    "         'TP': TP, \n",
    "         'FN': FN, \n",
    "         'FP': FP, \n",
    "         'TP/FN': TP_FN_R,\n",
    "         'n_gold': ref_n, \n",
    "         'n_sys': system_n, \n",
    "         'TM': TM\n",
    "    }\n",
    "    \n",
    "    if system_n - FP != TP:\n",
    "        print('inconsistent system n!')\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metric_data(analysis_type: str, corpus: str):\n",
    "   \n",
    "    usys_file, ref_table = AnalysisConfig().corpus_config()\n",
    "    systems = AnalysisConfig().systems\n",
    "    \n",
    "    sys_ann = pd.read_csv(analysisConf.data_dir + usys_file, dtype={'note_id': str})\n",
    "    \n",
    "#     sql = \"SELECT * FROM \" + ref_table #+ \" where semtype in('Anatomy', 'Chemicals_and_drugs')\" \n",
    "    \n",
    "#     ref_ann = pd.read_sql(sql, con=engine)\n",
    "    sys_ann = sys_ann.drop_duplicates()\n",
    "    ref_ann = None\n",
    "    \n",
    "    return ref_ann, sys_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of rank averages\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F1'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(analysis_type: str, corpus: str, filter_semtype, semtype = None):\n",
    "    start = time.time()\n",
    "\n",
    "    systems = AnalysisConfig().systems\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    __, sys_ann = get_metric_data(analysis_type, corpus)\n",
    "    c = None\n",
    "    \n",
    "    for sys in systems:\n",
    "       \n",
    "        if filter_semtype and semtype:\n",
    "            ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        system_annotations = sys_ann[sys_ann['system'] == sys].copy()\n",
    "\n",
    "        if filter_semtype:\n",
    "            st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "\n",
    "            if st: \n",
    "                system_annotations = sys_ann[sys_ann['semtypes'].isin(st)].copy()\n",
    "        else:\n",
    "            system_annotations = sys_ann.copy()\n",
    "\n",
    "        if (filter_semtype and st) or filter_semtype is False:\n",
    "            system = system_annotations.copy()\n",
    "\n",
    "            if sys == 'quick_umls':\n",
    "                system = system[system.score.astype(float) >= .8]\n",
    "\n",
    "            if sys == 'metamap' and modification == None:\n",
    "                system = system.fillna(0)\n",
    "                system = system[system.score.abs().astype(int) >= 800]\n",
    "\n",
    "            system = system.drop_duplicates()\n",
    "\n",
    "            ref_ann = ref_ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "            c = get_cooccurences(ref_ann, system, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "            \n",
    "            if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "                # get dictionary of confusion matrix metrics\n",
    "                d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "                d['system'] = sys\n",
    "\n",
    "                data = pd.DataFrame(d,  index=[0])\n",
    "                metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "                metrics.drop_duplicates(keep='last', inplace=True)\n",
    "            else:\n",
    "                print(\"NO EXACT MATCHES FOR\", sys)\n",
    "            elapsed = (time.time() - start)\n",
    "            print(\"elapsed:\", sys, elapsed)\n",
    "   \n",
    "    if c:\n",
    "        elapsed = (time.time() - start)\n",
    "        print(geometric_mean(metrics))\n",
    "\n",
    "        now = datetime.now()\n",
    "        timestamp = datetime.timestamp(now)\n",
    "\n",
    "        file_name = 'metrics_'\n",
    "\n",
    "        metrics.to_csv(analysisConf.data_dir + corpus + '_' + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "\n",
    "        print(\"total elapsed time:\", elapsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_n(analysis_type: str, corpus: str, filter_semtype: str) -> int:\n",
    "    \n",
    "    ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes, corpus).get_system_type('reference'))]\n",
    "            \n",
    "    if corpus == 'casi':\n",
    "        return len(ref_ann)\n",
    "        \n",
    "    else:\n",
    "        # do not overestimate fn\n",
    "        if 'entity' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'file']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type:\n",
    "            ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        elif 'full' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "        return ref_n\n",
    "    \n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_data(system: str, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> pd.DataFrame:\n",
    "   \n",
    "    _, data = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    out = data[data['system'] == system].copy()\n",
    "    \n",
    "    if filter_semtype:\n",
    "        st = SemanticTypes([semtype], corpus).get_system_type(system)\n",
    "        print(system, 'st', st)\n",
    "    \n",
    "    if corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap'] \n",
    "        out = out[cols_to_keep].drop_duplicates()\n",
    "        return out\n",
    "        \n",
    "    else:\n",
    "        if filter_semtype:\n",
    "            out = out[out['semtype'].isin(st)].copy()\n",
    "            \n",
    "        else:\n",
    "            out = out[out['system']== system].copy()\n",
    "            \n",
    "        if modification == 'negation':\n",
    "            out = out[out['modification'] == 'negation'].copy()\n",
    "        \n",
    "        if system == 'quick_umls':\n",
    "            out = out[(out.score.astype(float) >= 0.8) & (out[\"type\"] == 'concept')]\n",
    "            # fix for leading space on semantic type field\n",
    "            out = out.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) \n",
    "            out['semtype'] = out['semtype'].str.strip()\n",
    "        \n",
    "        if system == 'metamap' and modification == None:\n",
    "            out = out[out.score.abs().astype(int) >= 800]\n",
    "            \n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "        elif 'cui' in analysis_type:\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "        elif 'full' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id', 'polarity']\n",
    "\n",
    "        out = out[cols_to_keep]\n",
    "        \n",
    "        return out.drop_duplicates()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GENERATE merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTotals(object):\n",
    "    \"\"\" \n",
    "    returns an instance with merged match set numbers using either union or intersection of elements in set \n",
    "    \"\"\"\n",
    "    def __init__(self, ref_n, sys_n, match_set):\n",
    "\n",
    "        self = self    \n",
    "        self.ref_ann = ref_n\n",
    "        self.sys_n = sys_n\n",
    "        self.match_set = match_set\n",
    "\n",
    "    def get_ref_sys(self):\n",
    "\n",
    "        ref_only = self.ref_ann - len(self.match_set)\n",
    "        sys_only = self.sys_n - len(self.match_set)\n",
    "\n",
    "        return ref_only, sys_only, len(self.match_set), self.match_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_vote(arg):\n",
    "    arg['length'] = (arg.end - arg.begin).abs()\n",
    "    \n",
    "    df = arg[['begin', 'end', 'note_id', 'cui', 'length', 'polarity']].copy()\n",
    "    df.sort_values(by=['note_id','begin'],inplace=True)\n",
    "    df = df.drop_duplicates(['begin', 'end', 'note_id', 'cui', 'polarity'])\n",
    "    \n",
    "    cases = set(df['note_id'].tolist())\n",
    "    data = []\n",
    "    out = pd.DataFrame()\n",
    "    \n",
    "    for case in cases:\n",
    "        test = df[df['note_id']==case].copy()\n",
    "        \n",
    "        for row in test.itertuples():\n",
    "\n",
    "            iix = pd.IntervalIndex.from_arrays(test.begin, test.end, closed='neither')\n",
    "            span_range = pd.Interval(row.begin, row.end)\n",
    "            fx = test[iix.overlaps(span_range)].copy()\n",
    "\n",
    "            maxLength = fx['length'].max()\n",
    "            minLength = fx['length'].min()\n",
    "\n",
    "            if len(fx) > 1: \n",
    "                #if longer span exists use as tie-breaker\n",
    "                if maxLength > minLength:\n",
    "                    fx = fx[fx['length'] == fx['length'].max()]\n",
    "\n",
    "            data.append(fx)\n",
    "\n",
    "    out = pd.concat(data, axis=0)\n",
    "   \n",
    "    # Remaining ties on span with same or different CUIs\n",
    "    # randomly reindex to keep random selected row when dropping duplicates: https://gist.github.com/cadrev/6b91985a1660f26c2742\n",
    "    out.reset_index(inplace=True)\n",
    "    out = out.reindex(np.random.permutation(out.index))\n",
    "    \n",
    "    return out.drop_duplicates(['begin', 'end', 'note_id', 'polarity']) #out.drop('length', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Recursively evaluate parse tree, \n",
    "    with check for existence before build\n",
    "       :param sentence: to process\n",
    "       :return class of merged annotations, boolean operated system df \n",
    "    \"\"\"\n",
    "    \n",
    "    class Results(object):\n",
    "        def __init__(self):\n",
    "            self.results = set()\n",
    "            self.system_merges = pd.DataFrame()\n",
    "            \n",
    "    r = Results()\n",
    "    \n",
    "    if 'entity' in analysis_type and corpus != 'casi': \n",
    "        cols_to_keep = ['begin', 'end', 'note_id', 'polarity'] # entity only\n",
    "    elif 'full' in analysis_type: \n",
    "        cols_to_keep = ['cui', 'begin', 'end', 'note_id','polarity'] # entity only\n",
    "        join_cols = ['cui', 'begin', 'end', 'note_id', 'polarity']\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['cui', 'note_id', 'polarity'] # entity only\n",
    "    elif corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap']\n",
    "    \n",
    "    def evaluate(parseTree):\n",
    "        oper = {'&': op.and_, '|': op.or_}\n",
    "        \n",
    "        if parseTree:\n",
    "            leftC = gevent.spawn(evaluate, parseTree.getLeftChild())\n",
    "            rightC = gevent.spawn(evaluate, parseTree.getRightChild())\n",
    "            \n",
    "            if leftC.get() is not None and rightC.get() is not None:\n",
    "                system_query = pd.DataFrame()\n",
    "                fn = oper[parseTree.getRootVal()]\n",
    "                \n",
    "                if isinstance(leftC.get(), str):\n",
    "                    # get system as leaf node \n",
    "                    if filter_semtype:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype)\n",
    "                \n",
    "                elif isinstance(leftC.get(), pd.DataFrame):\n",
    "                    l_sys = leftC.get()\n",
    "                \n",
    "                if isinstance(rightC.get(), str):\n",
    "                    # get system as leaf node\n",
    "                    if filter_semtype:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype)\n",
    "                    \n",
    "                elif isinstance(rightC.get(), pd.DataFrame):\n",
    "                    r_sys = rightC.get()\n",
    "                    \n",
    "                if fn == op.or_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        frames = [left_sys, right_sys]\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [left_sys, r_sys]\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        frames = [l_sys, right_sys]\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [l_sys, r_sys]\n",
    "                    \n",
    "                    df = pd.concat(frames,  ignore_index=True)\n",
    "                    \n",
    "                    if analysis_type == 'full':\n",
    "                        df = union_vote(df)\n",
    "\n",
    "                if fn == op.and_:\n",
    "                    \n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        if not left_sys.empty and not right_sys.empty:\n",
    "                            df = left_sys.merge(right_sys, on=join_cols, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=join_cols)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(columns=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        if not left_sys.empty and not r_sys.empty:\n",
    "                            df = left_sys.merge(r_sys, on=join_cols, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=join_cols)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(columns=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        if not l_sys.empty and not right_sys.empty:\n",
    "                            df = l_sys.merge(right_sys, on=join_cols, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=join_cols)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(columns=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        if not l_sys.empty and not r_sys.empty:\n",
    "                            df = l_sys.merge(r_sys, on=join_cols, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=join_cols)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(columns=cols_to_keep)\n",
    "                \n",
    "                # get combined system results\n",
    "                r.system_merges = df\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    system_query = system_query.append(df)\n",
    "                else:\n",
    "                    print('wtf!')\n",
    "                    \n",
    "                return system_query\n",
    "            else:\n",
    "                return parseTree.getRootVal()\n",
    "    \n",
    "    if sentence.n_or > 0 or sentence.n_and > 0:\n",
    "        evaluate(pt)  \n",
    "    \n",
    "    # trivial case\n",
    "    elif sentence.n_or == 0 and sentence.n_and == 0:\n",
    "        \n",
    "        if filter_semtype:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Incoming Boolean sentences are parsed into a binary tree.\n",
    "\n",
    "Test expressions to parse:\n",
    "\n",
    "sentence = '((((A&B)|C)|D)&E)'\n",
    "\n",
    "sentence = '(E&(D|(C|(A&B))))'\n",
    "\n",
    "sentence = '(((A|(B&C))|(D&(E&F)))|(H&I))'\n",
    "\n",
    "\"\"\"\n",
    "# build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "def buildParseTree(fpexp):\n",
    "    \"\"\"\n",
    "       Iteratively build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "       :param fpexp: sentence to parse\n",
    "       :return eTree: parse tree representation\n",
    "       Incoming Boolean sentences are parsed into a binary tree.\n",
    "       Test expressions to parse:\n",
    "       sentence = '(A&B)'\n",
    "       sentence = '(A|B)'\n",
    "       sentence = '((A|B)&C)'\n",
    "       \n",
    "    \"\"\"\n",
    "    fplist = fpexp.split()\n",
    "    pStack = Stack()\n",
    "    eTree = BinaryTree('')\n",
    "    pStack.push(eTree)\n",
    "    currentTree = eTree\n",
    "\n",
    "    for i in fplist:\n",
    "\n",
    "        if i == '(':\n",
    "            currentTree.insertLeft('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getLeftChild()\n",
    "        elif i not in ['&', '|', ')']:\n",
    "            currentTree.setRootVal(i)\n",
    "            parent = pStack.pop()\n",
    "            currentTree = parent\n",
    "        elif i in ['&', '|']:\n",
    "            currentTree.setRootVal(i)\n",
    "            currentTree.insertRight('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getRightChild()\n",
    "        elif i == ')':\n",
    "            currentTree = pStack.pop()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return eTree\n",
    "\n",
    "def make_parse_tree(payload):\n",
    "    \"\"\"\n",
    "    Ensure data to create tree are in correct form\n",
    "    :param sentence: sentence to preprocess\n",
    "    :return pt, parse tree graph\n",
    "            sentence, processed sentence to build tree\n",
    "            a: order\n",
    "    \"\"\"\n",
    "    def preprocess_sentence(sentence):\n",
    "        # prepare statement for case when a boolean AND/OR is given\n",
    "        sentence = payload.replace('(', ' ( '). \\\n",
    "            replace(')', ' ) '). \\\n",
    "            replace('&', ' & '). \\\n",
    "            replace('|', ' | '). \\\n",
    "            replace('  ', ' ')\n",
    "        return sentence\n",
    "\n",
    "    sentence = preprocess_sentence(payload)\n",
    "    print('Processing sentence:', sentence)\n",
    "    \n",
    "    pt = buildParseTree(sentence)\n",
    "    #pt.postorder() \n",
    "    \n",
    "    return pt\n",
    "\n",
    "class Sentence(object):\n",
    "    '''\n",
    "    Details about boolean expression -> number operators and expression\n",
    "    '''\n",
    "    def __init__(self, sentence):\n",
    "        self = self\n",
    "        self.n_and = sentence.count('&')\n",
    "        self.n_or = sentence.count('|')\n",
    "        self.sentence = sentence\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_docs(corpus):\n",
    "    \n",
    "    # KLUDGE!!!\n",
    "    if corpus == 'ray_test':\n",
    "        corpus = 'fairview'\n",
    "        \n",
    "    sql = 'select distinct note_id, sofa from sofas where corpus = %(corpus)s order by note_id'\n",
    "    df = pd.read_sql(sql, params={\"corpus\":corpus}, con=engine)\n",
    "    df.drop_duplicates()\n",
    "    df['len_doc'] = df['sofa'].apply(len)\n",
    "    \n",
    "    subset = df[['note_id', 'len_doc']]\n",
    "    docs = [tuple(x) for x in subset.to_numpy()]\n",
    "    \n",
    "    return docs\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_ann(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    if filter_semtype:\n",
    "        if ',' in semtype:\n",
    "            semtype = semtype.split(',')\n",
    "        else:\n",
    "            semtype = [semtype]\n",
    "        \n",
    "    ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    ann = ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = ann[ann['semtype'].isin(semtype)]\n",
    "    if analysis_type == 'entity':   \n",
    "        ann[\"label\"] = 'concept'\n",
    "    elif analysis_type in ['cui','full']:\n",
    "        ann[\"label\"] = ann[\"value\"]\n",
    "        \n",
    "    if modification == 'negation':\n",
    "        ann = ann[ann['semtype'] == 'negation']\n",
    "    \n",
    "    \n",
    "    if analysis_type == 'entity':\n",
    "        cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    elif analysis_type == 'cui':\n",
    "        cols_to_keep = ['value', 'case', 'label']\n",
    "    elif analysis_type == 'full':\n",
    "        cols_to_keep = ['begin', 'end', 'value', 'case', 'label']\n",
    "    ann = ann[cols_to_keep]\n",
    "    \n",
    "    return ann\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_ann(analysis_type, r):\n",
    "    sys = r.system_merges   \n",
    "    \n",
    "    sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "    if analysis_type == 'entity':\n",
    "        sys[\"label\"] = 'concept'\n",
    "        cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    elif analysis_type == 'full':\n",
    "        sys[\"label\"] = sys[\"cui\"]\n",
    "        cols_to_keep = ['begin', 'end', 'case', 'value', 'label']\n",
    "    elif analysis_type == 'cui':\n",
    "        sys[\"label\"] = sys[\"cui\"]\n",
    "        cols_to_keep = ['case', 'cui', 'label']\n",
    "    \n",
    "    sys = sys[cols_to_keep]\n",
    "    return sys\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metrics(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    else:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    # vectorize merges using i-o labeling\n",
    "    if run_type == 'overlap':\n",
    "        if filter_semtype:\n",
    "             ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        print('results:',((TP, TN, FP, FN),(p,r,f1)))\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        if analysis_type != 'cui':\n",
    "            d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        else:\n",
    "            d = dict()\n",
    "            d['F1'] = 0\n",
    "            d['precision'] = 0 \n",
    "            d['recall'] = 0\n",
    "            d['TP/FN'] = 0\n",
    "            d['TM'] = 0\n",
    "            \n",
    "        d['TN'] = TN\n",
    "        d['macro_p'] = p\n",
    "        d['macro_r'] = r\n",
    "        d['macro_f1'] = f1\n",
    "        \n",
    "        \n",
    "        # return full metrics\n",
    "        return d\n",
    "\n",
    "    elif run_type == 'exact':\n",
    "        # total by number spans\n",
    "        \n",
    "        if filter_semtype:\n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else: \n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "        else:\n",
    "            d = None\n",
    "            \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_valid_systems(['biomedicus'], 'Anatomy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all combinations of given list of annotators:\n",
    "def partly_unordered_permutations(lst, k):\n",
    "    elems = set(lst)\n",
    "    for c in combinations(lst, k):\n",
    "        for d in permutations(elems - set(c)):\n",
    "            yield c + d\n",
    "            \n",
    "def expressions(l, n):\n",
    "    for (operations, *operands), operators in product(\n",
    "            combinations(l, n), product(('&', '|'), repeat=n - 1)):\n",
    "        for operation in zip(operators, operands):\n",
    "            operations = [operations, *operation]\n",
    "        yield operations\n",
    "\n",
    "# get list of systems with a semantic type in grouping\n",
    "def get_valid_systems(systems, semtype):\n",
    "    test = []\n",
    "    for sys in systems:\n",
    "        st = system_semtype_check(sys, semtype, corpus)\n",
    "        if st:\n",
    "            test.append(sys)\n",
    "\n",
    "    return test\n",
    "\n",
    "# permute system combinations and evaluate system merges for performance\n",
    "def run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type, semtype = None):\n",
    "    metrics = pd.DataFrame()\n",
    "    \n",
    "    # pass single system to evaluate\n",
    "    if expression_type == 'single':\n",
    "        for system in systems:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(system, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(system, analysis_type, corpus, run_type, filter_semtype)\n",
    "            d['merge'] = system\n",
    "            d['n_terms'] = 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "    \n",
    "    elif expression_type == 'nested':\n",
    "        for l in partly_unordered_permutations(systems, 2):\n",
    "            print('processing merge combo:', l)\n",
    "            for i in range(1, len(l)+1):\n",
    "                test = list(expressions(l, i))\n",
    "                for t in test:\n",
    "                    if i > 1:\n",
    "                        # format Boolean sentence for parse tree \n",
    "                        t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                    if filter_semtype:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype)\n",
    "\n",
    "                    d['merge'] = t\n",
    "                    d['n_terms'] = i\n",
    "\n",
    "                    frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "                    metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                    \n",
    "    elif expression_type == 'nested_with_singleton' and len(systems) == 5:\n",
    "        # form (((a&b)|c)&(d|e))\n",
    "        \n",
    "        nested = list(expressions(systems, 3))\n",
    "        test = list(expressions(systems, 2))\n",
    "        to_do_terms = []\n",
    "    \n",
    "        for n in nested:\n",
    "            # format Boolean sentence for parse tree \n",
    "            n = '(' + \" \".join(str(x) for x in n).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "            for t in test:\n",
    "                t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                new_and = '(' + n +'&'+ t + ')'\n",
    "                new_or = '(' + n +'|'+ t + ')'\n",
    "\n",
    "                if new_and.count('biomedicus') != 2 and new_and.count('clamp') != 2 and new_and.count('ctakes') != 2 and new_and.count('metamap') != 2 and new_and.count('quick_umls') != 2:\n",
    "\n",
    "                    if new_and.count('&') != 4 and new_or.count('|') != 4:\n",
    "                        #print(new_and)\n",
    "                        #print(new_or)\n",
    "                        to_do_terms.append(new_or)\n",
    "                        to_do_terms.append(new_and)\n",
    "        \n",
    "        print('nested_with_singleton', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                        \n",
    "    elif expression_type == 'paired':\n",
    "        m = list(expressions(systems, 2))\n",
    "        test = list(expressions(m, 2))\n",
    "\n",
    "        to_do_terms = []\n",
    "        for t in test:\n",
    "            # format Boolean sentence for parse tree \n",
    "            t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "            if t.count('biomedicus') != 2 and t.count('clamp') != 2 and t.count('ctakes') != 2 and t.count('metamap') != 2 and t.count('quick_umls') != 2:\n",
    "                if t.count('&') != 3 and t.count('|') != 3:\n",
    "                    to_do_terms.append(t)\n",
    "                    if len(systems) == 5:\n",
    "                        for i in systems:\n",
    "                            if i not in t:\n",
    "                                #print('('+t+'&'+i+')')\n",
    "                                #print('('+t+'|'+i+')')\n",
    "                                new_and = '('+t+'&'+i+')'\n",
    "                                new_or = '('+t+'|'+i+')'\n",
    "                                to_do_terms.append(new_and)\n",
    "                                to_do_terms.append(new_or)\n",
    "                            \n",
    "        print('paired', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "        \n",
    "    return metrics\n",
    "\n",
    "# write to file\n",
    "def generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype = None):\n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    file_name = corpus + '_all_'\n",
    "   \n",
    "    # drop exact matches:\n",
    "    metrics = metrics.drop_duplicates()\n",
    "    \n",
    "    if ensemble_type == 'merge':\n",
    "        metrics = metrics.sort_values(by=['n_terms', 'merge'])\n",
    "        file_name += 'merge_'\n",
    "    elif ensemble_type == 'vote':\n",
    "        file_name += '_'\n",
    "    \n",
    "    #metrics = metrics.drop_duplicates(subset=['TP', 'FN', 'FP', 'n_sys', 'precision', 'recall', 'F', 'TM', 'TP/FN', 'TM', 'n_terms'])\n",
    "\n",
    "    file = file_name + analysis_type + '_' + run_type +'_'\n",
    "    \n",
    "    if filter_semtype:\n",
    "        file += semtype\n",
    "        \n",
    "    \n",
    "    geometric_mean(metrics).to_csv(analysisConf.data_dir + file + str(timestamp) + '.csv')\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "# control ensemble run\n",
    "def ensemble_control(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSTEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            metrics = run_ensemble(test, analysis_type, corpus, filter_semtype, expression_type, semtype)\n",
    "            if (expression_type == 'nested_with_singleton' and len(test) == 5) or expression_type in ['nested', 'paired', 'single']:\n",
    "                generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "    else:\n",
    "        metrics = run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad hoc query for performance evaluation\n",
    "def get_merge_data(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "\n",
    "    r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    if run_type == 'overlap' and rtype != 6:\n",
    "        if filter_semtype:\n",
    "             ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "             ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        print(d)\n",
    "        \n",
    "    elif run_type == 'exact':\n",
    "        c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "\n",
    "            print('cm', d)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # get matched data from merge\n",
    "    return r.system_merges # merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad hoc query for performance evaluation\n",
    "def get_sys_merge(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "#     if filter_semtype:\n",
    "#         ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "#     else: \n",
    "#         ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "\n",
    "    for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "#     if run_type == 'overlap' and rtype != 6:\n",
    "#         if filter_semtype:\n",
    "#              ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "#         else:\n",
    "#              ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "\n",
    "#         # TODO: validate against ann1/sys1 where val = 1\n",
    "#         # total by number chars\n",
    "#         system_n = TP + FP\n",
    "#         reference_n = TP + FN\n",
    "\n",
    "#         d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "#         print(d)\n",
    "        \n",
    "#     elif run_type == 'exact':\n",
    "#         c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "#         if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "#             # get dictionary of confusion matrix metrics\n",
    "#             d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "\n",
    "#             print('cm', d)\n",
    "#     else:\n",
    "#         pass\n",
    "    \n",
    "    # get matched data from merge\n",
    "    return r.system_merges # merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority vote \n",
    "def vectorized_annotations(ann):\n",
    "    \n",
    "    docs = get_docs(corpus)\n",
    "    labels = [\"concept\"]\n",
    "    out= []\n",
    "    \n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        a = label_vector(docs[n][1], a1, labels)\n",
    "        out.append(a)\n",
    "\n",
    "    return out\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def get_reference_vector(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    df = ref_ann.copy()\n",
    "    df = df.drop_duplicates(subset=['begin','end','case'])\n",
    "    df['label'] = 'concept'\n",
    "\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ref = df[cols_to_keep].copy()\n",
    "    test = vectorized_annotations(ref)\n",
    "    ref =  np.asarray(flatten_list(test), dtype=np.int32) \n",
    "\n",
    "    return ref\n",
    "\n",
    "def majority_overlap_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    d = {}\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys_test = []\n",
    "    \n",
    "    for system in systems:\n",
    "        sys_ann = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        df = sys_ann.copy()\n",
    "        df['label'] = 'concept'\n",
    "        df = df.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "        sys = df[df['system']==system][cols_to_keep].copy()\n",
    "        test = vectorized_annotations(sys)\n",
    "        d[system] = flatten_list(test) \n",
    "        sys_test.append(d[system])\n",
    "\n",
    "    output = sum(np.array(sys_test))\n",
    "    \n",
    "    n = int(len(systems) / 2)\n",
    "    #print(n)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        vote = np.where(output > n, 1, 0)\n",
    "    else:\n",
    "        vote = np.where(output > n, 1, \n",
    "         (np.where(output == n, random.randint(0, 1), 0)))\n",
    "        \n",
    "    return vote\n",
    "\n",
    "def majority_overlap_vote_out(ref, vote, corpus):    \n",
    "    TP, TN, FP, FN = confused(ref, vote)\n",
    "    print(TP, TN, FP, FN)\n",
    "    system_n = TP + FP\n",
    "    reference_n = TP + FN\n",
    "\n",
    "    d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "\n",
    "    d['TN'] = TN\n",
    "    d['corpus'] = corpus\n",
    "    print(d)\n",
    "    \n",
    "    metrics = pd.DataFrame(d, index=[0])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# control vote run\n",
    "def majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            \n",
    "            if run_type == 'overlap':\n",
    "                ref = get_reference_vector(analysis_type, corpus, filter_semtype, semtype)\n",
    "                vote = majority_overlap_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                metrics = majority_overlap_vote_out(ref, vote, corpus)\n",
    "                #generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "            elif run_type == 'exact':\n",
    "                sys = majority_exact_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                d = majority_exact_vote_out(sys, filter_semtype, semtype)\n",
    "                metrics = pd.DataFrame(d, index=[0])\n",
    "            elif run_type == 'cui':\n",
    "                sys = majority_cui_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                d = majority_cui_vote_out(sys, filter_semtype, semtype)\n",
    "                metrics = pd.DataFrame(d, index=[0])\n",
    "           \n",
    "            metrics['systems'] = ','.join(test)\n",
    "            generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "                \n",
    "    else:\n",
    "        if run_type == 'overlap':\n",
    "            ref = get_reference_vector(analysis_type, corpus, filter_semtype)\n",
    "            vote = majority_overlap_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            metrics = majority_overlap_vote_out(ref, vote, corpus)\n",
    "            \n",
    "        elif run_type == 'exact':\n",
    "            sys = majority_exact_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            d = majority_exact_vote_out(sys, filter_semtype)\n",
    "            metrics = pd.DataFrame(d, index=[0])\n",
    "            \n",
    "        elif run_type == 'cui':\n",
    "            sys = majority_cui_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            d = majority_cui_vote_out(sys, filter_semtype)\n",
    "            metrics = pd.DataFrame(d, index=[0])\n",
    "            \n",
    "        metrics['systems'] = ','.join(systems)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "def majority_cui_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "   \n",
    "    cols_to_keep = ['cui', 'note_id', 'system']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for system in systems:\n",
    "        if filter_semtype:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        sys = sys[sys['system'] == system][cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        frames = [df, sys]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def majority_cui_vote_out(sys, filter_semtype, semtype = None):\n",
    "    \n",
    "    sys = sys.astype(str)\n",
    "    sys['value_cui'] = list(zip(sys.cui, sys.note_id.astype(str)))\n",
    "    sys['count'] = sys.groupby(['value_cui'])['value_cui'].transform('count')\n",
    "\n",
    "    n = int(len(systems) / 2)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        sys = sys[sys['count'] > n]\n",
    "    else:\n",
    "        # https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "        for i in sys.index:\n",
    "            if sys.at[i, 'count'] == n:\n",
    "                sys.at[i, 'count'] = random.choice([1,len(systems)])\n",
    "        sys = sys[sys['count'] > n]\n",
    "\n",
    "    sys = sys.drop_duplicates(subset=['value_cui', 'cui', 'note_id'])\n",
    "    ref = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    c = get_cooccurences(ref, sys, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "        # get dictionary of confusion matrix metrics\n",
    "        print(cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n))\n",
    "        return cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "    \n",
    "\n",
    "def majority_exact_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "   \n",
    "    cols_to_keep = ['begin', 'end', 'note_id', 'system']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for system in systems:\n",
    "        if filter_semtype:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        sys = sys[sys['system'] == system][cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        frames = [df, sys]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "    return df\n",
    "        \n",
    "def majority_exact_vote_out(sys, filter_semtype, semtype = None):\n",
    "    sys['span'] = list(zip(sys.begin, sys.end, sys.note_id.astype(str)))\n",
    "    sys['count'] = sys.groupby(['span'])['span'].transform('count')\n",
    "\n",
    "    n = int(len(systems) / 2)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        sys = sys[sys['count'] > n]\n",
    "    else:\n",
    "        # https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "        for i in sys.index:\n",
    "            if sys.at[i, 'count'] == n:\n",
    "                sys.at[i, 'count'] = random.choice([1,len(systems)])\n",
    "        sys = sys[sys['count'] > n]\n",
    "\n",
    "    sys = sys.drop_duplicates(subset=['span', 'begin', 'end', 'note_id'])\n",
    "    ref = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    c = get_cooccurences(ref, sys, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "        # get dictionary of confusion matrix metrics\n",
    "        print(cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n))\n",
    "        return cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "    \n",
    "#ensemble_type = 'vote'        \n",
    "#filter_semtype = False\n",
    "#majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'] ('analytical_fairview_cui.csv', 'covid-19.fairview_all')\n",
      "['Disorders']\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) & metamap ) | clamp ) \n",
      "biomedicus st {'T190', 'T049', 'T184', 'T047', 'T037', 'T050', 'T191', 'T048', 'T033', 'T019', 'T020', 'T046'}\n",
      "ctakes st {'SignSymptomMention', 'DiseaseDisorderMention'}\n",
      "metamap st {'dsyn', 'mobd', 'patf', 'sosy', 'comd', 'acab', 'anab', 'emod', 'fndg', 'inpo', 'neop', 'cgab'}\n",
      "clamp st {'labvalue', 'problem'}\n",
      " done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         72220093 function calls (71397752 primitive calls) in 54.130 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "12490258/12490236    3.158    0.000    5.209    0.000 {built-in method builtins.isinstance}\n",
       "  4679589    1.498    0.000    2.051    0.000 generic.py:10(_check)\n",
       "  1375011    1.362    0.000    3.346    0.000 common.py:1708(_is_dtype_type)\n",
       "   415537    1.352    0.000    1.352    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "109151/109066    1.186    0.000    9.508    0.000 base.py:276(__new__)\n",
       "7487724/7487722    1.164    0.000    1.774    0.000 {built-in method builtins.getattr}\n",
       "        1    1.006    1.006    1.065    1.065 {method 'read' of 'pandas._libs.parsers.TextReader' objects}\n",
       "    87737    0.997    0.000    5.915    0.000 algorithms.py:1565(take_nd)\n",
       "461030/351658    0.919    0.000    1.478    0.000 {built-in method numpy.array}\n",
       "  1096580    0.914    0.000    2.525    0.000 common.py:1565(is_extension_array_dtype)\n",
       "  1096761    0.825    0.000    1.219    0.000 dtypes.py:75(find)\n",
       "    44100    0.735    0.000    1.783    0.000 managers.py:212(_rebuild_blknos_and_blklocs)\n",
       "   437718    0.731    0.000    0.858    0.000 numerictypes.py:293(issubclass_)\n",
       "   983617    0.717    0.000    3.430    0.000 base.py:247(is_dtype)\n",
       "  4577764    0.674    0.000    0.675    0.000 {built-in method builtins.issubclass}\n",
       "    21727    0.647    0.000    0.892    0.000 concat.py:28(get_mgr_concatenation_plan)\n",
       "  1289666    0.642    0.000    0.820    0.000 {built-in method builtins.hasattr}\n",
       "   307910    0.602    0.000    2.193    0.000 _dtype.py:333(_name_get)\n",
       "   109641    0.588    0.000   14.309    0.000 frame.py:2767(__getitem__)\n",
       "        1    0.573    0.573   51.600   51.600 <ipython-input-19-7b4a6dc91c38>:1(union_vote)\n",
       "2448435/1868401    0.554    0.000    0.812    0.000 {built-in method builtins.len}\n",
       "   439587    0.526    0.000    0.882    0.000 {pandas._libs.lib.is_scalar}\n",
       "   217814    0.483    0.000    1.127    0.000 _ufunc_config.py:39(seterr)\n",
       "    87737    0.458    0.000    1.822    0.000 algorithms.py:1436(_get_take_nd_function)\n",
       "    65154    0.457    0.000    3.225    0.000 base.py:102(cmp_method)\n",
       "   109005    0.448    0.000    2.695    0.000 numeric.py:53(__new__)\n",
       "    87717    0.442    0.000    1.609    0.000 cast.py:347(maybe_promote)\n",
       "   197795    0.402    0.000    0.402    0.000 {built-in method numpy.empty}\n",
       "   632482    0.397    0.000    0.567    0.000 common.py:1844(pandas_dtype)\n",
       "   217814    0.395    0.000    0.426    0.000 _ufunc_config.py:139(geterr)\n",
       "   633670    0.368    0.000    0.544    0.000 common.py:1672(_get_dtype)\n",
       "    67081    0.367    0.000    4.445    0.000 base.py:3912(__getitem__)\n",
       "    63136    0.351    0.000    0.351    0.000 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
       "        5    0.350    0.070    8.627    1.725 concat.py:454(get_result)\n",
       "      220    0.350    0.002    0.350    0.002 {pandas._libs.ops.scalar_compare}\n",
       "    88216    0.350    0.000    1.256    0.000 blocks.py:343(ftype)\n",
       "    65194    0.338    0.000    1.822    0.000 missing.py:225(_isna_ndarraylike)\n",
       "   523850    0.335    0.000    0.561    0.000 managers.py:1548(dtype)\n",
       "   414633    0.334    0.000    1.438    0.000 common.py:222(is_object_dtype)\n",
       "  1221797    0.332    0.000    0.513    0.000 common.py:208(<lambda>)\n",
       "    43590    0.325    0.000    4.706    0.000 series.py:3857(_reduce)\n",
       "    43589    0.322    0.000    0.441    0.000 warnings.py:181(_add_filter)\n",
       "   218455    0.311    0.000    1.308    0.000 common.py:1435(is_bool_dtype)\n",
       "   154217    0.308    0.000    0.741    0.000 managers.py:163(shape)\n",
       "   370948    0.290    0.000    1.193    0.000 common.py:441(is_timedelta64_dtype)\n",
       "  1221797    0.287    0.000    0.287    0.000 common.py:206(classes)\n",
       "   153008    0.274    0.000    0.671    0.000 base.py:472(_simple_new)\n",
       "    44095    0.267    0.000    3.988    0.000 managers.py:122(__init__)\n",
       "    21718    0.265    0.000    8.078    0.000 interval.py:462(_validate)\n",
       "   523850    0.262    0.000    0.823    0.000 series.py:414(dtype)\n",
       "   261865    0.257    0.000    1.184    0.000 common.py:372(is_datetime64_dtype)\n",
       "       23    0.253    0.011    1.527    0.066 concat.py:268(_get_empty_dtype_and_na)\n",
       "    21871    0.252    0.000    0.555    0.000 nanfunctions.py:345(nanmax)\n",
       "   531744    0.247    0.000    0.249    0.000 {built-in method _abc._abc_instancecheck}\n",
       "   415537    0.246    0.000    0.595    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
       "155113/154678    0.246    0.000    0.863    0.000 generic.py:5257(__getattr__)\n",
       "   112196    0.240    0.000    0.482    0.000 blocks.py:118(__init__)\n",
       "   556139    0.237    0.000    0.316    0.000 base.py:615(__len__)\n",
       "   218859    0.234    0.000    1.114    0.000 numerictypes.py:365(issubdtype)\n",
       "   307910    0.233    0.000    1.347    0.000 _dtype.py:319(_name_includes_bit_suffix)\n",
       "   153446    0.232    0.000    2.463    0.000 missing.py:132(_isna_new)\n",
       "   136205    0.221    0.000    0.341    0.000 generic.py:5276(__setattr__)\n",
       "    22115    0.220    0.000    0.406    0.000 indexers.py:172(maybe_convert_indices)\n",
       "    22115    0.220    0.000    8.998    0.000 managers.py:1373(take)\n",
       "   393195    0.212    0.000    1.499    0.000 common.py:403(is_datetime64tz_dtype)\n",
       "    88216    0.210    0.000    0.870    0.000 _dtype.py:46(__str__)\n",
       "       12    0.204    0.017    1.624    0.135 concat.py:31(get_dtype_kinds)\n",
       "   112196    0.199    0.000    0.928    0.000 blocks.py:3021(make_block)\n",
       "    65564    0.191    0.000    4.689    0.000 base.py:544(_shallow_copy_with_infer)\n",
       "    44244    0.184    0.000    3.754    0.000 blocks.py:1271(take_nd)\n",
       "   109495    0.183    0.000    0.345    0.000 base.py:505(_get_attributes_dict)\n",
       "   174982    0.183    0.000    0.798    0.000 dtypes.py:917(is_dtype)\n",
       "   393012    0.183    0.000    1.275    0.000 common.py:542(is_categorical_dtype)\n",
       "   375014    0.180    0.000    0.272    0.000 inference.py:358(is_hashable)\n",
       "438542/329174    0.178    0.000    1.530    0.000 _asarray.py:16(asarray)\n",
       "    22112    0.173    0.000    9.697    0.000 generic.py:3300(take)\n",
       "    44086    0.172    0.000    0.470    0.000 frame.py:414(__init__)\n",
       "    21977    0.172    0.000    0.413    0.000 base.py:1656(is_unique)\n",
       "87253/87219    0.172    0.000    1.079    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
       "   131508    0.168    0.000    0.652    0.000 dtypes.py:1124(is_dtype)\n",
       "    43461    0.166    0.000    3.198    0.000 concat.py:173(get_reindexed_values)\n",
       "    21718    0.166    0.000   14.095    0.001 interval.py:188(_simple_new)\n",
       "     15/1    0.166    0.011   53.979   53.979 <ipython-input-20-7745f02ab811>:27(evaluate)\n",
       "    87510    0.164    0.000    5.092    0.000 numeric.py:107(_shallow_copy)\n",
       "    88251    0.164    0.000    0.164    0.000 {built-in method numpy.arange}\n",
       "   699812    0.164    0.000    0.164    0.000 blocks.py:339(dtype)\n",
       "    43589    0.164    0.000    3.065    0.000 nanops.py:95(f)\n",
       "    21950    0.162    0.000    2.741    0.000 managers.py:368(apply)\n",
       "   240306    0.161    0.000    0.389    0.000 base.py:5394(maybe_extract_name)\n",
       "   217814    0.158    0.000    0.158    0.000 {built-in method numpy.seterrobj}\n",
       "       24    0.158    0.007    0.158    0.007 {method 'factorize' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
       "   240973    0.157    0.000    0.314    0.000 base.py:3639(values)\n",
       "    43589    0.157    0.000    0.324    0.000 nanops.py:153(_has_infs)\n",
       "   531744    0.156    0.000    0.405    0.000 abc.py:137(__instancecheck__)\n",
       "   241031    0.156    0.000    0.156    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "   155730    0.155    0.000    5.443    0.000 base.py:5294(ensure_index)\n",
       "    68086    0.147    0.000    0.147    0.000 generic.py:190(__init__)\n",
       "    69472    0.143    0.000    0.720    0.000 common.py:99(is_bool_indexer)\n",
       "   130863    0.141    0.000    0.334    0.000 common.py:252(is_sparse)\n",
       "    43927    0.141    0.000    0.624    0.000 base.py:526(_shallow_copy)\n",
       "        4    0.141    0.035    0.141    0.035 {method 'get_labels_groupby' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "    22110    0.140    0.000    0.140    0.000 {pandas._libs.algos.take_2d_axis1_object_object}\n",
       "    43589    0.139    0.000    4.861    0.000 generic.py:11193(stat_func)\n",
       "   615881    0.139    0.000    0.139    0.000 managers.py:1520(_block)\n",
       "    21718    0.137    0.000    0.334    0.000 nanfunctions.py:230(nanmin)\n",
       "   131059    0.136    0.000    0.158    0.000 base.py:3898(__contains__)\n",
       "   462651    0.133    0.000    0.433    0.000 managers.py:165(<genexpr>)\n",
       "    87178    0.128    0.000    0.396    0.000 {method 'any' of 'numpy.generic' objects}\n",
       "   153288    0.127    0.000    0.384    0.000 common.py:685(is_dtype_equal)\n",
       "   111729    0.126    0.000    1.039    0.000 blocks.py:275(make_block_same_class)\n",
       "    21871    0.124    0.000    1.258    0.000 reduce.py:57(nanmax)\n",
       "   108907    0.124    0.000    0.623    0.000 _ufunc_config.py:446(__exit__)\n",
       "   219565    0.123    0.000    0.796    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
       "      201    0.122    0.001    0.123    0.001 {pandas._libs.lib.infer_dtype}\n",
       "   284066    0.122    0.000    0.920    0.000 common.py:472(is_period_dtype)\n",
       "   153214    0.121    0.000    0.168    0.000 common.py:216(<lambda>)\n",
       "    87627    0.119    0.000    1.497    0.000 generic.py:3581(_get_item_cache)\n",
       "    21718    0.119    0.000   15.230    0.001 interval.py:288(from_arrays)\n",
       "    21718    0.118    0.000    2.060    0.000 interval.py:1304(overlaps)\n",
       "   306743    0.118    0.000    0.941    0.000 _methods.py:44(_any)\n",
       "   108907    0.115    0.000    0.743    0.000 _ufunc_config.py:441(__enter__)\n",
       "    44219    0.115    0.000    0.187    0.000 numpy_.py:138(__init__)\n",
       "       32    0.115    0.004    0.115    0.004 {method 'factorize' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "   218870    0.115    0.000    0.115    0.000 {method 'format' of 'str' objects}\n",
       "    23577    0.114    0.000    0.457    0.000 managers.py:979(iget)\n",
       "   108907    0.111    0.000    0.145    0.000 _ufunc_config.py:437(__init__)\n",
       "506130/506113    0.110    0.000    0.112    0.000 {built-in method builtins.hash}\n",
       "   355275    0.109    0.000    0.109    0.000 {method 'get' of 'dict' objects}\n",
       "    43934    0.108    0.000    0.108    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "   109197    0.107    0.000    0.365    0.000 common.py:830(is_signed_integer_dtype)\n",
       "    43917    0.106    0.000    0.205    0.000 blocks.py:3047(_extend_blocks)\n",
       "    43589    0.105    0.000    0.114    0.000 warnings.py:474(__enter__)\n",
       "    22112    0.104    0.000   10.529    0.000 generic.py:3399(_take_with_is_copy)\n",
       "   240592    0.104    0.000    0.756    0.000 common.py:506(is_interval_dtype)\n",
       "    22123    0.103    0.000    0.424    0.000 indexers.py:277(check_array_indexer)\n",
       "    227/1    0.102    0.000   54.130   54.130 {built-in method builtins.exec}\n",
       "    65179    0.102    0.000    1.140    0.000 concat.py:145(is_na)\n",
       "    44097    0.102    0.000    1.427    0.000 managers.py:655(_consolidate_check)\n",
       "    66369    0.101    0.000    0.575    0.000 base.py:4047(equals)\n",
       "   218302    0.099    0.000    1.259    0.000 common.py:987(is_datetime64_any_dtype)\n",
       "    22146    0.098    0.000    0.360    0.000 managers.py:329(_verify_integrity)\n",
       "    86949    0.096    0.000    0.493    0.000 common.py:575(is_string_dtype)\n",
       "    65898    0.096    0.000    0.130    0.000 generic.py:396(_get_axis_number)\n",
       "   112199    0.095    0.000    0.110    0.000 blocks.py:251(mgr_locs)\n",
       "    87064    0.095    0.000    0.220    0.000 common.py:1108(is_datetime_or_timedelta_dtype)\n",
       "   307910    0.094    0.000    0.094    0.000 _dtype.py:36(_kind_name)\n",
       "    87827    0.092    0.000    0.165    0.000 {pandas._libs.lib.values_from_object}\n",
       "   174739    0.092    0.000    0.092    0.000 base.py:592(_reset_identity)\n",
       "   441505    0.092    0.000    0.092    0.000 blocks.py:247(mgr_locs)\n",
       "    21947    0.091    0.000    3.928    0.000 generic.py:5706(copy)\n",
       "    87717    0.091    0.000    0.373    0.000 cast.py:503(_ensure_dtype_type)\n",
       "   218230    0.091    0.000    0.091    0.000 {built-in method __new__ of type object at 0x5650d4a49240}\n",
       "   435628    0.090    0.000    0.090    0.000 {built-in method numpy.geterrobj}\n",
       "    22105    0.089    0.000   11.215    0.001 frame.py:2824(_getitem_bool_array)\n",
       "65154/43436    0.089    0.000    1.896    0.000 {built-in method _operator.lt}\n",
       "    22119    0.089    0.000    6.174    0.000 managers.py:1224(reindex_indexer)\n",
       "    21718    0.088    0.000    0.703    0.000 reduce.py:50(nanmin)\n",
       "    65203    0.086    0.000    1.226    0.000 concat.py:388(<genexpr>)\n",
       "    43461    0.085    0.000    0.172    0.000 concat.py:126(needs_filling)\n",
       "    21756    0.084    0.000    0.084    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
       "    22109    0.082    0.000    3.846    0.000 managers.py:1260(<listcomp>)\n",
       "    43454    0.082    0.000    1.739    0.000 missing.py:299(notna)\n",
       "    43589    0.081    0.000    0.081    0.000 {method 'remove' of 'list' objects}\n",
       "    44582    0.078    0.000    0.078    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
       "    44617    0.077    0.000    0.248    0.000 blocks.py:2585(__init__)\n",
       "    43823    0.076    0.000    0.629    0.000 series.py:707(__array__)\n",
       "    44485    0.076    0.000    0.105    0.000 generic.py:5235(__finalize__)\n",
       "   108705    0.075    0.000    0.427    0.000 common.py:1647(_is_dtype)\n",
       "24000/23999    0.073    0.000    0.462    0.000 series.py:183(__init__)\n",
       "    87278    0.072    0.000    0.350    0.000 common.py:1401(is_float_dtype)\n",
       "    43436    0.070    0.000    0.559    0.000 interval.py:1337(maybe_convert_platform_interval)\n",
       "    43898    0.070    0.000    0.744    0.000 base.py:660(view)\n",
       "    21949    0.070    0.000    3.632    0.000 managers.py:766(copy)\n",
       "    43589    0.069    0.000    0.505    0.000 nanops.py:132(_bn_ok_dtype)\n",
       "   109495    0.069    0.000    0.162    0.000 base.py:509(<dictcomp>)\n",
       "   153446    0.069    0.000    2.532    0.000 missing.py:49(isna)\n",
       "    22281    0.067    0.000    0.646    0.000 managers.py:950(get)\n",
       "    23999    0.067    0.000    0.120    0.000 managers.py:1467(__init__)\n",
       "    88200    0.066    0.000    0.066    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
       "    21986    0.066    0.000    0.239    0.000 base.py:602(_engine)\n",
       "    43589    0.066    0.000    0.072    0.000 warnings.py:493(__exit__)\n",
       "    21718    0.065    0.000    0.065    0.000 {built-in method _operator.le}\n",
       "       32    0.063    0.002    0.102    0.003 concat.py:434(combine_concat_plans)\n",
       "   112039    0.063    0.000    0.099    0.000 series.py:428(name)\n",
       "    22117    0.062    0.000    1.892    0.000 base.py:744(take)\n",
       "    69951    0.061    0.000    0.085    0.000 generic.py:409(_get_axis_name)\n",
       "    43589    0.060    0.000    0.508    0.000 warnings.py:165(simplefilter)\n",
       "    21718    0.060    0.000    0.179    0.000 interval.py:242(_simple_new)\n",
       "    22281    0.059    0.000    0.630    0.000 frame.py:3066(_box_item_values)\n",
       "    44080    0.059    0.000    0.068    0.000 generic.py:219(_init_mgr)\n",
       "    44219    0.059    0.000    0.059    0.000 numpy_.py:42(__init__)\n",
       "    23577    0.058    0.000    0.466    0.000 frame.py:3073(_box_col_values)\n",
       "   155115    0.058    0.000    0.078    0.000 managers.py:167(ndim)\n",
       "    44095    0.057    0.000    0.109    0.000 managers.py:128(<listcomp>)\n",
       "    43436    0.057    0.000    0.164    0.000 cast.py:70(maybe_convert_platform)\n",
       "    44097    0.057    0.000    1.313    0.000 managers.py:656(<listcomp>)\n",
       "    21718    0.057    0.000    0.081    0.000 contextlib.py:116(__exit__)\n",
       "    43843    0.056    0.000    0.203    0.000 generic.py:5331(_protect_consolidate)\n",
       "    43906    0.056    0.000    0.545    0.000 blocks.py:694(copy)\n",
       "    53288    0.055    0.000    0.103    0.000 {pandas._libs.lib.is_list_like}\n",
       "    21718    0.054    0.000    0.062    0.000 contextlib.py:81(__init__)\n",
       "    43439    0.054    0.000    0.260    0.000 base.py:3950(_can_hold_identifiers_and_holds_name)\n",
       "   112196    0.053    0.000    0.053    0.000 blocks.py:129(_check_ndim)\n",
       "   112252    0.052    0.000    0.068    0.000 common.py:335(apply_if_callable)\n",
       "    21718    0.052    0.000   14.706    0.001 interval.py:362(from_arrays)\n",
       "    43898    0.051    0.000    0.795    0.000 managers.py:784(copy_func)\n",
       "    21871    0.051    0.000    1.310    0.000 {built-in method bottleneck.reduce.nanmax}\n",
       "   174320    0.051    0.000    0.051    0.000 {method 'pop' of 'dict' objects}\n",
       "    86949    0.050    0.000    0.291    0.000 common.py:605(condition)\n",
       "    47670    0.049    0.000    0.086    0.000 managers.py:1565(internal_values)\n",
       "   130321    0.049    0.000    0.062    0.000 {built-in method builtins.next}\n",
       "    22132    0.049    0.000    0.049    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
       "    88958    0.048    0.000    0.212    0.000 construction.py:337(extract_array)\n",
       "    24000    0.048    0.000    0.088    0.000 series.py:376(_set_axis)\n",
       "    69941    0.048    0.000    0.165    0.000 generic.py:422(_get_axis)\n",
       "    43589    0.048    0.000    0.048    0.000 warnings.py:453(__init__)\n",
       "    44219    0.047    0.000    0.234    0.000 blocks.py:219(array_values)\n",
       "    43474    0.047    0.000    0.518    0.000 common.py:1282(needs_i8_conversion)\n",
       "    65181    0.047    0.000    0.350    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "    43843    0.046    0.000    0.138    0.000 generic.py:5344(f)\n",
       "    44219    0.046    0.000    0.290    0.000 series.py:515(array)\n",
       "    43458    0.045    0.000    0.101    0.000 <__array_function__ internals>:2(ndim)\n",
       "    22123    0.045    0.000    0.533    0.000 indexing.py:2285(check_bool_indexer)\n",
       "   131056    0.043    0.000    0.043    0.000 base.py:638(dtype)\n",
       "   153098    0.043    0.000    0.043    0.000 base.py:1182(name)\n",
       "        7    0.042    0.006    8.262    1.180 managers.py:1988(concatenate_block_managers)\n",
       "    22144    0.040    0.000    0.076    0.000 missing.py:402(array_equivalent)\n",
       "        1    0.040    0.040    0.040    0.040 {method 'factorize' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
       "    44581    0.040    0.000    0.118    0.000 base.py:2637(get_loc)\n",
       "   109623    0.039    0.000    0.039    0.000 {method 'update' of 'dict' objects}\n",
       "    22113    0.039    0.000    0.039    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "    88252    0.038    0.000    0.038    0.000 {built-in method pandas._libs.missing.checknull}\n",
       "    87827    0.038    0.000    0.038    0.000 {pandas._libs.algos.ensure_int64}\n",
       "    22103    0.038    0.000    0.065    0.000 generic.py:3627(_set_is_copy)\n",
       "    43823    0.038    0.000    0.074    0.000 numpy_.py:183(__array__)\n",
       "    21733    0.037    0.000    0.098    0.000 base.py:1186(name)\n",
       "    21718    0.037    0.000    0.052    0.000 contextlib.py:107(__enter__)\n",
       "   110045    0.037    0.000    0.037    0.000 managers.py:647(is_consolidated)\n",
       "    65203    0.037    0.000    0.037    0.000 concat.py:384(<genexpr>)\n",
       "    21718    0.037    0.000    0.037    0.000 {built-in method _operator.gt}\n",
       "    43443    0.036    0.000    0.146    0.000 base.py:1679(is_object)\n",
       "    21718    0.036    0.000    2.095    0.000 extension.py:79(method)\n",
       "    24000    0.035    0.000    0.035    0.000 series.py:403(_set_subtyp)\n",
       "    66447    0.035    0.000    0.053    0.000 managers.py:331(<genexpr>)\n",
       "   153214    0.035    0.000    0.035    0.000 common.py:211(classes_and_not_datetimelike)\n",
       "    47670    0.035    0.000    0.120    0.000 series.py:480(_values)\n",
       "    21871    0.034    0.000    0.623    0.000 <__array_function__ internals>:2(nanmax)\n",
       "    21718    0.034    0.000    0.737    0.000 {built-in method bottleneck.reduce.nanmin}\n",
       "    43464    0.034    0.000    0.105    0.000 common.py:1326(is_numeric_dtype)\n",
       "    22113    0.033    0.000    0.039    0.000 indexing.py:2260(convert_to_index_sliceable)\n",
       "       23    0.033    0.001    3.231    0.140 concat.py:247(<listcomp>)\n",
       "    43807    0.032    0.000    0.032    0.000 {method 'insert' of 'list' objects}\n",
       "    66203    0.032    0.000    0.057    0.000 managers.py:943(_consolidate_inplace)\n",
       "   218537    0.032    0.000    0.032    0.000 {method 'append' of 'list' objects}\n",
       "    22125    0.032    0.000    0.084    0.000 generic.py:426(_get_block_manager_axis)\n",
       "    43843    0.031    0.000    0.234    0.000 generic.py:5341(_consolidate_inplace)\n",
       "    21718    0.031    0.000    0.093    0.000 contextlib.py:237(helper)\n",
       "    65180    0.029    0.000    0.029    0.000 concat.py:115(__init__)\n",
       "   111696    0.029    0.000    0.029    0.000 {pandas._libs.lib.item_from_zerodim}\n",
       "    65181    0.029    0.000    0.303    0.000 _methods.py:47(_all)\n",
       "    66369    0.028    0.000    0.043    0.000 base.py:573(is_)\n",
       "    23577    0.028    0.000    0.069    0.000 generic.py:3227(_set_as_cached)\n",
       "    43461    0.028    0.000    0.214    0.000 concat.py:135(dtype)\n",
       "        5    0.028    0.006    0.965    0.193 concat.py:292(__init__)\n",
       "        2    0.028    0.014    0.028    0.014 {pandas._libs.writers.write_csv_rows}\n",
       "    24784    0.027    0.000    0.044    0.000 series.py:432(name)\n",
       "    43466    0.027    0.000    0.123    0.000 blocks.py:225(get_values)\n",
       "    44890    0.027    0.000    0.325    0.000 {built-in method builtins.any}\n",
       "    43766    0.027    0.000    0.027    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "    43460    0.026    0.000    0.044    0.000 generic.py:491(_info_axis)\n",
       "       12    0.026    0.002    0.183    0.015 sorting.py:21(get_group_index)\n",
       "       10    0.026    0.003    0.026    0.003 {pandas._libs.hashtable.duplicated_int64}\n",
       "    22015    0.026    0.000    0.153    0.000 base.py:862(_ndarray_values)\n",
       "    21949    0.026    0.000    0.821    0.000 managers.py:790(<listcomp>)\n",
       "    43843    0.026    0.000    0.045    0.000 managers.py:927(consolidate)\n",
       "    65702    0.025    0.000    0.025    0.000 function.py:42(__call__)\n",
       "    87694    0.025    0.000    0.025    0.000 blocks.py:243(fill_value)\n",
       "    43879    0.025    0.000    0.078    0.000 {built-in method builtins.sum}\n",
       "    21718    0.023    0.000    0.385    0.000 <__array_function__ internals>:2(nanmin)\n",
       "       12    0.023    0.002    0.044    0.004 managers.py:1828(_stack_arrays)\n",
       "    23577    0.023    0.000    0.023    0.000 blocks.py:365(iget)\n",
       "   111379    0.023    0.000    0.023    0.000 {pandas._libs.lib.is_float}\n",
       "    23625    0.022    0.000    0.029    0.000 common.py:156(cast_scalar_indexer)\n",
       "    68438    0.022    0.000    0.022    0.000 managers.py:232(items)\n",
       "   156170    0.021    0.000    0.021    0.000 {built-in method builtins.callable}\n",
       "    65225    0.021    0.000    0.021    0.000 {method 'copy' of 'dict' objects}\n",
       "    44288    0.021    0.000    0.072    0.000 base.py:3701(_internal_get_values)\n",
       "   130767    0.021    0.000    0.021    0.000 {built-in method _warnings._filters_mutated}\n",
       "    44478    0.021    0.000    0.021    0.000 generic.py:238(attrs)\n",
       "        4    0.021    0.005    0.021    0.005 {pandas._libs.hashtable.ismember_object}\n",
       "   109017    0.020    0.000    0.020    0.000 numeric.py:83(_validate_dtype)\n",
       "    21726    0.020    0.000    0.054    0.000 frame.py:532(shape)\n",
       "    47670    0.020    0.000    0.020    0.000 blocks.py:213(internal_values)\n",
       "    86872    0.020    0.000    0.020    0.000 interval.py:966(left)\n",
       "   109337    0.020    0.000    0.020    0.000 {method 'items' of 'dict' objects}\n",
       "    26096    0.020    0.000    0.056    0.000 inference.py:220(is_array_like)\n",
       "    21727    0.019    0.000    0.037    0.000 base.py:621(__array__)\n",
       "    21775    0.019    0.000    0.241    0.000 common.py:608(is_excluded_dtype)\n",
       "    65325    0.019    0.000    0.207    0.000 common.py:613(<genexpr>)\n",
       "    86872    0.019    0.000    0.019    0.000 interval.py:974(right)\n",
       "      216    0.019    0.000    0.127    0.001 __init__.py:316(namedtuple)\n",
       "    21787    0.019    0.000    0.044    0.000 frame.py:1037(__len__)\n",
       "    21718    0.018    0.000    0.038    0.000 __init__.py:403(_make)\n",
       "        2    0.018    0.009    0.018    0.009 {built-in method io.open}\n",
       "     2433    0.018    0.000    0.018    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
       "       43    0.016    0.000    0.017    0.000 {method 'execute' of 'psycopg2.extensions.cursor' objects}\n",
       "    69831    0.016    0.000    0.016    0.000 {pandas._libs.lib.is_integer}\n",
       "        1    0.016    0.016    0.016    0.016 parsers.py:1864(__init__)\n",
       "        1    0.016    0.016    0.016    0.016 {built-in method psycopg2._psycopg._connect}\n",
       "       16    0.015    0.001    0.015    0.001 {method 'factorize' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "        4    0.015    0.004    2.134    0.534 <ipython-input-17-95a0def431e1>:27(get_sys_data)\n",
       "  136/135    0.015    0.000    1.286    0.010 {built-in method builtins.all}\n",
       "    87544    0.015    0.000    0.015    0.000 base.py:1383(nlevels)\n",
       "    44308    0.015    0.000    0.015    0.000 blocks.py:335(shape)\n",
       "    21736    0.015    0.000    0.027    0.000 managers.py:199(_is_single_block)\n",
       "    86882    0.015    0.000    0.037    0.000 concat.py:459(_next_or_none)\n",
       "        8    0.015    0.002    0.015    0.002 {method 'factorize' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "    43458    0.014    0.000    0.014    0.000 fromnumeric.py:3037(ndim)\n",
       "    43436    0.014    0.000    0.014    0.000 interval.py:982(closed)\n",
       "       58    0.014    0.000    0.015    0.000 sorting.py:62(maybe_lift)\n",
       "    43450    0.014    0.000    0.083    0.000 concat.py:120(<genexpr>)\n",
       "        5    0.013    0.003    0.023    0.005 api.py:93(_get_distinct_objs)\n",
       "   111681    0.013    0.000    0.013    0.000 {method 'add' of 'set' objects}\n",
       "    21726    0.013    0.000    0.086    0.000 generic.py:5349(_consolidate)\n",
       "        7    0.013    0.002    0.905    0.129 managers.py:2001(<listcomp>)\n",
       "    44071    0.013    0.000    0.013    0.000 frame.py:399(_constructor)\n",
       "    43436    0.013    0.000    0.013    0.000 _exceptions.py:5(rewrite_exception)\n",
       "    21995    0.013    0.000    0.013    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "        1    0.012    0.012    0.042    0.042 api.py:278(<setcomp>)\n",
       "    21755    0.011    0.000    0.011    0.000 {pandas._libs.internals.get_blkno_placements}\n",
       "    22149    0.011    0.000    0.093    0.000 _asarray.py:88(asanyarray)\n",
       "        5    0.011    0.002    0.011    0.002 concat.py:559(<listcomp>)\n",
       "    43458    0.011    0.000    0.011    0.000 fromnumeric.py:3033(_ndim_dispatcher)\n",
       "    21756    0.010    0.000    0.040    0.000 common.py:1369(is_string_like_dtype)\n",
       "        1    0.010    0.010    1.196    1.196 parsers.py:416(_read)\n",
       "     1296    0.010    0.000    0.108    0.000 indexing.py:1363(_getitem_lowerdim)\n",
       "        4    0.010    0.002    0.010    0.002 {method 'close' of '_io.TextIOWrapper' objects}\n",
       "    23032    0.009    0.000    0.019    0.000 generic.py:515(ndim)\n",
       "        1    0.009    0.009    1.818    1.818 <ipython-input-14-ce7cc08b5375>:1(get_metric_data)\n",
       "    22225    0.009    0.000    0.009    0.000 {pandas._libs.algos.ensure_platform_int}\n",
       "        5    0.009    0.002    0.042    0.008 api.py:89(<listcomp>)\n",
       "        5    0.009    0.002    0.066    0.013 concat.py:378(<listcomp>)\n",
       "     1750    0.009    0.000    0.022    0.000 base.py:1035(__iter__)\n",
       "    21774    0.008    0.000    0.008    0.000 {built-in method builtins.max}\n",
       "    21765    0.008    0.000    0.008    0.000 concat.py:391(<genexpr>)\n",
       "    21782    0.008    0.000    0.013    0.000 base.py:1217(_get_names)\n",
       "    21723    0.007    0.000    0.017    0.000 common.py:195(any_not_none)\n",
       "    23152    0.006    0.000    0.006    0.000 base.py:3671(_values)\n",
       "       21    0.006    0.000    0.006    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "    21871    0.006    0.000    0.006    0.000 nanfunctions.py:341(_nanmax_dispatcher)\n",
       "    21756    0.006    0.000    0.006    0.000 common.py:1398(<lambda>)\n",
       "        1    0.006    0.006    0.006    0.006 managers.py:2018(<listcomp>)\n",
       "        2    0.006    0.003    0.006    0.003 managers.py:1959(<listcomp>)\n",
       "    21718    0.005    0.000    0.005    0.000 nanfunctions.py:226(_nanmin_dispatcher)\n",
       "        1    0.005    0.005    0.005    0.005 {method 'factorize' of 'pandas._libs.hashtable.Float64HashTable' objects}\n",
       "    23032    0.005    0.000    0.005    0.000 base.py:635(ndim)\n",
       "    43466    0.005    0.000    0.005    0.000 {method 'values' of 'dict' objects}\n",
       "        2    0.005    0.002    0.065    0.032 api.py:149(union_indexes)\n",
       "        4    0.005    0.001    0.011    0.003 numeric.py:152(<listcomp>)\n",
       "    21760    0.005    0.000    0.007    0.000 _validators.py:207(validate_bool_kwarg)\n",
       "    21950    0.005    0.000    0.005    0.000 managers.py:419(<dictcomp>)\n",
       "    23986    0.005    0.000    0.005    0.000 numeric.py:155(is_all_dates)\n",
       "       10    0.005    0.000    0.005    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
       "     1296    0.005    0.000    0.058    0.000 frame.py:2722(_ixs)\n",
       "       51    0.004    0.000    0.004    0.000 {built-in method posix.stat}\n",
       "     1296    0.004    0.000    0.147    0.000 indexing.py:1753(__getitem__)\n",
       "    21979    0.004    0.000    0.004    0.000 base.py:609(<lambda>)\n",
       "      216    0.004    0.000    0.305    0.001 frame.py:955(itertuples)\n",
       "        1    0.004    0.004    0.004    0.004 blocks.py:359(<listcomp>)\n",
       "    43448    0.004    0.000    0.004    0.000 common.py:199(<genexpr>)\n",
       "    43466    0.004    0.000    0.004    0.000 {built-in method builtins.id}\n",
       "      374    0.004    0.000    0.366    0.001 array_ops.py:202(comparison_op)\n",
       "     1296    0.004    0.000    0.076    0.000 indexing.py:2115(_getitem_axis)\n",
       "      451    0.004    0.000    0.073    0.000 construction.py:388(sanitize_array)\n",
       "      515    0.003    0.000    0.019    0.000 blocks.py:2975(get_block_type)\n",
       "        5    0.003    0.001    9.595    1.919 concat.py:65(concat)\n",
       "        6    0.003    0.001    0.009    0.001 base.py:3987(<setcomp>)\n",
       "     2592    0.003    0.000    0.023    0.000 indexing.py:1975(_validate_key)\n",
       "        2    0.003    0.002    0.003    0.002 {pandas._libs.join.inner_join}\n",
       "      450    0.003    0.000    0.005    0.000 cast.py:1097(maybe_castable)\n",
       "     2592    0.003    0.000    0.011    0.000 indexing.py:2044(_validate_integer)\n",
       "     1296    0.003    0.000    0.005    0.000 indexing.py:2015(_is_scalar_access)\n",
       "       10    0.003    0.000    0.620    0.062 frame.py:4829(duplicated)\n",
       "     1512    0.003    0.000    0.151    0.000 frame.py:1026(<genexpr>)\n",
       "        6    0.003    0.000    0.617    0.103 base.py:3963(append)\n",
       "      374    0.003    0.000    0.431    0.001 __init__.py:515(wrapper)\n",
       "       20    0.003    0.000    0.003    0.000 {method 'rollback' of 'psycopg2.extensions.connection' objects}\n",
       "     3888    0.002    0.000    0.004    0.000 indexing.py:1755(<genexpr>)\n",
       "       10    0.002    0.000    0.697    0.070 frame.py:4772(drop_duplicates)\n",
       "     1296    0.002    0.000    0.025    0.000 indexing.py:694(_has_valid_tuple)\n",
       "       18    0.002    0.000    0.002    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
       "     2940    0.002    0.000    0.003    0.000 base.py:194(construct_from_string)\n",
       "     1296    0.002    0.000    0.008    0.000 indexing.py:709(_is_nested_tuple_indexer)\n",
       "    21731    0.002    0.000    0.002    0.000 common.py:178(<genexpr>)\n",
       "        2    0.002    0.001    0.002    0.001 api.py:242(<setcomp>)\n",
       "    21803    0.002    0.000    0.002    0.000 {pandas._libs.lib.is_bool}\n",
       "     3888    0.002    0.000    0.007    0.000 indexers.py:22(is_list_like_indexer)\n",
       "      375    0.002    0.000    0.054    0.000 __init__.py:445(_construct_result)\n",
       "     1296    0.002    0.000    0.135    0.000 indexing.py:2064(_getitem_tuple)\n",
       "     2592    0.002    0.000    0.004    0.000 indexing.py:2391(is_label_like)\n",
       "      375    0.002    0.000    0.441    0.001 common.py:49(new_method)\n",
       "        9    0.002    0.000    0.002    0.000 numeric.py:2287(array_equal)\n",
       "        9    0.001    0.000    0.001    0.000 {method 'read' of '_io.FileIO' objects}\n",
       "     3888    0.001    0.000    0.004    0.000 indexing.py:715(<genexpr>)\n",
       "        2    0.001    0.001    0.002    0.001 merge.py:1957(_get_join_keys)\n",
       "     1701    0.001    0.000    0.003    0.000 managers.py:314(__len__)\n",
       "     1296    0.001    0.000    0.059    0.000 indexing.py:626(_get_loc)\n",
       "      220    0.001    0.000    0.352    0.002 array_ops.py:42(comp_method_OBJECT_ARRAY)\n",
       "       12    0.001    0.000    0.032    0.003 merge.py:1870(_factorize_keys)\n",
       "       37    0.001    0.000    0.001    0.000 socket.py:342(send)\n",
       "      108    0.001    0.000    0.001    0.000 {built-in method builtins.min}\n",
       "     1296    0.001    0.000    0.001    0.000 common.py:289(is_null_slice)\n",
       "      603    0.001    0.000    0.001    0.000 {built-in method builtins.repr}\n",
       "   323/35    0.001    0.000    0.001    0.000 {built-in method _abc._abc_subclasscheck}\n",
       "      387    0.001    0.000    0.001    0.000 generic.py:1797(__hash__)\n",
       "      451    0.001    0.000    0.008    0.000 construction.py:506(_try_cast)\n",
       "       10    0.001    0.000    0.003    0.000 blocks.py:3079(_merge_blocks)\n",
       "       44    0.001    0.000    0.001    0.000 cast.py:1467(construct_1d_object_array_from_listlike)\n",
       "      396    0.001    0.000    0.001    0.000 numpy_.py:421(to_numpy)\n",
       "     1296    0.001    0.000    0.001    0.000 indexing.py:92(iloc)\n",
       "     3993    0.001    0.000    0.001    0.000 {method 'startswith' of 'str' objects}\n",
       "      375    0.001    0.000    0.004    0.000 dispatch.py:21(should_extension_dispatch)\n",
       "        1    0.001    0.001   54.130   54.130 <ipython-input-27-073236436489>:2(main)\n",
       "     1394    0.001    0.000    0.001    0.000 frame.py:515(axes)\n",
       "        4    0.001    0.000    0.617    0.154 concat.py:586(_concat_indexes)\n",
       "        4    0.001    0.000    0.022    0.005 algorithms.py:390(isin)\n",
       "        9    0.001    0.000    0.001    0.000 {built-in method marshal.loads}\n",
       "      398    0.001    0.000    0.001    0.000 {method 'join' of 'str' objects}\n",
       "      421    0.001    0.000    0.002    0.000 common.py:775(is_integer_dtype)\n",
       "     3240    0.001    0.000    0.001    0.000 {method 'isidentifier' of 'str' objects}\n",
       "      236    0.001    0.000    0.152    0.001 {method 'extend' of 'list' objects}\n",
       "        5    0.001    0.000    0.088    0.018 api.py:107(_get_combined_index)\n",
       "       58    0.001    0.000    0.386    0.007 algorithms.py:456(_factorize_array)\n",
       "       36    0.001    0.000    0.001    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
       "        2    0.001    0.000    0.001    0.000 {method 'put' of 'numpy.ndarray' objects}\n",
       "      406    0.001    0.000    0.002    0.000 construction.py:570(is_empty_data)\n",
       "      294    0.001    0.000    0.001    0.000 dtypes.py:1072(construct_from_string)\n",
       "     1728    0.001    0.000    0.001    0.000 __init__.py:388(<genexpr>)\n",
       "      380    0.001    0.000    0.001    0.000 __init__.py:98(get_op_result_name)\n",
       "     3240    0.001    0.000    0.001    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "        1    0.001    0.001    0.001    0.001 range.py:355(get_indexer)\n",
       "        1    0.001    0.001    0.001    0.001 {method 'close' of 'pandas._libs.parsers.TextReader' objects}\n",
       "      234    0.001    0.000    0.001    0.000 {method 'replace' of 'str' objects}\n",
       "        1    0.001    0.001    0.001    0.001 {method 'permutation' of 'numpy.random.mtrand.RandomState' objects}\n",
       "      519    0.001    0.000    0.004    0.000 common.py:339(is_categorical)\n",
       "       19    0.001    0.000    0.002    0.000 managers.py:1037(set)\n",
       "       18    0.000    0.000    0.001    0.000 {pandas._libs.lib.clean_index_list}\n",
       "       19    0.000    0.000    0.001    0.000 expressions.py:178(binop)\n",
       "      294    0.000    0.000    0.001    0.000 dtypes.py:867(construct_from_string)\n",
       "       15    0.000    0.000    0.047    0.003 managers.py:1700(form_blocks)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _imp.create_dynamic}\n",
       "   234/18    0.000    0.000    0.001    0.000 arrayprint.py:738(recurser)\n",
       "       30    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
       "       10    0.000    0.000    0.007    0.001 managers.py:1274(_slice_take_blocks_ax0)\n",
       "        1    0.000    0.000    0.001    0.001 necompiler.py:765(evaluate)\n",
       "      160    0.000    0.000    0.002    0.000 common.py:224(asarray_tuplesafe)\n",
       "       58    0.000    0.000    0.405    0.007 algorithms.py:585(factorize)\n",
       "       87    0.000    0.000    0.002    0.000 cast.py:1218(maybe_cast_to_datetime)\n",
       "       58    0.000    0.000    0.066    0.001 algorithms.py:264(_check_object_for_strings)\n",
       "       89    0.000    0.000    0.002    0.000 cast.py:1111(maybe_infer_to_datetimelike)\n",
       "       23    0.000    0.000    5.904    0.257 concat.py:236(concatenate_join_units)\n",
       "      294    0.000    0.000    0.001    0.000 dtypes.py:715(construct_from_string)\n",
       "      294    0.000    0.000    0.000    0.000 dtypes.py:334(construct_from_string)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.groupsort_indexer}\n",
       "      117    0.000    0.000    0.008    0.000 frame.py:890(items)\n",
       "        9    0.000    0.000    0.074    0.008 <ipython-input-5-f3885a2e711d>:8(__init__)\n",
       "      196    0.000    0.000    0.000    0.000 _internal.py:830(npy_ctypes_check)\n",
       "      124    0.000    0.000    0.003    0.000 algorithms.py:64(_ensure_data)\n",
       "      2/1    0.000    0.000   54.130   54.130 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numexpr.interpreter._set_num_threads}\n",
       "       28    0.000    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:1356(find_spec)\n",
       "      133    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "      317    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
       "      405    0.000    0.000    0.002    0.000 series.py:548(__len__)\n",
       "       26    0.000    0.000    0.000    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
       "       43    0.000    0.000    0.000    0.000 {method 'cursor' of 'psycopg2.extensions.connection' objects}\n",
       "       26    0.000    0.000    0.005    0.000 base.py:2706(get_indexer)\n",
       "       15    0.000    0.000    0.001    0.000 {built-in method builtins.__build_class__}\n",
       "       54    0.000    0.000    0.397    0.007 frame.py:4861(f)\n",
       "       63    0.000    0.000    0.002    0.000 base.py:5464(_maybe_cast_data_without_dtype)\n",
       "       21    0.000    0.000    0.011    0.001 base.py:1157(_execute_context)\n",
       "      218    0.000    0.000    0.000    0.000 {built-in method sys._getframe}\n",
       "       18    0.000    0.000    0.028    0.002 base.py:770(_checkout)\n",
       "       58    0.000    0.000    0.011    0.000 algorithms.py:171(_reconstruct_data)\n",
       "      294    0.000    0.000    0.000    0.000 dtype.py:182(construct_from_string)\n",
       "      411    0.000    0.000    0.000    0.000 series.py:359(_constructor)\n",
       "       35    0.000    0.000    0.001    0.000 {method 'sub' of 're.Pattern' objects}\n",
       "        4    0.000    0.000    0.021    0.005 numeric.py:151(_concat_same_dtype)\n",
       "       10    0.000    0.000    0.000    0.000 {built-in method _operator.inv}\n",
       "      216    0.000    0.000    0.000    0.000 {built-in method sys.intern}\n",
       "       80    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
       "       30    0.000    0.000    0.000    0.000 _asarray.py:223(require)\n",
       "       18    0.000    0.000    0.003    0.000 base.py:4373(get_value)\n",
       "      216    0.000    0.000    0.000    0.000 arrayprint.py:715(_extendLine)\n",
       "       18    0.000    0.000    0.002    0.000 {method 'get_value' of 'pandas._libs.index.IndexEngine' objects}\n",
       "        9    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:914(get_data)\n",
       "       19    0.000    0.000    0.001    0.000 base.py:69(__init__)\n",
       "        9    0.000    0.000    0.001    0.000 default.py:725(_init_compiled)\n",
       "       66    0.000    0.000    0.001    0.000 base.py:1010(tolist)\n",
       "        1    0.000    0.000    0.015    0.015 blocks.py:354(concat_same_type)\n",
       "     10/1    0.000    0.000    0.000    0.000 sre_parse.py:469(_parse)\n",
       "       69    0.000    0.000    0.000    0.000 result.py:461(_colnames_from_description)\n",
       "       58    0.000    0.000    0.067    0.001 algorithms.py:255(_get_data_algo)\n",
       "      179    0.000    0.000    0.000    0.000 weakref.py:395(__getitem__)\n",
       "       64    0.000    0.000    0.006    0.000 frame.py:4887(<genexpr>)\n",
       "        4    0.000    0.000    0.146    0.036 sorting.py:373(compress_group_index)\n",
       "       21    0.000    0.000    0.001    0.000 result.py:215(__init__)\n",
       "        5    0.000    0.000    0.760    0.152 concat.py:516(<listcomp>)\n",
       "       34    0.000    0.000    0.002    0.000 iostream.py:384(write)\n",
       "        5    0.000    0.000    0.131    0.026 concat.py:520(_get_comb_axis)\n",
       "       24    0.000    0.000    0.002    0.000 generic.py:1649(_get_label_or_level_values)\n",
       "       18    0.000    0.000    0.008    0.000 series.py:868(__getitem__)\n",
       "        2    0.000    0.000    0.017    0.009 sorting.py:192(lexsort_indexer)\n",
       "       18    0.000    0.000    0.000    0.000 elements.py:932(__init__)\n",
       "       10    0.000    0.000    0.001    0.000 base.py:2436(difference)\n",
       "        9    0.000    0.000    0.000    0.000 schema.py:3782(__init__)\n",
       "       15    0.000    0.000    0.060    0.004 construction.py:300(_homogenize)\n",
       "       66    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "       18    0.000    0.000    0.000    0.000 blocks.py:368(set)\n",
       "       18    0.000    0.000    0.021    0.001 base.py:490(checkout)\n",
       "        7    0.000    0.000    0.005    0.001 indexing.py:1502(_get_listlike_indexer)\n",
       "        9    0.000    0.000    0.061    0.007 sql.py:336(read_sql)\n",
       "    26/12    0.000    0.000    0.000    0.000 langhelpers.py:273(get_cls_kwargs)\n",
       "        5    0.000    0.000    0.131    0.026 api.py:65(get_objs_combined_axis)\n",
       "       18    0.000    0.000    0.001    0.000 arrayprint.py:494(_array2string)\n",
       "       24    0.000    0.000    1.286    0.054 concat.py:375(is_uniform_join_units)\n",
       "       14    0.000    0.000    0.002    0.000 construction.py:331(extract_index)\n",
       "       17    0.000    0.000    0.000    0.000 fromnumeric.py:73(_wrapreduction)\n",
       "        9    0.000    0.000    0.002    0.000 construction.py:488(_list_to_arrays)\n",
       "       37    0.000    0.000    0.001    0.000 iostream.py:197(schedule)\n",
       "       12    0.000    0.000    0.002    0.000 compiler.py:527(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:628(__array_ufunc__)\n",
       "       12    0.000    0.000    0.000    0.000 result.py:1176(process_rows)\n",
       "       47    0.000    0.000    0.091    0.002 <__array_function__ internals>:2(concatenate)\n",
       "       43    0.000    0.000    0.001    0.000 deprecations.py:115(warned)\n",
       "       12    0.000    0.000    0.000    0.000 range.py:83(__new__)\n",
       "        9    0.000    0.000    0.012    0.001 frame.py:1549(from_records)\n",
       "       65    0.000    0.000    0.000    0.000 base.py:5410(_maybe_cast_with_dtype)\n",
       "    60/57    0.000    0.000    0.001    0.000 langhelpers.py:852(__get__)\n",
       "      132    0.000    0.000    0.000    0.000 common.py:887(is_unsigned_integer_dtype)\n",
       "       12    0.000    0.000    0.006    0.000 <frozen importlib._bootstrap>:882(_find_spec)\n",
       "        9    0.000    0.000    0.008    0.001 base.py:2582(has_table)\n",
       "        2    0.000    0.000    0.033    0.016 csvs.py:325(_save_chunk)\n",
       "       44    0.000    0.000    0.001    0.000 range.py:155(_data)\n",
       "      196    0.000    0.000    0.000    0.000 range.py:675(__len__)\n",
       "       18    0.000    0.000    0.002    0.000 arrayprint.py:532(array2string)\n",
       "        3    0.000    0.000    0.000    0.000 function_base.py:4218(delete)\n",
       "       22    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "      114    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
       "      302    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\n",
       "        1    0.000    0.000    0.002    0.002 expressions.py:11(<module>)\n",
       "      146    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:58(<listcomp>)\n",
       "       12    0.000    0.000    0.003    0.000 base.py:3101(reindex)\n",
       "        3    0.000    0.000    0.000    0.000 arraysetops.py:484(in1d)\n",
       "     18/1    0.000    0.000    0.000    0.000 sre_compile.py:71(_compile)\n",
       "        9    0.000    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:793(get_code)\n",
       "        9    0.000    0.000    0.000    0.000 {pandas._libs.lib.to_object_array_tuples}\n",
       "      146    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:56(_path_join)\n",
       "        1    0.000    0.000   53.980   53.980 <ipython-input-25-44ebf3633ec6>:2(get_sys_merge)\n",
       "        9    0.000    0.000    0.007    0.001 base.py:1050(_execute_clauseelement)\n",
       "        5    0.000    0.000    0.003    0.001 managers.py:1875(_consolidate)\n",
       "       18    0.000    0.000    0.000    0.000 arrayprint.py:425(_get_format_function)\n",
       "       50    0.000    0.000    0.000    0.000 managers.py:1568(get_values)\n",
       "       21    0.000    0.000    0.002    0.000 range.py:387(_shallow_copy)\n",
       "       36    0.000    0.000    0.000    0.000 numeric.py:283(full)\n",
       "       35    0.000    0.000    0.000    0.000 threading.py:335(notify)\n",
       "     14/6    0.000    0.000    0.012    0.002 <frozen importlib._bootstrap>:978(_find_and_load)\n",
       "        7    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
       "        2    0.000    0.000    0.033    0.017 csvs.py:308(_save)\n",
       "       23    0.000    0.000    0.002    0.000 generic.py:3998(_update_inplace)\n",
       "       18    0.000    0.000    0.000    0.000 queue.py:135(get)\n",
       "       12    0.000    0.000    0.000    0.000 default.py:953(_init_statement)\n",
       "        1    0.000    0.000   53.979   53.979 <ipython-input-20-7745f02ab811>:1(process_sentence)\n",
       "       34    0.000    0.000    0.000    0.000 generic.py:1553(_is_label_reference)\n",
       "       18    0.000    0.000    0.000    0.000 queue.py:92(put)\n",
       "      114    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n",
       "       18    0.000    0.000    0.029    0.002 base.py:2239(_contextual_connect)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:123(_join)\n",
       "        9    0.000    0.000    0.015    0.002 sql.py:121(_wrap_result)\n",
       "       10    0.000    0.000    0.001    0.000 generic.py:1911(__array_wrap__)\n",
       "        4    0.000    0.000    0.011    0.003 categorical.py:312(__init__)\n",
       "       21    0.000    0.000    0.001    0.000 result.py:738(_init_metadata)\n",
       "       15    0.000    0.000    0.110    0.007 construction.py:56(arrays_to_mgr)\n",
       "        6    0.000    0.000    1.145    0.191 concat.py:72(concat_compat)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1588(is_monotonic_increasing)\n",
       "        1    0.000    0.000    0.000    0.000 hub.py:396(__init__)\n",
       "       18    0.000    0.000    0.003    0.000 base.py:667(_finalize_fairy)\n",
       "       18    0.000    0.000    0.003    0.000 base.py:867(_reset)\n",
       "      203    0.000    0.000    0.000    0.000 weakref.py:435(__contains__)\n",
       "       56    0.000    0.000    0.000    0.000 managers.py:1562(external_values)\n",
       "       23    0.000    0.000    0.001    0.000 generic.py:3255(_maybe_update_cacher)\n",
       "       18    0.000    0.000    0.011    0.001 series.py:4416(dropna)\n",
       "        5    0.000    0.000    0.050    0.010 <ipython-input-6-73f63767e05a>:8(system_semtype_check)\n",
       "        4    0.000    0.000    0.003    0.001 blocks.py:673(to_native_types)\n",
       "       18    0.000    0.000    0.000    0.000 arrayprint.py:372(_get_formatdict)\n",
       "       20    0.000    0.000    0.000    0.000 sqltypes.py:412(__init__)\n",
       "       12    0.000    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:1240(_get_spec)\n",
       "       15    0.000    0.000    0.049    0.003 managers.py:1667(create_block_manager_from_arrays)\n",
       "       18    0.000    0.000    0.003    0.000 managers.py:1538(get_slice)\n",
       "       18    0.000    0.000    0.001    0.000 arrayprint.py:477(wrapper)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:516(checkin)\n",
       "       23    0.000    0.000    0.001    0.000 type_api.py:515(_dialect_info)\n",
       "       18    0.000    0.000    0.004    0.000 series.py:982(_get_values)\n",
       "       40    0.000    0.000    0.000    0.000 blocks.py:169(_consolidate_key)\n",
       "        4    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_int16}\n",
       "   323/35    0.000    0.000    0.001    0.000 abc.py:141(__subclasscheck__)\n",
       "        9    0.000    0.000    0.008    0.001 base.py:1602(run_callable)\n",
       "        2    0.000    0.000    0.004    0.002 sorting.py:394(_reorder_by_uniques)\n",
       "       14    0.000    0.000    0.000    0.000 sorting.py:54(_int64_cut_off)\n",
       "    32/12    0.000    0.000    0.002    0.000 visitors.py:86(_compiler_dispatch)\n",
       "        5    0.000    0.000    0.005    0.001 generic.py:4299(reindex)\n",
       "        9    0.000    0.000    0.001    0.000 compiler.py:1481(visit_bindparam)\n",
       "        2    0.000    0.000    0.002    0.001 managers.py:1158(insert)\n",
       "       40    0.000    0.000    0.000    0.000 generic.py:1523(_is_level_reference)\n",
       "       40    0.000    0.000    0.000    0.000 attr.py:166(update_subclass)\n",
       "       56    0.000    0.000    0.000    0.000 series.py:438(values)\n",
       "        2    0.000    0.000    0.009    0.004 managers.py:184(rename_axis)\n",
       "        9    0.000    0.000    0.024    0.003 sql.py:1167(read_query)\n",
       "       12    0.000    0.000    0.022    0.002 merge.py:1308(<genexpr>)\n",
       "       16    0.000    0.000    0.000    0.000 numerictypes.py:654(<listcomp>)\n",
       "        9    0.000    0.000    0.000    0.000 sql.py:1068(__init__)\n",
       "       24    0.000    0.000    0.000    0.000 generic.py:1606(_check_label_or_level_ambiguity)\n",
       "       18    0.000    0.000    0.004    0.000 series.py:912(_get_with)\n",
       "       10    0.000    0.000    0.002    0.000 generic.py:1440(__neg__)\n",
       "       69    0.000    0.000    0.000    0.000 result.py:559(_merge_cols_by_none)\n",
       "      295    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
       "        9    0.000    0.000    0.003    0.000 construction.py:437(to_arrays)\n",
       "        7    0.000    0.000    0.000    0.000 indexing.py:1599(_validate_read_indexer)\n",
       "        2    0.000    0.000    0.021    0.010 frame.py:4896(sort_values)\n",
       "       18    0.000    0.000    0.009    0.001 missing.py:578(remove_na_arraylike)\n",
       "       58    0.000    0.000    0.001    0.000 algorithms.py:247(_get_values_for_rank)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
       "        2    0.000    0.000    0.005    0.003 merge.py:929(_get_merge_keys)\n",
       "        4    0.000    0.000    0.023    0.006 series.py:4241(isin)\n",
       "       48    0.000    0.000    0.000    0.000 managers.py:1831(_asarray_compat)\n",
       "     12/4    0.000    0.000    0.012    0.003 <frozen importlib._bootstrap>:948(_find_and_load_unlocked)\n",
       "       34    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
       "       21    0.000    0.000    0.001    0.000 psycopg2.py:579(get_result_proxy)\n",
       "       19    0.000    0.000    0.000    0.000 base.py:77(__init__)\n",
       "        2    0.000    0.000    0.037    0.018 merge.py:1284(_get_join_indexers)\n",
       "       21    0.000    0.000    0.000    0.000 default.py:1038(should_autocommit)\n",
       "        9    0.000    0.000    0.036    0.004 base.py:2149(run_callable)\n",
       "       21    0.000    0.000    0.001    0.000 result.py:441(<listcomp>)\n",
       "        6    0.000    0.000    0.107    0.018 construction.py:213(init_dict)\n",
       "        2    0.000    0.000    0.000    0.000 merge.py:753(_maybe_add_join_keys)\n",
       "       17    0.000    0.000    0.000    0.000 fromnumeric.py:2843(prod)\n",
       "       18    0.000    0.000    0.007    0.000 default.py:550(do_ping)\n",
       "        9    0.000    0.000    0.000    0.000 result.py:586(_key_fallback)\n",
       "       18    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:271(cache_from_source)\n",
       "       54    0.000    0.000    0.000    0.000 expressions.py:89(ophelper)\n",
       "       18    0.000    0.000    0.003    0.000 base.py:863(close)\n",
       "       21    0.000    0.000    0.000    0.000 langhelpers.py:253(_inspect_func_args)\n",
       "       30    0.000    0.000    0.000    0.000 _asarray.py:300(<setcomp>)\n",
       "       37    0.000    0.000    0.000    0.000 threading.py:1092(is_alive)\n",
       "        2    0.000    0.000    0.044    0.022 merge.py:639(get_result)\n",
       "       18    0.000    0.000    0.002    0.000 range.py:685(__getitem__)\n",
       "       18    0.000    0.000    0.001    0.000 generic.py:3238(_maybe_cache_changed)\n",
       "       88    0.000    0.000    0.000    0.000 inference.py:96(is_iterator)\n",
       "       36    0.000    0.000    0.002    0.000 construction.py:586(convert)\n",
       "       58    0.000    0.000    0.000    0.000 algorithms.py:205(_ensure_arraylike)\n",
       "        7    0.000    0.000    0.005    0.001 algorithms.py:1940(safe_sort)\n",
       "       42    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(copyto)\n",
       "      153    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "       48    0.000    0.000    0.000    0.000 type_api.py:493(_cached_result_processor)\n",
       "        2    0.000    0.000    0.001    0.001 base.py:2392(intersection)\n",
       "       18    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "       21    0.000    0.000    0.012    0.001 base.py:916(execute)\n",
       "        8    0.000    0.000    0.002    0.000 dtypes.py:516(validate_categories)\n",
       "       21    0.000    0.000    0.001    0.000 result.py:712(__init__)\n",
       "       22    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "       18    0.000    0.000    0.000    0.000 blocks.py:311(_slice)\n",
       "       18    0.000    0.000    0.000    0.000 numeric.py:261(_convert_scalar_indexer)\n",
       "       72    0.000    0.000    0.000    0.000 generic.py:1899(<genexpr>)\n",
       "       18    0.000    0.000    0.000    0.000 arrayprint.py:69(_make_options_dict)\n",
       "       16    0.000    0.000    0.000    0.000 numerictypes.py:602(find_common_type)\n",
       "       19    0.000    0.000    0.002    0.000 default.py:537(do_rollback)\n",
       "       32    0.000    0.000    0.000    0.000 numerictypes.py:578(_can_coerce_all)\n",
       "        9    0.000    0.000    0.000    0.000 {method 'fetchall' of 'psycopg2.extensions.cursor' objects}\n",
       "       12    0.000    0.000    0.002    0.000 compiler.py:274(__init__)\n",
       "       19    0.000    0.000    0.001    0.000 base.py:295(__get__)\n",
       "        9    0.000    0.000    0.036    0.004 sql.py:1339(has_table)\n",
       "        9    0.000    0.000    0.003    0.000 sql.py:100(_parse_date_columns)\n",
       "        9    0.000    0.000    0.000    0.000 construction.py:484(<listcomp>)\n",
       "        2    0.000    0.000    0.066    0.033 csvs.py:157(save)\n",
       "       12    0.000    0.000    0.000    0.000 langhelpers.py:1139(constructor_copy)\n",
       "       46    0.000    0.000    0.000    0.000 concat.py:401(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:3092(<listcomp>)\n",
       "        4    0.000    0.000    0.003    0.001 generic.py:4584(_reindex_with_indexers)\n",
       "       29    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(can_cast)\n",
       "       48    0.000    0.000    0.000    0.000 default.py:1142(get_result_processor)\n",
       "       18    0.000    0.000    0.021    0.001 impl.py:112(_do_get)\n",
       "       34    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
       "      329    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
       "       12    0.000    0.000    0.000    0.000 type_api.py:1463(adapt_type)\n",
       "       13    0.000    0.000    0.000    0.000 range.py:131(_simple_new)\n",
       "       68    0.000    0.000    0.000    0.000 generic.py:1579(<genexpr>)\n",
       "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:504(_init_module_attrs)\n",
       "       40    0.000    0.000    0.000    0.000 attr.py:227(__init__)\n",
       "        2    0.000    0.000    0.037    0.018 merge.py:838(_get_join_indexers)\n",
       "       18    0.000    0.000    0.002    0.000 arrayprint.py:1489(_array_str_implementation)\n",
       "       39    0.000    0.000    0.000    0.000 __init__.py:1614(isEnabledFor)\n",
       "       54    0.000    0.000    0.000    0.000 weakref.py:408(__setitem__)\n",
       "     10/2    0.000    0.000    0.007    0.003 <frozen importlib._bootstrap>:663(_load_unlocked)\n",
       "        9    0.000    0.000    0.001    0.000 sql.py:570(pandasSQL_builder)\n",
       "        9    0.000    0.000    0.000    0.000 elements.py:1363(repl)\n",
       "       50    0.000    0.000    0.000    0.000 series.py:520(_internal_get_values)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:5388(default_index)\n",
       "        2    0.000    0.000    0.000    0.000 index_tricks.py:318(__getitem__)\n",
       "        2    0.000    0.000    0.001    0.000 csvs.py:34(__init__)\n",
       "        2    0.000    0.000    0.006    0.003 merge.py:554(__init__)\n",
       "       26    0.000    0.000    0.000    0.000 base.py:1667(is_boolean)\n",
       "        3    0.000    0.000    0.001    0.000 base.py:4993(drop)\n",
       "       18    0.000    0.000    0.001    0.000 arrayprint.py:729(_formatArray)\n",
       "       21    0.000    0.000    0.001    0.000 result.py:867(_soft_close)\n",
       "       21    0.000    0.000    0.000    0.000 default.py:1125(create_cursor)\n",
       "     21/4    0.000    0.000    0.000    0.000 sre_parse.py:174(getwidth)\n",
       "       22    0.000    0.000    0.000    0.000 sqltypes.py:141(__init__)\n",
       "       56    0.000    0.000    0.000    0.000 blocks.py:202(external_values)\n",
       "       21    0.000    0.000    0.001    0.000 result.py:334(_merge_cursor_description)\n",
       "       32    0.000    0.000    0.000    0.000 generic.py:3294(_clear_item_cache)\n",
       "        3    0.000    0.000    0.003    0.001 generic.py:3943(_drop_axis)\n",
       "       31    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1203(_path_importer_cache)\n",
       "        2    0.000    0.000    0.000    0.000 csvs.py:228(_save_header)\n",
       "       54    0.000    0.000    0.000    0.000 attr.py:269(__bool__)\n",
       "       12    0.000    0.000    0.001    0.000 type_api.py:450(dialect_impl)\n",
       "        1    0.000    0.000    1.065    1.065 parsers.py:2035(read)\n",
       "       50    0.000    0.000    0.000    0.000 blocks.py:240(to_dense)\n",
       "       10    0.000    0.000    0.000    0.000 shape_base.py:83(atleast_2d)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:589(get_connection)\n",
       "       21    0.000    0.000    0.000    0.000 {built-in method sqlalchemy.cutils._distill_params}\n",
       "      168    0.000    0.000    0.000    0.000 sre_parse.py:164(__getitem__)\n",
       "       22    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "        9    0.000    0.000    0.000    0.000 sql.py:39(_is_sqlalchemy_connectable)\n",
       "       46    0.000    0.000    0.001    0.000 base.py:1730(inferred_type)\n",
       "        6    0.000    0.000    0.604    0.101 base.py:3992(_concat)\n",
       "        9    0.000    0.000    0.000    0.000 parse.py:412(urlsplit)\n",
       "      8/1    0.000    0.000    0.000    0.000 sre_parse.py:411(_parse_sub)\n",
       "       51    0.000    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:74(_path_stat)\n",
       "       12    0.000    0.000    0.006    0.000 base.py:1132(_execute_text)\n",
       "      187    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
       "        4    0.000    0.000    0.000    0.000 version.py:307(parse)\n",
       "        3    0.000    0.000    0.006    0.002 frame.py:6949(append)\n",
       "       17    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(prod)\n",
       "       21    0.000    0.000    0.001    0.000 default.py:1199(_setup_crud_result_proxy)\n",
       "       24    0.000    0.000    0.002    0.000 generic.py:3415(xs)\n",
       "       18    0.000    0.000    0.000    0.000 log.py:56(_should_log_debug)\n",
       "        9    0.000    0.000    0.001    0.000 compiler.py:925(visit_textclause)\n",
       "       19    0.000    0.000    0.001    0.000 base.py:116(_for_class)\n",
       "       40    0.000    0.000    0.000    0.000 attr.py:160(_assign_cls_collection)\n",
       "        9    0.000    0.000    0.000    0.000 <string>:1(bindparam)\n",
       "       12    0.000    0.000    0.002    0.000 elements.py:470(_compiler)\n",
       "       56    0.000    0.000    0.000    0.000 langhelpers.py:1148(<genexpr>)\n",
       "        4    0.000    0.000    0.005    0.001 frame.py:3837(reindex)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:87(<dictcomp>)\n",
       "        9    0.000    0.000    0.000    0.000 type_api.py:483(_cached_bind_processor)\n",
       "       10    0.000    0.000    0.032    0.003 managers.py:1797(_simple_blockify)\n",
       "       12    0.000    0.000    0.000    0.000 common.py:188(all_none)\n",
       "      216    0.000    0.000    0.000    0.000 arrayprint.py:1162(__call__)\n",
       "       23    0.000    0.000    0.000    0.000 _collections_abc.py:72(_check_methods)\n",
       "        9    0.000    0.000    0.000    0.000 elements.py:1359(__init__)\n",
       "       18    0.000    0.000    0.000    0.000 blocks.py:3105(_safe_reshape)\n",
       "       24    0.000    0.000    0.000    0.000 generic.py:1852(empty)\n",
       "        2    0.000    0.000    0.000    0.000 function_base.py:4429(insert)\n",
       "       94    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
       "    21/12    0.000    0.000    0.002    0.000 compiler.py:349(process)\n",
       "       18    0.000    0.000    0.028    0.002 base.py:2273(_wrap_pool_connect)\n",
       "        1    0.000    0.000    1.169    1.169 parsers.py:1131(read)\n",
       "       18    0.000    0.000    0.000    0.000 blocks.py:2649(should_store)\n",
       "        2    0.000    0.000    0.069    0.034 generic.py:3042(to_csv)\n",
       "      197    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
       "       40    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "        9    0.000    0.000    0.000    0.000 elements.py:1515(bindparams)\n",
       "       10    0.000    0.000    0.000    0.000 managers.py:1970(_preprocess_slice_or_indexer)\n",
       "        2    0.000    0.000    0.000    0.000 sorting.py:348(get_group_index_sorter)\n",
       "       19    0.000    0.000    0.000    0.000 log.py:59(_should_log_info)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:11(<module>)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:1963(_fast_count_smallints)\n",
       "       18    0.000    0.000    0.028    0.002 base.py:354(connect)\n",
       "        9    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:523(_compile_bytecode)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1794(_label_select_column)\n",
       "        9    0.000    0.000    0.000    0.000 schema.py:4056(_bind_to)\n",
       "       26    0.000    0.000    0.000    0.000 base.py:4506(_maybe_promote)\n",
       "        1    0.000    0.000    0.000    0.000 cast.py:799(astype_nansafe)\n",
       "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:574(spec_from_file_location)\n",
       "        8    0.000    0.000    0.001    0.000 shape_base.py:224(vstack)\n",
       "       18    0.000    0.000    0.003    0.000 base.py:853(_checkin)\n",
       "       79    0.000    0.000    0.000    0.000 sre_parse.py:233(__next)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.sysconf}\n",
       "        1    0.000    0.000    0.000    0.000 csvs.py:3(<module>)\n",
       "        1    0.000    0.000    0.004    0.004 __init__.py:22(<module>)\n",
       "       21    0.000    0.000    0.000    0.000 base.py:2373(should_autocommit_text)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:2040(visit_select)\n",
       "       19    0.000    0.000    0.001    0.000 base.py:119(_for_instance)\n",
       "       12    0.000    0.000    0.000    0.000 type_api.py:534(adapt)\n",
       "        9    0.000    0.000    0.000    0.000 elements.py:1371(_create_text)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:42(_generative)\n",
       "        2    0.000    0.000    0.023    0.012 common.py:314(get_handle)\n",
       "        1    0.000    0.000    0.002    0.002 frame.py:4369(reset_index)\n",
       "        1    0.000    0.000    0.010    0.010 generic.py:932(rename)\n",
       "       49    0.000    0.000    0.000    0.000 cast.py:1492(construct_1d_ndarray_preserving_na)\n",
       "       24    0.000    0.000    0.000    0.000 common.py:179(ensure_python_int)\n",
       "       12    0.000    0.000    0.000    0.000 result.py:1190(<listcomp>)\n",
       "        1    0.000    0.000    0.020    0.020 base.py:644(__connect)\n",
       "       18    0.000    0.000    0.003    0.000 base.py:1009(close)\n",
       "        9    0.000    0.000    0.000    0.000 parse.py:361(urlparse)\n",
       "       32    0.000    0.000    0.000    0.000 typing.py:704(__setattr__)\n",
       "       11    0.000    0.000    0.000    0.000 weakref.py:358(remove)\n",
       "        9    0.000    0.000    0.000    0.000 compiler.py:647(_bind_processors)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2751(__init__)\n",
       "        2    0.000    0.000    0.013    0.007 managers.py:1811(_multi_blockify)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:2853(_convert_scalar_indexer)\n",
       "       31    0.000    0.000    0.000    0.000 missing.py:601(clean_reindex_fill_method)\n",
       "        1    0.000    0.000    0.005    0.005 expressions.py:7(<module>)\n",
       "       21    0.000    0.000    0.000    0.000 default.py:1093(_use_server_side_cursor)\n",
       "       37    0.000    0.000    0.000    0.000 threading.py:1050(_wait_for_tstate_lock)\n",
       "      9/2    0.000    0.000    0.007    0.003 <frozen importlib._bootstrap_external>:722(exec_module)\n",
       "       16    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.listdir}\n",
       "       12    0.000    0.000    0.002    0.000 <string>:1(<lambda>)\n",
       "       12    0.000    0.000    0.002    0.000 elements.py:405(compile)\n",
       "        2    0.000    0.000    0.000    0.000 merge.py:1045(_maybe_coerce_merge_keys)\n",
       "        4    0.000    0.000    0.002    0.001 base.py:1024(_format_native_types)\n",
       "    16/15    0.000    0.000    0.000    0.000 typing.py:248(inner)\n",
       "        9    0.000    0.000    0.008    0.001 base.py:2165(execute)\n",
       "        5    0.000    0.000    0.628    0.126 concat.py:526(_get_concat_axis)\n",
       "        2    0.000    0.000    0.037    0.019 merge.py:844(_get_join_info)\n",
       "       40    0.000    0.000    0.000    0.000 managers.py:1881(<lambda>)\n",
       "        2    0.000    0.000    0.001    0.000 frame.py:3570(_sanitize_column)\n",
       "       11    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_bool_array}\n",
       "        9    0.000    0.000    0.002    0.000 result.py:1193(fetchall)\n",
       "       17    0.000    0.000    0.000    0.000 queue.py:203(_get)\n",
       "       37    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "    88/44    0.000    0.000    0.000    0.000 necompiler.py:145(postorderWalk)\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:273(stringToExpression)\n",
       "        9    0.000    0.000    0.000    0.000 compiler.py:668(construct_params)\n",
       "        5    0.000    0.000    0.760    0.152 concat.py:513(_get_new_axes)\n",
       "        3    0.000    0.000    0.004    0.001 generic.py:3907(drop)\n",
       "       19    0.000    0.000    0.000    0.000 {pandas._libs.lib.array_equivalent_object}\n",
       "       12    0.000    0.000    0.000    0.000 result.py:1277(first)\n",
       "       18    0.000    0.000    0.000    0.000 impl.py:103(_do_return_conn)\n",
       "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:318(__exit__)\n",
       "       32    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "        2    0.000    0.000    0.049    0.025 frame.py:7265(merge)\n",
       "       12    0.000    0.000    0.002    0.000 dtypes.py:363(_finalize)\n",
       "       10    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(min_scalar_type)\n",
       "       17    0.000    0.000    0.000    0.000 fromnumeric.py:74(<dictcomp>)\n",
       "       37    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
       "        2    0.000    0.000    0.001    0.001 default.py:378(check_unicode)\n",
       "       12    0.000    0.000    0.000    0.000 default.py:445(type_descriptor)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:375(_return_conn)\n",
       "        1    0.000    0.000    0.001    0.001 expressions.py:393(ExpressionNode)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:554(precompile)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method psycopg2._psycopg.parse_dsn}\n",
       "       21    0.000    0.000    0.000    0.000 psycopg2.py:587(_log_notices)\n",
       "       18    0.000    0.000    0.000    0.000 compiler.py:652(<genexpr>)\n",
       "        9    0.000    0.000    0.001    0.000 compiler.py:926(do_bindparam)\n",
       "        9    0.000    0.000    0.000    0.000 <string>:1(text)\n",
       "        6    0.000    0.000    0.000    0.000 elements.py:721(__getattr__)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:324(_generate)\n",
       "       10    0.000    0.000    0.000    0.000 _collections.py:140(__new__)\n",
       "       23    0.000    0.000    0.000    0.000 concat.py:398(_is_uniform_reindex)\n",
       "       10    0.000    0.000    0.000    0.000 generic.py:343(_construct_axes_dict)\n",
       "       21    0.000    0.000    0.000    0.000 generic.py:1848(__contains__)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:628(shape)\n",
       "       23    0.000    0.000    0.009    0.000 default.py:587(do_execute)\n",
       "    32/19    0.000    0.000    0.000    0.000 typing.py:664(__hash__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:71(search_function)\n",
       "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:438(_classify_pyc)\n",
       "        1    0.000    0.000    0.000    0.000 <ipython-input-21-c9fd36f58387>:14(buildParseTree)\n",
       "        9    0.000    0.000    0.000    0.000 sql.py:57(_convert_params)\n",
       "       18    0.000    0.000    0.002    0.000 series.py:409(_update_inplace)\n",
       "       11    0.000    0.000    0.000    0.000 common.py:58(_expand_user)\n",
       "       11    0.000    0.000    0.000    0.000 range.py:170(_int64index)\n",
       "        5    0.000    0.000    0.000    0.000 generic.py:356(_construct_axes_from_arguments)\n",
       "        7    0.000    0.000    0.000    0.000 base.py:2967(_convert_listlike_indexer)\n",
       "        8    0.000    0.000    0.003    0.000 base.py:4489(get_indexer_for)\n",
       "        8    0.000    0.000    0.000    0.000 categorical.py:656(_get_codes)\n",
       "        4    0.000    0.000    0.000    0.000 dtypes.py:553(update_dtype)\n",
       "       10    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:576(module_from_spec)\n",
       "       60    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
       "       18    0.000    0.000    0.000    0.000 base.py:261(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:885(_get_options_with_defaults)\n",
       "        3    0.000    0.000    0.000    0.000 common.py:144(get_filepath_or_buffer)\n",
       "        4    0.000    0.000    0.004    0.001 frame.py:3732(_reindex_axes)\n",
       "        8    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(vstack)\n",
       "       18    0.000    0.000    0.000    0.000 queue.py:195(_full)\n",
       "       11    0.000    0.000    0.000    0.000 typing.py:113(_type_check)\n",
       "       14    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 extras.py:664(register_uuid)\n",
       "        9    0.000    0.000    0.002    0.000 construction.py:574(_convert_object_array)\n",
       "       18    0.000    0.000    0.000    0.000 series.py:370(_can_hold_na)\n",
       "        2    0.000    0.000    0.001    0.001 base.py:4973(insert)\n",
       "        4    0.000    0.000    0.000    0.000 typing.py:603(__init__)\n",
       "       64    0.000    0.000    0.000    0.000 sre_parse.py:254(get)\n",
       "       16    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:11(<module>)\n",
       "       21    0.000    0.000    0.000    0.000 base.py:1329(_safe_close_cursor)\n",
       "        9    0.000    0.000    0.000    0.000 <string>:1(_create_text)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1345(__init__)\n",
       "        2    0.000    0.000    0.049    0.025 merge.py:56(merge)\n",
       "        9    0.000    0.000    0.002    0.000 construction.py:592(<listcomp>)\n",
       "        2    0.000    0.000    0.008    0.004 managers.py:1941(_transform_index)\n",
       "       11    0.000    0.000    0.000    0.000 blocks.py:2591(is_bool)\n",
       "       10    0.000    0.000    0.000    0.000 generic.py:4530(<genexpr>)\n",
       "        2    0.000    0.000    0.003    0.002 generic.py:1717(_drop_labels_or_levels)\n",
       "        9    0.000    0.000    0.002    0.000 <__array_function__ internals>:2(array_equal)\n",
       "       18    0.000    0.000    0.000    0.000 arrayprint.py:379(<lambda>)\n",
       "       18    0.000    0.000    0.000    0.000 _config.py:140(get)\n",
       "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:369(_get_cached)\n",
       "       23    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
       "        9    0.000    0.000    0.008    0.001 sql.py:1085(execute)\n",
       "        1    0.000    0.000    0.000    0.000 blocks.py:554(astype)\n",
       "       68    0.000    0.000    0.000    0.000 generic.py:1574(<genexpr>)\n",
       "        4    0.000    0.000    0.002    0.001 base.py:993(to_native_types)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:1250(set_names)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:4963(delete)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:159(ones)\n",
       "      5/4    0.000    0.000    0.000    0.000 typing.py:340(__getitem__)\n",
       "       12    0.000    0.000    0.005    0.000 <frozen importlib._bootstrap_external>:1272(find_spec)\n",
       "       19    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:403(cached)\n",
       "       38    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:859(__exit__)\n",
       "       14    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:84(_path_is_mode_type)\n",
       "       31    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
       "       29    0.000    0.000    0.000    0.000 expressions.py:195(func)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:808(visit_label)\n",
       "        9    0.000    0.000    0.000    0.000 <string>:1(bindparams)\n",
       "        9    0.000    0.000    0.007    0.001 elements.py:291(_execute_on_connection)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _csv.writer}\n",
       "        1    0.000    0.000    1.196    1.196 parsers.py:530(parser_f)\n",
       "        8    0.000    0.000    0.000    0.000 common.py:88(stringify_path)\n",
       "        8    0.000    0.000    0.000    0.000 fromnumeric.py:997(argsort)\n",
       "        1    0.000    0.000    0.001    0.001 default.py:367(_check_unicode_returns)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:971(cursor)\n",
       "       11    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1351(_get_spec)\n",
       "      3/1    0.000    0.000    0.000    0.000 necompiler.py:188(typeCompileAst)\n",
       "       42    0.000    0.000    0.000    0.000 {method 'close' of 'psycopg2.extensions.cursor' objects}\n",
       "        9    0.000    0.000    0.000    0.000 compiler.py:1565(_truncate_bindparam)\n",
       "        9    0.000    0.000    0.000    0.000 compiler.py:1600(bindparam_string)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2228(_compose_select_body)\n",
       "        9    0.000    0.000    0.000    0.000 sqltypes.py:256(bind_processor)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1517(_maybe_dedup_names)\n",
       "       11    0.000    0.000    0.000    0.000 range.py:316(dtype)\n",
       "       23    0.000    0.000    0.000    0.000 base.py:62(_reset_cache)\n",
       "       21    0.000    0.000    0.000    0.000 result.py:266(<listcomp>)\n",
       "       49    0.000    0.000    0.000    0.000 sre_parse.py:172(append)\n",
       "       27    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:51(_r_long)\n",
       "       26    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'split' of 're.Pattern' objects}\n",
       "       21    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 csvs.py:33(CSVFormatter)\n",
       "        1    0.000    0.000    0.001    0.001 extras.py:909(get_oids)\n",
       "       12    0.000    0.000    0.000    0.000 type_api.py:531(_gen_dialect_impl)\n",
       "       23    0.000    0.000    0.000    0.000 blocks.py:300(__len__)\n",
       "       10    0.000    0.000    0.000    0.000 generic.py:345(<dictcomp>)\n",
       "       11    0.000    0.000    0.001    0.000 base.py:766(_assert_take_fillable)\n",
       "       13    0.000    0.000    0.000    0.000 base.py:675(size)\n",
       "       31    0.000    0.000    0.000    0.000 missing.py:73(clean_fill_method)\n",
       "        4    0.000    0.000    0.000    0.000 _validators.py:217(validate_axis_style_args)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:1225(is_datetimelike_v_numeric)\n",
       "        7    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "       18    0.000    0.000    0.000    0.000 arrayprint.py:1157(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:1277(normalize_axis_tuple)\n",
       "       12    0.000    0.000    0.000    0.000 result.py:899(close)\n",
       "        8    0.000    0.000    0.000    0.000 os.py:674(__getitem__)\n",
       "       10    0.000    0.000    0.000    0.000 _collections_abc.py:252(__subclasshook__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2199(_setup_select_stack)\n",
       "        1    0.000    0.000    0.003    0.003 strategies.py:194(first_connect)\n",
       "        9    0.000    0.000    0.002    0.000 base.py:180(__exit__)\n",
       "        9    0.000    0.000    0.000    0.000 sqltypes.py:2973(_resolve_value_to_type)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3024(_froms)\n",
       "        9    0.000    0.000    0.000    0.000 type_api.py:357(_has_bind_expression)\n",
       "        4    0.000    0.000    0.000    0.000 generic.py:4572(_needs_reindex_multi)\n",
       "        5    0.000    0.000    0.000    0.000 generic.py:384(_from_axes)\n",
       "       12    0.000    0.000    0.000    0.000 base.py:2581(_assert_can_do_setop)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:4000(_concat_same_dtype)\n",
       "       10    0.000    0.000    0.000    0.000 base.py:879(empty)\n",
       "        2    0.000    0.000    0.006    0.003 sorting.py:180(indexer_from_factorized)\n",
       "       12    0.000    0.000    0.002    0.000 dtypes.py:221(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 dtypes.py:244(_from_values_or_dtype)\n",
       "       18    0.000    0.000    0.000    0.000 arrayprint.py:74(<dictcomp>)\n",
       "       47    0.000    0.000    0.000    0.000 multiarray.py:145(concatenate)\n",
       "       18    0.000    0.000    0.000    0.000 queue.py:191(_empty)\n",
       "       18    0.000    0.000    0.000    0.000 queue.py:199(_put)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:792(find_spec)\n",
       "       38    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:855(__enter__)\n",
       "       63    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "       76    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
       "        3    0.000    0.000    0.001    0.000 {built-in method builtins.__import__}\n",
       "       12    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numexpr.interpreter._set_vml_num_threads}\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:73(_can_use_numexpr)\n",
       "        1    0.000    0.000   53.990   53.990 <ipython-input-27-073236436489>:68(ad_hoc)\n",
       "        9    0.000    0.000    0.000    0.000 compiler.py:915(post_process_text)\n",
       "       18    0.000    0.000    0.000    0.000 attr.py:257(__call__)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3053(_get_display_froms)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:939(_clean_options)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:259(infer_compression)\n",
       "        1    0.000    0.000    0.006    0.006 array_ops.py:156(arithmetic_op)\n",
       "        5    0.000    0.000    0.015    0.003 _decorators.py:225(wrapper)\n",
       "        8    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(argsort)\n",
       "        2    0.000    0.000    0.000    0.000 numeric.py:1340(moveaxis)\n",
       "       18    0.000    0.000    0.000    0.000 _config.py:49(getter)\n",
       "       21    0.000    0.000    0.000    0.000 result.py:862(_cursor_description)\n",
       "        1    0.000    0.000    0.003    0.003 default.py:297(initialize)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:737(__init__)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:980(__getattr__)\n",
       "        4    0.000    0.000    0.000    0.000 typing.py:212(_remove_dups_flatten)\n",
       "     13/2    0.000    0.000    0.005    0.002 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "       44    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:535(getContext)\n",
       "       42    0.000    0.000    0.000    0.000 base.py:105(_event_descriptors)\n",
       "        3    0.000    0.000    0.000    0.000 <string>:1(select)\n",
       "        7    0.000    0.000    0.000    0.000 indexing.py:230(loc)\n",
       "        1    0.000    0.000    0.001    0.001 frame.py:3478(insert)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:1329(rename)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:757(coerce_indexer_dtype)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
       "       34    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
       "       12    0.000    0.000    0.000    0.000 result.py:1144(_fetchone_impl)\n",
       "       18    0.000    0.000    0.000    0.000 parse.py:109(_coerce_args)\n",
       "        1    0.000    0.000    0.001    0.001 re.py:271(_compile)\n",
       "       18    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:62(_path_split)\n",
       "       14    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "        9    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
       "       51    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
       "       15    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:607(NumExpr)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:100(_init_num_threads)\n",
       "        1    0.000    0.000    0.003    0.003 psycopg2.py:715(initialize)\n",
       "        1    0.000    0.000    0.001    0.001 base.py:2692(_get_server_version_info)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:862(visit_column)\n",
       "        1    0.000    0.000    0.016    0.016 parsers.py:792(__init__)\n",
       "        3    0.000    0.000    0.001    0.000 frame.py:3769(_reindex_columns)\n",
       "        1    0.000    0.000    0.010    0.010 frame.py:4000(rename)\n",
       "       10    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(atleast_2d)\n",
       "        9    0.000    0.000    0.000    0.000 result.py:1159(_fetchall_impl)\n",
       "       47    0.000    0.000    0.000    0.000 sre_parse.py:160(__len__)\n",
       "        4    0.000    0.000    0.000    0.000 sre_compile.py:276(_optimize_charset)\n",
       "       13    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
       "      6/2    0.000    0.000    0.000    0.000 necompiler.py:158(expressionToAST)\n",
       "        2    0.000    0.000    0.000    0.000 expressions.py:118(commonKind)\n",
       "        1    0.000    0.000    0.050    0.050 <ipython-input-23-322c5c19857e>:16(get_valid_systems)\n",
       "        2    0.000    0.000    0.000    0.000 extensions.py:146(make_dsn)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:1031(visit_cast)\n",
       "        9    0.000    0.000    0.000    0.000 sqltypes.py:264(process)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3925(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4680(_interpret_as_column_or_from)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:367(_validate_integer)\n",
       "        1    0.000    0.000    0.016    0.016 parsers.py:1112(_make_engine)\n",
       "        3    0.000    0.000    0.000    0.000 common.py:40(is_url)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:226(get_compression_method)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method pandas._libs.writers.word_len}\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:9535(abs)\n",
       "        2    0.000    0.000    0.002    0.001 api.py:221(_sanitize_and_check)\n",
       "        1    0.000    0.000    0.001    0.001 frame.py:2922(__setitem__)\n",
       "       10    0.000    0.000    0.000    0.000 generic.py:1582(_is_label_or_level_reference)\n",
       "       24    0.000    0.000    0.000    0.000 generic.py:1684(<listcomp>)\n",
       "       24    0.000    0.000    0.000    0.000 generic.py:3656(_check_setitem_copy)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1737(is_all_dates)\n",
       "        2    0.000    0.000    0.001    0.000 base.py:3810(_coerce_scalar_to_index)\n",
       "       19    0.000    0.000    0.000    0.000 base.py:4723(_maybe_cast_indexer)\n",
       "        1    0.000    0.000    0.006    0.006 __init__.py:492(wrapper)\n",
       "        1    0.000    0.000    0.004    0.004 _optional.py:47(import_optional_dependency)\n",
       "        8    0.000    0.000    0.000    0.000 fromnumeric.py:55(_wrapfunc)\n",
       "        5    0.000    0.000    0.000    0.000 _config.py:135(_default)\n",
       "        4    0.000    0.000    0.000    0.000 typing.py:165(_collect_type_vars)\n",
       "       37    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
       "       34    0.000    0.000    0.000    0.000 sre_parse.py:249(match)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:945(parse_template)\n",
       "        8    0.000    0.000    0.000    0.000 os.py:752(encode)\n",
       "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:951(path_stats)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:471(_validate_timestamp_pyc)\n",
       "       14    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "       34    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
       "       76    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
       "       12    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}\n",
       "       17    0.000    0.000    0.000    0.000 necompiler.py:151(allOf)\n",
       "      6/2    0.000    0.000    0.000    0.000 necompiler.py:169(sigPerms)\n",
       "        1    0.000    0.000    0.000    0.000 __config__.py:3(<module>)\n",
       "        1    0.000    0.000    0.003    0.003 base.py:2451(initialize)\n",
       "        2    0.000    0.000    0.000    0.000 merge.py:718(_maybe_restore_index_levels)\n",
       "        1    0.000    0.000    0.001    0.001 series.py:313(_init_dict)\n",
       "        3    0.000    0.000    0.000    0.000 managers.py:171(set_axis)\n",
       "       37    0.000    0.000    0.000    0.000 managers.py:1544(index)\n",
       "       18    0.000    0.000    0.000    0.000 managers.py:1572(_can_hold_na)\n",
       "        6    0.000    0.000    0.000    0.000 concat.py:91(is_nonempty)\n",
       "       12    0.000    0.000    0.000    0.000 concat.py:104(<genexpr>)\n",
       "        6    0.000    0.000    0.000    0.000 __init__.py:121(_maybe_match_name)\n",
       "       11    0.000    0.000    0.000    0.000 inference.py:325(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op}\n",
       "       42    0.000    0.000    0.000    0.000 multiarray.py:1043(copyto)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:43(normalize_encoding)\n",
       "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:401(_check_name_wrapper)\n",
       "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:35(_new_module)\n",
       "       41    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
       "       27    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:416(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:706(getExprNames)\n",
       "        9    0.000    0.000    0.000    0.000 <ipython-input-5-f3885a2e711d>:51(get_system_type)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:908(scalar)\n",
       "        3    0.000    0.000    0.000    0.000 <string>:1(__init__)\n",
       "        2    0.000    0.000    0.004    0.002 attr.py:316(__call__)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:885(anon_label)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:2473(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'writerow' of '_csv.writer' objects}\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1174(_is_potential_multi_index)\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:1969(close)\n",
       "       12    0.000    0.000    0.000    0.000 managers.py:1837(_shape_compat)\n",
       "       12    0.000    0.000    0.000    0.000 range.py:210(start)\n",
       "        3    0.000    0.000    0.004    0.001 frame.py:3858(drop)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:1775(hasnans)\n",
       "        7    0.000    0.000    0.000    0.000 base.py:3004(_convert_arr_indexer)\n",
       "        5    0.000    0.000    0.000    0.000 base.py:4077(identical)\n",
       "       20    0.000    0.000    0.000    0.000 base.py:429(<genexpr>)\n",
       "        1    0.000    0.000    0.006    0.006 array_ops.py:126(na_arithmetic_op)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:174(not_none)\n",
       "        3    0.000    0.000    0.000    0.000 arraysetops.py:745(setdiff1d)\n",
       "        3    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(delete)\n",
       "        8    0.000    0.000    0.000    0.000 shape_base.py:220(_vhstack_dispatcher)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:225(_import_one)\n",
       "        1    0.000    0.000    0.001    0.001 expressions.py:99(_evaluate_numexpr)\n",
       "        9    0.000    0.000    0.000    0.000 default.py:985(<listcomp>)\n",
       "       21    0.000    0.000    0.000    0.000 result.py:263(<listcomp>)\n",
       "       32    0.000    0.000    0.000    0.000 typing.py:590(_is_dunder)\n",
       "        1    0.000    0.000    0.001    0.001 sre_compile.py:759(compile)\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1190(_path_hooks)\n",
       "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:93(_path_isfile)\n",
       "       40    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "       55    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "       37    0.000    0.000    0.000    0.000 {method 'group' of 're.Match' objects}\n",
       "       12    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:409(optimizeTemporariesAllocation)\n",
       "        8    0.000    0.000    0.000    0.000 extensions.py:180(_param_escape)\n",
       "        1    0.000    0.000    0.001    0.001 psycopg2.py:899(_hstore_oids)\n",
       "        4    0.000    0.000    0.000    0.000 elements.py:709(comparator)\n",
       "        3    0.000    0.000    0.000    0.000 langhelpers.py:897(expire_instance)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:11343(logical_func)\n",
       "        1    0.000    0.000    0.002    0.002 frame.py:3749(_reindex_index)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:1614(is_complex_dtype)\n",
       "        3    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(setdiff1d)\n",
       "        5    0.000    0.000    0.000    0.000 function_base.py:257(iterable)\n",
       "       18    0.000    0.000    0.000    0.000 default.py:828(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 typing.py:713(__subclasscheck__)\n",
       "        7    0.000    0.000    0.000    0.000 sre_parse.py:343(_escape)\n",
       "        3    0.000    0.000    0.004    0.001 __init__.py:109(import_module)\n",
       "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:719(find_spec)\n",
       "       28    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:40(_relax_case)\n",
       "       35    0.000    0.000    0.000    0.000 {method '_is_owned' of '_thread.RLock' objects}\n",
       "        6    0.000    0.000    0.000    0.000 expressions.py:401(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 necompiler.py:94(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:314(getInputOrder)\n",
       "        2    0.000    0.000    0.000    0.000 extensions.py:171(<listcomp>)\n",
       "        2    0.000    0.000    0.001    0.001 psycopg2.py:844(on_connect)\n",
       "       18    0.000    0.000    0.000    0.000 compiler.py:650(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:1578(_truncated_identifier)\n",
       "        1    0.000    0.000    0.004    0.004 attr.py:281(_exec_once_impl)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4037(_set_table)\n",
       "        9    0.000    0.000    0.000    0.000 elements.py:4443(_string_or_unprintable)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:39(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 langhelpers.py:875(oneshot)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:925(__getattr__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:775(unique_list)\n",
       "        2    0.000    0.000    0.001    0.001 merge.py:2012(_items_overlap_with_suffix)\n",
       "        6    0.000    0.000    0.000    0.000 range.py:444(equals)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:5563(astype)\n",
       "        1    0.000    0.000    0.001    0.001 frame.py:2988(_set_item)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:4524(_maybe_casted_values)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:1220(_set_names)\n",
       "        7    0.000    0.000    0.000    0.000 base.py:3044(_convert_list_indexer)\n",
       "       12    0.000    0.000    0.000    0.000 base.py:5361(_ensure_has_len)\n",
       "        2    0.000    0.000    0.000    0.000 sorting.py:129(is_int64_overflow_possible)\n",
       "        3    0.000    0.000    0.000    0.000 common.py:247(index_labels_to_array)\n",
       "        3    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(in1d)\n",
       "        4    0.000    0.000    0.000    0.000 typing.py:710(__instancecheck__)\n",
       "        4    0.000    0.000    0.000    0.000 sre_compile.py:249(_compile_charset)\n",
       "       10    0.000    0.000    0.000    0.000 sre_compile.py:423(_simple)\n",
       "        1    0.000    0.000    0.000    0.000 sre_compile.py:536(_compile_info)\n",
       "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:884(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1404(_fill_cache)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:94(__new__)\n",
       "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:194(_lock_unlock_module)\n",
       "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:307(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:311(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:873(_find_spec_legacy)\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:368(assignLeafRegisters)\n",
       "        1    0.000    0.000    0.016    0.016 __init__.py:82(connect)\n",
       "        7    0.000    0.000    0.000    0.000 binaryTree.py:56(getRootVal)\n",
       "       12    0.000    0.000    0.000    0.000 compiler.py:352(__str__)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:911(visit_typeclause)\n",
       "        1    0.000    0.000    0.016    0.016 strategies.py:106(connect)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1289(_cursor_execute)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:94(__getattr__)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3718(_columns_plus_names)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2160(__init__)\n",
       "       11    0.000    0.000    0.000    0.000 elements.py:4257(__new__)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:38(_from_objects)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:361(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 merge.py:1987(_should_fill)\n",
       "        4    0.000    0.000    0.000    0.000 merge.py:1993(_any)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:3093(<listcomp>)\n",
       "        1    0.000    0.000    0.042    0.042 api.py:260(get_consensus_names)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:1748(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:1762(<listcomp>)\n",
       "       12    0.000    0.000    0.000    0.000 base.py:2210(_validate_sort_keyword)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:2586(_convert_can_do_setop)\n",
       "       12    0.000    0.000    0.000    0.000 concat.py:119(<genexpr>)\n",
       "       24    0.000    0.000    0.000    0.000 common.py:192(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:209(count_not_none)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:469(get_rename_function)\n",
       "        4    0.000    0.000    0.000    0.000 inference.py:299(is_dict_like)\n",
       "       20    0.000    0.000    0.000    0.000 dtypes.py:588(categories)\n",
       "        1    0.000    0.000    0.004    0.004 check.py:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:546(_dialect_specific_select_one)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:212(_acquireLock)\n",
       "       22    0.000    0.000    0.000    0.000 sre_parse.py:111(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 sre_parse.py:224(__init__)\n",
       "       25    0.000    0.000    0.000    0.000 sre_parse.py:286(tell)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:913(parse)\n",
       "        1    0.000    0.000    0.000    0.000 posixpath.py:154(dirname)\n",
       "       21    0.000    0.000    0.000    0.000 _collections_abc.py:302(__subclasshook__)\n",
       "        5    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "        1    0.000    0.000    0.000    0.000 utf_8.py:33(getregentry)\n",
       "       17    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
       "      9/3    0.000    0.000    0.000    0.000 necompiler.py:127(__hash__)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:200(__setitem__)\n",
       "        2    0.000    0.000    0.000    0.000 expressions.py:90(func)\n",
       "        9    0.000    0.000    0.000    0.000 <ipython-input-5-f3885a2e711d>:16(<listcomp>)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method psycopg2._psycopg.register_type}\n",
       "       15    0.000    0.000    0.000    0.000 {method 'fetchone' of 'psycopg2.extensions.cursor' objects}\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2516(get_isolation_level)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:436(__missing__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2123(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:2412(literal_column)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:4305(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:4420(apply_map)\n",
       "        9    0.000    0.000    0.000    0.000 sql.py:552(_engine_builder)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1842(_do_date_conversions)\n",
       "        2    0.000    0.000    0.000    0.000 merge.py:1960(<lambda>)\n",
       "        5    0.000    0.000    0.000    0.000 concat.py:507(_get_result_dim)\n",
       "       10    0.000    0.000    0.000    0.000 merge.py:951(<lambda>)\n",
       "       10    0.000    0.000    0.000    0.000 merge.py:952(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:601(sanitize_index)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:687(construct_return)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'add' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "       18    0.000    0.000    0.000    0.000 managers.py:1057(value_getitem)\n",
       "       12    0.000    0.000    0.000    0.000 range.py:256(step)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:175(_unique_indices)\n",
       "        2    0.000    0.000    0.001    0.000 frame.py:4920(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:1760(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:2081(_get_unique_index)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:234(_get_values)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:156(maybe_upcast_for_op)\n",
       "       12    0.000    0.000    0.000    0.000 dtypes.py:497(validate_ordered)\n",
       "       12    0.000    0.000    0.000    0.000 dtypes.py:595(ordered)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:83(_get_single_key)\n",
       "        2    0.000    0.000    0.000    0.000 function_base.py:4640(append)\n",
       "        6    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
       "        7    0.000    0.000    0.000    0.000 _methods.py:36(_sum)\n",
       "       16    0.000    0.000    0.000    0.000 numerictypes.py:587(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(where)\n",
       "        1    0.000    0.000    0.016    0.016 default.py:488(connect)\n",
       "       14    0.000    0.000    0.000    0.000 typing.py:351(<genexpr>)\n",
       "       14    0.000    0.000    0.000    0.000 typing.py:893(cast)\n",
       "       11    0.000    0.000    0.000    0.000 sre_parse.py:168(__setitem__)\n",
       "        8    0.000    0.000    0.000    0.000 re.py:307(_subx)\n",
       "        1    0.000    0.000    0.000    0.000 weakref.py:356(__init__)\n",
       "       18    0.000    0.000    0.000    0.000 _collections_abc.py:271(__subclasshook__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1319(__init__)\n",
       "        3    0.000    0.000    0.004    0.001 <frozen importlib._bootstrap>:994(_gcd_import)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:486(VariableNode)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:427(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:505(quadrupleToString)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:148(detect_number_of_cores)\n",
       "        2    0.000    0.000    0.000    0.000 utils.py:196(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 expressions.py:183(operation)\n",
       "        2    0.000    0.000    0.000    0.000 psycopg2.py:804(on_connect)\n",
       "        7    0.000    0.000    0.000    0.000 binaryTree.py:17(__init__)\n",
       "        1    0.000    0.000    0.004    0.004 attr.py:301(exec_once_unless_exception)\n",
       "        3    0.000    0.000    0.000    0.000 type_api.py:317(_has_column_expression)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4466(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4461(_select_iterables)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:60(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:1051(module)\n",
       "        9    0.000    0.000    0.000    0.000 _collections.py:151(union)\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:882(close)\n",
       "        6    0.000    0.000    0.000    0.000 parsers.py:1191(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1979(_set_noconvert_columns)\n",
       "        2    0.000    0.000    0.000    0.000 merge.py:1175(_validate_specification)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:4027(reindex)\n",
       "       12    0.000    0.000    0.000    0.000 range.py:233(stop)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:3590(reindexer)\n",
       "        5    0.000    0.000    0.000    0.000 generic.py:381(<dictcomp>)\n",
       "       24    0.000    0.000    0.000    0.000 generic.py:1625(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 generic.py:3623(_set_item)\n",
       "        4    0.000    0.000    0.000    0.000 categorical.py:396(categories)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:88(_ensure_type)\n",
       "        1    0.000    0.000    0.001    0.001 construction.py:590(create_series_with_explicit_dtype)\n",
       "        8    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(putmask)\n",
       "       16    0.000    0.000    0.000    0.000 numerictypes.py:655(<listcomp>)\n",
       "       10    0.000    0.000    0.000    0.000 multiarray.py:584(min_scalar_type)\n",
       "       29    0.000    0.000    0.000    0.000 multiarray.py:469(can_cast)\n",
       "        3    0.000    0.000    0.000    0.000 <ipython-input-4-01a4bf55ac48>:9(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 version.py:302(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 version.py:312(<listcomp>)\n",
       "        9    0.000    0.000    0.000    0.000 result.py:758(keys)\n",
       "        3    0.000    0.000    0.000    0.000 result.py:1304(scalar)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:3555(_requires_quotes)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:3607(quote)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method now}\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1216(getLogger)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1336(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 __init__.py:1600(getEffectiveLevel)\n",
       "        3    0.000    0.000    0.000    0.000 sre_parse.py:96(closegroup)\n",
       "        1    0.000    0.000    0.000    0.000 enum.py:836(__and__)\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1040(create_module)\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1445(path_hook_for_FileFinder)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
       "      6/2    0.000    0.000    0.000    0.000 necompiler.py:166(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:387(collapseDuplicateSubtrees)\n",
       "        3    0.000    0.000    0.000    0.000 necompiler.py:602(<genexpr>)\n",
       "        1    0.000    0.000    0.001    0.001 <ipython-input-20-7745f02ab811>:11(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 <ipython-input-21-c9fd36f58387>:83(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 expressions.py:191(evaluate)\n",
       "        2    0.000    0.000    0.000    0.000 psycopg2.py:797(on_connect)\n",
       "        7    0.000    0.000    0.000    0.000 stack.py:14(push)\n",
       "        7    0.000    0.000    0.000    0.000 stack.py:17(pop)\n",
       "        2    0.000    0.000    0.001    0.001 strategies.py:183(on_connect)\n",
       "        5    0.000    0.000    0.000    0.000 type_api.py:1453(to_instance)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:2537(_from_objects)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:4665(_literal_as_binds)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:274(_type_memos)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:396(__iter__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:779(<listcomp>)\n",
       "        9    0.000    0.000    0.000    0.000 sql.py:68(_process_parse_dates_argument)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:1545(_maybe_make_multi_index_columns)\n",
       "        2    0.000    0.000    0.000    0.000 merge.py:1312(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 construction.py:249(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 common.py:120(is_s3_url)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:581(astype)\n",
       "        2    0.000    0.000    0.000    0.000 frame.py:3046(_ensure_valid_index)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:660(_set_axis)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1581(is_monotonic)\n",
       "        4    0.000    0.000    0.000    0.000 categorical.py:446(dtype)\n",
       "       12    0.000    0.000    0.000    0.000 common.py:213(<genexpr>)\n",
       "        8    0.000    0.000    0.000    0.000 common.py:274(maybe_make_list)\n",
       "        3    0.000    0.000    0.000    0.000 inference.py:395(is_sequence)\n",
       "       17    0.000    0.000    0.000    0.000 fromnumeric.py:2838(_prod_dispatcher)\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(bincount)\n",
       "        8    0.000    0.000    0.000    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
       "        1    0.000    0.000    0.000    0.000 hub.py:430(backend)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:212(_import_one_of)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:248(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:245(validate)\n",
       "        1    0.000    0.000    0.001    0.001 default.py:415(<setcomp>)\n",
       "        1    0.000    0.000    0.020    0.020 base.py:434(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:3340(_render_string_type)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:3355(visit_VARCHAR)\n",
       "       10    0.000    0.000    0.000    0.000 typing.py:317(__eq__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1267(_fixupParents)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1925(getLogger)\n",
       "        2    0.000    0.000    0.000    0.000 copy.py:66(copy)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:954(addgroup)\n",
       "       40    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:321(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method builtins.eval}\n",
       "       12    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
       "        6    0.000    0.000    0.000    0.000 csvs.py:135(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 expressions.py:489(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 expressions.py:532(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:80(ASTNode)\n",
       "        3    0.000    0.000    0.000    0.000 necompiler.py:242(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 necompiler.py:311(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:413(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:450(setRegisterNumbersForTemporaries)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:483(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 necompiler.py:492(nToChr)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:512(toString)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:724(getArguments)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:65(set_vml_num_threads)\n",
       "        1    0.000    0.000    0.000    0.000 <expr>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 <ipython-input-21-c9fd36f58387>:54(make_parse_tree)\n",
       "        4    0.000    0.000    0.000    0.000 expressions.py:77(set_new_context)\n",
       "        1    0.000    0.000    0.000    0.000 extras.py:790(_solve_conn_curs)\n",
       "        1    0.000    0.000    0.000    0.000 psycopg2.py:747(_psycopg2_extras)\n",
       "        2    0.000    0.000    0.001    0.001 psycopg2.py:812(on_connect)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2703(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 <ipython-input-4-01a4bf55ac48>:14(corpus_config)\n",
       "        3    0.000    0.000    0.000    0.000 binaryTree.py:22(insertLeft)\n",
       "       10    0.000    0.000    0.000    0.000 binaryTree.py:50(getLeftChild)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:399(process)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:410(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1791(_add_to_result_map)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:278(_memoized_attr__exec_once_mutex)\n",
       "        2    0.000    0.000    0.000    0.000 <string>:1(cast)\n",
       "        6    0.000    0.000    0.000    0.000 elements.py:4034(_get_table)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4043(_from_objects)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:1068(__getattr__)\n",
       "        1    0.000    0.000    0.003    0.003 langhelpers.py:1478(go)\n",
       "        1    0.000    0.000    0.000    0.000 inspection.py:38(inspect)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1170(_is_index_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1551(_make_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2110(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3258(_process_date_conversion)\n",
       "        5    0.000    0.000    0.000    0.000 construction.py:252(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 common.py:127(is_gcs_url)\n",
       "        7    0.000    0.000    0.000    0.000 indexing.py:1343(_convert_for_reindex)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:7264(isna)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1755(_isnan)\n",
       "       12    0.000    0.000    0.000    0.000 concat.py:105(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:396(nanany)\n",
       "        1    0.000    0.000    0.000    0.000 missing.py:136(dispatch_fill_zeros)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:280(maybe_iterable_to_list)\n",
       "        7    0.000    0.000    0.000    0.000 common.py:476(f)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:101(_get_option)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:230(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:551(_get_root)\n",
       "        2    0.000    0.000    0.000    0.000 config.py:566(_get_deprecated_option)\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(insert)\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(append)\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(moveaxis)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1693(ravel)\n",
       "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(may_share_memory)\n",
       "       10    0.000    0.000    0.000    0.000 shape_base.py:79(_atleast_2d_dispatcher)\n",
       "        4    0.000    0.000    0.000    0.000 multiarray.py:312(where)\n",
       "        7    0.000    0.000    0.000    0.000 timeout.py:260(_start_new_or_dummy)\n",
       "        3    0.000    0.000    0.000    0.000 default.py:1034(no_parameters)\n",
       "        9    0.000    0.000    0.000    0.000 default.py:1136(pre_exec)\n",
       "        1    0.000    0.000    0.020    0.020 base.py:305(_create_connection)\n",
       "        1    0.000    0.000    0.000    0.000 impl.py:143(_inc_overflow)\n",
       "       16    0.000    0.000    0.000    0.000 typing.py:322(__hash__)\n",
       "        3    0.000    0.000    0.000    0.000 parse.py:394(_checknetloc)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:1098(machine)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:221(_releaseLock)\n",
       "        8    0.000    0.000    0.000    0.000 sre_parse.py:81(groups)\n",
       "        3    0.000    0.000    0.000    0.000 sre_parse.py:84(opengroup)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:297(_compile_repl)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:284(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_compile.py:461(_get_literal_prefix)\n",
       "        3    0.000    0.000    0.000    0.000 _collections_abc.py:349(__subclasshook__)\n",
       "        2    0.000    0.000    0.000    0.000 codecs.py:186(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:424(has_location)\n",
       "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:929(_sanity_check)\n",
       "       36    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'rsplit' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'join' of 'bytes' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:493(RawNode)\n",
       "      3/1    0.000    0.000    0.000    0.000 necompiler.py:228(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:332(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:442(setOrderedRegisterNumbers)\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:685(getType)\n",
       "        6    0.000    0.000    0.000    0.000 expressions.py:113(isConstant)\n",
       "        1    0.000    0.000    0.000    0.000 <ipython-input-21-c9fd36f58387>:62(preprocess_sentence)\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:160(_has_bool_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:52(Expression)\n",
       "        1    0.000    0.000    0.000    0.000 __config__.py:15(get_info)\n",
       "        2    0.000    0.000    0.000    0.000 extensions.py:164(<dictcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method psycopg2._psycopg.new_type}\n",
       "        2    0.000    0.000    0.000    0.000 extensions.py:103(register_adapter)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1681(get_select_precolumns)\n",
       "       10    0.000    0.000    0.000    0.000 binaryTree.py:47(getRightChild)\n",
       "        1    0.000    0.000    0.000    0.000 stack.py:8(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:419(type)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:920(escape_literal_column)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2121(<listcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 base.py:364(connection)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:330(__bool__)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3740(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:1305(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1321(_validate_parse_dates_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2108(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3346(_clean_na_values)\n",
       "        3    0.000    0.000    0.000    0.000 concat.py:562(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 concat.py:576(_maybe_check_integrity)\n",
       "        5    0.000    0.000    0.000    0.000 construction.py:245(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 series.py:678(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:4400(isna)\n",
       "        2    0.000    0.000    0.000    0.000 range.py:320(is_unique)\n",
       "        2    0.000    0.000    0.000    0.000 api.py:190(conv)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:195(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:255(_validate_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:3084(_can_reindex)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:4013(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:4020(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:189(_maybe_get_mask)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:424(_align_method_SERIES)\n",
       "        1    0.000    0.000    0.000    0.000 inference.py:130(is_file_like)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.fast_unique_multiple_list}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "        1    0.000    0.000    0.000    0.000 config.py:533(_select_options)\n",
       "        3    0.000    0.000    0.000    0.000 arraysetops.py:741(_setdiff1d_dispatcher)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(ravel)\n",
       "        1    0.000    0.000    0.000    0.000 hub.py:426(loop_class)\n",
       "        1    0.000    0.000    0.000    0.000 hub.py:594(start_periodic_monitoring_thread)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:69(__ge__)\n",
       "        2    0.000    0.000    0.000    0.000 version.py:331(_cmp)\n",
       "        2    0.000    0.000    0.000    0.000 compiler.py:3676(format_label)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'timestamp' of 'datetime.datetime' objects}\n",
       "       16    0.000    0.000    0.000    0.000 typing.py:613(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 typing.py:655(__eq__)\n",
       "        9    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
       "        2    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1164(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1356(debug)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1368(info)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_parse.py:897(fix_flags)\n",
       "        1    0.000    0.000    0.001    0.001 re.py:170(match)\n",
       "        3    0.000    0.000    0.000    0.000 sre_compile.py:65(_combine_flags)\n",
       "        2    0.000    0.000    0.000    0.000 enum.py:526(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 sre_compile.py:492(_get_charset_prefix)\n",
       "        1    0.000    0.000    0.000    0.000 sre_compile.py:598(_code)\n",
       "        1    0.000    0.000    0.000    0.000 posixpath.py:75(join)\n",
       "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:909(get_filename)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method builtins.chr}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {method 'isalnum' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'index' of 'tuple' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'issuperset' of 'set' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:512(ConstantNode)\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:529(OpNode)\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:139(key)\n",
       "        3    0.000    0.000    0.000    0.000 necompiler.py:197(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:231(Register)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:260(Immediate)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:309(isReduction)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:345(getConstants)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:380(assignBranchRegisters)\n",
       "        2    0.000    0.000    0.000    0.000 necompiler.py:414(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:474(convertASTtoThreeAddrForm)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:525(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:487(compileThreeAddrForm)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:821(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:81(set_num_threads)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:191(CacheDict)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:11(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:69(Context)\n",
       "        2    0.000    0.000    0.000    0.000 expressions.py:105(allConstantNodes)\n",
       "        2    0.000    0.000    0.000    0.000 expressions.py:119(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 <ipython-input-20-7745f02ab811>:10(Results)\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:169(_bool_arith_check)\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:53(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2563(_get_default_schema_name)\n",
       "        7    0.000    0.000    0.000    0.000 binaryTree.py:53(setRootVal)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:177(__enter__)\n",
       "        3    0.000    0.000    0.000    0.000 type_api.py:279(result_processor)\n",
       "       10    0.000    0.000    0.000    0.000 _collections.py:145(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:923(_check_file_or_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1156(_create_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1271(_validate_usecols_arg)\n",
       "        4    0.000    0.000    0.000    0.000 merge.py:1997(_validate_operand)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:661(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 managers.py:1815(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1582(_consolidate_inplace)\n",
       "        1    0.000    0.000    0.000    0.000 blocks.py:187(is_categorical_astype)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:4092(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:166(_get_fill_value)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:329(_na_ok_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_float64}\n",
       "        1    0.000    0.000    0.000    0.000 config.py:607(_warn_if_deprecated)\n",
       "        2    0.000    0.000    0.000    0.000 function_base.py:4425(_insert_dispatcher)\n",
       "        2    0.000    0.000    0.000    0.000 function_base.py:4636(_append_dispatcher)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1689(_ravel_dispatcher)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:1327(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 numeric.py:1336(_moveaxis_dispatcher)\n",
       "        2    0.000    0.000    0.000    0.000 numeric.py:1403(<listcomp>)\n",
       "        9    0.000    0.000    0.000    0.000 numeric.py:2283(_array_equal_dispatcher)\n",
       "        2    0.000    0.000    0.000    0.000 multiarray.py:853(bincount)\n",
       "        2    0.000    0.000    0.000    0.000 multiarray.py:1078(putmask)\n",
       "        2    0.000    0.000    0.000    0.000 _config.py:91(validate_bool)\n",
       "        3    0.000    0.000    0.000    0.000 _config.py:109(validate_anything)\n",
       "        3    0.000    0.000    0.000    0.000 _config.py:130(_convert)\n",
       "        1    0.000    0.000    0.000    0.000 version.py:51(__lt__)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:355(_check_max_identifier_length)\n",
       "        9    0.000    0.000    0.000    0.000 default.py:1139(post_exec)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:3412(visit_unicode)\n",
       "        1    0.000    0.000    0.000    0.000 platform.py:923(uname)\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:72(isclass)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:187(_checkLevel)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:716(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 sre_compile.py:595(isstring)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
       "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:719(create_module)\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1029(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1048(exec_module)\n",
       "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1325(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:98(_path_isdir)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _imp.exec_dynamic}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:482(LeafNode)\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:538(FuncNode)\n",
       "        3    0.000    0.000    0.000    0.000 necompiler.py:142(typecode)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:354(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:558(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:601(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 necompiler.py:721(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 expressions.py:74(get_current_context)\n",
       "        4    0.000    0.000    0.000    0.000 expressions.py:240(gen_reduce_axis_func)\n",
       "        1    0.000    0.000    0.000    0.000 expressions.py:40(set_use_numexpr)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method psycopg2._psycopg.new_array_type}\n",
       "        3    0.000    0.000    0.000    0.000 binaryTree.py:34(insertRight)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:735(default_from)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:365(for_modify)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3067(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:755(_select_iterable)\n",
       "        2    0.000    0.000    0.000    0.000 langhelpers.py:878(memo)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:396(_validate_names)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1432(_has_complex_date_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3213(_make_date_converter)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:658(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 series.py:659(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:78(validate_header_arg)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1576(is_consolidated)\n",
       "        1    0.000    0.000    0.000    0.000 _optional.py:36(_get_version)\n",
       "        1    0.000    0.000    0.000    0.000 config.py:594(_translate_key)\n",
       "        3    0.000    0.000    0.000    0.000 arraysetops.py:480(_in1d_dispatcher)\n",
       "        3    0.000    0.000    0.000    0.000 function_base.py:4214(_delete_dispatcher)\n",
       "        8    0.000    0.000    0.000    0.000 fromnumeric.py:993(_argsort_dispatcher)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method greenlet.getcurrent}\n",
       "        7    0.000    0.000    0.000    0.000 timeout.py:56(stop)\n",
       "        1    0.000    0.000    0.000    0.000 multiarray.py:1309(may_share_memory)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        4    0.000    0.000    0.000    0.000 typing.py:176(<listcomp>)\n",
       "       18    0.000    0.000    0.000    0.000 parse.py:98(_noop)\n",
       "        2    0.000    0.000    0.000    0.000 sre_compile.py:453(_get_iscased)\n",
       "        1    0.000    0.000    0.000    0.000 _collections_abc.py:367(__subclasshook__)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "def main():\n",
    "    '''\n",
    "        corpora: i2b2, mipacq, fv017\n",
    "        analyses: entity only (exact span), cui by document, full (aka (entity and cui on exaact span/exact cui)\n",
    "        systems: ctakes, biomedicus, clamp, metamap, quick_umls\n",
    "        \n",
    "        TODO -> Vectorization (entity only) -> done:\n",
    "                add switch for use of TN on single system performance evaluations -> done\n",
    "                add switch for overlap matching versus exact span -> done\n",
    "             -> Other tasks besides concept extraction\n",
    "        \n",
    "    ''' \n",
    "    analysisConf =  AnalysisConfig()\n",
    "    print(analysisConf.systems, analysisConf.corpus_config())\n",
    "    \n",
    "    if (rtype == 1):\n",
    "        print(semtypes, systems)\n",
    "        if filter_semtype:\n",
    "            for semtype in semtypes:\n",
    "                test = get_valid_systems(systems, semtype)\n",
    "                print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "                generate_metrics(analysis_type, corpus, filter_semtype, semtype)\n",
    "            \n",
    "        else:\n",
    "            generate_metrics(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    elif (rtype == 2):\n",
    "        print('run_type:', run_type)\n",
    "        if filter_semtype:\n",
    "            print(semtypes)\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype)\n",
    "    elif (rtype == 3):\n",
    "        t = ['concept_jaccard_score_false']\n",
    "        test_systems(analysis_type, analysisConf.systems, corpus)  \n",
    "        test_count(analysis_type, corpus)\n",
    "        test_ensemble(analysis_type, corpus)\n",
    "    elif (rtype == 4):\n",
    "        if filter_semtype:\n",
    "            majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            majority_vote(systems, analysis_type, corpus, run_type, filter_semtype)\n",
    "    elif (rtype == 5):\n",
    "        \n",
    "        # control filter_semtype in get_sys_data, get_ref_n and generate_metrics. TODO consolidate. \n",
    "        # # run single ad hoc statement\n",
    "        statement = '((ctakes&biomedicus)|metamap)'\n",
    "\n",
    "        def ad_hoc(analysis_type, corpus, statement):\n",
    "            sys = get_merge_data(statement, analysis_type, corpus, run_type, filter_semtype)\n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "            sys['label'] = 'concept'\n",
    "\n",
    "            ref = get_reference_vector(analysis_type, corpus, filter_semtype)\n",
    "            sys = vectorized_annotations(sys)\n",
    "            sys = np.asarray(flatten_list(list(sys)), dtype=np.int32)\n",
    "\n",
    "            return ref, sys\n",
    "\n",
    "        ref, sys = ad_hoc(analysis_type, corpus, statement)\n",
    "\n",
    "    elif (rtype == 6): # 5 w/o evaluation\n",
    "        \n",
    "        statement = '(((biomedicus&ctakes)&metamap)|clamp)' #'((((biomedicus&ctakes)&metamap)&quick_umls)|clamp)' #'(ctakes|biomedicus)' #((((A∧C)∧D)∧E)∨B)->for covid pipeline\n",
    "\n",
    "        def ad_hoc(analysis_type, corpus, statement):\n",
    "            print(semtypes)\n",
    "            for semtype in semtypes:\n",
    "                sys = get_sys_merge(statement, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "                sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "\n",
    "            return sys\n",
    "\n",
    "        sys = ad_hoc(analysis_type, corpus, statement).sort_values(by=['case', 'begin'])\n",
    "        sys.drop_duplicates(['cui', 'case', 'polarity'],inplace=True)\n",
    "        sys.to_csv(data_directory + 'test_new.csv')\n",
    "       \n",
    "        now = datetime.now()\n",
    "        timestamp = datetime.timestamp(now)\n",
    "        test = sys.copy()\n",
    "        test.drop(['begin','end'], axis=1, inplace=True) \n",
    "        test.to_csv(data_directory + 'ensemble_' + str(timestamp) + '.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    %prun main()\n",
    "    #main()\n",
    "    print('done!')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
