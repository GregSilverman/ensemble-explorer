{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Copyright (c) 2019 Regents of the University of Minnesota.\n",
    " \n",
    "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    " \n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pymysql\n",
    "import time \n",
    "import functools as ft\n",
    "import glob, os, sys   \n",
    "import operator as op\n",
    "import shelve\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, permutations\n",
    "from sqlalchemy.engine import create_engine\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from scipy import stats  \n",
    "from scipy.stats.mstats import gmean\n",
    "from pythonds.basic.stack import Stack\n",
    "from pythonds.trees.binaryTree import BinaryTree\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from typing import List, Set, Tuple \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cell below contains the configurable parameters to ensure that our ensemble explorer runs properaly on your machine. \n",
    "Please read carfully through steps (1-11) before running the rest of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-1: CHOOSE YOUR CORPUS\n",
    "# TODO: get working with list of corpora\n",
    "#corpora = ['mipacq','i2b2','fairview'] #options for concept extraction include 'fairview', 'mipacq' OR 'i2b2'\n",
    "\n",
    "# cross-system semantic union merge filter for cross system aggregations using custom system annotations file with corpus name and system name using 'ray_test': \n",
    "# need to add semantic type filrering when reading in sys_data\n",
    "#corpus = 'ray_test'\n",
    "corpus = 'clinical_trial'\n",
    "#corpus = 'i2b2'\n",
    "#corpora = ['i2b2','fairview']\n",
    "\n",
    "# STEP-2: CHOOSE YOUR DATA DIRECTORY; this is where output data will be saved on your machine\n",
    "data_directory = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/' \n",
    "\n",
    "# STEP-3: CHOOSE WHICH SYSTEMS YOU'D LIKE TO EVALUATE AGAINST THE CORPUS REFERENCE SET\n",
    "systems = ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
    "#systems = ['biomedicus', 'clamp', 'metamap', 'quick_umls']\n",
    "#systems = ['biomedicus', 'quick_umls']\n",
    "#systems = ['biomedicus', 'ctakes', 'quick_umls']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['ctakes', 'quick_umls', 'biomedicus', 'metamap']\n",
    "#systems = ['biomedicus', 'metamap']\n",
    "#systems = ['ray_test']\n",
    "#systems = ['quick_umls']\n",
    "\n",
    "# STEP-4: CHOOSE TYPE OF RUN\n",
    "rtype = 2      # OPTIONS INCLUDE: 1->Single systems; 2->Ensemble; 3->Tests; 4 -> majority vote \n",
    "               # The Ensemble can include the max system set ['ctakes','biomedicus','clamp','metamap','quick_umls']\n",
    "    \n",
    "# STEP-5: CHOOSE WHAT TYPE OF ANALYSIS YOU'D LIKE TO RUN ON THE CORPUS\n",
    "analysis_type = 'entity' #options include 'entity', 'cui' OR 'full'\n",
    "\n",
    "# STEP-(6A): ENTER DETAILS FOR ACCESSING MANUAL ANNOTATION DATA\n",
    "database_type = 'mysql+pymysql' # We use mysql+pymql as default\n",
    "database_username = 'gms'\n",
    "database_password = 'nej123' \n",
    "database_url = 'localhost' # HINT: use localhost if you're running database on your local machine\n",
    "database_name = 'clinical_trial' # Enter database name\n",
    "#database_name = 'concepts' # Enter database name\n",
    "\n",
    "def ref_data(corpus):\n",
    "    return corpus + '_all' # Enter the table within the database where your reference data is stored\n",
    "\n",
    "table_name = ref_data(corpus)\n",
    "\n",
    "# STEP-(6B): ENTER DETAILS FOR ACCESSING SYSTEM ANNOTATION DATA\n",
    "\n",
    "def sys_data(corpus, analysis_type):\n",
    "    if analysis_type == 'entity':\n",
    "        return 'analytical_'+corpus+'.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "    elif analysis_type in ('cui', 'full'):\n",
    "        return 'analytical_'+corpus+'_cui.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "        \n",
    "system_annotation = sys_data(corpus, analysis_type)\n",
    "\n",
    "# STEP-7: CREATE A DB CONNECTION POOL\n",
    "engine_request = str(database_type)+'://'+database_username+':'+database_password+\"@\"+database_url+'/'+database_name\n",
    "engine = create_engine(engine_request, pool_pre_ping=True, pool_size=20, max_overflow=30)\n",
    "\n",
    "# STEP-(8A): FILTER BY SEMTYPE\n",
    "filter_semtype = True#False\n",
    "\n",
    "# STEP-(8B): IF STEP-(8A) == True -> GET REFERENCE SEMTYPES\n",
    "\n",
    "### Fairview -> ['drug', 'finding', 'anatomy', 'procedure']\n",
    "### i2b2 -> ['test, treatment', 'problem']\n",
    "### MiPACQ -> ['procedures', 'disorders, sign_symptom', 'anatomy', 'chemicals_and_drugs']\n",
    "\n",
    "# semtypes = ['Anatomy']\n",
    "def ref_semtypes(filter_semtype, corpus):\n",
    "    if filter_semtype:\n",
    "        if corpus == 'fairview':\n",
    "            semtypes = ['Drug', 'Finding', 'Anatomy', 'Procedure']\n",
    "        elif corpus == 'i2b2':\n",
    "            semtypes = ['test,treatment', 'problem']\n",
    "        elif corpus == 'mipacq':\n",
    "            semtypes = ['Procedures', 'Disorders,Sign_Symptom', 'Anatomy', 'Chemicals_and_drugs']\n",
    "            #semtypes = ['Anatomy']\n",
    "        elif corpus in ['clinical_trial', 'clinical_trial2']:\n",
    "            semtypes = [#'drug,drug::drug_name,drug::drug_dose,dietary_supplement::dietary_supplement_name,dietary_supplement::dietary_supplement_dose']#, -> all systems, nested\n",
    "                        'temporal_measurement,qualifier,measurement']#, #-> single ctakes, b9, qu\n",
    "                        #'device',#, # all but ctakes, nested; single for #2\n",
    "                        #'condition,observation', # all, nested\n",
    "                        #'demographics::age,demographics::sex,demographics::race_ethnicity,demographics::bmi,demographics::weight']#eva,# single,b9, qu\n",
    "                        #'diet']#, # single qu\n",
    "                        #'measurement,qualifier']#,# ctakes, b9 and qu -> single\n",
    "                        #'procedure,observation'] # -> all, nested; single for #2\n",
    "\n",
    "#             semtypes = ['condition',\n",
    "#                         'qualifier',\n",
    "#                         'drug::drug_name',\n",
    "#                         'temporal_measurement',\n",
    "#                         'observation',\n",
    "#                         'demographics::age',\n",
    "#                         'demographics::weight',\n",
    "#                         'measurement',\n",
    "#                         'demographics::BMI',\n",
    "#                         'diet',\n",
    "#                         'procedure',\n",
    "#                         'device',\n",
    "#                         'demographics::gender',\n",
    "#                         'negation',\n",
    "#                         'dietary_supplement::dietary_supplement_name',\n",
    "#                         'dietary_supplement::dietary_supplement_dose',\n",
    "#                         'demographics::race_ethnicity',\n",
    "#                         'drug::drug_dose',\n",
    "#                         'drug'\n",
    "#                         ]\n",
    "        \n",
    "        return semtypes\n",
    "\n",
    "semtypes = ref_semtypes(filter_semtype, corpus)\n",
    "\n",
    "# STEP-9: Set data directory/table for source documents for vectorization\n",
    "src_table = 'sofa'\n",
    "\n",
    "# STEP-10: Specificy match type from {'exact', 'overlap', 'cui' -> kludge for majority}\n",
    "run_type = 'overlap'\n",
    "\n",
    "# for clinical trial, measurement/temoral are single system since no overlap for intersect\n",
    "# STEP-11: Specify expression type for run (TODO: run all at once; make less kludgey)\n",
    "expression_type = 'nested' #'nested_with_singleton' # type of merge expression: nested ((A&B)|C), paired ((A&B)|(C&D)), nested_with_singleton ((A&B)|((C&D)|E)) \n",
    "# -> NB: len(systems) for pair must be >= 4, and for nested_with_singleton == 5; single-> skip merges\n",
    "\n",
    "# STEP-12: Specify type of ensemble: merge or vote\n",
    "ensemble_type = 'merge'\n",
    "\n",
    "# STEP-13: run on negation modifier (TODO: negated entity)\n",
    "modification = None#'negation' "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "****** TODO \n",
    "-> add 'semtype' to output file name -> done\n",
    "-> filter for case when a system has no equivalent semtypes for a given reference -> done: still need to validate that all semtypes in corpus!\n",
    "-> case when system annotations empty from semtype filter; print as 0\n",
    "-> trim whitespace on CSV import -> done for semtypes\n",
    "-> eliminate rtype = 1 for expression_type = 'single'\n",
    "-> cross-system semantic union merge on aggregation\n",
    "-> negation: testing\n",
    "-> other modification, such as 'present'\n",
    "-> clean up configuration process\n",
    "-> allow iteration through all corpora and semtypes\n",
    "-> handle case where intersect merges are empty/any confusion matrix values are 0; specificallly on empty df in evaluate method\n",
    "-> add majority vote to union for analysis_type = 'full'\n",
    "-> optimize vecorization (remove confusion?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config class for analysis\n",
    "class AnalysisConfig():\n",
    "    \"\"\"\n",
    "    Configuration object:\n",
    "    systems to use\n",
    "    notes by corpus\n",
    "    paths by output, gold and system location\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self = self    \n",
    "        self.systems = systems\n",
    "        self.data_dir = data_directory\n",
    "    \n",
    "    def corpus_config(self): \n",
    "        usys_data = system_annotation\n",
    "        ref_data = database_name+'.'+table_name\n",
    "        return usys_data, ref_data\n",
    "\n",
    "analysisConf =  AnalysisConfig()\n",
    "#usys, ref = analysisConf.corpus_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticTypes(object):\n",
    "    '''\n",
    "    Filter semantic types based on: https://metamap.nlm.nih.gov/SemanticTypesAndGroups.shtml\n",
    "    :params: semtypes list from corpus, system to query\n",
    "    :return: list of equivalent system semtypes \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, semtypes, corpus):\n",
    "        self = self\n",
    "        \n",
    "        if corpus == 'clinical_trial2':\n",
    "            corpus = 'clinical_trial' # kludge!!\n",
    "        sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name, biomedicus_name FROM clinical_trial.semantic_groups sg join semantic_types st on sg.tui = st.tui where \" + corpus + \"_name in ({})\"\\\n",
    "            .format(', '.join(['%s' for _ in semtypes]))  \n",
    "#        sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name FROM concepts.semantic_groups sg join semantic_types st on sg.tui = st.tui where \" + corpus + \"_name in ({})\"\\\n",
    "#           .format(', '.join(['%s' for _ in semtypes]))  \n",
    "        \n",
    "        stypes = pd.read_sql(sql, params=[semtypes], con=engine) \n",
    "       \n",
    "        if len(stypes['tui'].tolist()) > 0:\n",
    "            self.biomedicus_types = set(stypes['tui'].tolist())\n",
    "            self.qumls_types = set(stypes['tui'].tolist())\n",
    "        \n",
    "        else:\n",
    "            self.biomedicus_types = None\n",
    "            self.qumls_types = None\n",
    "        \n",
    "        if stypes['clamp_name'].dropna(inplace=True) or len(stypes['clamp_name']) == 0:\n",
    "            self.clamp_types = None\n",
    "        else:\n",
    "            self.clamp_types = set(stypes['clamp_name'].tolist()[0].split(','))\n",
    "         \n",
    "        if stypes['ctakes_name'].dropna(inplace=True) or len(stypes['ctakes_name']) == 0:\n",
    "            self.ctakes_types = None\n",
    "        else:\n",
    "            self.ctakes_types = set(stypes['ctakes_name'].tolist()[0].split(','))\n",
    " \n",
    "# # Kludge for b9 temporal\n",
    "        if stypes['biomedicus_name'].dropna(inplace=True) or len(stypes['biomedicus_name']) > 0:\n",
    "            self.biomedicus_types.update(set(stypes['biomedicus_name'].tolist()[0].split(',')))\n",
    "        #else:\n",
    "        #    self.biomedicus_type = None\n",
    "        \n",
    "        if len(stypes['abbreviation'].tolist()) > 0:\n",
    "            self.metamap_types = set(stypes['abbreviation'].tolist())\n",
    "        else:\n",
    "            self.metamap_types = None\n",
    "        \n",
    "        self.reference_types =  set(semtypes)\n",
    "    \n",
    "    def get_system_type(self, system):  \n",
    "        \n",
    "        if system == 'biomedicus':\n",
    "            semtypes = self.biomedicus_types\n",
    "        elif system == 'ctakes':\n",
    "            semtypes = self.ctakes_types\n",
    "        elif system == 'clamp':\n",
    "            semtypes = self.clamp_types\n",
    "        elif system == 'metamap':\n",
    "            semtypes = self.metamap_types\n",
    "        elif system == 'quick_umls':\n",
    "            semtypes = self.qumls_types\n",
    "        elif system == 'reference':\n",
    "            semtypes = self.reference_types\n",
    "            \n",
    "        return semtypes\n",
    "    \n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('biomedicus'))\n",
    "#print(SemanticTypes(['Drug'], corpus).get_system_type('quick_umls'))\n",
    "#print(SemanticTypes(['drug'], corpus).get_system_type('clamp'))\n",
    "#print(SemanticTypes(['Anatomy'], 'mipacq').get_system_type('ctakes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#semtypes = ['test,treatment']\n",
    "#semtypes = 'drug,drug::drug_name,drug::drug_dose,dietary_supplement::dietary_supplement_name,dietary_supplement::dietary_supplement_dose'\n",
    "#semtypes =  'demographics::age,demographics::sex,demographics::race_ethnicity,demographics::bmi,demographics::weight'\n",
    "#corpus = 'clinical_trial'\n",
    "#sys = 'quick_umls'\n",
    "\n",
    "# is semantic type in particular system\n",
    "def system_semtype_check(sys, semtype, corpus):\n",
    "    st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "    if st:\n",
    "        return sys\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#print(system_semtype_check(sys, semtypes, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for systems\n",
    "class AnnotationSystems():\n",
    "    \"\"\"   \n",
    "    System annotations of interest for UMLS concept extraction\n",
    "    NB: ctakes combines all \"mentions\" annotation types\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"   \n",
    "        \n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\"]\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\"]\n",
    "        self.ctakes_types = [\"ctakes_mentions\"]\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\"]\n",
    "        self.qumls_types = [\"concept_jaccard_score_False\"]\n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "        \n",
    "        elif system == \"quick_umls\":\n",
    "            types = self.qumls_types\n",
    "            \n",
    "        return types, view\n",
    "    \n",
    "annSys = AnnotationSystems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython\n",
    "\n",
    "#import numpy as np # access to Numpy from Python layer\n",
    "#import math\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"\n",
    "    metrics class:\n",
    "    returns an instance with confusion matrix metrics\n",
    "    \"\"\"\n",
    "    def __init__(self, system_only, gold_only, gold_system_match, system_n, neither = 0): # neither: no sys or manual annotation\n",
    "\n",
    "        self = self    \n",
    "        self.system_only = system_only\n",
    "        self.gold_only = gold_only\n",
    "        self.gold_system_match = gold_system_match\n",
    "        self.system_n = system_n\n",
    "        self.neither = neither\n",
    "        \n",
    "    def get_confusion_metrics(self, corpus = None, test = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        compute confusion matrix measures, as per  \n",
    "        https://stats.stackexchange.com/questions/51296/how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\n",
    "        \"\"\"\n",
    "#         cdef:\n",
    "#             int TP, FP, FN\n",
    "#             double TM\n",
    "\n",
    "        TP = self.gold_system_match\n",
    "        FP = self.system_only\n",
    "        FN = self.gold_only\n",
    "        \n",
    "        TM = TP/math.sqrt(self.system_n) # TigMetric\n",
    "       \n",
    "        if not test:\n",
    "            \n",
    "            if corpus == 'casi':\n",
    "                recall = TP/(TP + FN)\n",
    "                precision = TP/(TP + FP)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "            else:\n",
    "                if self.neither == 0:\n",
    "                    confusion = [[0, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                else:\n",
    "                    confusion = [[self.neither, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                c = np.asarray(confusion)\n",
    "                \n",
    "                if TP != 0 or FP != 0:\n",
    "                    precision = TP/(TP+FP)\n",
    "                else:\n",
    "                    precision = 0\n",
    "                \n",
    "                if TP != 0 or FN != 0:\n",
    "                    recall = TP/(TP+FN)\n",
    "                else:\n",
    "                    recall = 0\n",
    "                \n",
    "                if precision + recall != 0:\n",
    "                    F = 2*(precision*recall)/(precision + recall)\n",
    "                else:\n",
    "                    F = 0\n",
    "    \n",
    "#                 recall = np.diag(c) / np.sum(c, axis = 1)\n",
    "#                 precision = np.diag(c) / np.sum(c, axis = 0)\n",
    "#                 #print('Yo!', np.mean(precision), np.mean(recall))\n",
    "#                 if np.mean(precision) != 0 and np.mean(recall) != 0:\n",
    "#                     F = 2*(precision*recall)/(precision + recall)\n",
    "#                 else:\n",
    "#                     F = 0\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            F = 2*(precision*recall)/(precision + recall)\n",
    "        \n",
    "        # Tignanelli Metric\n",
    "        if FN == 0:\n",
    "            TP_FN_R = TP\n",
    "        elif FN > 0:\n",
    "            TP_FN_R = TP/FN\n",
    " \n",
    "        return F, recall, precision, TP, FP, FN, TP_FN_R, TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_set(df, analysis_type = 'entity', df_type = 'sys', corpus = None):\n",
    "    \n",
    "    # get values for creation of series of type tuple\n",
    "    if 'entity' in analysis_type: \n",
    "        if corpus == 'casi':\n",
    "            arg = df.case, df.overlap\n",
    "        else:    \n",
    "            arg = df.begin, df.end, df.case\n",
    "            \n",
    "    elif 'cui' in analysis_type:\n",
    "        arg = df.value, df.case\n",
    "    elif 'full' in analysis_type:\n",
    "        arg = df.begin, df.end, df.value, df.case\n",
    "    \n",
    "    return set(list(zip(*arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython \n",
    "\n",
    "from __main__ import df_to_set, engine\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "def get_cooccurences(ref, sys, analysis_type: str, corpus: str):\n",
    "    \"\"\"\n",
    "    get cooccurences between system and reference; exact match; TODO: add relaxed -> done in single system evals during ensemble run\n",
    "    \"\"\"\n",
    "    # cooccurences\n",
    "    class Cooccurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = set()\n",
    "            self.false_negatives = set()\n",
    "            self.corpus = corpus\n",
    "\n",
    "    c = Cooccurences()\n",
    "    \n",
    "    if c.corpus != 'casi':\n",
    "        if analysis_type in ['cui', 'full']:\n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\", \"cui\": \"value\"})\n",
    "            # do not overestimate FP\n",
    "            sys = sys[~sys['value'].isnull()] \n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "        \n",
    "        if 'entity' in analysis_type: \n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "            cols_to_keep = ['begin', 'end', 'case']\n",
    "        elif 'cui' in analysis_type: \n",
    "            cols_to_keep = ['value', 'case']\n",
    "        elif 'full' in analysis_type: \n",
    "            cols_to_keep = ['begin', 'end', 'value', 'case']\n",
    "        \n",
    "        sys = sys[cols_to_keep].drop_duplicates()\n",
    "        ref = ref[cols_to_keep].drop_duplicates()\n",
    "        # matches via inner join\n",
    "        tp = pd.merge(sys, ref, how = 'inner', left_on=cols_to_keep, right_on = cols_to_keep) \n",
    "        # reference-only via left outer join\n",
    "        fn = pd.merge(ref, sys, how = 'left', left_on=cols_to_keep, right_on = cols_to_keep, indicator=True) \n",
    "        fn = fn[fn[\"_merge\"] == 'left_only']\n",
    "\n",
    "        tp = tp[cols_to_keep]\n",
    "        fn = fn[cols_to_keep]\n",
    "\n",
    "        # use for metrics \n",
    "        c.matches = c.matches.union(df_to_set(tp, analysis_type, 'ref'))\n",
    "        c.false_negatives = c.false_negatives.union(df_to_set(fn, analysis_type, 'ref'))\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches) # fp\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        c.ref_only = len(c.false_negatives)\n",
    "        \n",
    "    else:\n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where overlap = 1 and `system` = %(sys.name)s\"  \n",
    "        tp = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where (overlap = 0 or overlap is null) and `system` = %(sys.name)s\"  \n",
    "        fn = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        c.matches = df_to_set(tp, 'entity', 'sys', 'casi')\n",
    "        c.fn = df_to_set(fn, 'entity', 'sys', 'casi')\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(tp) + len(fn)\n",
    "        c.ref_n = len(tp) + len(fn)\n",
    "        c.ref_only = len(fn)\n",
    "        \n",
    "    # sanity check\n",
    "    if len(ref) - c.ref_system_match < 0:\n",
    "        print('Error: ref_system_match > len(ref)!')\n",
    "    if len(ref) != c.ref_system_match + c.ref_only:\n",
    "        print('Error: ref count mismatch!', len(ref), c.ref_system_match, c.ref_only)\n",
    "   \n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vector(doc: str, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.begin, a.end) for a in ann if a.label == lab]\n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v\n",
    "\n",
    "# test confusion matrix elements for vectorized annotation set; includes TN\n",
    "# https://kawahara.ca/how-to-compute-truefalse-positives-and-truefalse-negatives-in-python-for-binary-classification-problems/\n",
    "# def confused(sys1, ann1):\n",
    "#     TP = np.sum(np.logical_and(ann1 == 1, sys1 == 1))\n",
    "\n",
    "#     # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "#     TN = np.sum(np.logical_and(ann1 == 0, sys1 == 0))\n",
    "\n",
    "#     # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "#     FP = np.sum(np.logical_and(ann1 == 0, sys1 == 1))\n",
    "\n",
    "#     # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "#     FN = np.sum(np.logical_and(ann1 == 1, sys1 == 0))\n",
    "    \n",
    "#     return TP, TN, FP, FN\n",
    "\n",
    "def confused(sys1, ann1):\n",
    "    TP = np.sum(np.logical_and(ann1 > 0, sys1 == ann1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(ann1 == 0, sys1 == ann1))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(sys1 > 0, sys1 != ann1))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(ann1 > 0, sys1 == 0))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def vectorized_cooccurences(r: object, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> np.int64:\n",
    "    docs = get_docs(corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    sys = get_sys_ann(analysis_type, r)\n",
    "    \n",
    "    #cvals = []\n",
    "    if analysis_type == 'entity':\n",
    "        labels = [\"concept\"]\n",
    "    elif analysis_type in ['cui', 'full']:\n",
    "        labels = list(set(ann[\"value\"].tolist()))\n",
    "    \n",
    "    sys2 = list()\n",
    "    ann2 = list()\n",
    "    s2 = list()\n",
    "    a2 = list()\n",
    "    \n",
    "    for n in range(len(docs)):\n",
    "        \n",
    "        if analysis_type != 'cui':\n",
    "            a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "            s1 = list(sys.loc[sys[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "            ann1 = label_vector(docs[n][1], a1, labels)\n",
    "            sys1 = label_vector(docs[n][1], s1, labels)\n",
    "\n",
    "            #TP, TN, FP, FN = confused(sys1, ann1)\n",
    "            #cvals.append([TP, TN, FP, FN])\n",
    "            sys2.append(list(sys1))\n",
    "            ann2.append(list(ann1))\n",
    "\n",
    "        else:\n",
    "            a = ann.loc[ann[\"case\"] == docs[n][0]]['label'].tolist()\n",
    "            s = sys.loc[sys[\"case\"] == docs[n][0]]['label'].tolist()\n",
    "            x = [1 if x in a else 0 for x in labels]\n",
    "            y = [1 if x in s else 0 for x in labels]\n",
    "#             x_sparse = sparse.csr_matrix(x)\n",
    "#             y_sparse = sparse.csr_matrix(y)\n",
    "            s2.append(y)\n",
    "            a2.append(x)\n",
    "           \n",
    "            \n",
    "            #a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "            #s1 = list(sys.loc[sys[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "   \n",
    "    if analysis_type != 'cui':\n",
    "        a2 = [item for sublist in ann2 for item in sublist]\n",
    "        s2 = [item for sublist in sys2 for item in sublist]\n",
    "        report = classification_report(a2, s2, output_dict=True)\n",
    "        #print('classification:', report)\n",
    "        macro_precision =  report['macro avg']['precision'] \n",
    "        macro_recall = report['macro avg']['recall']    \n",
    "        macro_f1 = report['macro avg']['f1-score']\n",
    "        TN, FP, FN, TP = confusion_matrix(a2, s2).ravel()\n",
    "        \n",
    "        #return (np.sum(cvals, axis=0), (macro_precision, macro_recall, macro_f1))\n",
    "        return ((TP, TN, FP, FN), (macro_precision, macro_recall, macro_f1))\n",
    "    else:\n",
    "        x_sparse = sparse.csr_matrix(a2)\n",
    "        y_sparse = sparse.csr_matrix(s2)\n",
    "        report = classification_report(x_sparse, y_sparse, output_dict=True)\n",
    "        macro_precision =  report['macro avg']['precision'] \n",
    "        macro_recall = report['macro avg']['recall']    \n",
    "        macro_f1 = report['macro avg']['f1-score']\n",
    "        #print((macro_precision, macro_recall, macro_f1))\n",
    "        return ((0, 0, 0, 0), (macro_precision, macro_recall, macro_f1))\n",
    "                                       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_dict(ref_only: int, system_only: int, ref_system_match: int, system_n: int, ref_n: int) -> dict:\n",
    "    \"\"\"\n",
    "    Generate dictionary of confusion matrix params and measures\n",
    "    :params: ref_only, system_only, reference_system_match -> sets\n",
    "    matches, system_n, reference_n -> counts\n",
    "    :return: dictionary object\n",
    "    \"\"\"\n",
    "\n",
    "    if ref_only + ref_system_match != ref_n:\n",
    "        print('ERROR!')\n",
    "        \n",
    "    # get evaluation metrics\n",
    "    F, recall, precision, TP, FP, FN, TP_FN_R, TM  = Metrics(system_only, ref_only, ref_system_match, system_n).get_confusion_metrics()\n",
    "\n",
    "    d = {\n",
    "#          'F1': F[1], \n",
    "#          'precision': precision[1], \n",
    "#          'recall': recall[1], \n",
    "         'F1': F, \n",
    "         'precision': precision, \n",
    "         'recall': recall, \n",
    "         'TP': TP, \n",
    "         'FN': FN, \n",
    "         'FP': FP, \n",
    "         'TP/FN': TP_FN_R,\n",
    "         'n_gold': ref_n, \n",
    "         'n_sys': system_n, \n",
    "         'TM': TM\n",
    "    }\n",
    "    \n",
    "    if system_n - FP != TP:\n",
    "        print('inconsistent system n!')\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metric_data(analysis_type: str, corpus: str):\n",
    "   \n",
    "    usys_file, ref_table = AnalysisConfig().corpus_config()\n",
    "    systems = AnalysisConfig().systems\n",
    "    \n",
    "    sys_ann = pd.read_csv(analysisConf.data_dir + usys_file, dtype={'note_id': str})\n",
    "    \n",
    "    sql = \"SELECT * FROM \" + ref_table #+ \" where semtype in('Anatomy', 'Chemicals_and_drugs')\" \n",
    "    \n",
    "    ref_ann = pd.read_sql(sql, con=engine)\n",
    "    sys_ann = sys_ann.drop_duplicates()\n",
    "    \n",
    "    return ref_ann, sys_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of rank averages\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F1'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(analysis_type: str, corpus: str, filter_semtype, semtype = None):\n",
    "    start = time.time()\n",
    "\n",
    "    systems = AnalysisConfig().systems\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    __, sys_ann = get_metric_data(analysis_type, corpus)\n",
    "    c = None\n",
    "    \n",
    "    for sys in systems:\n",
    "       \n",
    "        if filter_semtype and semtype:\n",
    "            ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        system_annotations = sys_ann[sys_ann['system'] == sys].copy()\n",
    "\n",
    "        if filter_semtype:\n",
    "            st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "\n",
    "            if st: \n",
    "                system_annotations = sys_ann[sys_ann['semtypes'].isin(st)].copy()\n",
    "        else:\n",
    "            system_annotations = sys_ann.copy()\n",
    "\n",
    "        if (filter_semtype and st) or filter_semtype is False:\n",
    "            system = system_annotations.copy()\n",
    "\n",
    "            if sys == 'quick_umls':\n",
    "                system = system[system.score.astype(float) >= .8]\n",
    "\n",
    "            if sys == 'metamap' and modification == None:\n",
    "                system = system.fillna(0)\n",
    "                system = system[system.score.abs().astype(int) >= 800]\n",
    "\n",
    "            system = system.drop_duplicates()\n",
    "\n",
    "            ref_ann = ref_ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "            c = get_cooccurences(ref_ann, system, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "            \n",
    "            if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "                # get dictionary of confusion matrix metrics\n",
    "                d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "                d['system'] = sys\n",
    "\n",
    "                data = pd.DataFrame(d,  index=[0])\n",
    "                metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "                metrics.drop_duplicates(keep='last', inplace=True)\n",
    "            else:\n",
    "                print(\"NO EXACT MATCHES FOR\", sys)\n",
    "            elapsed = (time.time() - start)\n",
    "            print(\"elapsed:\", sys, elapsed)\n",
    "   \n",
    "    if c:\n",
    "        elapsed = (time.time() - start)\n",
    "        print(geometric_mean(metrics))\n",
    "\n",
    "        now = datetime.now()\n",
    "        timestamp = datetime.timestamp(now)\n",
    "\n",
    "        file_name = 'metrics_'\n",
    "\n",
    "        metrics.to_csv(analysisConf.data_dir + corpus + '_' + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "\n",
    "        print(\"total elapsed time:\", elapsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_n(analysis_type: str, corpus: str, filter_semtype: str) -> int:\n",
    "    \n",
    "    ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes, corpus).get_system_type('reference'))]\n",
    "            \n",
    "    if corpus == 'casi':\n",
    "        return len(ref_ann)\n",
    "        \n",
    "    else:\n",
    "        # do not overestimate fn\n",
    "        if 'entity' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'file']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type:\n",
    "            ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        elif 'full' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "        return ref_n\n",
    "    \n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_data(system: str, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> pd.DataFrame:\n",
    "   \n",
    "    _, data = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    out = data[data['system'] == system].copy()\n",
    "    \n",
    "    if filter_semtype:\n",
    "        st = SemanticTypes([semtype], corpus).get_system_type(system)\n",
    "        print(system, 'st', st)\n",
    "    \n",
    "    if corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap'] \n",
    "        out = out[cols_to_keep].drop_duplicates()\n",
    "        return out\n",
    "        \n",
    "    else:\n",
    "        if filter_semtype:\n",
    "            out = out[out['semtypes'].isin(st)].copy()\n",
    "            \n",
    "        else:\n",
    "            out = out[out['system']== system].copy()\n",
    "            \n",
    "        if modification == 'negation':\n",
    "            out = out[out['modification'] == 'negation'].copy()\n",
    "        \n",
    "        if system == 'quick_umls':\n",
    "            out = out[(out.score.astype(float) >= 0.8) & (out[\"type\"] == 'concept_jaccard_score_False')]\n",
    "            # fix for leading space on semantic type field\n",
    "            out = out.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) \n",
    "            out['semtypes'] = out['semtypes'].str.strip()\n",
    "        \n",
    "        if system == 'metamap' and modification == None:\n",
    "            out = out[out.score.abs().astype(int) >= 800]\n",
    "            \n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "        elif 'cui' in analysis_type:\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "        elif 'full' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "        out = out[cols_to_keep]\n",
    "        \n",
    "        return out.drop_duplicates()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GENERATE merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTotals(object):\n",
    "    \"\"\" \n",
    "    returns an instance with merged match set numbers using either union or intersection of elements in set \n",
    "    \"\"\"\n",
    "    def __init__(self, ref_n, sys_n, match_set):\n",
    "\n",
    "        self = self    \n",
    "        self.ref_ann = ref_n\n",
    "        self.sys_n = sys_n\n",
    "        self.match_set = match_set\n",
    "\n",
    "    def get_ref_sys(self):\n",
    "\n",
    "        ref_only = self.ref_ann - len(self.match_set)\n",
    "        sys_only = self.sys_n - len(self.match_set)\n",
    "\n",
    "        return ref_only, sys_only, len(self.match_set), self.match_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Recursively evaluate parse tree, \n",
    "    with check for existence before build\n",
    "       :param sentence: to process\n",
    "       :return class of merged annotations, boolean operated system df \n",
    "    \"\"\"\n",
    "    \n",
    "    class Results(object):\n",
    "        def __init__(self):\n",
    "            self.results = set()\n",
    "            self.system_merges = pd.DataFrame()\n",
    "            \n",
    "    r = Results()\n",
    "    \n",
    "    if 'entity' in analysis_type and corpus != 'casi': \n",
    "        cols_to_keep = ['begin', 'end', 'note_id'] # entity only\n",
    "    elif 'full' in analysis_type: \n",
    "        cols_to_keep = ['cui', 'begin', 'end', 'note_id'] # entity only\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['cui', 'note_id'] # entity only\n",
    "    elif corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap']\n",
    "    \n",
    "    def evaluate(parseTree):\n",
    "        oper = {'&': op.and_, '|': op.or_}\n",
    "        \n",
    "        if parseTree:\n",
    "            leftC = gevent.spawn(evaluate, parseTree.getLeftChild())\n",
    "            rightC = gevent.spawn(evaluate, parseTree.getRightChild())\n",
    "            \n",
    "            if leftC.get() is not None and rightC.get() is not None:\n",
    "                system_query = pd.DataFrame()\n",
    "                fn = oper[parseTree.getRootVal()]\n",
    "                \n",
    "                if isinstance(leftC.get(), str):\n",
    "                    # get system as leaf node \n",
    "                    if filter_semtype:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype)\n",
    "                \n",
    "                elif isinstance(leftC.get(), pd.DataFrame):\n",
    "                    l_sys = leftC.get()\n",
    "                \n",
    "                if isinstance(rightC.get(), str):\n",
    "                    # get system as leaf node\n",
    "                    if filter_semtype:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype)\n",
    "                    \n",
    "                elif isinstance(rightC.get(), pd.DataFrame):\n",
    "                    r_sys = rightC.get()\n",
    "                    \n",
    "                if fn == op.or_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        frames = [left_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [left_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        frames = [l_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [l_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                if fn == op.and_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        \n",
    "                        if not left_sys.empty and not right_sys.empty:\n",
    "                            df = left_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(columns=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        if not left_sys.empty and not r_sys.empty:\n",
    "                            df = left_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(columns=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        if not l_sys.empty and not right_sys.empty:\n",
    "                            df = l_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(columns=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        if not l_sys.empty and not r_sys.empty:\n",
    "                            df = l_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(columns=cols_to_keep)\n",
    "                \n",
    "                # get combined system results\n",
    "                r.system_merges = df\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    system_query = system_query.append(df)\n",
    "                else:\n",
    "                    print('wtf!')\n",
    "                    \n",
    "                return system_query\n",
    "            else:\n",
    "                return parseTree.getRootVal()\n",
    "    \n",
    "    if sentence.n_or > 0 or sentence.n_and > 0:\n",
    "        evaluate(pt)  \n",
    "    \n",
    "    # trivial case\n",
    "    elif sentence.n_or == 0 and sentence.n_and == 0:\n",
    "        \n",
    "        if filter_semtype:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Incoming Boolean sentences are parsed into a binary tree.\n",
    "\n",
    "Test expressions to parse:\n",
    "\n",
    "sentence = '((((A&B)|C)|D)&E)'\n",
    "\n",
    "sentence = '(E&(D|(C|(A&B))))'\n",
    "\n",
    "sentence = '(((A|(B&C))|(D&(E&F)))|(H&I))'\n",
    "\n",
    "\"\"\"\n",
    "# build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "def buildParseTree(fpexp):\n",
    "    \"\"\"\n",
    "       Iteratively build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "       :param fpexp: sentence to parse\n",
    "       :return eTree: parse tree representation\n",
    "       Incoming Boolean sentences are parsed into a binary tree.\n",
    "       Test expressions to parse:\n",
    "       sentence = '(A&B)'\n",
    "       sentence = '(A|B)'\n",
    "       sentence = '((A|B)&C)'\n",
    "       \n",
    "    \"\"\"\n",
    "    fplist = fpexp.split()\n",
    "    pStack = Stack()\n",
    "    eTree = BinaryTree('')\n",
    "    pStack.push(eTree)\n",
    "    currentTree = eTree\n",
    "\n",
    "    for i in fplist:\n",
    "\n",
    "        if i == '(':\n",
    "            currentTree.insertLeft('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getLeftChild()\n",
    "        elif i not in ['&', '|', ')']:\n",
    "            currentTree.setRootVal(i)\n",
    "            parent = pStack.pop()\n",
    "            currentTree = parent\n",
    "        elif i in ['&', '|']:\n",
    "            currentTree.setRootVal(i)\n",
    "            currentTree.insertRight('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getRightChild()\n",
    "        elif i == ')':\n",
    "            currentTree = pStack.pop()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return eTree\n",
    "\n",
    "def make_parse_tree(payload):\n",
    "    \"\"\"\n",
    "    Ensure data to create tree are in correct form\n",
    "    :param sentence: sentence to preprocess\n",
    "    :return pt, parse tree graph\n",
    "            sentence, processed sentence to build tree\n",
    "            a: order\n",
    "    \"\"\"\n",
    "    def preprocess_sentence(sentence):\n",
    "        # prepare statement for case when a boolean AND/OR is given\n",
    "        sentence = payload.replace('(', ' ( '). \\\n",
    "            replace(')', ' ) '). \\\n",
    "            replace('&', ' & '). \\\n",
    "            replace('|', ' | '). \\\n",
    "            replace('  ', ' ')\n",
    "        return sentence\n",
    "\n",
    "    sentence = preprocess_sentence(payload)\n",
    "    print('Processing sentence:', sentence)\n",
    "    \n",
    "    pt = buildParseTree(sentence)\n",
    "    #pt.postorder() \n",
    "    \n",
    "    return pt\n",
    "\n",
    "class Sentence(object):\n",
    "    '''\n",
    "    Details about boolean expression -> number operators and expression\n",
    "    '''\n",
    "    def __init__(self, sentence):\n",
    "        self = self\n",
    "        self.n_and = sentence.count('&')\n",
    "        self.n_or = sentence.count('|')\n",
    "        self.sentence = sentence\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_docs(corpus):\n",
    "    \n",
    "    # KLUDGE!!!\n",
    "    if corpus == 'ray_test':\n",
    "        corpus = 'fairview'\n",
    "        \n",
    "    sql = 'select distinct note_id, sofa from sofas where corpus = %(corpus)s order by note_id'\n",
    "    df = pd.read_sql(sql, params={\"corpus\":corpus}, con=engine)\n",
    "    df.drop_duplicates()\n",
    "    df['len_doc'] = df['sofa'].apply(len)\n",
    "    \n",
    "    subset = df[['note_id', 'len_doc']]\n",
    "    docs = [tuple(x) for x in subset.to_numpy()]\n",
    "    \n",
    "    return docs\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_ann(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    if filter_semtype:\n",
    "        if ',' in semtype:\n",
    "            semtype = semtype.split(',')\n",
    "        else:\n",
    "            semtype = [semtype]\n",
    "        \n",
    "    ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    ann = ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = ann[ann['semtype'].isin(semtype)]\n",
    "    if analysis_type == 'entity':   \n",
    "        ann[\"label\"] = 'concept'\n",
    "    elif analysis_type in ['cui','full']:\n",
    "        ann[\"label\"] = ann[\"value\"]\n",
    "        \n",
    "    if modification == 'negation':\n",
    "        ann = ann[ann['semtype'] == 'negation']\n",
    "    \n",
    "    \n",
    "    if analysis_type == 'entity':\n",
    "        cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    elif analysis_type == 'cui':\n",
    "        cols_to_keep = ['value', 'case', 'label']\n",
    "    elif analysis_type == 'full':\n",
    "        cols_to_keep = ['begin', 'end', 'value', 'case', 'label']\n",
    "    ann = ann[cols_to_keep]\n",
    "    \n",
    "    return ann\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_ann(analysis_type, r):\n",
    "    sys = r.system_merges   \n",
    "    \n",
    "    sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "    if analysis_type == 'entity':\n",
    "        sys[\"label\"] = 'concept'\n",
    "        cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    elif analysis_type == 'full':\n",
    "        sys[\"label\"] = sys[\"cui\"]\n",
    "        cols_to_keep = ['begin', 'end', 'case', 'value', 'label']\n",
    "    elif analysis_type == 'cui':\n",
    "        sys[\"label\"] = sys[\"cui\"]\n",
    "        cols_to_keep = ['case', 'cui', 'label']\n",
    "    \n",
    "    sys = sys[cols_to_keep]\n",
    "    return sys\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metrics(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    else:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    # vectorize merges using i-o labeling\n",
    "    if run_type == 'overlap':\n",
    "        if filter_semtype:\n",
    "             ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            ((TP, TN, FP, FN),(p,r,f1)) = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        print('results:',((TP, TN, FP, FN),(p,r,f1)))\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        if analysis_type != 'cui':\n",
    "            d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        else:\n",
    "            d = dict()\n",
    "            d['F1'] = 0\n",
    "            d['precision'] = 0 \n",
    "            d['recall'] = 0\n",
    "            d['TP/FN'] = 0\n",
    "            d['TM'] = 0\n",
    "            \n",
    "        d['TN'] = TN\n",
    "        d['macro_p'] = p\n",
    "        d['macro_r'] = r\n",
    "        d['macro_f1'] = f1\n",
    "        \n",
    "        \n",
    "        # return full metrics\n",
    "        return d\n",
    "\n",
    "    elif run_type == 'exact':\n",
    "        # total by number spans\n",
    "        \n",
    "        if filter_semtype:\n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else: \n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "        else:\n",
    "            d = None\n",
    "            \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_valid_systems(['biomedicus'], 'Anatomy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all combinations of given list of annotators:\n",
    "def partly_unordered_permutations(lst, k):\n",
    "    elems = set(lst)\n",
    "    for c in combinations(lst, k):\n",
    "        for d in permutations(elems - set(c)):\n",
    "            yield c + d\n",
    "            \n",
    "def expressions(l, n):\n",
    "    for (operations, *operands), operators in product(\n",
    "            combinations(l, n), product(('&', '|'), repeat=n - 1)):\n",
    "        for operation in zip(operators, operands):\n",
    "            operations = [operations, *operation]\n",
    "        yield operations\n",
    "\n",
    "# get list of systems with a semantic type in grouping\n",
    "def get_valid_systems(systems, semtype):\n",
    "    test = []\n",
    "    for sys in systems:\n",
    "        st = system_semtype_check(sys, semtype, corpus)\n",
    "        if st:\n",
    "            test.append(sys)\n",
    "\n",
    "    return test\n",
    "\n",
    "# permute system combinations and evaluate system merges for performance\n",
    "def run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type, semtype = None):\n",
    "    metrics = pd.DataFrame()\n",
    "    \n",
    "    # pass single system to evaluate\n",
    "    if expression_type == 'single':\n",
    "        for system in systems:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(system, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(system, analysis_type, corpus, run_type, filter_semtype)\n",
    "            d['merge'] = system\n",
    "            d['n_terms'] = 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "    \n",
    "    elif expression_type == 'nested':\n",
    "        for l in partly_unordered_permutations(systems, 2):\n",
    "            print('processing merge combo:', l)\n",
    "            for i in range(1, len(l)+1):\n",
    "                test = list(expressions(l, i))\n",
    "                for t in test:\n",
    "                    if i > 1:\n",
    "                        # format Boolean sentence for parse tree \n",
    "                        t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                    if filter_semtype:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype)\n",
    "\n",
    "                    d['merge'] = t\n",
    "                    d['n_terms'] = i\n",
    "\n",
    "                    frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "                    metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                    \n",
    "    elif expression_type == 'nested_with_singleton' and len(systems) == 5:\n",
    "        # form (((a&b)|c)&(d|e))\n",
    "        \n",
    "        nested = list(expressions(systems, 3))\n",
    "        test = list(expressions(systems, 2))\n",
    "        to_do_terms = []\n",
    "    \n",
    "        for n in nested:\n",
    "            # format Boolean sentence for parse tree \n",
    "            n = '(' + \" \".join(str(x) for x in n).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "            for t in test:\n",
    "                t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                new_and = '(' + n +'&'+ t + ')'\n",
    "                new_or = '(' + n +'|'+ t + ')'\n",
    "\n",
    "                if new_and.count('biomedicus') != 2 and new_and.count('clamp') != 2 and new_and.count('ctakes') != 2 and new_and.count('metamap') != 2 and new_and.count('quick_umls') != 2:\n",
    "\n",
    "                    if new_and.count('&') != 4 and new_or.count('|') != 4:\n",
    "                        #print(new_and)\n",
    "                        #print(new_or)\n",
    "                        to_do_terms.append(new_or)\n",
    "                        to_do_terms.append(new_and)\n",
    "        \n",
    "        print('nested_with_singleton', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                        \n",
    "    elif expression_type == 'paired':\n",
    "        m = list(expressions(systems, 2))\n",
    "        test = list(expressions(m, 2))\n",
    "\n",
    "        to_do_terms = []\n",
    "        for t in test:\n",
    "            # format Boolean sentence for parse tree \n",
    "            t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "            if t.count('biomedicus') != 2 and t.count('clamp') != 2 and t.count('ctakes') != 2 and t.count('metamap') != 2 and t.count('quick_umls') != 2:\n",
    "                if t.count('&') != 3 and t.count('|') != 3:\n",
    "                    to_do_terms.append(t)\n",
    "                    if len(systems) == 5:\n",
    "                        for i in systems:\n",
    "                            if i not in t:\n",
    "                                #print('('+t+'&'+i+')')\n",
    "                                #print('('+t+'|'+i+')')\n",
    "                                new_and = '('+t+'&'+i+')'\n",
    "                                new_or = '('+t+'|'+i+')'\n",
    "                                to_do_terms.append(new_and)\n",
    "                                to_do_terms.append(new_or)\n",
    "                            \n",
    "        print('paired', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "        \n",
    "    return metrics\n",
    "\n",
    "# write to file\n",
    "def generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype = None):\n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    file_name = corpus + '_all_'\n",
    "   \n",
    "    # drop exact matches:\n",
    "    metrics = metrics.drop_duplicates()\n",
    "    \n",
    "    if ensemble_type == 'merge':\n",
    "        metrics = metrics.sort_values(by=['n_terms', 'merge'])\n",
    "        file_name += 'merge_'\n",
    "    elif ensemble_type == 'vote':\n",
    "        file_name += 'vote_'\n",
    "    \n",
    "    #metrics = metrics.drop_duplicates(subset=['TP', 'FN', 'FP', 'n_sys', 'precision', 'recall', 'F', 'TM', 'TP/FN', 'TM', 'n_terms'])\n",
    "\n",
    "    file = file_name + analysis_type + '_' + run_type +'_'\n",
    "    \n",
    "    if filter_semtype:\n",
    "        file += semtype\n",
    "        \n",
    "    \n",
    "    geometric_mean(metrics).to_csv(analysisConf.data_dir + file + str(timestamp) + '.csv')\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "# control ensemble run\n",
    "def ensemble_control(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSTEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            metrics = run_ensemble(test, analysis_type, corpus, filter_semtype, expression_type, semtype)\n",
    "            if (expression_type == 'nested_with_singleton' and len(test) == 5) or expression_type in ['nested', 'paired', 'single']:\n",
    "                generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "    else:\n",
    "        metrics = run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad hoc query\n",
    "def get_merge_data(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "\n",
    "    r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    if run_type == 'overlap':\n",
    "        if filter_semtype:\n",
    "            TP, TN, FP, FN = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            TP, TN, FP, FN = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        print(d)\n",
    "        \n",
    "    elif run_type == 'exact':\n",
    "        c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "\n",
    "            print('cm', d)\n",
    "    \n",
    "    # get matched data from merge\n",
    "    return r.system_merges # merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority vote \n",
    "def vectorized_annotations(ann):\n",
    "    \n",
    "    docs = get_docs(corpus)\n",
    "    labels = [\"concept\"]\n",
    "    out= []\n",
    "    \n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        a = label_vector(docs[n][1], a1, labels)\n",
    "        out.append(a)\n",
    "\n",
    "    return out\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def get_reference_vector(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    df = ref_ann.copy()\n",
    "    df = df.drop_duplicates(subset=['begin','end','case'])\n",
    "    df['label'] = 'concept'\n",
    "\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ref = df[cols_to_keep].copy()\n",
    "    test = vectorized_annotations(ref)\n",
    "    ref =  np.asarray(flatten_list(test), dtype=np.int32) \n",
    "\n",
    "    return ref\n",
    "\n",
    "def majority_overlap_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    d = {}\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys_test = []\n",
    "    \n",
    "    for system in systems:\n",
    "        sys_ann = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        df = sys_ann.copy()\n",
    "        df['label'] = 'concept'\n",
    "        df = df.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "        sys = df[df['system']==system][cols_to_keep].copy()\n",
    "        test = vectorized_annotations(sys)\n",
    "        d[system] = flatten_list(test) \n",
    "        sys_test.append(d[system])\n",
    "\n",
    "    output = sum(np.array(sys_test))\n",
    "    \n",
    "    n = int(len(systems) / 2)\n",
    "    #print(n)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        vote = np.where(output > n, 1, 0)\n",
    "    else:\n",
    "        vote = np.where(output > n, 1, \n",
    "         (np.where(output == n, random.randint(0, 1), 0)))\n",
    "        \n",
    "    return vote\n",
    "\n",
    "def majority_overlap_vote_out(ref, vote, corpus):    \n",
    "    TP, TN, FP, FN = confused(ref, vote)\n",
    "    print(TP, TN, FP, FN)\n",
    "    system_n = TP + FP\n",
    "    reference_n = TP + FN\n",
    "\n",
    "    d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "\n",
    "    d['TN'] = TN\n",
    "    d['corpus'] = corpus\n",
    "    print(d)\n",
    "    \n",
    "    metrics = pd.DataFrame(d, index=[0])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# control vote run\n",
    "def majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            \n",
    "            if run_type == 'overlap':\n",
    "                ref = get_reference_vector(analysis_type, corpus, filter_semtype, semtype)\n",
    "                vote = majority_overlap_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                metrics = majority_overlap_vote_out(ref, vote, corpus)\n",
    "                #generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "            elif run_type == 'exact':\n",
    "                sys = majority_exact_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                d = majority_exact_vote_out(sys, filter_semtype, semtype)\n",
    "                metrics = pd.DataFrame(d, index=[0])\n",
    "            elif run_type == 'cui':\n",
    "                sys = majority_cui_sys(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "                d = majority_cui_vote_out(sys, filter_semtype, semtype)\n",
    "                metrics = pd.DataFrame(d, index=[0])\n",
    "           \n",
    "            metrics['systems'] = ','.join(test)\n",
    "            generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "                \n",
    "    else:\n",
    "        if run_type == 'overlap':\n",
    "            ref = get_reference_vector(analysis_type, corpus, filter_semtype)\n",
    "            vote = majority_overlap_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            metrics = majority_overlap_vote_out(ref, vote, corpus)\n",
    "            \n",
    "        elif run_type == 'exact':\n",
    "            sys = majority_exact_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            d = majority_exact_vote_out(sys, filter_semtype)\n",
    "            metrics = pd.DataFrame(d, index=[0])\n",
    "            \n",
    "        elif run_type == 'cui':\n",
    "            sys = majority_cui_sys(systems, analysis_type, corpus, filter_semtype)\n",
    "            d = majority_cui_vote_out(sys, filter_semtype)\n",
    "            metrics = pd.DataFrame(d, index=[0])\n",
    "            \n",
    "        metrics['systems'] = ','.join(systems)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)\n",
    "    \n",
    "    print(metrics)\n",
    "    \n",
    "def majority_cui_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "   \n",
    "    cols_to_keep = ['cui', 'note_id', 'system']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for system in systems:\n",
    "        if filter_semtype:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        sys = sys[sys['system'] == system][cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        frames = [df, sys]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def majority_cui_vote_out(sys, filter_semtype, semtype = None):\n",
    "    \n",
    "    sys = sys.astype(str)\n",
    "    sys['value_cui'] = list(zip(sys.cui, sys.note_id.astype(str)))\n",
    "    sys['count'] = sys.groupby(['value_cui'])['value_cui'].transform('count')\n",
    "\n",
    "    n = int(len(systems) / 2)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        sys = sys[sys['count'] > n]\n",
    "    else:\n",
    "        # https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "        for i in sys.index:\n",
    "            if sys.at[i, 'count'] == n:\n",
    "                sys.at[i, 'count'] = random.choice([1,len(systems)])\n",
    "        sys = sys[sys['count'] > n]\n",
    "\n",
    "    sys = sys.drop_duplicates(subset=['value_cui', 'cui', 'note_id'])\n",
    "    ref = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    c = get_cooccurences(ref, sys, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "        # get dictionary of confusion matrix metrics\n",
    "        print(cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n))\n",
    "        return cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "    \n",
    "\n",
    "def majority_exact_sys(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "   \n",
    "    cols_to_keep = ['begin', 'end', 'note_id', 'system']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for system in systems:\n",
    "        if filter_semtype:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            sys = get_sys_data(system, analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        sys = sys[sys['system'] == system][cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        frames = [df, sys]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "    return df\n",
    "        \n",
    "def majority_exact_vote_out(sys, filter_semtype, semtype = None):\n",
    "    sys['span'] = list(zip(sys.begin, sys.end, sys.note_id.astype(str)))\n",
    "    sys['count'] = sys.groupby(['span'])['span'].transform('count')\n",
    "\n",
    "    n = int(len(systems) / 2)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        sys = sys[sys['count'] > n]\n",
    "    else:\n",
    "        # https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "        for i in sys.index:\n",
    "            if sys.at[i, 'count'] == n:\n",
    "                sys.at[i, 'count'] = random.choice([1,len(systems)])\n",
    "        sys = sys[sys['count'] > n]\n",
    "\n",
    "    sys = sys.drop_duplicates(subset=['span', 'begin', 'end', 'note_id'])\n",
    "    ref = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "\n",
    "    c = get_cooccurences(ref, sys, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "        # get dictionary of confusion matrix metrics\n",
    "        print(cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n))\n",
    "        return cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "    \n",
    "#ensemble_type = 'vote'        \n",
    "#filter_semtype = False\n",
    "#majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'] ('analytical_clinical_trial.csv', 'clinical_trial.clinical_trial_all')\n",
      "run_type: overlap\n",
      "['temporal_measurement,qualifier,measurement']\n",
      "SYSTEMS FOR SEMTYPE temporal_measurement,qualifier,measurement ARE ['biomedicus', 'ctakes', 'metamap', 'quick_umls']\n",
      "processing merge combo: ('biomedicus', 'ctakes', 'metamap', 'quick_umls')\n",
      "Processing sentence: biomedicus\n",
      "biomedicus st {'T081', 'T079', 'T080', 'temporal'}\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence: ctakes\n",
      "ctakes st {'temporal'}\n",
      "results: ((26, 274083, 30, 38142), (0.6710619059057685, 0.5002858774973081, 0.46812901031069326))\n",
      "Processing sentence: metamap\n",
      "metamap st {'tmco', 'qnco', 'qlco'}\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence: quick_umls\n",
      "quick_umls st {'T081', 'T079', 'T080'}\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( biomedicus & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( biomedicus | ctakes ) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results: ((9198, 269271, 4842, 28970), (0.7789959982457828, 0.6116614832321611, 0.6466422320478586))\n",
      "Processing sentence:  ( biomedicus & metamap ) \n",
      "results: ((654, 273945, 168, 37514), (0.8375872040708432, 0.5082609433288785, 0.4845981544368057))\n",
      "Processing sentence:  ( biomedicus | metamap ) \n",
      "results: ((14616, 246691, 27422, 23552), (0.6302671169574771, 0.6414497761508722, 0.6354102927244968))\n",
      "Processing sentence:  ( biomedicus & quick_umls ) \n",
      "results: ((32, 274099, 14, 38136), (0.7867567001164814, 0.5003936624156724, 0.46830551416981386))\n",
      "Processing sentence:  ( biomedicus | quick_umls ) \n",
      "results: ((13648, 234645, 39468, 24520), (0.58116775917814, 0.6067963063451589, 0.5895164404462477))\n",
      "Processing sentence:  ( ctakes & metamap ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ctakes | metamap ) \n",
      "results: ((9226, 249991, 24122, 28942), (0.5864492930678985, 0.576860304475695, 0.5810317869867334))\n",
      "Processing sentence:  ( ctakes & quick_umls ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ctakes | quick_umls ) \n",
      "results: ((5886, 238583, 35530, 32282), (0.5114689229667675, 0.5122974380214722, 0.5117442343850704))\n",
      "Processing sentence:  ( metamap & quick_umls ) \n",
      "results: ((92, 273935, 178, 38076), (0.609353290844328, 0.5008805144558021, 0.4697604383418928))\n",
      "Processing sentence:  ( metamap | quick_umls ) \n",
      "results: ((13702, 218461, 55652, 24466), (0.5484263635345168, 0.5779830330817545, 0.549956820922619))\n",
      "Processing sentence:  ( ( biomedicus & ctakes ) & metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( biomedicus & ctakes ) | metamap ) \n",
      "wtf!\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence:  ( ( biomedicus | ctakes ) & metamap ) \n",
      "results: ((654, 273945, 168, 37514), (0.8375872040708432, 0.5082609433288785, 0.4845981544368057))\n",
      "Processing sentence:  ( ( biomedicus | ctakes ) | metamap ) \n",
      "results: ((14628, 246665, 27448, 23540), (0.6302687910519306, 0.6415595502026508, 0.6354574114447574))\n",
      "Processing sentence:  ( ( biomedicus & ctakes ) & quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( biomedicus & ctakes ) | quick_umls ) \n",
      "wtf!\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( ( biomedicus | ctakes ) & quick_umls ) \n",
      "results: ((32, 274099, 14, 38136), (0.7867567001164814, 0.5003936624156724, 0.46830551416981386))\n",
      "Processing sentence:  ( ( biomedicus | ctakes ) | quick_umls ) \n",
      "results: ((13660, 234619, 39494, 24508), (0.5812050099688713, 0.6069060803969375, 0.5895682277265739))\n",
      "Processing sentence:  ( ( biomedicus & metamap ) & quick_umls ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( biomedicus & metamap ) | quick_umls ) \n",
      "results: ((6436, 238479, 35634, 31732), (0.517774485027999, 0.5193127237066837, 0.5183309470116264))\n",
      "Processing sentence:  ( ( biomedicus | metamap ) & quick_umls ) \n",
      "results: ((112, 273921, 192, 38056), (0.6232188506473908, 0.5011169771229941, 0.4702814072675595))\n",
      "Processing sentence:  ( ( biomedicus | metamap ) | quick_umls ) \n",
      "results: ((18166, 215731, 58382, 20002), (0.5762324577810924, 0.6314816413627831, 0.5814860179427812))\n",
      "Processing sentence:  ( ( ctakes & metamap ) & quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ctakes & metamap ) | quick_umls ) \n",
      "wtf!\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( ( ctakes | metamap ) & quick_umls ) \n",
      "results: ((92, 273935, 178, 38076), (0.609353290844328, 0.5008805144558021, 0.4697604383418928))\n",
      "Processing sentence:  ( ( ctakes | metamap ) | quick_umls ) \n",
      "results: ((13714, 218431, 55682, 24454), (0.5484690334531582, 0.5780855108725022, 0.5499949213863276))\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) & metamap ) & quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) & metamap ) | quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) | metamap ) & quick_umls ) \n",
      "wtf!\n",
      "results: ((92, 273935, 178, 38076), (0.609353290844328, 0.5008805144558021, 0.4697604383418928))\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) | metamap ) | quick_umls ) \n",
      "wtf!\n",
      "results: ((13702, 218461, 55652, 24466), (0.5484263635345168, 0.5779830330817545, 0.549956820922619))\n",
      "Processing sentence:  ( ( ( biomedicus | ctakes ) & metamap ) & quick_umls ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( biomedicus | ctakes ) & metamap ) | quick_umls ) \n",
      "results: ((6436, 238479, 35634, 31732), (0.517774485027999, 0.5193127237066837, 0.5183309470116264))\n",
      "Processing sentence:  ( ( ( biomedicus | ctakes ) | metamap ) & quick_umls ) \n",
      "results: ((112, 273921, 192, 38056), (0.6232188506473908, 0.5011169771229941, 0.4702814072675595))\n",
      "Processing sentence:  ( ( ( biomedicus | ctakes ) | metamap ) | quick_umls ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('biomedicus', 'ctakes', 'quick_umls', 'metamap')\n",
      "Processing sentence:  ( quick_umls & metamap ) \n",
      "results: ((92, 273935, 178, 38076), (0.609353290844328, 0.5008805144558021, 0.4697604383418928))\n",
      "Processing sentence:  ( quick_umls | metamap ) \n",
      "results: ((13702, 218461, 55652, 24466), (0.5484263635345168, 0.5779830330817545, 0.549956820922619))\n",
      "Processing sentence:  ( ( biomedicus & quick_umls ) & metamap ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( biomedicus & quick_umls ) | metamap ) \n",
      "results: ((9222, 250007, 24106, 28946), (0.5864688441743169, 0.576837089603659, 0.5810245109053385))\n",
      "Processing sentence:  ( ( biomedicus | quick_umls ) & metamap ) \n",
      "results: ((734, 273767, 346, 37434), (0.7796704065384918, 0.5089842580362001, 0.486428314348939))\n",
      "Processing sentence:  ( ( biomedicus | quick_umls ) | metamap ) \n",
      "results: ((18166, 215731, 58382, 20002), (0.5762324577810924, 0.6314816413627831, 0.5814860179427812))\n",
      "Processing sentence:  ( ( ctakes & quick_umls ) & metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ctakes & quick_umls ) | metamap ) \n",
      "wtf!\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence:  ( ( ctakes | quick_umls ) & metamap ) \n",
      "results: ((92, 273935, 178, 38076), (0.609353290844328, 0.5008805144558021, 0.4697604383418928))\n",
      "Processing sentence:  ( ( ctakes | quick_umls ) | metamap ) \n",
      "results: ((13714, 218431, 55682, 24454), (0.5484690334531582, 0.5780855108725022, 0.5499949213863276))\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) & quick_umls ) & metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) & quick_umls ) | metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) | quick_umls ) & metamap ) \n",
      "wtf!\n",
      "results: ((92, 273935, 178, 38076), (0.609353290844328, 0.5008805144558021, 0.4697604383418928))\n",
      "Processing sentence:  ( ( ( biomedicus & ctakes ) | quick_umls ) | metamap ) \n",
      "wtf!\n",
      "results: ((13702, 218461, 55652, 24466), (0.5484263635345168, 0.5779830330817545, 0.549956820922619))\n",
      "Processing sentence:  ( ( ( biomedicus | ctakes ) & quick_umls ) & metamap ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( biomedicus | ctakes ) & quick_umls ) | metamap ) \n",
      "results: ((9222, 250007, 24106, 28946), (0.5864688441743169, 0.576837089603659, 0.5810245109053385))\n",
      "Processing sentence:  ( ( ( biomedicus | ctakes ) | quick_umls ) & metamap ) \n",
      "results: ((734, 273767, 346, 37434), (0.7796704065384918, 0.5089842580362001, 0.486428314348939))\n",
      "Processing sentence:  ( ( ( biomedicus | ctakes ) | quick_umls ) | metamap ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('biomedicus', 'metamap', 'ctakes', 'quick_umls')\n",
      "Processing sentence:  ( metamap & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( metamap | ctakes ) \n",
      "results: ((9226, 249991, 24122, 28942), (0.5864492930678985, 0.576860304475695, 0.5810317869867334))\n",
      "Processing sentence:  ( ( biomedicus & metamap ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( biomedicus & metamap ) | ctakes ) \n",
      "results: ((680, 273915, 198, 37488), (0.8270516374210781, 0.5085468208261866, 0.4852334858962234))\n",
      "Processing sentence:  ( ( biomedicus | metamap ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( biomedicus | metamap ) | ctakes ) \n",
      "results: ((14628, 246665, 27448, 23540), (0.6302687910519306, 0.6415595502026508, 0.6354574114447574))\n",
      "Processing sentence:  ( ( metamap & ctakes ) & quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( metamap & ctakes ) | quick_umls ) \n",
      "wtf!\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( ( metamap | ctakes ) & quick_umls ) \n",
      "results: ((92, 273935, 178, 38076), (0.609353290844328, 0.5008805144558021, 0.4697604383418928))\n",
      "Processing sentence:  ( ( metamap | ctakes ) | quick_umls ) \n",
      "results: ((13714, 218431, 55682, 24454), (0.5484690334531582, 0.5780855108725022, 0.5499949213863276))\n",
      "Processing sentence:  ( ( ( biomedicus & metamap ) & ctakes ) & quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus & metamap ) & ctakes ) | quick_umls ) \n",
      "wtf!\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( ( ( biomedicus & metamap ) | ctakes ) & quick_umls ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( biomedicus & metamap ) | ctakes ) | quick_umls ) \n",
      "results: ((6454, 238449, 35664, 31714), (0.5179238773066238, 0.5194938013716716, 0.51849070903235))\n",
      "Processing sentence:  ( ( ( biomedicus | metamap ) & ctakes ) & quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus | metamap ) & ctakes ) | quick_umls ) \n",
      "wtf!\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( ( ( biomedicus | metamap ) | ctakes ) & quick_umls ) \n",
      "results: ((112, 273921, 192, 38056), (0.6232188506473908, 0.5011169771229941, 0.4702814072675595))\n",
      "Processing sentence:  ( ( ( biomedicus | metamap ) | ctakes ) | quick_umls ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('biomedicus', 'metamap', 'quick_umls', 'ctakes')\n",
      "Processing sentence:  ( quick_umls & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( quick_umls | ctakes ) \n",
      "results: ((5886, 238583, 35530, 32282), (0.5114689229667675, 0.5122974380214722, 0.5117442343850704))\n",
      "Processing sentence:  ( ( biomedicus & quick_umls ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( biomedicus & quick_umls ) | ctakes ) \n",
      "results: ((58, 274069, 44, 38110), (0.723275026538633, 0.5006795399129805, 0.4689771535882995))\n",
      "Processing sentence:  ( ( biomedicus | quick_umls ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( biomedicus | quick_umls ) | ctakes ) \n",
      "results: ((13660, 234619, 39494, 24508), (0.5812050099688713, 0.6069060803969375, 0.5895682277265739))\n",
      "Processing sentence:  ( ( metamap & quick_umls ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( metamap & quick_umls ) | ctakes ) \n",
      "results: ((118, 273905, 208, 38050), (0.6199952348798144, 0.5011663919531101, 0.47042585560711336))\n",
      "Processing sentence:  ( ( metamap | quick_umls ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( metamap | quick_umls ) | ctakes ) \n",
      "results: ((13714, 218431, 55682, 24454), (0.5484690334531582, 0.5780855108725022, 0.5499949213863276))\n",
      "Processing sentence:  ( ( ( biomedicus & metamap ) & quick_umls ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus & metamap ) & quick_umls ) | ctakes ) \n",
      "results: ((38, 274083, 30, 38130), (0.7183476834536604, 0.5004430772457885, 0.46845220420436895))\n",
      "Processing sentence:  ( ( ( biomedicus & metamap ) | quick_umls ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus & metamap ) | quick_umls ) | ctakes ) \n",
      "results: ((6454, 238449, 35664, 31714), (0.5179238773066238, 0.5194938013716716, 0.51849070903235))\n",
      "Processing sentence:  ( ( ( biomedicus | metamap ) & quick_umls ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus | metamap ) & quick_umls ) | ctakes ) \n",
      "results: ((138, 273891, 222, 38030), (0.6307057182213872, 0.5014028546203022, 0.47094547895081473))\n",
      "Processing sentence:  ( ( ( biomedicus | metamap ) | quick_umls ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus | metamap ) | quick_umls ) | ctakes ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('biomedicus', 'quick_umls', 'ctakes', 'metamap')\n",
      "Processing sentence:  ( ( quick_umls & ctakes ) & metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( quick_umls & ctakes ) | metamap ) \n",
      "wtf!\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence:  ( ( quick_umls | ctakes ) & metamap ) \n",
      "results: ((92, 273935, 178, 38076), (0.609353290844328, 0.5008805144558021, 0.4697604383418928))\n",
      "Processing sentence:  ( ( quick_umls | ctakes ) | metamap ) \n",
      "results: ((13714, 218431, 55682, 24454), (0.5484690334531582, 0.5780855108725022, 0.5499949213863276))\n",
      "Processing sentence:  ( ( ( biomedicus & quick_umls ) & ctakes ) & metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus & quick_umls ) & ctakes ) | metamap ) \n",
      "wtf!\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence:  ( ( ( biomedicus & quick_umls ) | ctakes ) & metamap ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( biomedicus & quick_umls ) | ctakes ) | metamap ) \n",
      "results: ((9240, 249977, 24136, 28928), (0.5865628664784346, 0.5770181672686469, 0.5811745529619096))\n",
      "Processing sentence:  ( ( ( biomedicus | quick_umls ) & ctakes ) & metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus | quick_umls ) & ctakes ) | metamap ) \n",
      "wtf!\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence:  ( ( ( biomedicus | quick_umls ) | ctakes ) & metamap ) \n",
      "results: ((734, 273767, 346, 37434), (0.7796704065384918, 0.5089842580362001, 0.486428314348939))\n",
      "Processing sentence:  ( ( ( biomedicus | quick_umls ) | ctakes ) | metamap ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('biomedicus', 'quick_umls', 'metamap', 'ctakes')\n",
      "Processing sentence:  ( ( quick_umls & metamap ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( quick_umls & metamap ) | ctakes ) \n",
      "results: ((118, 273905, 208, 38050), (0.6199952348798144, 0.5011663919531101, 0.47042585560711336))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) | ctakes ) \n",
      "results: ((13714, 218431, 55682, 24454), (0.5484690334531582, 0.5780855108725022, 0.5499949213863276))\n",
      "Processing sentence:  ( ( ( biomedicus & quick_umls ) & metamap ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus & quick_umls ) & metamap ) | ctakes ) \n",
      "results: ((38, 274083, 30, 38130), (0.7183476834536604, 0.5004430772457885, 0.46845220420436895))\n",
      "Processing sentence:  ( ( ( biomedicus & quick_umls ) | metamap ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus & quick_umls ) | metamap ) | ctakes ) \n",
      "results: ((9240, 249977, 24136, 28928), (0.5865628664784346, 0.5770181672686469, 0.5811745529619096))\n",
      "Processing sentence:  ( ( ( biomedicus | quick_umls ) & metamap ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus | quick_umls ) & metamap ) | ctakes ) \n",
      "results: ((760, 273737, 376, 37408), (0.7743935903259632, 0.5092701355335082, 0.48705667342194425))\n",
      "Processing sentence:  ( ( ( biomedicus | quick_umls ) | metamap ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( biomedicus | quick_umls ) | metamap ) | ctakes ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('ctakes', 'metamap', 'biomedicus', 'quick_umls')\n",
      "Processing sentence:  ( ctakes & biomedicus ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ctakes | biomedicus ) \n",
      "results: ((9198, 269271, 4842, 28970), (0.7789959982457828, 0.6116614832321611, 0.6466422320478586))\n",
      "Processing sentence:  ( metamap & biomedicus ) \n",
      "results: ((654, 273945, 168, 37514), (0.8375872040708432, 0.5082609433288785, 0.4845981544368057))\n",
      "Processing sentence:  ( metamap | biomedicus ) \n",
      "results: ((14616, 246691, 27422, 23552), (0.6302671169574771, 0.6414497761508722, 0.6354102927244968))\n",
      "Processing sentence:  ( ( ctakes & metamap ) & biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ctakes & metamap ) | biomedicus ) \n",
      "wtf!\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence:  ( ( ctakes | metamap ) & biomedicus ) \n",
      "results: ((654, 273945, 168, 37514), (0.8375872040708432, 0.5082609433288785, 0.4845981544368057))\n",
      "Processing sentence:  ( ( ctakes | metamap ) | biomedicus ) \n",
      "results: ((14628, 246665, 27448, 23540), (0.6302687910519306, 0.6415595502026508, 0.6354574114447574))\n",
      "Processing sentence:  ( ( ctakes & biomedicus ) & quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ctakes & biomedicus ) | quick_umls ) \n",
      "wtf!\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( ( ctakes | biomedicus ) & quick_umls ) \n",
      "results: ((32, 274099, 14, 38136), (0.7867567001164814, 0.5003936624156724, 0.46830551416981386))\n",
      "Processing sentence:  ( ( ctakes | biomedicus ) | quick_umls ) \n",
      "results: ((13660, 234619, 39494, 24508), (0.5812050099688713, 0.6069060803969375, 0.5895682277265739))\n",
      "Processing sentence:  ( ( metamap & biomedicus ) & quick_umls ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( metamap & biomedicus ) | quick_umls ) \n",
      "results: ((6436, 238479, 35634, 31732), (0.517774485027999, 0.5193127237066837, 0.5183309470116264))\n",
      "Processing sentence:  ( ( metamap | biomedicus ) & quick_umls ) \n",
      "results: ((112, 273921, 192, 38056), (0.6232188506473908, 0.5011169771229941, 0.4702814072675595))\n",
      "Processing sentence:  ( ( metamap | biomedicus ) | quick_umls ) \n",
      "results: ((18166, 215731, 58382, 20002), (0.5762324577810924, 0.6314816413627831, 0.5814860179427812))\n",
      "Processing sentence:  ( ( ( ctakes & metamap ) & biomedicus ) & quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( ctakes & metamap ) & biomedicus ) | quick_umls ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((5868, 238613, 35500, 32300), (0.5113111522300652, 0.5121163603564843, 0.5115790443119964))\n",
      "Processing sentence:  ( ( ( ctakes & metamap ) | biomedicus ) & quick_umls ) \n",
      "wtf!\n",
      "results: ((32, 274099, 14, 38136), (0.7867567001164814, 0.5003936624156724, 0.46830551416981386))\n",
      "Processing sentence:  ( ( ( ctakes & metamap ) | biomedicus ) | quick_umls ) \n",
      "wtf!\n",
      "results: ((13648, 234645, 39468, 24520), (0.58116775917814, 0.6067963063451589, 0.5895164404462477))\n",
      "Processing sentence:  ( ( ( ctakes | metamap ) & biomedicus ) & quick_umls ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( ctakes | metamap ) & biomedicus ) | quick_umls ) \n",
      "results: ((6436, 238479, 35634, 31732), (0.517774485027999, 0.5193127237066837, 0.5183309470116264))\n",
      "Processing sentence:  ( ( ( ctakes | metamap ) | biomedicus ) & quick_umls ) \n",
      "results: ((112, 273921, 192, 38056), (0.6232188506473908, 0.5011169771229941, 0.4702814072675595))\n",
      "Processing sentence:  ( ( ( ctakes | metamap ) | biomedicus ) | quick_umls ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('ctakes', 'metamap', 'quick_umls', 'biomedicus')\n",
      "Processing sentence:  ( quick_umls & biomedicus ) \n",
      "results: ((32, 274099, 14, 38136), (0.7867567001164814, 0.5003936624156724, 0.46830551416981386))\n",
      "Processing sentence:  ( quick_umls | biomedicus ) \n",
      "results: ((13648, 234645, 39468, 24520), (0.58116775917814, 0.6067963063451589, 0.5895164404462477))\n",
      "Processing sentence:  ( ( ctakes & quick_umls ) & biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ctakes & quick_umls ) | biomedicus ) \n",
      "wtf!\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence:  ( ( ctakes | quick_umls ) & biomedicus ) \n",
      "results: ((32, 274099, 14, 38136), (0.7867567001164814, 0.5003936624156724, 0.46830551416981386))\n",
      "Processing sentence:  ( ( ctakes | quick_umls ) | biomedicus ) \n",
      "results: ((13660, 234619, 39494, 24508), (0.5812050099688713, 0.6069060803969375, 0.5895682277265739))\n",
      "Processing sentence:  ( ( metamap & quick_umls ) & biomedicus ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( metamap & quick_umls ) | biomedicus ) \n",
      "results: ((9248, 269119, 4994, 28920), (0.7761563605385469, 0.6120392242649834, 0.6468176457561035))\n",
      "Processing sentence:  ( ( metamap | quick_umls ) & biomedicus ) \n",
      "results: ((674, 273931, 182, 37494), (0.8334941094561553, 0.5084974059960705, 0.4850993006657862))\n",
      "Processing sentence:  ( ( metamap | quick_umls ) | biomedicus ) \n",
      "results: ((18166, 215731, 58382, 20002), (0.5762324577810924, 0.6314816413627831, 0.5814860179427812))\n",
      "Processing sentence:  ( ( ( ctakes & metamap ) & quick_umls ) & biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( ctakes & metamap ) & quick_umls ) | biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence:  ( ( ( ctakes & metamap ) | quick_umls ) & biomedicus ) \n",
      "wtf!\n",
      "results: ((32, 274099, 14, 38136), (0.7867567001164814, 0.5003936624156724, 0.46830551416981386))\n",
      "Processing sentence:  ( ( ( ctakes & metamap ) | quick_umls ) | biomedicus ) \n",
      "wtf!\n",
      "results: ((13648, 234645, 39468, 24520), (0.58116775917814, 0.6067963063451589, 0.5895164404462477))\n",
      "Processing sentence:  ( ( ( ctakes | metamap ) & quick_umls ) & biomedicus ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( ctakes | metamap ) & quick_umls ) | biomedicus ) \n",
      "results: ((9248, 269119, 4994, 28920), (0.7761563605385469, 0.6120392242649834, 0.6468176457561035))\n",
      "Processing sentence:  ( ( ( ctakes | metamap ) | quick_umls ) & biomedicus ) \n",
      "results: ((674, 273931, 182, 37494), (0.8334941094561553, 0.5084974059960705, 0.4850993006657862))\n",
      "Processing sentence:  ( ( ( ctakes | metamap ) | quick_umls ) | biomedicus ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('ctakes', 'quick_umls', 'metamap', 'biomedicus')\n",
      "Processing sentence:  ( ( quick_umls & metamap ) & biomedicus ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( quick_umls & metamap ) | biomedicus ) \n",
      "results: ((9248, 269119, 4994, 28920), (0.7761563605385469, 0.6120392242649834, 0.6468176457561035))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) & biomedicus ) \n",
      "results: ((674, 273931, 182, 37494), (0.8334941094561553, 0.5084974059960705, 0.4850993006657862))\n",
      "Processing sentence:  ( ( quick_umls | metamap ) | biomedicus ) \n",
      "results: ((18166, 215731, 58382, 20002), (0.5762324577810924, 0.6314816413627831, 0.5814860179427812))\n",
      "Processing sentence:  ( ( ( ctakes & quick_umls ) & metamap ) & biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( ctakes & quick_umls ) & metamap ) | biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence:  ( ( ( ctakes & quick_umls ) | metamap ) & biomedicus ) \n",
      "wtf!\n",
      "results: ((654, 273945, 168, 37514), (0.8375872040708432, 0.5082609433288785, 0.4845981544368057))\n",
      "Processing sentence:  ( ( ( ctakes & quick_umls ) | metamap ) | biomedicus ) \n",
      "wtf!\n",
      "results: ((14616, 246691, 27422, 23552), (0.6302671169574771, 0.6414497761508722, 0.6354102927244968))\n",
      "Processing sentence:  ( ( ( ctakes | quick_umls ) & metamap ) & biomedicus ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( ctakes | quick_umls ) & metamap ) | biomedicus ) \n",
      "results: ((9248, 269119, 4994, 28920), (0.7761563605385469, 0.6120392242649834, 0.6468176457561035))\n",
      "Processing sentence:  ( ( ( ctakes | quick_umls ) | metamap ) & biomedicus ) \n",
      "results: ((674, 273931, 182, 37494), (0.8334941094561553, 0.5084974059960705, 0.4850993006657862))\n",
      "Processing sentence:  ( ( ( ctakes | quick_umls ) | metamap ) | biomedicus ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('ctakes', 'quick_umls', 'biomedicus', 'metamap')\n",
      "Processing sentence:  ( ( ctakes & biomedicus ) & metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ctakes & biomedicus ) | metamap ) \n",
      "wtf!\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence:  ( ( ctakes | biomedicus ) & metamap ) \n",
      "results: ((654, 273945, 168, 37514), (0.8375872040708432, 0.5082609433288785, 0.4845981544368057))\n",
      "Processing sentence:  ( ( ctakes | biomedicus ) | metamap ) \n",
      "results: ((14628, 246665, 27448, 23540), (0.6302687910519306, 0.6415595502026508, 0.6354574114447574))\n",
      "Processing sentence:  ( ( quick_umls & biomedicus ) & metamap ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( quick_umls & biomedicus ) | metamap ) \n",
      "results: ((9222, 250007, 24106, 28946), (0.5864688441743169, 0.576837089603659, 0.5810245109053385))\n",
      "Processing sentence:  ( ( quick_umls | biomedicus ) & metamap ) \n",
      "results: ((734, 273767, 346, 37434), (0.7796704065384918, 0.5089842580362001, 0.486428314348939))\n",
      "Processing sentence:  ( ( quick_umls | biomedicus ) | metamap ) \n",
      "results: ((18166, 215731, 58382, 20002), (0.5762324577810924, 0.6314816413627831, 0.5814860179427812))\n",
      "Processing sentence:  ( ( ( ctakes & quick_umls ) & biomedicus ) & metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( ctakes & quick_umls ) & biomedicus ) | metamap ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((9208, 250021, 24092, 28960), (0.5863550820562947, 0.5766792268107072, 0.5808815817764968))\n",
      "Processing sentence:  ( ( ( ctakes & quick_umls ) | biomedicus ) & metamap ) \n",
      "wtf!\n",
      "results: ((654, 273945, 168, 37514), (0.8375872040708432, 0.5082609433288785, 0.4845981544368057))\n",
      "Processing sentence:  ( ( ( ctakes & quick_umls ) | biomedicus ) | metamap ) \n",
      "wtf!\n",
      "results: ((14616, 246691, 27422, 23552), (0.6302671169574771, 0.6414497761508722, 0.6354102927244968))\n",
      "Processing sentence:  ( ( ( ctakes | quick_umls ) & biomedicus ) & metamap ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( ctakes | quick_umls ) & biomedicus ) | metamap ) \n",
      "results: ((9222, 250007, 24106, 28946), (0.5864688441743169, 0.576837089603659, 0.5810245109053385))\n",
      "Processing sentence:  ( ( ( ctakes | quick_umls ) | biomedicus ) & metamap ) \n",
      "results: ((734, 273767, 346, 37434), (0.7796704065384918, 0.5089842580362001, 0.486428314348939))\n",
      "Processing sentence:  ( ( ( ctakes | quick_umls ) | biomedicus ) | metamap ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('metamap', 'quick_umls', 'ctakes', 'biomedicus')\n",
      "Processing sentence:  ( ( metamap & ctakes ) & biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( metamap & ctakes ) | biomedicus ) \n",
      "wtf!\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence:  ( ( metamap | ctakes ) & biomedicus ) \n",
      "results: ((654, 273945, 168, 37514), (0.8375872040708432, 0.5082609433288785, 0.4845981544368057))\n",
      "Processing sentence:  ( ( metamap | ctakes ) | biomedicus ) \n",
      "results: ((14628, 246665, 27448, 23540), (0.6302687910519306, 0.6415595502026508, 0.6354574114447574))\n",
      "Processing sentence:  ( ( quick_umls & ctakes ) & biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( quick_umls & ctakes ) | biomedicus ) \n",
      "wtf!\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence:  ( ( quick_umls | ctakes ) & biomedicus ) \n",
      "results: ((32, 274099, 14, 38136), (0.7867567001164814, 0.5003936624156724, 0.46830551416981386))\n",
      "Processing sentence:  ( ( quick_umls | ctakes ) | biomedicus ) \n",
      "results: ((13660, 234619, 39494, 24508), (0.5812050099688713, 0.6069060803969375, 0.5895682277265739))\n",
      "Processing sentence:  ( ( ( metamap & quick_umls ) & ctakes ) & biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( metamap & quick_umls ) & ctakes ) | biomedicus ) \n",
      "wtf!\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence:  ( ( ( metamap & quick_umls ) | ctakes ) & biomedicus ) \n",
      "results: ((12, 274113, 0, 38156), (0.9389052387524859, 0.5001571997484804, 0.46777919557885))\n",
      "Processing sentence:  ( ( ( metamap & quick_umls ) | ctakes ) | biomedicus ) \n",
      "results: ((9268, 269093, 5020, 28900), (0.775837035564868, 0.6122537981490823, 0.6470365531578434))\n",
      "Processing sentence:  ( ( ( metamap | quick_umls ) & ctakes ) & biomedicus ) \n",
      "wtf!\n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( metamap | quick_umls ) & ctakes ) | biomedicus ) \n",
      "wtf!\n",
      "results: ((9178, 269297, 4816, 28990), (0.7793321149073965, 0.6114469093480621, 0.6464217934204923))\n",
      "Processing sentence:  ( ( ( metamap | quick_umls ) | ctakes ) & biomedicus ) \n",
      "results: ((674, 273931, 182, 37494), (0.8334941094561553, 0.5084974059960705, 0.4850993006657862))\n",
      "Processing sentence:  ( ( ( metamap | quick_umls ) | ctakes ) | biomedicus ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "processing merge combo: ('metamap', 'quick_umls', 'biomedicus', 'ctakes')\n",
      "Processing sentence:  ( ( metamap & biomedicus ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( metamap & biomedicus ) | ctakes ) \n",
      "results: ((680, 273915, 198, 37488), (0.8270516374210781, 0.5085468208261866, 0.4852334858962234))\n",
      "Processing sentence:  ( ( metamap | biomedicus ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( metamap | biomedicus ) | ctakes ) \n",
      "results: ((14628, 246665, 27448, 23540), (0.6302687910519306, 0.6415595502026508, 0.6354574114447574))\n",
      "Processing sentence:  ( ( quick_umls & biomedicus ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( quick_umls & biomedicus ) | ctakes ) \n",
      "results: ((58, 274069, 44, 38110), (0.723275026538633, 0.5006795399129805, 0.4689771535882995))\n",
      "Processing sentence:  ( ( quick_umls | biomedicus ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( quick_umls | biomedicus ) | ctakes ) \n",
      "results: ((13660, 234619, 39494, 24508), (0.5812050099688713, 0.6069060803969375, 0.5895682277265739))\n",
      "Processing sentence:  ( ( ( metamap & quick_umls ) & biomedicus ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( metamap & quick_umls ) & biomedicus ) | ctakes ) \n",
      "results: ((38, 274083, 30, 38130), (0.7183476834536604, 0.5004430772457885, 0.46845220420436895))\n",
      "Processing sentence:  ( ( ( metamap & quick_umls ) | biomedicus ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( metamap & quick_umls ) | biomedicus ) | ctakes ) \n",
      "results: ((9268, 269093, 5020, 28900), (0.775837035564868, 0.6122537981490823, 0.6470365531578434))\n",
      "Processing sentence:  ( ( ( metamap | quick_umls ) & biomedicus ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( metamap | quick_umls ) & biomedicus ) | ctakes ) \n",
      "results: ((700, 273901, 212, 37468), (0.823605375029447, 0.5087832834933786, 0.4857333602085763))\n",
      "Processing sentence:  ( ( ( metamap | quick_umls ) | biomedicus ) & ctakes ) \n",
      "wtf!\n",
      "results: ((0, 274113, 0, 38168), (0.43888837297177863, 0.5, 0.4674553286698022))\n",
      "Processing sentence:  ( ( ( metamap | quick_umls ) | biomedicus ) | ctakes ) \n",
      "results: ((18172, 215705, 58408, 19996), (0.5762290179451243, 0.6315128155403216, 0.581469705317581))\n",
      "           F1  precision    recall     TP     FN     FP     TP/FN  n_gold  \\\n",
      "0    0.351904   0.655853  0.240463   9178  28990   4816  0.316592   38168   \n",
      "1    0.001360   0.464286  0.000681     26  38142     30  0.000682   38168   \n",
      "2    0.257682   0.276517  0.241249   9208  28960  24092  0.317956   38168   \n",
      "3    0.147556   0.141849  0.153741   5868  32300  35500  0.181672   38168   \n",
      "4    0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "6    0.033547   0.795620  0.017135    654  37514    168  0.017433   38168   \n",
      "8    0.001675   0.695652  0.000838     32  38136     14  0.000839   38168   \n",
      "5    0.352360   0.655128  0.240987   9198  28970   4842  0.317501   38168   \n",
      "7    0.364462   0.347685  0.382939  14616  23552  27422  0.620584   38168   \n",
      "9    0.299023   0.256947  0.357577  13648  24520  39468  0.556607   38168   \n",
      "246  0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "10   0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "12   0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "247  0.352360   0.655128  0.240987   9198  28970   4842  0.317501   38168   \n",
      "11   0.258012   0.276658  0.241721   9226  28942  24122  0.318775   38168   \n",
      "13   0.147919   0.142119  0.154213   5886  32282  35530  0.182331   38168   \n",
      "250  0.033547   0.795620  0.017135    654  37514    168  0.017433   38168   \n",
      "90   0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "14   0.004787   0.340741  0.002410     92  38076    178  0.002416   38168   \n",
      "251  0.364462   0.347685  0.382939  14616  23552  27422  0.620584   38168   \n",
      "91   0.258012   0.276658  0.241721   9226  28942  24122  0.318775   38168   \n",
      "15   0.254869   0.197566  0.358992  13702  24466  55652  0.560043   38168   \n",
      "294  0.001675   0.695652  0.000838     32  38136     14  0.000839   38168   \n",
      "134  0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "54   0.004787   0.340741  0.002410     92  38076    178  0.002416   38168   \n",
      "295  0.299023   0.256947  0.357577  13648  24520  39468  0.556607   38168   \n",
      "135  0.147919   0.142119  0.154213   5886  32282  35530  0.182331   38168   \n",
      "55   0.254869   0.197566  0.358992  13702  24466  55652  0.560043   38168   \n",
      "16   0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "20   0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "..        ...        ...       ...    ...    ...    ...       ...     ...   \n",
      "316  0.000629   1.000000  0.000314     12  38156      0  0.000314   38168   \n",
      "317  0.352910   0.649347  0.242297   9248  28920   4994  0.319779   38168   \n",
      "278  0.005822   0.368421  0.002934    112  38056    192  0.002943   38168   \n",
      "279  0.316729   0.237294  0.476106  18172  19996  58408  0.908782   38168   \n",
      "318  0.034543   0.787383  0.017659    674  37494    182  0.017976   38168   \n",
      "319  0.316729   0.237294  0.476106  18172  19996  58408  0.908782   38168   \n",
      "396  0.000629   1.000000  0.000314     12  38156      0  0.000314   38168   \n",
      "397  0.257972   0.276704  0.241616   9222  28946  24106  0.318593   38168   \n",
      "356  0.000629   1.000000  0.000314     12  38156      0  0.000314   38168   \n",
      "357  0.352910   0.649347  0.242297   9248  28920   4994  0.319779   38168   \n",
      "398  0.037403   0.679630  0.019231    734  37434    346  0.019608   38168   \n",
      "399  0.316729   0.237294  0.476106  18172  19996  58408  0.908782   38168   \n",
      "358  0.034543   0.787383  0.017659    674  37494    182  0.017976   38168   \n",
      "359  0.316729   0.237294  0.476106  18172  19996  58408  0.908782   38168   \n",
      "472  0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "473  0.001988   0.558824  0.000996     38  38130     30  0.000997   38168   \n",
      "432  0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "433  0.351904   0.655853  0.240463   9178  28990   4816  0.316592   38168   \n",
      "474  0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "475  0.353363   0.648656  0.242821   9268  28900   5020  0.320692   38168   \n",
      "434  0.000629   1.000000  0.000314     12  38156      0  0.000314   38168   \n",
      "435  0.353363   0.648656  0.242821   9268  28900   5020  0.320692   38168   \n",
      "476  0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "477  0.035824   0.767544  0.018340    700  37468    212  0.018683   38168   \n",
      "436  0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "437  0.351904   0.655853  0.240463   9178  28990   4816  0.316592   38168   \n",
      "478  0.000000   0.000000  0.000000      0  38168      0  0.000000   38168   \n",
      "479  0.316729   0.237294  0.476106  18172  19996  58408  0.908782   38168   \n",
      "438  0.034543   0.787383  0.017659    674  37494    182  0.017976   38168   \n",
      "439  0.316729   0.237294  0.476106  18172  19996  58408  0.908782   38168   \n",
      "\n",
      "     n_sys         TM      TN   macro_p   macro_r  macro_f1  \\\n",
      "0    13994  77.584885  269297  0.779332  0.611447  0.646422   \n",
      "1       56   3.474396  274083  0.671062  0.500286  0.468129   \n",
      "2    33300  50.459529  250021  0.586355  0.576679  0.580882   \n",
      "3    41368  28.850799  238613  0.511311  0.512116  0.511579   \n",
      "4        0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "6      822  22.810869  273945  0.837587  0.508261  0.484598   \n",
      "8       46   4.718143  274099  0.786757  0.500394  0.468306   \n",
      "5    14040  77.626472  269271  0.778996  0.611661  0.646642   \n",
      "7    42038  71.286536  246691  0.630267  0.641450  0.635410   \n",
      "9    53116  59.218354  234645  0.581168  0.606796  0.589516   \n",
      "246      0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "10       0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "12       0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "247  14040  77.626472  269271  0.778996  0.611661  0.646642   \n",
      "11   33348  50.521770  249991  0.586449  0.576860  0.581032   \n",
      "13   41416  28.922523  238583  0.511469  0.512297  0.511744   \n",
      "250    822  22.810869  273945  0.837587  0.508261  0.484598   \n",
      "90       0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "14     270   5.598942  273935  0.609353  0.500881  0.469760   \n",
      "251  42038  71.286536  246691  0.630267  0.641450  0.635410   \n",
      "91   33348  50.521770  249991  0.586449  0.576860  0.581032   \n",
      "15   69354  52.029327  218461  0.548426  0.577983  0.549957   \n",
      "294     46   4.718143  274099  0.786757  0.500394  0.468306   \n",
      "134      0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "54     270   5.598942  273935  0.609353  0.500881  0.469760   \n",
      "295  53116  59.218354  234645  0.581168  0.606796  0.589516   \n",
      "135  41416  28.922523  238583  0.511469  0.512297  0.511744   \n",
      "55   69354  52.029327  218461  0.548426  0.577983  0.549957   \n",
      "16       0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "20       0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "..     ...        ...     ...       ...       ...       ...   \n",
      "316     12   3.464102  274113  0.938905  0.500157  0.467779   \n",
      "317  14242  77.492974  269119  0.776156  0.612039  0.646818   \n",
      "278    304   6.423641  273921  0.623219  0.501117  0.470281   \n",
      "279  76580  65.666678  215705  0.576229  0.631513  0.581470   \n",
      "318    856  23.036846  273931  0.833494  0.508497  0.485099   \n",
      "319  76580  65.666678  215705  0.576229  0.631513  0.581470   \n",
      "396     12   3.464102  274113  0.938905  0.500157  0.467779   \n",
      "397  33328  50.515016  250007  0.586469  0.576837  0.581025   \n",
      "356     12   3.464102  274113  0.938905  0.500157  0.467779   \n",
      "357  14242  77.492974  269119  0.776156  0.612039  0.646818   \n",
      "398   1080  22.334909  273767  0.779670  0.508984  0.486428   \n",
      "399  76580  65.666678  215705  0.576229  0.631513  0.581470   \n",
      "358    856  23.036846  273931  0.833494  0.508497  0.485099   \n",
      "359  76580  65.666678  215705  0.576229  0.631513  0.581470   \n",
      "472      0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "473     68   4.608177  274083  0.718348  0.500443  0.468452   \n",
      "432      0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "433  13994  77.584885  269297  0.779332  0.611447  0.646422   \n",
      "474      0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "475  14288  77.535449  269093  0.775837  0.612254  0.647037   \n",
      "434     12   3.464102  274113  0.938905  0.500157  0.467779   \n",
      "435  14288  77.535449  269093  0.775837  0.612254  0.647037   \n",
      "476      0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "477    912  23.179316  273901  0.823605  0.508783  0.485733   \n",
      "436      0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "437  13994  77.584885  269297  0.779332  0.611447  0.646422   \n",
      "478      0        NaN  274113  0.438888  0.500000  0.467455   \n",
      "479  76580  65.666678  215705  0.576229  0.631513  0.581470   \n",
      "438    856  23.036846  273931  0.833494  0.508497  0.485099   \n",
      "439  76580  65.666678  215705  0.576229  0.631513  0.581470   \n",
      "\n",
      "                                          merge  n_terms  F1 rank  TP/FN rank  \\\n",
      "0                                    biomedicus        1     23.0        78.0   \n",
      "1                                        ctakes        1    151.0       151.0   \n",
      "2                                       metamap        1     68.0        67.0   \n",
      "3                                    quick_umls        1     95.0        95.0   \n",
      "4                           (biomedicus&ctakes)        2    193.5       193.5   \n",
      "6                          (biomedicus&metamap)        2    117.5       117.5   \n",
      "8                       (biomedicus&quick_umls)        2    146.5       146.5   \n",
      "5                           (biomedicus|ctakes)        2     17.5        72.5   \n",
      "7                          (biomedicus|metamap)        2      8.5        26.5   \n",
      "9                       (biomedicus|quick_umls)        2     53.5        46.5   \n",
      "246                         (ctakes&biomedicus)        2    193.5       193.5   \n",
      "10                             (ctakes&metamap)        2    193.5       193.5   \n",
      "12                          (ctakes&quick_umls)        2    193.5       193.5   \n",
      "247                         (ctakes|biomedicus)        2     17.5        72.5   \n",
      "11                             (ctakes|metamap)        2     58.5        57.5   \n",
      "13                          (ctakes|quick_umls)        2     89.5        89.5   \n",
      "250                        (metamap&biomedicus)        2    117.5       117.5   \n",
      "90                             (metamap&ctakes)        2    193.5       193.5   \n",
      "14                         (metamap&quick_umls)        2    133.5       133.5   \n",
      "251                        (metamap|biomedicus)        2      8.5        26.5   \n",
      "91                             (metamap|ctakes)        2     58.5        57.5   \n",
      "15                         (metamap|quick_umls)        2     80.5        36.5   \n",
      "294                     (quick_umls&biomedicus)        2    146.5       146.5   \n",
      "134                         (quick_umls&ctakes)        2    193.5       193.5   \n",
      "54                         (quick_umls&metamap)        2    133.5       133.5   \n",
      "295                     (quick_umls|biomedicus)        2     53.5        46.5   \n",
      "135                         (quick_umls|ctakes)        2     89.5        89.5   \n",
      "55                         (quick_umls|metamap)        2     80.5        36.5   \n",
      "16                ((biomedicus&ctakes)&metamap)        3    193.5       193.5   \n",
      "20             ((biomedicus&ctakes)&quick_umls)        3    193.5       193.5   \n",
      "..                                          ...      ...      ...         ...   \n",
      "316  (((ctakes|metamap)&quick_umls)&biomedicus)        4    159.0       159.0   \n",
      "317  (((ctakes|metamap)&quick_umls)|biomedicus)        4     14.5        52.5   \n",
      "278  (((ctakes|metamap)|biomedicus)&quick_umls)        4    127.0       127.0   \n",
      "279  (((ctakes|metamap)|biomedicus)|quick_umls)        4     33.5         6.5   \n",
      "318  (((ctakes|metamap)|quick_umls)&biomedicus)        4    111.0       111.0   \n",
      "319  (((ctakes|metamap)|quick_umls)|biomedicus)        4     33.5         6.5   \n",
      "396  (((ctakes|quick_umls)&biomedicus)&metamap)        4    159.0       159.0   \n",
      "397  (((ctakes|quick_umls)&biomedicus)|metamap)        4     61.5        60.5   \n",
      "356  (((ctakes|quick_umls)&metamap)&biomedicus)        4    159.0       159.0   \n",
      "357  (((ctakes|quick_umls)&metamap)|biomedicus)        4     14.5        52.5   \n",
      "398  (((ctakes|quick_umls)|biomedicus)&metamap)        4    103.0       103.0   \n",
      "399  (((ctakes|quick_umls)|biomedicus)|metamap)        4     33.5         6.5   \n",
      "358  (((ctakes|quick_umls)|metamap)&biomedicus)        4    111.0       111.0   \n",
      "359  (((ctakes|quick_umls)|metamap)|biomedicus)        4     33.5         6.5   \n",
      "472  (((metamap&quick_umls)&biomedicus)&ctakes)        4    193.5       193.5   \n",
      "473  (((metamap&quick_umls)&biomedicus)|ctakes)        4    141.0       141.0   \n",
      "432  (((metamap&quick_umls)&ctakes)&biomedicus)        4    193.5       193.5   \n",
      "433  (((metamap&quick_umls)&ctakes)|biomedicus)        4     23.0        78.0   \n",
      "474  (((metamap&quick_umls)|biomedicus)&ctakes)        4    193.5       193.5   \n",
      "475  (((metamap&quick_umls)|biomedicus)|ctakes)        4     11.5        49.5   \n",
      "434  (((metamap&quick_umls)|ctakes)&biomedicus)        4    159.0       159.0   \n",
      "435  (((metamap&quick_umls)|ctakes)|biomedicus)        4     11.5        49.5   \n",
      "476  (((metamap|quick_umls)&biomedicus)&ctakes)        4    193.5       193.5   \n",
      "477  (((metamap|quick_umls)&biomedicus)|ctakes)        4    106.0       106.0   \n",
      "436  (((metamap|quick_umls)&ctakes)&biomedicus)        4    193.5       193.5   \n",
      "437  (((metamap|quick_umls)&ctakes)|biomedicus)        4     23.0        78.0   \n",
      "478  (((metamap|quick_umls)|biomedicus)&ctakes)        4    193.5       193.5   \n",
      "479  (((metamap|quick_umls)|biomedicus)|ctakes)        4     33.5         6.5   \n",
      "438  (((metamap|quick_umls)|ctakes)&biomedicus)        4    111.0       111.0   \n",
      "439  (((metamap|quick_umls)|ctakes)|biomedicus)        4     33.5         6.5   \n",
      "\n",
      "     TM rank       Gmean  \n",
      "0        7.0   23.325618  \n",
      "1      151.0  151.000000  \n",
      "2       78.0   71.801222  \n",
      "3       95.0   95.000000  \n",
      "4        NaN         NaN  \n",
      "6      111.5  114.794473  \n",
      "8      143.5  145.159001  \n",
      "5        1.5   11.045745  \n",
      "7       25.5   22.958920  \n",
      "9       53.5   50.267438  \n",
      "246      NaN         NaN  \n",
      "10       NaN         NaN  \n",
      "12       NaN         NaN  \n",
      "247      1.5   11.045745  \n",
      "11      68.5   62.271270  \n",
      "13      89.5   89.500000  \n",
      "250    111.5  114.794473  \n",
      "90       NaN         NaN  \n",
      "14     135.5  134.385218  \n",
      "251     25.5   22.958920  \n",
      "91      68.5   62.271270  \n",
      "15      63.5   50.973006  \n",
      "294    143.5  145.159001  \n",
      "134      NaN         NaN  \n",
      "54     135.5  134.385218  \n",
      "295     53.5   50.267438  \n",
      "135     89.5   89.500000  \n",
      "55      63.5   50.973006  \n",
      "16       NaN         NaN  \n",
      "20       NaN         NaN  \n",
      "..       ...         ...  \n",
      "316    159.0  159.000000  \n",
      "317     15.5   26.460159  \n",
      "278    127.0  127.000000  \n",
      "279     33.5   16.163743  \n",
      "318    103.0  107.370473  \n",
      "319     33.5   16.163743  \n",
      "396    159.0  159.000000  \n",
      "397     71.5   65.281661  \n",
      "356    159.0  159.000000  \n",
      "357     15.5   26.460159  \n",
      "398    119.0  109.826772  \n",
      "399     33.5   16.163743  \n",
      "358    103.0  107.370473  \n",
      "359     33.5   16.163743  \n",
      "472      NaN         NaN  \n",
      "473    149.0  144.501110  \n",
      "432      NaN         NaN  \n",
      "433      7.0   23.325618  \n",
      "474      NaN         NaN  \n",
      "475     12.5   22.831200  \n",
      "434    159.0  159.000000  \n",
      "435     12.5   22.831200  \n",
      "476      NaN         NaN  \n",
      "477    100.0  103.290128  \n",
      "436      NaN         NaN  \n",
      "437      7.0   23.325618  \n",
      "478      NaN         NaN  \n",
      "479     33.5   16.163743  \n",
      "438    103.0  107.370473  \n",
      "439     33.5   16.163743  \n",
      "\n",
      "[220 rows x 20 columns]\n",
      " done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         191227493 function calls (190510325 primitive calls) in 277.116 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "    14300   84.162    0.006   84.162    0.006 {method 'sort' of 'numpy.ndarray' objects}\n",
       "324563/289956   69.001    0.000   69.540    0.000 {built-in method numpy.array}\n",
       "      220   15.006    0.068   21.777    0.099 classification.py:274(<listcomp>)\n",
       "      220   14.627    0.066   21.299    0.097 classification.py:275(<listcomp>)\n",
       "137809860   13.529    0.000   13.529    0.000 {method 'get' of 'dict' objects}\n",
       "      220    6.969    0.032  273.268    1.242 <ipython-input-44-c9fd36f58387>:157(get_metrics)\n",
       "      220    6.874    0.031  262.199    1.192 <ipython-input-36-29545697688e>:44(vectorized_cooccurences)\n",
       "     2640    3.848    0.001    3.848    0.001 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
       "    14300    3.084    0.000   89.640    0.006 arraysetops.py:299(_unique1d)\n",
       "     5280    2.593    0.000   63.110    0.012 multiclass.py:174(type_of_target)\n",
       "    14300    2.284    0.000    2.284    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
       "    16725    2.179    0.000    2.179    0.000 {pandas._libs.ops.scalar_compare}\n",
       "    11265    2.174    0.000    2.174    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "    16720    2.138    0.000    5.967    0.000 <ipython-input-36-29545697688e>:1(label_vector)\n",
       "8302030/8302008    2.067    0.000    3.566    0.000 {built-in method builtins.isinstance}\n",
       "    16720    2.000    0.000    2.000    0.000 <ipython-input-36-29545697688e>:9(<listcomp>)\n",
       "     2866    1.732    0.001    1.732    0.001 {built-in method numpy.bincount}\n",
       "      220    1.508    0.007    1.508    0.007 <ipython-input-36-29545697688e>:94(<listcomp>)\n",
       "      220    1.495    0.007    1.495    0.007 <ipython-input-36-29545697688e>:95(<listcomp>)\n",
       "  1307343    1.314    0.000    1.314    0.000 {built-in method numpy.arange}\n",
       "  1282870    1.177    0.000    1.177    0.000 {built-in method __new__ of type object at 0x108286778}\n",
       "      880    1.020    0.001   75.018    0.085 classification.py:882(precision_recall_fscore_support)\n",
       "  16721/1    0.951    0.000  277.127  277.127 {built-in method builtins.exec}\n",
       "    14300    0.897    0.000   90.597    0.006 arraysetops.py:151(unique)\n",
       "  3034748    0.867    0.000    1.196    0.000 generic.py:7(_check)\n",
       "      220    0.813    0.004   97.882    0.445 classification.py:187(confusion_matrix)\n",
       "    10930    0.807    0.000    0.807    0.000 {built-in method numpy.concatenate}\n",
       "    16720    0.758    0.000    1.920    0.000 __init__.py:316(namedtuple)\n",
       "   129143    0.753    0.000    0.753    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "   428425    0.661    0.000    1.700    0.000 dtypes.py:68(find)\n",
       "4019392/3406499    0.634    0.000    0.875    0.000 {built-in method builtins.len}\n",
       "4705239/4705236    0.627    0.000    0.736    0.000 {built-in method builtins.getattr}\n",
       "   564637    0.602    0.000    1.380    0.000 common.py:1845(_is_dtype_type)\n",
       "    16720    0.492    0.000    1.734    0.000 <ipython-input-36-29545697688e>:8(<listcomp>)\n",
       "   820067    0.488    0.000    0.750    0.000 {built-in method builtins.hasattr}\n",
       "   427791    0.479    0.000    0.799    0.000 {method 'format' of 'str' objects}\n",
       "    45300    0.461    0.000    3.124    0.000 algorithms.py:1544(take_nd)\n",
       "   627419    0.458    0.000    1.946    0.000 base.py:75(is_dtype)\n",
       "    66904    0.432    0.000    4.969    0.000 indexing.py:960(_getitem_lowerdim)\n",
       "      147    0.430    0.003    0.430    0.003 {method 'recv_into' of '_socket.socket' objects}\n",
       "   203332    0.368    0.000    0.930    0.000 _dtype.py:319(_name_get)\n",
       "    22997    0.366    0.000    0.844    0.000 managers.py:186(_rebuild_blknos_and_blklocs)\n",
       "   192983    0.363    0.000    0.708    0.000 generic.py:5069(__setattr__)\n",
       "   410398    0.359    0.000    1.661    0.000 common.py:1702(is_extension_array_dtype)\n",
       "   124145    0.354    0.000    0.354    0.000 {built-in method numpy.empty}\n",
       "  1254440    0.352    0.000    1.601    0.000 __init__.py:403(_make)\n",
       "  2154398    0.321    0.000    0.321    0.000 {built-in method builtins.issubclass}\n",
       "      220    0.309    0.001  119.276    0.542 classification.py:1448(classification_report)\n",
       "86453/86416    0.309    0.000    3.886    0.000 series.py:152(__init__)\n",
       "   342381    0.295    0.000    0.918    0.000 common.py:1981(pandas_dtype)\n",
       "    68710    0.282    0.000    1.093    0.000 managers.py:963(iget)\n",
       "   132095    0.271    0.000    0.667    0.000 blocks.py:78(__init__)\n",
       "   219374    0.253    0.000    1.180    0.000 common.py:93(is_bool_indexer)\n",
       "    16727    0.250    0.000    7.294    0.000 ops.py:1660(wrapper)\n",
       "    84479    0.241    0.000    1.993    0.000 base.py:1117(__iter__)\n",
       "    83624    0.233    0.000   14.893    0.000 indexing.py:1485(__getitem__)\n",
       "    66911    0.233    0.000    2.756    0.000 frame.py:2829(_ixs)\n",
       "    45300    0.223    0.000    0.635    0.000 algorithms.py:1417(_get_take_nd_function)\n",
       "   406668    0.223    0.000    0.332    0.000 numerictypes.py:293(issubclass_)\n",
       "   144050    0.211    0.000    0.487    0.000 common.py:160(is_sparse)\n",
       "   442959    0.211    0.000    0.708    0.000 inference.py:253(is_list_like)\n",
       "    17811    0.210    0.000    0.387    0.000 indexing.py:2575(maybe_convert_indices)\n",
       "   203334    0.209    0.000    0.562    0.000 numerictypes.py:365(issubdtype)\n",
       "   279855    0.207    0.000    0.292    0.000 generic.py:363(_get_axis_name)\n",
       "   506412    0.198    0.000    0.208    0.000 {built-in method _abc._abc_instancecheck}\n",
       "   132095    0.194    0.000    1.638    0.000 blocks.py:3080(make_block)\n",
       "     1320    0.190    0.000   21.328    0.016 arraysetops.py:704(union1d)\n",
       "    43926    0.187    0.000    0.724    0.000 cast.py:255(maybe_promote)\n",
       "   572268    0.185    0.000    0.254    0.000 base.py:652(__len__)\n",
       "   132095    0.183    0.000    0.225    0.000 blocks.py:199(mgr_locs)\n",
       "    86452    0.183    0.000    0.894    0.000 managers.py:1443(__init__)\n",
       "    16720    0.179    0.000   11.109    0.001 frame.py:849(itertuples)\n",
       "   507012    0.176    0.000    0.176    0.000 common.py:117(classes)\n",
       "140310/140308    0.175    0.000    0.337    0.000 generic.py:5053(__getattr__)\n",
       "   278765    0.172    0.000    0.539    0.000 generic.py:377(_get_axis)\n",
       "     1320    0.171    0.000  102.816    0.078 classification.py:44(_check_targets)\n",
       "    17811    0.168    0.000    5.842    0.000 managers.py:1329(take)\n",
       "   353017    0.166    0.000    1.246    0.000 common.py:434(is_datetime64tz_dtype)\n",
       "   286565    0.157    0.000    0.253    0.000 managers.py:1549(internal_values)\n",
       "    66904    0.156    0.000    3.556    0.000 indexing.py:2205(_getitem_axis)\n",
       "   163689    0.155    0.000    0.777    0.000 common.py:403(is_datetime64_dtype)\n",
       "   107602    0.155    0.000    0.155    0.000 generic.py:127(__init__)\n",
       "    25485    0.149    0.000    1.769    0.000 construction.py:537(sanitize_array)\n",
       "    88529    0.147    0.000    0.366    0.000 managers.py:139(shape)\n",
       "     5280    0.146    0.000   20.005    0.004 fromnumeric.py:1785(shape)\n",
       "        1    0.142    0.142    0.144    0.144 {method 'read' of 'pandas._libs.parsers.TextReader' objects}\n",
       "      442    0.141    0.000    0.142    0.000 managers.py:2004(<listcomp>)\n",
       "    86454    0.140    0.000    0.263    0.000 series.py:354(_set_axis)\n",
       "   506412    0.140    0.000    0.348    0.000 abc.py:137(__instancecheck__)\n",
       "    16875    0.139    0.000    0.139    0.000 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
       "    66904    0.138    0.000    1.255    0.000 indexing.py:217(_has_valid_tuple)\n",
       "   295904    0.137    0.000    0.373    0.000 integer.py:80(construct_from_string)\n",
       "   133808    0.136    0.000    1.017    0.000 indexing.py:2056(_validate_key)\n",
       "   103856    0.132    0.000    0.225    0.000 series.py:392(name)\n",
       "    66904    0.132    0.000    0.242    0.000 indexing.py:2089(_is_scalar_access)\n",
       "9604/6586    0.132    0.000    0.883    0.000 base.py:253(__new__)\n",
       "    32890    0.131    0.000    0.836    0.000 blocks.py:3034(get_block_type)\n",
       "   507012    0.131    0.000    0.198    0.000 common.py:119(<lambda>)\n",
       "   154660    0.131    0.000    0.499    0.000 common.py:131(is_object_dtype)\n",
       "    88345    0.130    0.000    0.380    0.000 dtypes.py:973(is_dtype)\n",
       "    34704    0.128    0.000    2.878    0.000 blocks.py:1217(take_nd)\n",
       "    17810    0.122    0.000    6.967    0.000 generic.py:3323(_take)\n",
       "   280768    0.120    0.000    0.232    0.000 generic.py:450(ndim)\n",
       "   133800    0.119    0.000    0.480    0.000 indexing.py:2116(_validate_integer)\n",
       "    76679    0.117    0.000    0.183    0.000 base.py:3940(__getitem__)\n",
       "   186331    0.115    0.000    0.193    0.000 managers.py:1522(dtype)\n",
       "    49940    0.114    0.000    0.320    0.000 _dtype.py:46(__str__)\n",
       "    40006    0.113    0.000    0.222    0.000 dtypes.py:786(construct_from_string)\n",
       "      220    0.112    0.001    0.112    0.001 {built-in method scipy.sparse._sparsetools.coo_todense}\n",
       "    83600    0.111    0.000    6.974    0.000 frame.py:919(<genexpr>)\n",
       "     1296    0.111    0.000    0.114    0.000 {method 'factorize' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "   146626    0.111    0.000    0.526    0.000 common.py:472(is_timedelta64_dtype)\n",
       "   351765    0.109    0.000    0.144    0.000 managers.py:143(ndim)\n",
       "     8242    0.109    0.000    0.158    0.000 {pandas._libs.lib.infer_dtype}\n",
       "   144566    0.108    0.000    0.154    0.000 {pandas._libs.lib.is_scalar}\n",
       "    14648    0.105    0.000    0.105    0.000 {pandas._libs.algos.take_2d_axis1_object_object}\n",
       "    39783    0.105    0.000    0.119    0.000 base.py:3918(__contains__)\n",
       "    19245    0.104    0.000    1.414    0.000 frame.py:2893(__getitem__)\n",
       "   286565    0.104    0.000    0.356    0.000 series.py:476(_values)\n",
       "    57291    0.102    0.000    0.386    0.000 blocks.py:2626(__init__)\n",
       "   278806    0.102    0.000    0.405    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
       "    68710    0.102    0.000    1.012    0.000 frame.py:3349(_box_col_values)\n",
       "   200712    0.097    0.000    0.154    0.000 indexing.py:1487(<genexpr>)\n",
       "     3053    0.097    0.000    0.097    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "     1267    0.096    0.000    0.096    0.000 {built-in method posix.stat}\n",
       "    16942    0.096    0.000    0.096    0.000 {built-in method numpy.zeros}\n",
       "   201430    0.095    0.000    0.441    0.000 indexing.py:2689(is_list_like_indexer)\n",
       "    84542    0.094    0.000    1.205    0.000 common.py:702(is_datetimelike)\n",
       "    72414    0.094    0.000    0.184    0.000 dtypes.py:672(construct_from_string)\n",
       "187526/152922    0.094    0.000   40.597    0.000 numeric.py:469(asarray)\n",
       "   491558    0.093    0.000    0.093    0.000 managers.py:1488(_block)\n",
       "    36330    0.092    0.000    0.227    0.000 numeric.py:2656(seterr)\n",
       "    24935    0.091    0.000    0.462    0.000 cast.py:953(maybe_cast_to_datetime)\n",
       "     4389    0.091    0.000    0.420    0.000 concat.py:261(get_empty_dtype_and_na)\n",
       "    22292    0.088    0.000    1.896    0.000 managers.py:97(__init__)\n",
       "    27614    0.086    0.000    0.207    0.000 base.py:504(_simple_new)\n",
       " 2664/216    0.086    0.000    3.203    0.015 <ipython-input-43-aac7f0a44aac>:26(evaluate)\n",
       "    17768    0.085    0.000    0.203    0.000 cast.py:832(maybe_castable)\n",
       "    16720    0.085    0.000    7.971    0.000 indexing.py:1855(_getitem_axis)\n",
       "   107066    0.085    0.000    0.826    0.000 blocks.py:225(make_block_same_class)\n",
       "    40388    0.084    0.000    0.619    0.000 base.py:4051(equals)\n",
       "    21311    0.083    0.000    0.277    0.000 managers.py:306(_verify_integrity)\n",
       "    36330    0.079    0.000    0.084    0.000 numeric.py:2758(geterr)\n",
       "    66904    0.077    0.000    0.234    0.000 indexing.py:229(_is_nested_tuple_indexer)\n",
       "    21149    0.076    0.000    1.908    0.000 frame.py:378(__init__)\n",
       "   186331    0.076    0.000    0.268    0.000 series.py:406(dtype)\n",
       "    20385    0.075    0.000    0.319    0.000 base.py:566(_shallow_copy)\n",
       "    25485    0.073    0.000    1.177    0.000 construction.py:684(_try_cast)\n",
       "   204569    0.073    0.000    0.348    0.000 inference.py:304(is_array_like)\n",
       "   159383    0.071    0.000    0.139    0.000 common.py:1809(_get_dtype)\n",
       "   139113    0.071    0.000    0.547    0.000 common.py:572(is_categorical_dtype)\n",
       "    86997    0.070    0.000    0.126    0.000 series.py:399(name)\n",
       "    17190    0.069    0.000    0.437    0.000 base.py:786(array)\n",
       "    17190    0.069    0.000    0.170    0.000 numpy_.py:35(__init__)\n",
       "    17813    0.067    0.000    0.067    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
       "   265587    0.067    0.000    0.219    0.000 managers.py:141(<genexpr>)\n",
       "   101910    0.067    0.000    0.067    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "    18027    0.067    0.000    4.640    0.000 managers.py:1198(reindex_indexer)\n",
       "   108617    0.066    0.000    0.453    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
       "   261142    0.066    0.000    0.066    0.000 {method 'startswith' of 'str' objects}\n",
       "     2640    0.065    0.000    0.100    0.000 arraysetops.py:484(in1d)\n",
       "   290623    0.064    0.000    0.064    0.000 blocks.py:308(dtype)\n",
       "    67287    0.063    0.000    0.063    0.000 dtypes.py:452(construct_from_string)\n",
       "    57172    0.061    0.000    0.224    0.000 dtypes.py:827(is_dtype)\n",
       "   138472    0.061    0.000    0.602    0.000 base.py:5318(ensure_index)\n",
       "   133808    0.061    0.000    0.188    0.000 indexing.py:2695(is_label_like)\n",
       "      775    0.060    0.000    0.062    0.000 {method 'factorize' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "     2239    0.059    0.000    0.091    0.000 concat.py:22(get_mgr_concatenation_plan)\n",
       "   170103    0.059    0.000    0.079    0.000 common.py:316(apply_if_callable)\n",
       "    40096    0.057    0.000    0.093    0.000 dtypes.py:929(construct_from_string)\n",
       "    66904    0.057    0.000    6.284    0.000 indexing.py:2141(_getitem_tuple)\n",
       "    17378    0.057    0.000    0.057    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "    68710    0.056    0.000    0.160    0.000 generic.py:3070(_set_as_cached)\n",
       "     1320    0.056    0.000   40.744    0.031 multiclass.py:42(unique_labels)\n",
       "    17811    0.056    0.000    0.483    0.000 base.py:784(take)\n",
       "   132095    0.055    0.000    0.055    0.000 blocks.py:89(_check_ndim)\n",
       "   200712    0.055    0.000    0.075    0.000 indexing.py:230(<genexpr>)\n",
       "    82091    0.055    0.000    0.154    0.000 {built-in method builtins.any}\n",
       "    49940    0.055    0.000    0.573    0.000 blocks.py:312(ftype)\n",
       "    37452    0.054    0.000    0.271    0.000 common.py:1578(is_bool_dtype)\n",
       "   287458    0.053    0.000    0.053    0.000 blocks.py:195(mgr_locs)\n",
       "    16720    0.052    0.000    7.281    0.000 indexing.py:1511(_getbool_axis)\n",
       "     3076    0.052    0.000    0.052    0.000 {built-in method numpy.copyto}\n",
       "    66900    0.051    0.000    2.807    0.000 indexing.py:143(_get_loc)\n",
       "    68710    0.051    0.000    0.051    0.000 blocks.py:332(iget)\n",
       "      390    0.051    0.000    0.052    0.000 {method 'factorize' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
       "    22514    0.051    0.000    0.657    0.000 managers.py:599(_consolidate_check)\n",
       "    84618    0.051    0.000    0.103    0.000 base.py:3608(values)\n",
       "    97398    0.051    0.000    0.430    0.000 common.py:536(is_interval_dtype)\n",
       "   109663    0.050    0.000    0.072    0.000 inference.py:438(is_hashable)\n",
       "    17117    0.049    0.000    2.838    0.000 managers.py:1233(<listcomp>)\n",
       "    38664    0.047    0.000    0.047    0.000 {method 'match' of 're.Pattern' objects}\n",
       "    20965    0.047    0.000    0.162    0.000 missing.py:360(array_equivalent)\n",
       "     2331    0.047    0.000    0.047    0.000 socket.py:337(send)\n",
       "    53967    0.045    0.000    0.045    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
       "   286621    0.044    0.000    0.044    0.000 blocks.py:165(internal_values)\n",
       "     9072    0.043    0.000    0.228    0.000 fromnumeric.py:69(_wrapreduction)\n",
       "      432    0.042    0.000    0.044    0.000 {method 'factorize' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "        1    0.042    0.042    0.042    0.042 {built-in method gc.collect}\n",
       "    17215    0.042    0.000    0.919    0.000 indexing.py:2475(check_bool_indexer)\n",
       "   109277    0.042    0.000    0.389    0.000 _methods.py:42(_any)\n",
       "    60671    0.041    0.000    0.104    0.000 {pandas._libs.lib.values_from_object}\n",
       "    66908    0.041    0.000    0.046    0.000 common.py:279(is_null_slice)\n",
       "    17190    0.038    0.000    0.212    0.000 numpy_.py:127(__init__)\n",
       "    72740    0.037    0.000    0.037    0.000 frame.py:474(axes)\n",
       "    18278    0.037    0.000    0.037    0.000 _internal.py:886(npy_ctypes_check)\n",
       "     1866    0.037    0.000    0.164    0.000 blocks.py:3131(_merge_blocks)\n",
       "    17017    0.037    0.000    0.037    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
       "   242774    0.036    0.000    0.036    0.000 {pandas._libs.lib.is_integer}\n",
       "    36842    0.036    0.000    0.088    0.000 common.py:1545(is_float_dtype)\n",
       "    17189    0.035    0.000    0.596    0.000 series.py:669(__array__)\n",
       "     1722    0.035    0.000    0.035    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
       "    32231    0.035    0.000    0.035    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "     1256    0.035    0.000    0.367    0.000 managers.py:1696(form_blocks)\n",
       "    36330    0.035    0.000    0.035    0.000 {built-in method numpy.seterrobj}\n",
       "    76611    0.035    0.000    0.046    0.000 common.py:144(cast_scalar_indexer)\n",
       "    86454    0.034    0.000    0.034    0.000 series.py:382(_set_subtyp)\n",
       "    58029    0.033    0.000    0.272    0.000 common.py:262(is_categorical)\n",
       "     4167    0.032    0.000    0.032    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
       "     1327    0.032    0.000    2.221    0.002 managers.py:2029(concatenate_block_managers)\n",
       "     1494    0.032    0.000    0.055    0.000 managers.py:1841(_stack_arrays)\n",
       "    28753    0.032    0.000    0.250    0.000 missing.py:105(_isna_new)\n",
       "    10162    0.032    0.000    0.291    0.000 concat.py:137(is_na)\n",
       "     5805    0.032    0.000    0.171    0.000 missing.py:183(_isna_ndarraylike)\n",
       "    57172    0.032    0.000    0.256    0.000 common.py:503(is_period_dtype)\n",
       "    54237    0.032    0.000    0.081    0.000 managers.py:291(__len__)\n",
       "     8338    0.031    0.000    0.062    0.000 concat.py:117(needs_filling)\n",
       "     4544    0.031    0.000    0.222    0.000 concat.py:20(get_dtype_kinds)\n",
       "     8338    0.031    0.000    0.595    0.000 concat.py:165(get_reindexed_values)\n",
       "    34437    0.031    0.000    0.093    0.000 common.py:868(is_integer_dtype)\n",
       "     7457    0.031    0.000    0.043    0.000 concat.py:425(combine_concat_plans)\n",
       "     4282    0.031    0.000    0.051    0.000 cast.py:1193(construct_1d_object_array_from_listlike)\n",
       "    38301    0.030    0.000    0.069    0.000 common.py:746(is_dtype_equal)\n",
       "    24007    0.030    0.000    0.055    0.000 {method 'join' of 'str' objects}\n",
       "    20512    0.030    0.000    0.490    0.000 generic.py:5122(_protect_consolidate)\n",
       "    18315    0.030    0.000    7.004    0.000 {method 'extend' of 'list' objects}\n",
       "    16727    0.030    0.000    2.407    0.000 ops.py:1615(na_op)\n",
       "    30364    0.030    0.000    0.040    0.000 generic.py:349(_get_axis_number)\n",
       "   149677    0.030    0.000    0.031    0.000 {built-in method builtins.hash}\n",
       "    63870    0.030    0.000   19.788    0.000 numeric.py:541(asanyarray)\n",
       "      385    0.029    0.000    0.029    0.000 {pandas._libs.hashtable.duplicated_int64}\n",
       "    16720    0.029    0.000    0.029    0.000 {built-in method builtins.repr}\n",
       "    68700    0.029    0.000    0.045    0.000 managers.py:308(<genexpr>)\n",
       "    40388    0.029    0.000    0.036    0.000 base.py:613(is_)\n",
       "    36988    0.029    0.000    0.052    0.000 sparse.py:196(construct_from_string)\n",
       "     3379    0.028    0.000    0.028    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
       "    22514    0.028    0.000    0.601    0.000 managers.py:600(<listcomp>)\n",
       "    28363    0.027    0.000    0.044    0.000 __init__.py:221(iteritems)\n",
       "    16725    0.027    0.000    2.233    0.000 ops.py:1591(_comp_method_OBJECT_ARRAY)\n",
       "    16954    0.026    0.000    0.061    0.000 ops.py:43(get_op_result_name)\n",
       "    18165    0.026    0.000    0.032    0.000 numeric.py:3054(__init__)\n",
       "    17017    0.025    0.000    0.089    0.000 base.py:1736(is_all_dates)\n",
       "    25137    0.025    0.000    0.300    0.000 common.py:1643(is_extension_type)\n",
       "    17279    0.025    0.000    0.068    0.000 managers.py:1556(get_values)\n",
       "    22292    0.024    0.000    0.046    0.000 managers.py:98(<listcomp>)\n",
       "    18165    0.024    0.000    0.115    0.000 numeric.py:3063(__exit__)\n",
       "     9391    0.024    0.000    0.110    0.000 common.py:222(asarray_tuplesafe)\n",
       "    30504    0.024    0.000    0.098    0.000 common.py:1784(_is_dtype)\n",
       "    18165    0.024    0.000    0.160    0.000 numeric.py:3058(__enter__)\n",
       "     1259    0.023    0.000    0.333    0.000 {pandas._libs.lib.clean_index_list}\n",
       "    57625    0.023    0.000    0.031    0.000 common.py:127(<lambda>)\n",
       "    83600    0.023    0.000    0.023    0.000 __init__.py:388(<genexpr>)\n",
       "     1760    0.023    0.000    0.046    0.000 classification.py:838(_prf_divide)\n",
       "    21695    0.023    0.000    0.046    0.000 base.py:547(_get_attributes_dict)\n",
       "    19904    0.023    0.000    0.026    0.000 generic.py:144(_init_mgr)\n",
       "    24703    0.022    0.000    0.070    0.000 {built-in method builtins.sum}\n",
       "    20512    0.021    0.000    0.454    0.000 generic.py:5135(f)\n",
       "     1111    0.021    0.000    0.468    0.000 concat.py:237(__init__)\n",
       "    72660    0.021    0.000    0.021    0.000 {built-in method numpy.geterrobj}\n",
       "5037/1260    0.021    0.000    0.281    0.000 <frozen importlib._bootstrap>:978(_find_and_load)\n",
       "   150480    0.021    0.000    0.021    0.000 {method '__contains__' of 'frozenset' objects}\n",
       "    20898    0.021    0.000    0.021    0.000 {method 'replace' of 'str' objects}\n",
       "     7700    0.021    0.000    0.233    0.000 fromnumeric.py:2083(any)\n",
       "    24625    0.021    0.000    0.054    0.000 cast.py:1218(construct_1d_ndarray_preserving_na)\n",
       "   125207    0.021    0.000    0.021    0.000 {pandas._libs.lib.is_float}\n",
       "     7752    0.021    0.000    0.147    0.000 cast.py:1151(construct_1d_arraylike_from_scalar)\n",
       "   170111    0.021    0.000    0.021    0.000 {built-in method builtins.callable}\n",
       "     1111    0.021    0.000    2.171    0.002 concat.py:383(get_result)\n",
       "     1260    0.020    0.000    0.181    0.000 <frozen importlib._bootstrap>:882(_find_spec)\n",
       "      216    0.020    0.000    0.052    0.000 {pandas._libs.join.inner_join}\n",
       "     5280    0.020    0.000   39.732    0.008 validation.py:771(column_or_1d)\n",
       "    14786    0.020    0.000    0.035    0.000 generic.py:3175(_set_is_copy)\n",
       "    17190    0.020    0.000    0.033    0.000 common.py:1118(is_datetime64_ns_dtype)\n",
       "    39755    0.019    0.000    0.297    0.000 managers.py:927(_consolidate_inplace)\n",
       "    14300    0.019    0.000    0.024    0.000 arraysetops.py:138(_unpack_tuple)\n",
       "    48366    0.019    0.000    0.019    0.000 {pandas._libs.algos.ensure_int64}\n",
       "   150480    0.019    0.000    0.019    0.000 {method 'isidentifier' of 'str' objects}\n",
       "    16758    0.019    0.000    0.145    0.000 base.py:3975(_can_hold_identifiers_and_holds_name)\n",
       "    19381    0.019    0.000    0.118    0.000 generic.py:3056(_get_item_cache)\n",
       "    15139    0.019    0.000    0.304    0.000 concat.py:379(<genexpr>)\n",
       "    80727    0.019    0.000    0.019    0.000 managers.py:206(items)\n",
       "        1    0.019    0.019  276.868  276.868 <ipython-input-46-f115cb93ab3a>:26(run_ensemble)\n",
       "     6820    0.018    0.000    0.061    0.000 validation.py:127(_num_samples)\n",
       "    60228    0.018    0.000    0.027    0.000 managers.py:591(is_consolidated)\n",
       "    20873    0.018    0.000    0.022    0.000 generic.py:5036(__finalize__)\n",
       "    10174    0.018    0.000    0.051    0.000 blocks.py:128(_consolidate_key)\n",
       "    21695    0.018    0.000    0.023    0.000 base.py:551(<dictcomp>)\n",
       "    19584    0.018    0.000    0.046    0.000 generic.py:381(_get_block_manager_axis)\n",
       "    20512    0.018    0.000    0.508    0.000 generic.py:5132(_consolidate_inplace)\n",
       "     8122    0.017    0.000    0.025    0.000 cast.py:341(infer_dtype_from_scalar)\n",
       "     3949    0.017    0.000    0.278    0.000 concat.py:101(_concat_compat)\n",
       "    41930    0.017    0.000    0.060    0.000 base.py:3663(get_values)\n",
       "      864    0.017    0.000    0.201    0.000 merge.py:1617(_factorize_keys)\n",
       "    25485    0.017    0.000    0.081    0.000 arrays.py:7(extract_array)\n",
       "      912    0.016    0.000    0.253    0.000 managers.py:1241(_slice_take_blocks_ax0)\n",
       "      386    0.016    0.000    0.041    0.000 sorting.py:20(get_group_index)\n",
       "    69095    0.016    0.000    0.016    0.000 {method 'items' of 'dict' objects}\n",
       "     5732    0.016    0.000   19.708    0.003 fromnumeric.py:1583(ravel)\n",
       "     2041    0.016    0.000    0.016    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
       "    10541    0.016    0.000    0.016    0.000 {method 'settimeout' of '_socket.socket' objects}\n",
       "     4389    0.016    0.000    1.318    0.000 concat.py:230(concatenate_join_units)\n",
       "26332/26331    0.016    0.000    0.357    0.000 {built-in method builtins.all}\n",
       "    22238    0.016    0.000    0.257    0.000 inference.py:121(is_iterator)\n",
       "    16804    0.015    0.000    0.634    0.000 generic.py:178(_validate_dtype)\n",
       "    17189    0.015    0.000    0.035    0.000 numpy_.py:170(__array__)\n",
       "     1760    0.015    0.000   12.841    0.007 label.py:113(_encode_check_unknown)\n",
       "    28360    0.015    0.000    0.015    0.000 base.py:633(_reset_identity)\n",
       "    28753    0.015    0.000    0.265    0.000 missing.py:25(isna)\n",
       "   146586    0.015    0.000    0.015    0.000 {method 'add' of 'set' objects}\n",
       "     1267    0.015    0.000    0.131    0.000 <frozen importlib._bootstrap_external>:1356(find_spec)\n",
       "     7912    0.015    0.000    0.104    0.000 cast.py:846(maybe_infer_to_datetimelike)\n",
       "    17415    0.015    0.000    0.081    0.000 base.py:802(_assert_take_fillable)\n",
       "     5025    0.015    0.000    0.047    0.000 connections.py:1195(_read_row_from_packet)\n",
       "    36989    0.014    0.000    0.014    0.000 {method 'search' of 're.Pattern' objects}\n",
       "   105098    0.014    0.000    0.014    0.000 {method 'append' of 'list' objects}\n",
       "     5037    0.014    0.000    0.025    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "     1245    0.014    0.000    1.756    0.001 construction.py:170(init_dict)\n",
       "     2256    0.013    0.000    0.013    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
       "    47399    0.013    0.000    0.013    0.000 blocks.py:304(shape)\n",
       "     5301    0.013    0.000    0.338    0.000 concat.py:367(is_uniform_join_units)\n",
       "    20512    0.013    0.000    0.406    0.000 managers.py:911(consolidate)\n",
       "    16760    0.013    0.000    0.056    0.000 base.py:1681(is_object)\n",
       "    73810    0.013    0.000    0.013    0.000 base.py:3632(_values)\n",
       "     2640    0.013    0.000    0.120    0.000 arraysetops.py:745(setdiff1d)\n",
       "    17279    0.013    0.000    0.081    0.000 series.py:490(get_values)\n",
       "    57625    0.013    0.000    0.013    0.000 common.py:122(classes_and_not_datetimelike)\n",
       "     5224    0.012    0.000    0.482    0.000 connections.py:648(_read_packet)\n",
       "      216    0.012    0.000    0.024    0.000 merge.py:1701(_get_join_keys)\n",
       "     4794    0.012    0.000    0.033    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
       "     2640    0.012    0.000   19.081    0.007 multiclass.py:24(_unique_multiclass)\n",
       "     2640    0.012    0.000   16.737    0.006 label.py:77(_encode)\n",
       "     2420    0.012    0.000    0.138    0.000 validation.py:220(check_consistent_length)\n",
       "     5280    0.012    0.000    0.021    0.000 multiclass.py:111(is_multilabel)\n",
       "    17190    0.011    0.000    0.035    0.000 common.py:1167(is_timedelta64_ns_dtype)\n",
       "    24189    0.011    0.000    0.015    0.000 {built-in method builtins.max}\n",
       "     1132    0.011    0.000    0.014    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
       "     2683    0.011    0.000    0.024    0.000 numeric.py:676(require)\n",
       "5037/1260    0.011    0.000    0.254    0.000 <frozen importlib._bootstrap>:948(_find_and_load_unlocked)\n",
       "    18057    0.011    0.000    0.019    0.000 generic.py:426(_info_axis)\n",
       "    12085    0.011    0.000    0.016    0.000 range.py:510(__len__)\n",
       "    10448    0.011    0.000    0.462    0.000 connections.py:687(_read_bytes)\n",
       "    11988    0.011    0.000    0.015    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "    38764    0.011    0.000    0.011    0.000 blocks.py:191(fill_value)\n",
       "    17279    0.011    0.000    0.027    0.000 blocks.py:184(to_dense)\n",
       "     4401    0.010    0.000    0.010    0.000 numerictypes.py:654(<listcomp>)\n",
       "      385    0.010    0.000    0.700    0.002 frame.py:4639(duplicated)\n",
       "     1256    0.010    0.000    0.596    0.000 construction.py:254(_homogenize)\n",
       "    62345    0.010    0.000    0.013    0.000 strings.py:1519(<lambda>)\n",
       "     1760    0.010    0.000   16.769    0.010 label.py:239(transform)\n",
       "     1932    0.010    0.000    0.010    0.000 {pandas._libs.algos.take_2d_axis1_float64_float64}\n",
       "    66971    0.010    0.000    0.010    0.000 base.py:704(ndim)\n",
       "    29339    0.010    0.000    0.010    0.000 {built-in method builtins.iter}\n",
       "      220    0.010    0.000    0.208    0.001 coo.py:261(_check)\n",
       "    22948    0.010    0.000    0.010    0.000 {built-in method pandas._libs.missing.checknull}\n",
       "     4401    0.009    0.000    0.030    0.000 numerictypes.py:602(find_common_type)\n",
       "    37013    0.009    0.000    0.009    0.000 {method 'lower' of 'str' objects}\n",
       "     9072    0.009    0.000    0.009    0.000 fromnumeric.py:70(<dictcomp>)\n",
       "     1284    0.009    0.000    0.019    0.000 base.py:1658(is_unique)\n",
       "      587    0.009    0.000    0.116    0.000 {built-in method builtins.print}\n",
       "    21785    0.009    0.000    0.009    0.000 {method 'update' of 'dict' objects}\n",
       "     8338    0.009    0.000    0.073    0.000 concat.py:126(dtype)\n",
       "     9766    0.009    0.000    0.028    0.000 common.py:923(is_signed_integer_dtype)\n",
       "     1132    0.009    0.000    0.297    0.000 base.py:2715(get_indexer)\n",
       "     1177    0.009    0.000    0.385    0.000 algorithms.py:559(factorize)\n",
       "     1980    0.009    0.000    0.043    0.000 function_base.py:294(average)\n",
       "     1185    0.008    0.000    0.009    0.000 blocks.py:3145(<listcomp>)\n",
       "    20404    0.008    0.000    0.010    0.000 protocol.py:63(read)\n",
       "     2640    0.008    0.000   16.718    0.006 label.py:40(_encode_numpy)\n",
       "     2242    0.008    0.000    0.037    0.000 {built-in method builtins.sorted}\n",
       "    11332    0.008    0.000    0.112    0.000 common.py:1078(is_datetime64_any_dtype)\n",
       "      705    0.008    0.000    0.239    0.000 managers.py:1887(_consolidate)\n",
       "      216    0.008    0.000    0.286    0.001 merge.py:1104(_get_join_indexers)\n",
       "     5037    0.008    0.000    0.009    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "      730    0.008    0.000    0.452    0.001 indexing.py:1271(_convert_to_indexer)\n",
       "    20440    0.008    0.000    0.028    0.000 protocol.py:168(read_length_coded_string)\n",
       "     2105    0.008    0.000    0.078    0.000 iostream.py:382(write)\n",
       "     2331    0.008    0.000    0.065    0.000 iostream.py:195(schedule)\n",
       "     8802    0.008    0.000    0.010    0.000 numerictypes.py:578(_can_coerce_all)\n",
       "    26791    0.008    0.000    0.008    0.000 {method 'pop' of 'dict' objects}\n",
       "      220    0.008    0.000    0.010    0.000 <ipython-input-33-b81133635a32>:20(get_confusion_metrics)\n",
       "    37537    0.008    0.000    0.008    0.000 {pandas._libs.algos.ensure_platform_int}\n",
       "     4389    0.008    0.000    0.603    0.000 concat.py:240(<listcomp>)\n",
       "     3800    0.007    0.000    0.015    0.000 blocks.py:3100(_extend_blocks)\n",
       "     1322    0.007    0.000    0.018    0.000 _methods.py:58(_mean)\n",
       "     1177    0.007    0.000    0.012    0.000 sorting.py:55(maybe_lift)\n",
       "    22271    0.007    0.000    0.007    0.000 base.py:676(dtype)\n",
       "     1021    0.007    0.000    0.179    0.000 managers.py:318(apply)\n",
       "    11592    0.007    0.000    0.046    0.000 common.py:634(condition)\n",
       "     5037    0.007    0.000    0.008    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "    11592    0.007    0.000    0.078    0.000 common.py:605(is_string_dtype)\n",
       "    16720    0.007    0.000    0.007    0.000 {built-in method sys._getframe}\n",
       "    16720    0.007    0.000    0.007    0.000 {built-in method sys.intern}\n",
       "    16720    0.007    0.000    0.010    0.000 indexing.py:1831(_get_partial_string_timestamp_match_key)\n",
       "     2640    0.007    0.000    3.863    0.001 fromnumeric.py:1179(searchsorted)\n",
       "     3825    0.007    0.000    3.862    0.001 fromnumeric.py:54(_wrapfunc)\n",
       "     1760    0.007    0.000    0.013    0.000 validation.py:903(check_is_fitted)\n",
       "     5940    0.007    0.000    0.007    0.000 {built-in method _abc._abc_subclasscheck}\n",
       "      475    0.007    0.000    1.032    0.002 frame.py:4605(drop_duplicates)\n",
       "        9    0.006    0.001    0.017    0.002 {pandas._libs.lib.map_infer_mask}\n",
       "        3    0.006    0.002    0.006    0.002 {method 'factorize' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
       "    15463    0.006    0.000    0.006    0.000 concat.py:376(<genexpr>)\n",
       "    18291    0.006    0.000    0.006    0.000 {method 'rpartition' of 'str' objects}\n",
       "     1298    0.006    0.000    0.059    0.000 generic.py:1657(_get_label_or_level_values)\n",
       "     3076    0.006    0.000    0.084    0.000 numeric.py:175(ones)\n",
       "     4637    0.006    0.000    0.010    0.000 shape_base.py:83(atleast_2d)\n",
       "    28938    0.006    0.000    0.006    0.000 {pandas._libs.algos.ensure_object}\n",
       "     2370    0.006    0.000    0.049    0.000 algorithms.py:38(_ensure_data)\n",
       "     1260    0.006    0.000    0.140    0.000 <frozen importlib._bootstrap_external>:1240(_get_spec)\n",
       "       20    0.006    0.000    0.101    0.005 connections.py:1182(_read_rowdata_packet)\n",
       "      965    0.006    0.000    0.092    0.000 managers.py:1810(_multi_blockify)\n",
       "    20574    0.006    0.000    0.010    0.000 protocol.py:150(read_length_encoded_integer)\n",
       "    18783    0.006    0.000    0.006    0.000 frame.py:361(_constructor)\n",
       "     6328    0.006    0.000    0.017    0.000 common.py:1472(is_numeric_dtype)\n",
       "      220    0.006    0.000    0.460    0.002 coo.py:126(__init__)\n",
       "     5037    0.006    0.000    0.009    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "      694    0.006    0.000    0.381    0.001 indexing.py:1108(_get_listlike_indexer)\n",
       "     3780    0.006    0.000    0.010    0.000 <frozen importlib._bootstrap>:873(_find_spec_legacy)\n",
       "     2420    0.006    0.000    0.046    0.000 validation.py:231(<listcomp>)\n",
       "     3960    0.006    0.000   21.585    0.005 multiclass.py:77(<genexpr>)\n",
       "     4937    0.006    0.000    0.014    0.000 common.py:1198(is_datetime_or_timedelta_dtype)\n",
       "     1503    0.006    0.000    0.022    0.000 numeric.py:34(__new__)\n",
       "     1111    0.005    0.000    0.129    0.000 concat.py:440(_get_new_axes)\n",
       "     1799    0.005    0.000    0.046    0.000 managers.py:934(get)\n",
       "     1946    0.005    0.000    0.016    0.000 generic.py:1546(_is_label_reference)\n",
       "     1111    0.005    0.000    2.644    0.002 concat.py:24(concat)\n",
       "     1256    0.005    0.000    0.464    0.000 managers.py:1663(create_block_manager_from_arrays)\n",
       "     1177    0.005    0.000    0.187    0.000 algorithms.py:434(_factorize_array)\n",
       "      432    0.005    0.000    0.007    0.000 base.py:1587(is_monotonic_increasing)\n",
       "     8348    0.005    0.000    0.022    0.000 blocks.py:175(get_values)\n",
       "      694    0.005    0.000    0.016    0.000 indexing.py:1209(_validate_read_indexer)\n",
       "     6335    0.005    0.000    0.013    0.000 <frozen importlib._bootstrap_external>:56(_path_join)\n",
       "     7094    0.005    0.000    0.014    0.000 common.py:980(is_unsigned_integer_dtype)\n",
       "      216    0.005    0.000    0.009    0.000 function_base.py:4220(delete)\n",
       "     7861    0.005    0.000    0.015    0.000 managers.py:1844(_asarray_compat)\n",
       "     4568    0.005    0.000    0.038    0.000 base.py:2650(get_loc)\n",
       "     4400    0.005    0.000    0.005    0.000 {method 'item' of 'numpy.generic' objects}\n",
       "      220    0.005    0.000    0.934    0.004 <ipython-input-44-c9fd36f58387>:139(get_sys_ann)\n",
       "     4863    0.005    0.000    0.055    0.000 common.py:1431(needs_i8_conversion)\n",
       "     2592    0.005    0.000    0.012    0.000 generic.py:1513(_is_level_reference)\n",
       "     5037    0.005    0.000    0.039    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "     1111    0.005    0.000    0.025    0.000 concat.py:84(_get_frame_result_type)\n",
       "    10991    0.005    0.000    0.005    0.000 concat.py:104(__init__)\n",
       "     1190    0.005    0.000    0.005    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "    11006    0.005    0.000    0.007    0.000 concat.py:450(_next_or_none)\n",
       "    10174    0.005    0.000    0.056    0.000 managers.py:1893(<lambda>)\n",
       "      226    0.005    0.000    0.011    0.000 index_tricks.py:316(__getitem__)\n",
       "      221    0.005    0.000    0.404    0.002 generic.py:960(rename)\n",
       "    20575    0.005    0.000    0.005    0.000 protocol.py:117(read_uint8)\n",
       "     1256    0.005    0.000    1.395    0.001 construction.py:43(arrays_to_mgr)\n",
       "     8778    0.005    0.000    0.007    0.000 concat.py:391(<genexpr>)\n",
       "     6265    0.004    0.000    0.030    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "     5037    0.004    0.000    0.006    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "    10448    0.004    0.000    0.435    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
       "     6335    0.004    0.000    0.006    0.000 <frozen importlib._bootstrap_external>:58(<listcomp>)\n",
       "      216    0.004    0.000    0.004    0.000 base.py:221(_inner_indexer)\n",
       "     1177    0.004    0.000    0.133    0.000 algorithms.py:132(_reconstruct_data)\n",
       "     5271    0.004    0.000    0.004    0.000 {pandas._libs.lib.array_equivalent_object}\n",
       "      220    0.004    0.000    0.009    0.000 <ipython-input-44-c9fd36f58387>:14(buildParseTree)\n",
       "      216    0.004    0.000    0.554    0.003 merge.py:541(get_result)\n",
       "    19978    0.004    0.000    0.004    0.000 base.py:1396(nlevels)\n",
       "3778/1260    0.004    0.000    0.249    0.000 {built-in method builtins.__import__}\n",
       "     1799    0.004    0.000    0.041    0.000 frame.py:3342(_box_item_values)\n",
       "      216    0.004    0.000    0.298    0.001 merge.py:777(_get_merge_keys)\n",
       "     1760    0.004    0.000    0.006    0.000 shape_base.py:25(atleast_1d)\n",
       "     3960    0.004    0.000   19.084    0.005 multiclass.py:98(<genexpr>)\n",
       "      226    0.004    0.000    0.103    0.000 managers.py:1134(insert)\n",
       "      220    0.004    0.000    4.002    0.018 <ipython-input-43-aac7f0a44aac>:1(process_sentence)\n",
       "     1322    0.004    0.000    0.004    0.000 _methods.py:48(_count_reduce_items)\n",
       "    20282    0.004    0.000    0.004    0.000 {method 'decode' of 'bytes' objects}\n",
       "     1987    0.004    0.000    0.006    0.000 base.py:643(_engine)\n",
       "      220    0.004    0.000    0.004    0.000 {built-in method builtins.__build_class__}\n",
       "     1175    0.004    0.000    0.398    0.000 frame.py:4666(f)\n",
       "     1298    0.004    0.000    0.008    0.000 generic.py:1607(_check_label_or_level_ambiguity)\n",
       "     6863    0.004    0.000    0.004    0.000 {built-in method builtins.min}\n",
       "    17243    0.004    0.000    0.004    0.000 series.py:338(_constructor)\n",
       "    10075    0.004    0.000    0.004    0.000 {built-in method _thread.allocate_lock}\n",
       "        4    0.004    0.001    0.691    0.173 <ipython-input-41-ca3a4ead7b00>:27(get_sys_data)\n",
       "      880    0.004    0.000    0.004    0.000 getlimits.py:497(__init__)\n",
       "     4389    0.004    0.000    0.012    0.000 concat.py:388(is_uniform_reindex)\n",
       "     1111    0.004    0.000    0.061    0.000 concat.py:475(_get_concat_axis)\n",
       "     2331    0.004    0.000    0.008    0.000 threading.py:1080(is_alive)\n",
       "      910    0.004    0.000    0.105    0.000 base.py:3089(reindex)\n",
       "     2222    0.003    0.000    0.296    0.000 generic.py:5140(_consolidate)\n",
       "    54551    0.003    0.000    0.003    0.000 {method 'strip' of 'str' objects}\n",
       "     1622    0.003    0.000    0.087    0.000 frame.py:742(iteritems)\n",
       "      880    0.003    0.000    0.018    0.000 shape_base.py:286(hstack)\n",
       "     3949    0.003    0.000    0.006    0.000 concat.py:126(<listcomp>)\n",
       "     2683    0.003    0.000    0.004    0.000 numeric.py:748(<setcomp>)\n",
       "     3448    0.003    0.000    0.019    0.000 base.py:963(_ndarray_values)\n",
       "        3    0.003    0.001    0.003    0.001 {method 'get_labels_groupby' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "    17190    0.003    0.000    0.003    0.000 common.py:1195(<lambda>)\n",
       "     3949    0.003    0.000    0.018    0.000 concat.py:151(<listcomp>)\n",
       "      880    0.003    0.000    0.034    0.000 label.py:207(fit)\n",
       "      696    0.003    0.000    0.041    0.000 api.py:128(_union_indexes)\n",
       "      440    0.003    0.000    0.008    0.000 sputils.py:120(get_index_dtype)\n",
       "     1361    0.003    0.000    0.048    0.000 numeric.py:67(_shallow_copy)\n",
       "      744    0.003    0.000    0.010    0.000 range.py:69(__new__)\n",
       "     2105    0.003    0.000    0.004    0.000 iostream.py:307(_is_master_process)\n",
       "      977    0.003    0.000    0.211    0.000 managers.py:710(copy)\n",
       "    11298    0.003    0.000    0.003    0.000 concat.py:381(<genexpr>)\n",
       "      216    0.003    0.000    0.289    0.001 merge.py:730(_get_join_indexers)\n",
       "     7898    0.003    0.000    0.003    0.000 concat.py:120(is_nonempty)\n",
       "     2065    0.003    0.000    0.005    0.000 shape_base.py:220(_warn_for_nonsequence)\n",
       "        5    0.003    0.001    0.003    0.001 {pandas._libs.hashtable.ismember_object}\n",
       "     1111    0.003    0.000    0.011    0.000 concat.py:309(<listcomp>)\n",
       "     2966    0.003    0.000    0.024    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "     8006    0.003    0.000    0.005    0.000 concat.py:136(<genexpr>)\n",
       "      216    0.003    0.000    0.314    0.001 merge.py:474(__init__)\n",
       "      868    0.003    0.000    0.074    0.000 base.py:584(_shallow_copy_with_infer)\n",
       "    17634    0.003    0.000    0.003    0.000 {built-in method _imp.acquire_lock}\n",
       "     9395    0.003    0.000    0.005    0.000 format.py:301(len)\n",
       "     1111    0.003    0.000    0.048    0.000 api.py:87(_get_combined_index)\n",
       "    17634    0.003    0.000    0.003    0.000 {built-in method _imp.release_lock}\n",
       "     1111    0.003    0.000    0.004    0.000 api.py:73(_get_distinct_objs)\n",
       "     5280    0.003    0.000    0.003    0.000 base.py:1237(_get_names)\n",
       "     1111    0.003    0.000    0.061    0.000 concat.py:464(_get_comb_axis)\n",
       "    12334    0.003    0.000    0.007    0.000 {built-in method builtins.next}\n",
       "      912    0.003    0.000    0.056    0.000 blocks.py:323(concat_same_type)\n",
       "     1954    0.003    0.000    0.032    0.000 base.py:700(view)\n",
       "     3159    0.003    0.000    0.004    0.000 managers.py:174(_is_single_block)\n",
       "     5940    0.003    0.000    0.009    0.000 abc.py:141(__subclasscheck__)\n",
       "     5037    0.003    0.000    0.011    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "     7793    0.003    0.000    0.005    0.000 strings.py:87(g)\n",
       "      216    0.003    0.000    0.011    0.000 merge.py:647(_maybe_add_join_keys)\n",
       "      743    0.003    0.000    0.014    0.000 base.py:5408(default_index)\n",
       "     7560    0.003    0.000    0.004    0.000 <frozen importlib._bootstrap>:859(__exit__)\n",
       "      730    0.003    0.000    0.009    0.000 indexing.py:256(_convert_scalar_indexer)\n",
       "     2223    0.002    0.000    0.007    0.000 frame.py:491(shape)\n",
       "     6335    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "     3165    0.002    0.000    0.002    0.000 {pandas._libs.internals.get_blkno_placements}\n",
       "     6265    0.002    0.000    0.025    0.000 _methods.py:45(_all)\n",
       "       88    0.002    0.000    0.002    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
       "      258    0.002    0.000    0.114    0.000 managers.py:1019(set)\n",
       "     3858    0.002    0.000    0.011    0.000 generic.py:1895(<genexpr>)\n",
       "     1897    0.002    0.000    0.083    0.000 blocks.py:749(copy)\n",
       "      695    0.002    0.000    0.004    0.000 api.py:262(<setcomp>)\n",
       "      746    0.002    0.000    0.004    0.000 range.py:136(_simple_new)\n",
       "     1132    0.002    0.000    0.007    0.000 base.py:4459(_maybe_promote)\n",
       "      442    0.002    0.000    0.342    0.001 managers.py:159(rename_axis)\n",
       "      912    0.002    0.000    0.004    0.000 managers.py:2015(_preprocess_slice_or_indexer)\n",
       "     7560    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:855(__enter__)\n",
       "      231    0.002    0.000    0.005    0.000 base.py:3926(contains)\n",
       "      216    0.002    0.000    0.054    0.000 base.py:4939(drop)\n",
       "      231    0.002    0.000    0.026    0.000 frame.py:3565(_sanitize_column)\n",
       "      595    0.002    0.000    0.074    0.000 base.py:3988(append)\n",
       "     1327    0.002    0.000    0.093    0.000 managers.py:2041(<listcomp>)\n",
       "     1111    0.002    0.000    0.010    0.000 generic.py:337(_from_axes)\n",
       "     1321    0.002    0.000    0.009    0.000 indexing.py:2450(convert_to_index_sliceable)\n",
       "      216    0.002    0.000    0.144    0.001 generic.py:3787(_drop_axis)\n",
       "     1183    0.002    0.000    0.061    0.000 algorithms.py:217(_get_data_algo)\n",
       "      535    0.002    0.000    0.134    0.000 generic.py:5699(copy)\n",
       "     3960    0.002    0.000    0.004    0.000 multiclass.py:101(<genexpr>)\n",
       "      220    0.002    0.000    0.013    0.000 <ipython-input-37-9baebd4da2b7>:1(cm_dict)\n",
       "     1208    0.002    0.000    0.003    0.000 common.py:212(dict_keys_to_ordered_list)\n",
       "     1111    0.002    0.000    0.056    0.000 api.py:44(_get_objs_combined_axis)\n",
       "     1132    0.002    0.000    0.018    0.000 base.py:1669(is_boolean)\n",
       "     1185    0.002    0.000    0.047    0.000 shape_base.py:229(vstack)\n",
       "      396    0.002    0.000    0.264    0.001 frame.py:2952(_getitem_bool_array)\n",
       "      217    0.002    0.000    0.080    0.000 generic.py:4113(reindex)\n",
       "    12748    0.002    0.000    0.002    0.000 {pandas._libs.lib.is_bool}\n",
       "     3892    0.002    0.000    0.005    0.000 generic.py:1576(<genexpr>)\n",
       "     1185    0.002    0.000    0.011    0.000 shape_base.py:283(<listcomp>)\n",
       "     4389    0.002    0.000    0.003    0.000 blocks.py:255(__len__)\n",
       "     5037    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "      378    0.002    0.000    0.166    0.000 frame.py:6558(append)\n",
       "        1    0.002    0.002    0.002    0.002 {pandas._libs.writers.write_csv_rows}\n",
       "    12733    0.002    0.000    0.002    0.000 {method 'rstrip' of 'str' objects}\n",
       "     1560    0.002    0.000    0.089    0.000 frame.py:4685(<genexpr>)\n",
       "      216    0.002    0.000    0.043    0.000 base.py:2357(intersection)\n",
       "      442    0.002    0.000    0.255    0.001 managers.py:1988(_transform_index)\n",
       "      421    0.002    0.000    0.002    0.000 {built-in method _operator.inv}\n",
       "       40    0.002    0.000    0.007    0.000 {pandas._libs.lib.map_infer}\n",
       "      660    0.002    0.000    0.008    0.000 fromnumeric.py:1966(sum)\n",
       "     1177    0.002    0.000    0.388    0.000 _decorators.py:146(wrapper)\n",
       "      775    0.002    0.000    0.125    0.000 construction.py:284(extract_index)\n",
       "        1    0.002    0.002    0.002    0.002 {built-in method io.open}\n",
       "3777/1259    0.002    0.000    0.249    0.000 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "     1260    0.002    0.000    0.142    0.000 <frozen importlib._bootstrap_external>:1272(find_spec)\n",
       "      267    0.002    0.000    0.004    0.000 numeric.py:2551(array_equal)\n",
       "      216    0.002    0.000    0.012    0.000 merge.py:889(_maybe_coerce_merge_keys)\n",
       "     2331    0.002    0.000    0.002    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "     2331    0.002    0.000    0.004    0.000 threading.py:1038(_wait_for_tstate_lock)\n",
       "      220    0.002    0.000    0.003    0.000 sputils.py:266(check_shape)\n",
       "      226    0.002    0.000    0.014    0.000 managers.py:2008(_fast_count_smallints)\n",
       "      880    0.002    0.000    0.008    0.000 shape_base.py:335(<listcomp>)\n",
       "      793    0.002    0.000    0.004    0.000 base.py:2849(_convert_scalar_indexer)\n",
       "     8006    0.002    0.000    0.003    0.000 concat.py:137(<genexpr>)\n",
       "     2520    0.002    0.000    0.002    0.000 six.py:184(find_module)\n",
       "     1298    0.002    0.000    0.027    0.000 generic.py:3461(xs)\n",
       "     1328    0.002    0.000    0.014    0.000 generic.py:1848(empty)\n",
       "       90    0.002    0.000    0.002    0.000 {method 'sendall' of '_socket.socket' objects}\n",
       "        1    0.002    0.002    0.176    0.176 parsers.py:403(_read)\n",
       "      216    0.002    0.000    0.872    0.004 frame.py:6858(merge)\n",
       "      216    0.002    0.000    0.051    0.000 generic.py:4469(_reindex_with_indexers)\n",
       "    11286    0.002    0.000    0.002    0.000 {method 'copy' of 'dict' objects}\n",
       "      220    0.002    0.000    0.117    0.001 coo.py:315(toarray)\n",
       "      115    0.002    0.000    0.002    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
       "     1750    0.002    0.000    0.002    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "     2448    0.002    0.000    0.002    0.000 _config.py:49(getter)\n",
       "     1654    0.002    0.000    0.002    0.000 generic.py:3149(_clear_item_cache)\n",
       "      216    0.002    0.000    0.025    0.000 concat.py:486(_concat_index_asobject)\n",
       "      595    0.002    0.000    0.071    0.000 base.py:4017(_concat)\n",
       "     5239    0.002    0.000    0.002    0.000 {built-in method _struct.unpack}\n",
       "     1260    0.002    0.000    0.002    0.000 __init__.py:23(find_module)\n",
       "     2331    0.002    0.000    0.002    0.000 iostream.py:93(_event_pipe)\n",
       "     2562    0.002    0.000    0.005    0.000 frame.py:937(__len__)\n",
       "      660    0.002    0.000    0.005    0.000 classification.py:1589(<listcomp>)\n",
       "      695    0.002    0.000    0.006    0.000 api.py:243(_get_consensus_names)\n",
       "      216    0.002    0.000    0.229    0.001 generic.py:1729(_drop_labels_or_levels)\n",
       "        1    0.002    0.002    0.002    0.002 parsers.py:1830(__init__)\n",
       "      712    0.002    0.000    0.012    0.000 fromnumeric.py:2664(prod)\n",
       "     8813    0.002    0.000    0.002    0.000 {method 'values' of 'dict' objects}\n",
       "    10137    0.002    0.000    0.002    0.000 {built-in method _thread.get_ident}\n",
       "       11    0.002    0.000    0.002    0.000 __init__.py:131(lmap)\n",
       "     9395    0.002    0.000    0.002    0.000 __init__.py:291(strlen)\n",
       "      438    0.002    0.000    0.002    0.000 generic.py:297(_construct_axes_from_arguments)\n",
       "      216    0.002    0.000    0.869    0.004 merge.py:37(merge)\n",
       "     1954    0.002    0.000    0.033    0.000 managers.py:729(<lambda>)\n",
       "      696    0.002    0.000    0.002    0.000 api.py:205(_sanitize_and_check)\n",
       "     1111    0.002    0.000    0.006    0.000 api.py:67(<listcomp>)\n",
       "        1    0.002    0.002    0.563    0.563 <ipython-input-38-ae69ae0eb560>:1(get_metric_data)\n",
       "     2855    0.002    0.000    0.002    0.000 _validators.py:221(validate_bool_kwarg)\n",
       "     2090    0.002    0.000    0.014    0.000 base.py:646(<lambda>)\n",
       "     1185    0.002    0.000    0.008    0.000 fromnumeric.py:942(argsort)\n",
       "      220    0.002    0.000    0.002    0.000 classification.py:1546(<listcomp>)\n",
       "     1760    0.001    0.000    0.002    0.000 validation.py:950(<listcomp>)\n",
       "     1728    0.001    0.000    0.001    0.000 <ipython-input-46-f115cb93ab3a>:50(<genexpr>)\n",
       "     5225    0.001    0.000    0.003    0.000 protocol.py:214(check_error)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method posix.listdir}\n",
       "     1260    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "     2966    0.001    0.000    0.021    0.000 _methods.py:34(_sum)\n",
       "      216    0.001    0.000    0.321    0.001 merge.py:737(_get_join_info)\n",
       "     1267    0.001    0.000    0.097    0.000 <frozen importlib._bootstrap_external>:74(_path_stat)\n",
       "     5045    0.001    0.000    0.002    0.000 connections.py:1137(_check_packet_is_eof)\n",
       "      162    0.001    0.000    0.001    0.000 {built-in method _warnings.warn}\n",
       "     1236    0.001    0.000    0.002    0.000 managers.py:1546(external_values)\n",
       "     1941    0.001    0.000    0.029    0.000 base.py:1729(inferred_type)\n",
       "      385    0.001    0.000    0.043    0.000 generic.py:1439(__neg__)\n",
       "      694    0.001    0.000    0.254    0.000 base.py:4447(get_indexer_for)\n",
       "     3165    0.001    0.000    0.002    0.000 managers.py:706(nblocks)\n",
       "      422    0.001    0.000    0.037    0.000 series.py:730(__array_wrap__)\n",
       "      379    0.001    0.000    0.012    0.000 base.py:1272(set_names)\n",
       "      694    0.001    0.000    0.012    0.000 base.py:2965(_convert_listlike_indexer)\n",
       "      385    0.001    0.000    0.021    0.000 base.py:2445(difference)\n",
       "        2    0.001    0.001    0.003    0.001 managers.py:772(_interleave)\n",
       "     2222    0.001    0.000    0.007    0.000 concat.py:92(<genexpr>)\n",
       "      437    0.001    0.000    0.002    0.000 _validators.py:230(validate_axis_style_args)\n",
       "      660    0.001    0.000    0.003    0.000 {method 'any' of 'numpy.generic' objects}\n",
       "      226    0.001    0.000    0.071    0.000 base.py:4919(insert)\n",
       "     7210    0.001    0.000    0.001    0.000 managers.py:1814(<lambda>)\n",
       "     2065    0.001    0.000    0.002    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
       "     5225    0.001    0.000    0.001    0.000 protocol.py:211(is_error_packet)\n",
       "     1268    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:1203(_path_importer_cache)\n",
       "      284    0.001    0.000    0.027    0.000 range.py:272(_shallow_copy)\n",
       "     1488    0.001    0.000    0.001    0.000 range.py:89(ensure_int)\n",
       "      388    0.001    0.000    0.001    0.000 sorting.py:47(_int64_cut_off)\n",
       "     1322    0.001    0.000    0.019    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
       "      231    0.001    0.000    0.193    0.001 frame.py:3356(__setitem__)\n",
       "     1349    0.001    0.000    0.002    0.000 missing.py:530(clean_reindex_fill_method)\n",
       "      231    0.001    0.000    0.184    0.001 frame.py:3433(_set_item)\n",
       "      220    0.001    0.000    0.001    0.000 base.py:72(__init__)\n",
       "      379    0.001    0.000    0.009    0.000 concat.py:481(_concat_index_same_dtype)\n",
       "      444    0.001    0.000    0.002    0.000 managers.py:147(set_axis)\n",
       "     2105    0.001    0.000    0.007    0.000 iostream.py:320(_schedule_flush)\n",
       "      529    0.001    0.000    0.044    0.000 managers.py:1796(_simple_blockify)\n",
       "     1722    0.001    0.000    0.004    0.000 common.py:1513(is_string_like_dtype)\n",
       "      678    0.001    0.000    0.002    0.000 format.py:1019(base_formatter)\n",
       "      221    0.001    0.000    0.407    0.002 frame.py:3942(rename)\n",
       "     5224    0.001    0.000    0.001    0.000 protocol.py:56(__init__)\n",
       "     1503    0.001    0.000    0.001    0.000 base.py:3806(_coerce_to_ndarray)\n",
       "     1296    0.001    0.000    0.007    0.000 generic.py:1844(__contains__)\n",
       "      220    0.001    0.000    0.038    0.000 <ipython-input-44-c9fd36f58387>:54(make_parse_tree)\n",
       "      216    0.001    0.000    0.082    0.000 frame.py:3794(reindex)\n",
       "      440    0.001    0.000    0.001    0.000 coo.py:235(getnnz)\n",
       "      977    0.001    0.000    0.035    0.000 managers.py:730(<listcomp>)\n",
       "      379    0.001    0.000    0.022    0.000 numeric.py:110(_concat_same_dtype)\n",
       "      216    0.001    0.000    0.151    0.001 generic.py:3759(drop)\n",
       "     2172    0.001    0.000    0.001    0.000 base.py:475(<genexpr>)\n",
       "     1260    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:792(find_spec)\n",
       "      679    0.001    0.000    0.002    0.000 config.py:78(_get_single_key)\n",
       "     5085    0.001    0.000    0.001    0.000 protocol.py:190(is_eof_packet)\n",
       "     1208    0.001    0.000    0.001    0.000 construction.py:210(<listcomp>)\n",
       "      243    0.001    0.000    0.007    0.000 generic.py:3840(_update_inplace)\n",
       "      452    0.001    0.000    0.005    0.000 function_base.py:4641(append)\n",
       "     2640    0.001    0.000    0.001    0.000 {method 'pop' of 'set' objects}\n",
       "     2222    0.001    0.000    0.008    0.000 concat.py:93(<genexpr>)\n",
       "      730    0.001    0.000    0.012    0.000 base.py:1672(is_integer)\n",
       "     1267    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:36(_relax_case)\n",
       "      440    0.001    0.000    0.001    0.000 getlimits.py:508(min)\n",
       "     1111    0.001    0.000    0.001    0.000 common.py:162(_not_none)\n",
       "      440    0.001    0.000    0.003    0.000 classification.py:1565(<listcomp>)\n",
       "      216    0.001    0.000    0.066    0.000 frame.py:3754(_reindex_columns)\n",
       "      648    0.001    0.000    0.008    0.000 generic.py:1578(_is_label_or_level_reference)\n",
       "      220    0.001    0.000    0.100    0.000 <ipython-input-43-aac7f0a44aac>:11(__init__)\n",
       "     1111    0.001    0.000    0.001    0.000 concat.py:507(<listcomp>)\n",
       "      437    0.001    0.000    0.490    0.001 _decorators.py:195(wrapper)\n",
       "      660    0.001    0.000    0.001    0.000 {built-in method numpy.result_type}\n",
       "     3333    0.001    0.000    0.001    0.000 common.py:164(<genexpr>)\n",
       "     1260    0.001    0.000    0.001    0.000 {built-in method _imp.is_frozen}\n",
       "     1111    0.001    0.000    0.002    0.000 concat.py:434(_get_result_dim)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method _socket.getaddrinfo}\n",
       "     3358    0.001    0.000    0.001    0.000 numerictypes.py:587(<listcomp>)\n",
       "      660    0.001    0.000    0.001    0.000 sputils.py:279(<genexpr>)\n",
       "     1236    0.001    0.000    0.003    0.000 series.py:434(values)\n",
       "        9    0.001    0.000    0.001    0.000 {method 'factorize' of 'pandas._libs.hashtable.Float64HashTable' objects}\n",
       "     1494    0.001    0.000    0.002    0.000 managers.py:1850(_shape_compat)\n",
       "      528    0.001    0.000    0.001    0.000 <ipython-input-46-f115cb93ab3a>:8(expressions)\n",
       "        1    0.001    0.001    0.001    0.001 {method 'writelines' of '_io._IOBase' objects}\n",
       "     2222    0.001    0.000    0.004    0.000 concat.py:97(<genexpr>)\n",
       "      220    0.001    0.000    0.001    0.000 classification.py:1562(<dictcomp>)\n",
       "      379    0.001    0.000    0.002    0.000 base.py:1240(_set_names)\n",
       "      220    0.001    0.000    0.002    0.000 base.py:1176(_process_toarray_args)\n",
       "      226    0.001    0.000    0.045    0.000 base.py:3830(_coerce_scalar_to_index)\n",
       "      216    0.001    0.000    0.067    0.000 frame.py:3729(_reindex_axes)\n",
       "      332    0.001    0.000    0.001    0.000 printing.py:185(as_escaped_unicode)\n",
       "     2628    0.001    0.000    0.002    0.000 format.py:1401(just)\n",
       "      220    0.001    0.000    0.001    0.000 sputils.py:187(isintlike)\n",
       "     4401    0.001    0.000    0.001    0.000 numerictypes.py:655(<listcomp>)\n",
       "     2106    0.001    0.000    0.001    0.000 {built-in method posix.getpid}\n",
       "     2448    0.001    0.000    0.001    0.000 _config.py:140(get)\n",
       "      216    0.001    0.000    0.013    0.000 base.py:4909(delete)\n",
       "      461    0.001    0.000    0.102    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "      216    0.001    0.000    0.021    0.000 base.py:2354(_wrap_setop_result)\n",
       "   252/63    0.001    0.000    0.001    0.000 arrayprint.py:716(recurser)\n",
       "       90    0.001    0.000    0.014    0.000 base.py:732(astype)\n",
       "      216    0.001    0.000    0.005    0.000 merge.py:614(_maybe_restore_index_levels)\n",
       "     1320    0.001    0.000    0.001    0.000 {built-in method from_iterable}\n",
       "     1177    0.001    0.000    0.006    0.000 algorithms.py:163(_ensure_arraylike)\n",
       "       36    0.001    0.000    0.005    0.000 blocks.py:800(setitem)\n",
       "      511    0.001    0.000    0.002    0.000 range.py:330(equals)\n",
       "      332    0.001    0.000    0.002    0.000 printing.py:156(pprint_thing)\n",
       "      660    0.001    0.000    0.001    0.000 classification.py:272(<genexpr>)\n",
       "      379    0.001    0.000    0.039    0.000 concat.py:531(_concat_indexes)\n",
       "      396    0.001    0.000    0.001    0.000 generic.py:1814(__hash__)\n",
       "      108    0.001    0.000    0.001    0.000 concat.py:396(trim_join_unit)\n",
       "       37    0.001    0.000    0.006    0.000 format.py:931(_format_strings)\n",
       "      231    0.001    0.000    0.113    0.000 generic.py:3171(_set_item)\n",
       "     2159    0.001    0.000    0.003    0.000 concat.py:510(<genexpr>)\n",
       "      921    0.001    0.000    0.001    0.000 {method 'split' of 'str' objects}\n",
       "     2706    0.001    0.000    0.002    0.000 format.py:1392(<genexpr>)\n",
       "      252    0.001    0.000    0.001    0.000 {built-in method pandas._libs.lib.is_bool_array}\n",
       "     1356    0.001    0.000    0.001    0.000 config.py:561(_get_deprecated_option)\n",
       "     1822    0.001    0.000    0.001    0.000 common.py:183(_any_not_none)\n",
       "     1228    0.001    0.000    0.001    0.000 binaryTree.py:17(__init__)\n",
       "     2684    0.001    0.000    0.001    0.000 {method 'upper' of 'str' objects}\n",
       "       74    0.001    0.000    0.010    0.000 series.py:3600(_reduce)\n",
       "     2736    0.001    0.000    0.001    0.000 concat.py:383(<genexpr>)\n",
       "       63    0.001    0.000    0.004    0.000 {method 'get_value' of 'pandas._libs.index.IndexEngine' objects}\n",
       "      220    0.001    0.000    0.002    0.000 data.py:22(__init__)\n",
       "       41    0.001    0.000    0.003    0.000 printing.py:15(adjoin)\n",
       "     3920    0.001    0.000    0.001    0.000 {method 'endswith' of 'str' objects}\n",
       "     1185    0.001    0.000    0.001    0.000 blocks.py:3146(<listcomp>)\n",
       "     2331    0.001    0.000    0.001    0.000 threading.py:507(is_set)\n",
       "      694    0.001    0.000    0.010    0.000 base.py:2999(_convert_arr_indexer)\n",
       "     1260    0.001    0.000    0.001    0.000 {method 'partition' of 'str' objects}\n",
       "      677    0.001    0.000    0.001    0.000 config.py:546(_get_root)\n",
       "      504    0.001    0.000    0.001    0.000 binaryTree.py:22(insertLeft)\n",
       "      677    0.001    0.000    0.004    0.000 config.py:96(_get_option)\n",
       "      216    0.001    0.000    0.151    0.001 frame.py:3819(drop)\n",
       "     1946    0.001    0.000    0.001    0.000 generic.py:1567(<listcomp>)\n",
       "      220    0.001    0.000    0.001    0.000 <ipython-input-33-b81133635a32>:11(__init__)\n",
       "      279    0.001    0.000    0.003    0.000 generic.py:3115(_maybe_update_cacher)\n",
       "     1722    0.001    0.000    0.001    0.000 common.py:1542(<lambda>)\n",
       "      220    0.001    0.000    0.001    0.000 <ipython-input-44-c9fd36f58387>:83(__init__)\n",
       "      434    0.001    0.000    0.006    0.000 generic.py:4341(<genexpr>)\n",
       "      379    0.001    0.000    0.012    0.000 base.py:1346(rename)\n",
       "      220    0.001    0.000    0.001    0.000 sputils.py:92(to_native)\n",
       "       36    0.001    0.000    0.008    0.000 indexing.py:299(_setitem_with_indexer)\n",
       "     2520    0.001    0.000    0.001    0.000 format.py:1418(_is_number)\n",
       "      696    0.001    0.000    0.001    0.000 api.py:226(<setcomp>)\n",
       "     1228    0.001    0.000    0.001    0.000 stack.py:14(push)\n",
       "       15    0.001    0.000    0.001    0.000 result.py:1192(<listcomp>)\n",
       "      216    0.001    0.000    0.001    0.000 generic.py:4378(_needs_reindex_multi)\n",
       "      611    0.001    0.000    0.003    0.000 base.py:2590(_assert_can_do_setop)\n",
       "      324    0.001    0.000    0.001    0.000 copy.py:66(copy)\n",
       "     1320    0.001    0.000    0.001    0.000 base.py:86(get_shape)\n",
       "      910    0.001    0.000    0.001    0.000 base.py:5381(_ensure_has_len)\n",
       "     1449    0.001    0.000    0.001    0.000 {method 'pop' of 'list' objects}\n",
       "      437    0.000    0.000    0.001    0.000 common.py:199(count_not_none)\n",
       "      220    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.dtype' objects}\n",
       "       74    0.000    0.000    0.005    0.000 nanops.py:203(_get_values)\n",
       "       88    0.000    0.000    0.003    0.000 connections.py:744(_execute_command)\n",
       "      442    0.000    0.000    0.002    0.000 common.py:457(_get_rename_function)\n",
       "      216    0.000    0.000    0.044    0.000 managers.py:1959(items_overlap_with_suffix)\n",
       "      504    0.000    0.000    0.001    0.000 binaryTree.py:34(insertRight)\n",
       "      557    0.000    0.000    0.001    0.000 inference.py:470(is_sequence)\n",
       "       63    0.000    0.000    0.022    0.000 series.py:865(__getitem__)\n",
       "     3679    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
       "      912    0.000    0.000    0.000    0.000 blocks.py:327(<listcomp>)\n",
       "       78    0.000    0.000    0.003    0.000 format.py:1407(<listcomp>)\n",
       "      730    0.000    0.000    0.001    0.000 indexing.py:2676(is_nested_tuple)\n",
       "      648    0.000    0.000    0.001    0.000 merge.py:1731(_should_fill)\n",
       "      595    0.000    0.000    0.000    0.000 base.py:4012(<setcomp>)\n",
       "      440    0.000    0.000    0.002    0.000 base.py:243(nnz)\n",
       "      216    0.000    0.000    0.000    0.000 sorting.py:124(is_int64_overflow_possible)\n",
       "       63    0.000    0.000    0.006    0.000 base.py:4342(get_value)\n",
       "       36    0.000    0.000    0.020    0.001 series.py:1369(__unicode__)\n",
       "      440    0.000    0.000    0.090    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "      742    0.000    0.000    0.004    0.000 missing.py:259(notna)\n",
       "      432    0.000    0.000    0.001    0.000 merge.py:1738(_any)\n",
       "     1298    0.000    0.000    0.000    0.000 generic.py:1693(<listcomp>)\n",
       "     1349    0.000    0.000    0.000    0.000 missing.py:71(clean_fill_method)\n",
       "     2353    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "     2449    0.000    0.000    0.000    0.000 numeric.py:113(is_all_dates)\n",
       "      694    0.000    0.000    0.000    0.000 base.py:3035(_convert_list_indexer)\n",
       "       57    0.000    0.000    0.001    0.000 protocol.py:283(__init__)\n",
       "     1654    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "       57    0.000    0.000    0.021    0.000 format.py:848(format_array)\n",
       "      252    0.000    0.000    0.001    0.000 blocks.py:2633(is_bool)\n",
       "      260    0.000    0.000    0.007    0.000 common.py:1320(is_datetimelike_v_numeric)\n",
       "      221    0.000    0.000    0.011    0.000 cast.py:1123(cast_scalar_to_array)\n",
       "      264    0.000    0.000    0.003    0.000 range.py:180(_int64index)\n",
       "      385    0.000    0.000    0.001    0.000 base.py:978(empty)\n",
       "      648    0.000    0.000    0.002    0.000 merge.py:799(<lambda>)\n",
       "      438    0.000    0.000    0.001    0.000 generic.py:334(<dictcomp>)\n",
       "      912    0.000    0.000    0.000    0.000 managers.py:2058(<listcomp>)\n",
       "       11    0.000    0.000    0.575    0.052 sql.py:317(read_sql)\n",
       "     1228    0.000    0.000    0.001    0.000 stack.py:17(pop)\n",
       "      216    0.000    0.000    0.003    0.000 common.py:246(index_labels_to_array)\n",
       "      116    0.000    0.000    0.001    0.000 printing.py:59(<listcomp>)\n",
       "      265    0.000    0.000    0.002    0.000 range.py:176(_data)\n",
       "      216    0.000    0.000    0.001    0.000 merge.py:1704(<lambda>)\n",
       "       63    0.000    0.000    0.002    0.000 arrayprint.py:480(_array2string)\n",
       "      461    0.000    0.000    0.102    0.000 _methods.py:26(_amax)\n",
       "      221    0.000    0.000    0.000    0.000 __init__.py:125(lrange)\n",
       "      216    0.000    0.000    0.009    0.000 generic.py:1765(<listcomp>)\n",
       "      379    0.000    0.000    0.000    0.000 concat.py:483(<listcomp>)\n",
       "      147    0.000    0.000    0.431    0.003 socket.py:575(readinto)\n",
       "      440    0.000    0.000    0.000    0.000 getlimits.py:522(max)\n",
       "      216    0.000    0.000    0.026    0.000 base.py:4025(_concat_same_dtype)\n",
       "     1424    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
       "       27    0.000    0.000    0.001    0.000 format.py:1422(<listcomp>)\n",
       "     1298    0.000    0.000    0.000    0.000 generic.py:1627(<listcomp>)\n",
       "      864    0.000    0.000    0.000    0.000 common.py:273(maybe_make_list)\n",
       "       20    0.000    0.000    0.003    0.000 connections.py:1213(_get_descriptions)\n",
       "      220    0.000    0.000    0.001    0.000 <ipython-input-44-c9fd36f58387>:62(preprocess_sentence)\n",
       "     1728    0.000    0.000    0.000    0.000 binaryTree.py:50(getLeftChild)\n",
       "     1260    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:719(find_spec)\n",
       "      216    0.000    0.000    0.000    0.000 merge.py:1011(_validate_specification)\n",
       "      385    0.000    0.000    0.000    0.000 base.py:759(size)\n",
       "       36    0.000    0.000    0.001    0.000 shutil.py:1070(get_terminal_size)\n",
       "       63    0.000    0.000    0.003    0.000 arrayprint.py:518(array2string)\n",
       "      672    0.000    0.000    0.000    0.000 fromnumeric.py:2847(ndim)\n",
       "     1224    0.000    0.000    0.000    0.000 binaryTree.py:56(getRootVal)\n",
       "      677    0.000    0.000    0.004    0.000 config.py:226(__call__)\n",
       "       78    0.000    0.000    0.008    0.000 format.py:1384(_make_fixed_width)\n",
       "        6    0.000    0.000    0.000    0.000 {pandas._libs.algos.rank_1d_float64}\n",
       "     1236    0.000    0.000    0.000    0.000 blocks.py:161(external_values)\n",
       "      456    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "       12    0.000    0.000    0.006    0.000 format.py:1060(format_values_with)\n",
       "       11    0.000    0.000    0.000    0.000 {pandas._libs.lib.to_object_array_tuples}\n",
       "     1220    0.000    0.000    0.001    0.000 format.py:541(<genexpr>)\n",
       "      220    0.000    0.000    0.001    0.000 sputils.py:209(isshape)\n",
       "       36    0.000    0.000    0.000    0.000 {built-in method posix.get_terminal_size}\n",
       "       36    0.000    0.000    0.005    0.000 nanops.py:68(_f)\n",
       "      104    0.000    0.000    0.001    0.000 printing.py:55(<listcomp>)\n",
       "     1311    0.000    0.000    0.000    0.000 common.py:201(<genexpr>)\n",
       "      546    0.000    0.000    0.002    0.000 series.py:591(__len__)\n",
       "      378    0.000    0.000    0.000    0.000 function_base.py:258(iterable)\n",
       "     1728    0.000    0.000    0.000    0.000 binaryTree.py:47(getRightChild)\n",
       "     2129    0.000    0.000    0.000    0.000 {method 'ljust' of 'str' objects}\n",
       "       63    0.000    0.000    0.008    0.000 managers.py:1506(get_slice)\n",
       "       68    0.000    0.000    0.001    0.000 protocol.py:237(_parse_field_descriptor)\n",
       "       12    0.000    0.000    0.007    0.001 format.py:1045(get_result_as_array)\n",
       "      145    0.000    0.000    0.000    0.000 protocol.py:180(read_struct)\n",
       "     2548    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "     1224    0.000    0.000    0.000    0.000 timeout.py:260(_start_new_or_dummy)\n",
       "      220    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
       "      216    0.000    0.000    0.000    0.000 concat.py:503(<listcomp>)\n",
       "      456    0.000    0.000    0.043    0.000 generic.py:3205(_check_setitem_copy)\n",
       "       36    0.000    0.000    0.001    0.000 format.py:202(_get_footer)\n",
       "      216    0.000    0.000    0.000    0.000 {built-in method numpy.can_cast}\n",
       "       15    0.000    0.000    0.001    0.000 format.py:1427(<listcomp>)\n",
       "      440    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}\n",
       "      216    0.000    0.000    0.003    0.000 generic.py:1778(<listcomp>)\n",
       "      440    0.000    0.000    0.089    0.000 _methods.py:30(_amin)\n",
       "      744    0.000    0.000    0.000    0.000 common.py:175(_all_none)\n",
       "      231    0.000    0.000    0.001    0.000 frame.py:3416(_ensure_valid_index)\n",
       "      648    0.000    0.000    0.001    0.000 merge.py:800(<lambda>)\n",
       "       36    0.000    0.000    0.016    0.000 format.py:258(to_string)\n",
       "       36    0.000    0.000    0.017    0.000 series.py:1388(to_string)\n",
       "        9    0.000    0.000    0.228    0.025 <ipython-input-29-6b0f59a80c87>:8(__init__)\n",
       "       38    0.000    0.000    0.005    0.000 base.py:998(_format_with_header)\n",
       "      220    0.000    0.000    0.000    0.000 stack.py:8(__init__)\n",
       "      432    0.000    0.000    0.008    0.000 base.py:1580(is_monotonic)\n",
       "       11    0.000    0.000    0.003    0.000 base.py:1343(_handle_dbapi_exception)\n",
       "      168    0.000    0.000    0.002    0.000 format.py:945(_format)\n",
       "       26    0.000    0.000    0.466    0.018 base.py:1163(_execute_context)\n",
       "     1224    0.000    0.000    0.000    0.000 timeout.py:56(stop)\n",
       "       36    0.000    0.000    0.001    0.000 cast.py:65(maybe_downcast_to_dtype)\n",
       "       31    0.000    0.000    0.463    0.015 cursors.py:151(execute)\n",
       "      677    0.000    0.000    0.001    0.000 config.py:602(_warn_if_deprecated)\n",
       "      216    0.000    0.000    0.003    0.000 generic.py:1775(<listcomp>)\n",
       "      679    0.000    0.000    0.000    0.000 config.py:528(_select_options)\n",
       "      220    0.000    0.000    0.000    0.000 <ipython-input-43-aac7f0a44aac>:10(Results)\n",
       "       63    0.000    0.000    0.001    0.000 arrayprint.py:411(_get_format_function)\n",
       "       63    0.000    0.000    0.003    0.000 arrayprint.py:463(wrapper)\n",
       "       63    0.000    0.000    0.000    0.000 arrayprint.py:358(_get_formatdict)\n",
       "       75    0.000    0.000    0.000    0.000 {built-in method numpy.putmask}\n",
       "      664    0.000    0.000    0.000    0.000 common.py:464(f)\n",
       "       38    0.000    0.000    0.005    0.000 generic.py:11018(logical_func)\n",
       "     1021    0.000    0.000    0.000    0.000 managers.py:376(<dictcomp>)\n",
       "      611    0.000    0.000    0.000    0.000 base.py:2249(_validate_sort_keyword)\n",
       "      744    0.000    0.000    0.000    0.000 range.py:165(_validate_dtype)\n",
       "       63    0.000    0.000    0.010    0.000 series.py:913(_get_with)\n",
       "       63    0.000    0.000    0.009    0.000 series.py:975(_get_values)\n",
       "      227    0.000    0.000    0.000    0.000 ops.py:66(_maybe_match_name)\n",
       "     1228    0.000    0.000    0.000    0.000 binaryTree.py:53(setRootVal)\n",
       "       72    0.000    0.000    0.000    0.000 os.py:673(__getitem__)\n",
       "        1    0.000    0.000    0.020    0.020 format.py:503(_to_str_columns)\n",
       "       57    0.000    0.000    0.052    0.001 connections.py:393(_read_ok_packet)\n",
       "       22    0.000    0.000    0.114    0.005 base.py:748(_checkout)\n",
       "      258    0.000    0.000    0.001    0.000 common.py:1752(is_complex_dtype)\n",
       "      228    0.000    0.000    0.000    0.000 base.py:658(__array__)\n",
       "      432    0.000    0.000    0.000    0.000 {method 'add' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "       63    0.000    0.000    0.000    0.000 arrayprint.py:69(_make_options_dict)\n",
       "       37    0.000    0.000    0.001    0.000 base.py:1010(<listcomp>)\n",
       "       36    0.000    0.000    0.001    0.000 format.py:165(__init__)\n",
       "      432    0.000    0.000    0.000    0.000 merge.py:1742(validate_operand)\n",
       "      162    0.000    0.000    0.000    0.000 {method 'title' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}\n",
       "       12    0.000    0.000    0.002    0.000 format.py:1078(<listcomp>)\n",
       "      253    0.000    0.000    0.000    0.000 base.py:4683(_maybe_cast_indexer)\n",
       "      189    0.000    0.000    0.000    0.000 arrayprint.py:693(_extendLine)\n",
       "      679    0.000    0.000    0.000    0.000 config.py:589(_translate_key)\n",
       "       11    0.000    0.000    0.018    0.002 frame.py:1430(from_records)\n",
       "       36    0.000    0.000    0.033    0.001 indexing.py:183(__setitem__)\n",
       "       94    0.000    0.000    0.001    0.000 format.py:338(_get_adjustment)\n",
       "      379    0.000    0.000    0.000    0.000 concat.py:523(_maybe_check_integrity)\n",
       "      881    0.000    0.000    0.000    0.000 format.py:1423(<genexpr>)\n",
       "      216    0.000    0.000    0.001    0.000 concat.py:496(<listcomp>)\n",
       "       63    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "       37    0.000    0.000    0.009    0.000 series.py:271(_init_dict)\n",
       "      217    0.000    0.000    0.005    0.000 base.py:4071(identical)\n",
       "       36    0.000    0.000    0.001    0.000 missing.py:478(na_value_for_dtype)\n",
       "      243    0.000    0.000    0.001    0.000 base.py:100(_reset_cache)\n",
       "       57    0.000    0.000    0.018    0.000 format.py:927(get_result)\n",
       "       10    0.000    0.000    0.000    0.000 blocks.py:2689(set)\n",
       "       26    0.000    0.000    0.000    0.000 default.py:862(_init_statement)\n",
       "      222    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1747(_extend_string)\n",
       "       23    0.000    0.000    0.001    0.000 base.py:69(__init__)\n",
       "      694    0.000    0.000    0.000    0.000 indexing.py:937(_convert_for_reindex)\n",
       "       41    0.000    0.000    0.003    0.000 format.py:307(adjoin)\n",
       "       63    0.000    0.000    0.004    0.000 arrayprint.py:1499(_array_str_implementation)\n",
       "       36    0.000    0.000    0.004    0.000 nanops.py:403(nansum)\n",
       "       31    0.000    0.000    0.462    0.015 connections.py:508(query)\n",
       "      220    0.000    0.000    0.001    0.000 printing.py:50(justify)\n",
       "       36    0.000    0.000    0.006    0.000 generic.py:10910(stat_func)\n",
       "       36    0.000    0.000    0.000    0.000 nanops.py:1052(_maybe_null_out)\n",
       "       90    0.000    0.000    0.002    0.000 connections.py:710(_write_bytes)\n",
       "       15    0.000    0.000    0.001    0.000 result.py:215(__init__)\n",
       "      220    0.000    0.000    0.000    0.000 data.py:25(_get_dtype)\n",
       "       36    0.000    0.000    0.000    0.000 format.py:185(_chk_truncate)\n",
       "       36    0.000    0.000    0.001    0.000 terminal.py:25(get_terminal_size)\n",
       "      440    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
       "      648    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "       63    0.000    0.000    0.001    0.000 base.py:1096(tolist)\n",
       "       36    0.000    0.000    0.004    0.000 generic.py:1463(__invert__)\n",
       "       12    0.000    0.000    0.000    0.000 format.py:1430(<listcomp>)\n",
       "      732    0.000    0.000    0.000    0.000 format.py:1107(<genexpr>)\n",
       "        8    0.000    0.000    0.001    0.000 format.py:1140(<listcomp>)\n",
       "       36    0.000    0.000    0.002    0.000 blocks.py:676(_try_cast_result)\n",
       "       36    0.000    0.000    0.025    0.001 indexing.py:153(_get_setitem_indexer)\n",
       "       11    0.000    0.000    0.021    0.002 sql.py:136(_wrap_result)\n",
       "       11    0.000    0.000    0.000    0.000 schema.py:3753(__init__)\n",
       "       22    0.000    0.000    0.000    0.000 queue.py:92(put)\n",
       "      845    0.000    0.000    0.000    0.000 format.py:1424(<genexpr>)\n",
       "       34    0.000    0.000    0.006    0.000 base.py:2223(do_rollback)\n",
       "      144    0.000    0.000    0.000    0.000 nanops.py:71(<genexpr>)\n",
       "       38    0.000    0.000    0.005    0.000 base.py:983(format)\n",
       "      220    0.000    0.000    0.002    0.000 format.py:304(justify)\n",
       "       37    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "       52    0.000    0.000    0.000    0.000 langhelpers.py:852(__get__)\n",
       "       22    0.000    0.000    0.004    0.000 connections.py:532(ping)\n",
       "       77    0.000    0.000    0.000    0.000 blocks.py:266(_slice)\n",
       "      147    0.000    0.000    0.000    0.000 {method '_checkReadable' of '_io._IOBase' objects}\n",
       "       11    0.000    0.000    0.201    0.018 base.py:2312(has_table)\n",
       "      171    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "       57    0.000    0.000    0.000    0.000 format.py:912(__init__)\n",
       "      168    0.000    0.000    0.001    0.000 format.py:943(<lambda>)\n",
       "      457    0.000    0.000    0.000    0.000 printing.py:62(_join_unicode)\n",
       "       11    0.000    0.000    0.000    0.000 sql.py:972(__init__)\n",
       "       22    0.000    0.000    0.110    0.005 base.py:481(checkout)\n",
       "       26    0.000    0.000    0.466    0.018 base.py:1138(_execute_text)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
       "       63    0.000    0.000    0.001    0.000 arrayprint.py:707(_formatArray)\n",
       "       22    0.000    0.000    0.115    0.005 base.py:2223(_contextual_connect)\n",
       "       96    0.000    0.000    0.000    0.000 weakref.py:395(__getitem__)\n",
       "        1    0.000    0.000    0.049    0.049 <ipython-input-44-c9fd36f58387>:106(get_ref_ann)\n",
       "      134    0.000    0.000    0.000    0.000 protocol.py:186(is_ok_packet)\n",
       "       36    0.000    0.000    0.004    0.000 format.py:241(_get_formatted_index)\n",
       "       20    0.000    0.000    0.014    0.001 format.py:702(_format_col)\n",
       "       11    0.000    0.000    0.003    0.000 construction.py:429(_list_to_arrays)\n",
       "       29    0.000    0.000    0.000    0.000 cursors.py:116(_escape_args)\n",
       "        1    0.000    0.000    0.053    0.053 <ipython-input-46-f115cb93ab3a>:142(generate_ensemble_metrics)\n",
       "       94    0.000    0.000    0.001    0.000 format.py:298(__init__)\n",
       "       31    0.000    0.000    0.461    0.015 connections.py:1073(read)\n",
       "       27    0.000    0.000    0.010    0.000 missing.py:522(remove_na_arraylike)\n",
       "       22    0.000    0.000    0.000    0.000 queue.py:135(get)\n",
       "       36    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.TextIOWrapper' objects}\n",
       "       36    0.000    0.000    0.009    0.000 format.py:253(_get_formatted_values)\n",
       "        2    0.000    0.000    0.000    0.000 {function socket.close at 0x109089510}\n",
       "       37    0.000    0.000    0.049    0.001 base.py:48(__str__)\n",
       "       68    0.000    0.000    0.000    0.000 protocol.py:86(advance)\n",
       "      480    0.000    0.000    0.000    0.000 format.py:1139(<lambda>)\n",
       "       27    0.000    0.000    0.012    0.000 series.py:4221(dropna)\n",
       "       11    0.000    0.000    0.000    0.000 exc.py:390(instance)\n",
       "       63    0.000    0.000    0.000    0.000 arrayprint.py:365(<lambda>)\n",
       "       41    0.000    0.000    0.000    0.000 format.py:356(_get_formatter)\n",
       "       43    0.000    0.000    0.000    0.000 threading.py:335(notify)\n",
       "       37    0.000    0.000    0.006    0.000 series.py:4209(isnull)\n",
       "       31    0.000    0.000    0.461    0.015 connections.py:720(_read_query_result)\n",
       "      101    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
       "       31    0.000    0.000    0.000    0.000 connections.py:1053(__init__)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:507(checkin)\n",
       "        2    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "      136    0.000    0.000    0.000    0.000 protocol.py:264(get_column_length)\n",
       "      145    0.000    0.000    0.000    0.000 {method 'unpack_from' of 'Struct' objects}\n",
       "      108    0.000    0.000    0.000    0.000 nanops.py:63(check)\n",
       "      216    0.000    0.000    0.000    0.000 base.py:3072(_can_reindex)\n",
       "       22    0.000    0.000    0.004    0.000 base.py:845(_reset)\n",
       "       31    0.000    0.000    0.463    0.015 cursors.py:324(_query)\n",
       "       78    0.000    0.000    0.000    0.000 result.py:461(_colnames_from_description)\n",
       "       31    0.000    0.000    0.000    0.000 cursors.py:135(mogrify)\n",
       "      291    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
       "        6    0.000    0.000    0.000    0.000 function_base.py:1149(diff)\n",
       "       38    0.000    0.000    0.003    0.000 nanops.py:337(nanany)\n",
       "       36    0.000    0.000    0.002    0.000 blocks.py:725(_try_coerce_and_cast_result)\n",
       "       36    0.000    0.000    0.006    0.000 managers.py:509(setitem)\n",
       "       34    0.000    0.000    0.006    0.000 connections.py:422(rollback)\n",
       "       20    0.000    0.000    0.104    0.005 connections.py:1149(_read_result_packet)\n",
       "       63    0.000    0.000    0.000    0.000 type_api.py:483(_cached_result_processor)\n",
       "       68    0.000    0.000    0.001    0.000 protocol.py:233(__init__)\n",
       "       22    0.000    0.000    0.005    0.000 base.py:645(_finalize_fairy)\n",
       "       51    0.000    0.000    0.003    0.000 construction.py:495(convert)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'close' of 'pandas._libs.parsers.TextReader' objects}\n",
       "       37    0.000    0.000    0.006    0.000 generic.py:7083(isnull)\n",
       "        2    0.000    0.000    0.007    0.003 <ipython-input-39-6708c31f37df>:7(geometric_mean)\n",
       "       74    0.000    0.000    0.000    0.000 nanops.py:270(_na_ok_dtype)\n",
       "       78    0.000    0.000    0.000    0.000 result.py:560(_merge_cols_by_none)\n",
       "       63    0.000    0.000    0.000    0.000 arrayprint.py:1149(__init__)\n",
       "       41    0.000    0.000    0.001    0.000 printing.py:36(<listcomp>)\n",
       "       56    0.000    0.000    0.000    0.000 managers.py:1552(formatting_values)\n",
       "       11    0.000    0.000    0.258    0.023 sql.py:1055(read_query)\n",
       "        9    0.000    0.000    0.002    0.000 strings.py:1854(_wrap_result)\n",
       "       36    0.000    0.000    0.000    0.000 indexing.py:2501(check_setitem_lengths)\n",
       "       38    0.000    0.000    0.000    0.000 managers.py:627(is_view)\n",
       "       11    0.000    0.000    0.005    0.000 construction.py:382(to_arrays)\n",
       "       23    0.000    0.000    0.000    0.000 deprecations.py:117(warned)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:2260(is_disconnect)\n",
       "       11    0.000    0.000    0.003    0.000 sql.py:115(_parse_date_columns)\n",
       "       68    0.000    0.000    0.000    0.000 protocol.py:253(description)\n",
       "       72    0.000    0.000    0.000    0.000 os.py:751(encode)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:183(execution_options)\n",
       "       27    0.000    0.000    0.000    0.000 numeric.py:203(_convert_scalar_indexer)\n",
       "       20    0.000    0.000    0.000    0.000 protocol.py:308(__init__)\n",
       "      148    0.000    0.000    0.000    0.000 socket.py:614(readable)\n",
       "       27    0.000    0.000    0.002    0.000 format.py:1421(_cond)\n",
       "       63    0.000    0.000    0.000    0.000 arrayprint.py:74(<dictcomp>)\n",
       "       15    0.000    0.000    0.000    0.000 result.py:441(<listcomp>)\n",
       "       11    0.000    0.000    0.316    0.029 base.py:2133(run_callable)\n",
       "       11    0.000    0.000    0.000    0.000 result.py:588(_key_fallback)\n",
       "       23    0.000    0.000    0.000    0.000 base.py:77(__init__)\n",
       "        1    0.000    0.000  277.126  277.126 <ipython-input-46-f115cb93ab3a>:169(ensemble_control)\n",
       "       38    0.000    0.000    0.000    0.000 generic.py:3110(_is_view)\n",
       "       15    0.000    0.000    0.000    0.000 default.py:947(should_autocommit)\n",
       "     10/9    0.000    0.000    0.026    0.003 strings.py:62(_map)\n",
       "       12    0.000    0.000    0.002    0.000 format.py:1412(_trim_zeros)\n",
       "       11    0.000    0.000    0.000    0.000 pymysql.py:64(is_disconnect)\n",
       "       49    0.000    0.000    0.000    0.000 protocol.py:122(read_uint16)\n",
       "       22    0.000    0.000    0.005    0.000 base.py:869(close)\n",
       "       15    0.000    0.000    0.001    0.000 result.py:1178(process_rows)\n",
       "       36    0.000    0.000    0.001    0.000 blocks.py:213(make_block)\n",
       "        6    0.000    0.000    0.000    0.000 common.py:120(_stringify_path)\n",
       "       26    0.000    0.000    0.466    0.018 base.py:922(execute)\n",
       "       27    0.000    0.000    0.003    0.000 range.py:520(__getitem__)\n",
       "       11    0.000    0.000    0.002    0.000 base.py:729(_rollback_impl)\n",
       "        1    0.000    0.000    0.005    0.005 csvs.py:290(_save_chunk)\n",
       "       36    0.000    0.000    0.000    0.000 nanops.py:276(_wrap_results)\n",
       "       26    0.000    0.000    0.000    0.000 default.py:1034(create_cursor)\n",
       "       11    0.000    0.000    0.000    0.000 err.py:100(raise_mysql_exception)\n",
       "       23    0.000    0.000    0.000    0.000 base.py:295(__get__)\n",
       "       15    0.000    0.000    0.001    0.000 result.py:740(_init_metadata)\n",
       "       46    0.000    0.000    0.000    0.000 __init__.py:1619(isEnabledFor)\n",
       "       36    0.000    0.000    0.000    0.000 generic.py:3184(_check_is_chained_assignment_possible)\n",
       "       56    0.000    0.000    0.000    0.000 series.py:483(_formatting_values)\n",
       "       31    0.000    0.000    0.000    0.000 cursors.py:40(__init__)\n",
       "        5    0.000    0.000    0.004    0.001 algorithms.py:370(isin)\n",
       "       11    0.000    0.000    0.000    0.000 exc.py:462(__init__)\n",
       "       23    0.000    0.000    0.000    0.000 base.py:116(_for_class)\n",
       "       13    0.000    0.000    0.000    0.000 <ipython-input-46-f115cb93ab3a>:2(partly_unordered_permutations)\n",
       "      134    0.000    0.000    0.000    0.000 managers.py:1513(index)\n",
       "       11    0.000    0.000    0.000    0.000 exc.py:328(__init__)\n",
       "     20/3    0.000    0.000    0.001    0.000 visitors.py:85(_compiler_dispatch)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:123(_join)\n",
       "        1    0.000    0.000  277.127  277.127 <ipython-input-49-9c24994163af>:2(main)\n",
       "       37    0.000    0.000    0.000    0.000 __init__.py:227(itervalues)\n",
       "       27    0.000    0.000    0.002    0.000 generic.py:3093(_maybe_cache_changed)\n",
       "        4    0.000    0.000    0.002    0.001 generic.py:3155(_slice)\n",
       "       14    0.000    0.000    0.000    0.000 blocks.py:284(getitem_block)\n",
       "      144    0.000    0.000    0.000    0.000 cursors.py:71(_get_db)\n",
       "       22    0.000    0.000    0.005    0.000 base.py:831(_checkin)\n",
       "       22    0.000    0.000    0.109    0.005 impl.py:111(_do_get)\n",
       "        2    0.000    0.000    0.001    0.001 categorical.py:317(__init__)\n",
       "       11    0.000    0.000    0.000    0.000 sql.py:508(pandasSQL_builder)\n",
       "     14/4    0.000    0.000    0.000    0.000 langhelpers.py:273(get_cls_kwargs)\n",
       "       12    0.000    0.000    0.026    0.002 <ipython-input-41-ca3a4ead7b00>:56(<lambda>)\n",
       "       62    0.000    0.000    0.000    0.000 cursors.py:89(_nextset)\n",
       "       67    0.000    0.000    0.000    0.000 attr.py:267(__bool__)\n",
       "       26    0.000    0.000    0.000    0.000 default.py:1002(_use_server_side_cursor)\n",
       "      147    0.000    0.000    0.000    0.000 {method '_checkClosed' of '_io._IOBase' objects}\n",
       "        1    0.000    0.000    0.007    0.007 {pandas._libs.reduction.reduce}\n",
       "       31    0.000    0.000    0.000    0.000 connections.py:481(cursor)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:1999(visit_select)\n",
       "       22    0.000    0.000    0.000    0.000 log.py:56(_should_log_debug)\n",
       "       15    0.000    0.000    0.000    0.000 result.py:266(<listcomp>)\n",
       "        6    0.000    0.000    0.001    0.000 generic.py:5581(astype)\n",
       "       57    0.000    0.000    0.000    0.000 protocol.py:297(__getattr__)\n",
       "       13    0.000    0.000    0.000    0.000 compiler.py:3464(quote_identifier)\n",
       "       22    0.000    0.000    0.114    0.005 base.py:345(connect)\n",
       "       15    0.000    0.000    0.003    0.000 result.py:869(_soft_close)\n",
       "       26    0.000    0.000    0.000    0.000 {built-in method sqlalchemy.cutils._distill_params}\n",
       "       11    0.000    0.000    0.316    0.029 sql.py:1197(has_table)\n",
       "      189    0.000    0.000    0.000    0.000 arrayprint.py:1154(__call__)\n",
       "       36    0.000    0.000    0.000    0.000 blocks.py:884(_is_empty_indexer)\n",
       "       11    0.000    0.000    0.000    0.000 sql.py:45(_is_sqlalchemy_connectable)\n",
       "       63    0.000    0.000    0.000    0.000 default.py:1051(get_result_processor)\n",
       "       23    0.000    0.000    0.000    0.000 _collections.py:140(__new__)\n",
       "       15    0.000    0.000    0.001    0.000 result.py:714(__init__)\n",
       "       22    0.000    0.000    0.004    0.000 mysqldb.py:120(do_ping)\n",
       "        1    0.000    0.000    0.001    0.001 sorting.py:189(lexsort_indexer)\n",
       "        6    0.000    0.000    0.001    0.000 generic.py:8324(ranker)\n",
       "        1    0.000    0.000    0.001    0.001 connections.py:786(_request_authentication)\n",
       "       62    0.000    0.000    0.000    0.000 cursors.py:106(nextset)\n",
       "       20    0.000    0.000    0.000    0.000 cursors.py:341(_do_get_result)\n",
       "        1    0.000    0.000    0.003    0.003 format.py:642(_join_multiline)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:580(get_connection)\n",
       "      109    0.000    0.000    0.000    0.000 __init__.py:275(u)\n",
       "       36    0.000    0.000    0.000    0.000 blocks.py:2721(_try_coerce_args)\n",
       "       11    0.000    0.000    0.234    0.021 base.py:2149(execute)\n",
       "       22    0.000    0.000    0.005    0.000 base.py:987(close)\n",
       "        1    0.000    0.000    0.009    0.009 csvs.py:130(save)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.001    0.001 socket.py:691(create_connection)\n",
       "       74    0.000    0.000    0.000    0.000 function.py:40(__call__)\n",
       "       27    0.000    0.000    0.000    0.000 blocks.py:3183(_safe_reshape)\n",
       "       10    0.000    0.000    0.000    0.000 elements.py:717(__getattr__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method now}\n",
       "        6    0.000    0.000    0.000    0.000 blocks.py:536(_astype)\n",
       "       12    0.000    0.000    0.007    0.001 format.py:1128(_format_strings)\n",
       "       26    0.000    0.000    0.000    0.000 base.py:1327(_safe_close_cursor)\n",
       "        2    0.000    0.000    0.000    0.000 stats.py:256(gmean)\n",
       "        5    0.000    0.000    0.000    0.000 types.py:69(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 strings.py:1805(_validate)\n",
       "        5    0.000    0.000    0.002    0.000 blocks.py:1982(to_native_types)\n",
       "        1    0.000    0.000    0.001    0.001 format.py:651(<listcomp>)\n",
       "       11    0.000    0.000    0.000    0.000 compat.py:123(reraise)\n",
       "       23    0.000    0.000    0.000    0.000 log.py:59(_should_log_info)\n",
       "       22    0.000    0.000    0.000    0.000 impl.py:102(_do_return_conn)\n",
       "       15    0.000    0.000    0.001    0.000 result.py:334(_merge_cursor_description)\n",
       "       29    0.000    0.000    0.462    0.016 default.py:551(do_execute)\n",
       "       95    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
       "       44    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "      112    0.000    0.000    0.000    0.000 base.py:540(_constructor)\n",
       "        1    0.000    0.000    0.029    0.029 frame.py:678(to_string)\n",
       "       11    0.000    0.000    0.234    0.021 sql.py:988(execute)\n",
       "       31    0.000    0.000    0.000    0.000 cursors.py:51(close)\n",
       "       15    0.000    0.000    0.000    0.000 base.py:1174(should_autocommit_text)\n",
       "        1    0.000    0.000    0.000    0.000 csvs.py:30(__init__)\n",
       "       49    0.000    0.000    0.000    0.000 {built-in method _struct.unpack_from}\n",
       "      216    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "        1    0.000    0.000    0.029    0.029 frame.py:614(__unicode__)\n",
       "       56    0.000    0.000    0.000    0.000 blocks.py:171(formatting_values)\n",
       "        5    0.000    0.000    0.004    0.001 series.py:3947(isin)\n",
       "       11    0.000    0.000    0.000    0.000 exc.py:24(__init__)\n",
       "       15    0.000    0.000    0.001    0.000 default.py:1092(get_result_proxy)\n",
       "       15    0.000    0.000    0.001    0.000 default.py:1108(_setup_crud_result_proxy)\n",
       "        1    0.000    0.000    0.020    0.020 apply.py:262(apply_series_generator)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "       63    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "        3    0.000    0.000    0.003    0.001 sorting.py:366(compress_group_index)\n",
       "        4    0.000    0.000    0.002    0.001 managers.py:684(get_slice)\n",
       "       11    0.000    0.000    0.003    0.000 construction.py:501(<listcomp>)\n",
       "       58    0.000    0.000    0.000    0.000 protocol.py:77(read_all)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:500(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 compiler.py:3529(quote)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:949(cursor)\n",
       "        1    0.000    0.000    0.000    0.000 <ipython-input-44-c9fd36f58387>:102(<listcomp>)\n",
       "       22    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "        2    0.000    0.000    0.000    0.000 socket.py:412(_real_close)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:1761(_label_select_column)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:5948(fillna)\n",
       "       10    0.000    0.000    0.000    0.000 blocks.py:2736(should_store)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:371(_force_close)\n",
       "        8    0.000    0.000    0.000    0.000 type_api.py:505(_dialect_info)\n",
       "       11    0.000    0.000    0.000    0.000 schema.py:4027(_bind_to)\n",
       "       11    0.000    0.000    0.201    0.018 base.py:1591(run_callable)\n",
       "       13    0.000    0.000    0.000    0.000 compiler.py:3425(_escape_identifier)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:366(_return_conn)\n",
       "        3    0.000    0.000    0.002    0.001 default.py:342(check_unicode)\n",
       "       11    0.000    0.000    0.003    0.000 result.py:1195(fetchall)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "        8    0.000    0.000    0.000    0.000 weakref.py:435(__contains__)\n",
       "        1    0.000    0.000    0.005    0.005 format.py:431(_chk_truncate)\n",
       "       11    0.000    0.000    0.003    0.000 construction.py:484(_convert_object_array)\n",
       "       27    0.000    0.000    0.002    0.000 series.py:388(_update_inplace)\n",
       "        2    0.000    0.000    0.001    0.000 series.py:3466(apply)\n",
       "        1    0.000    0.000    0.144    0.144 parsers.py:1993(read)\n",
       "        1    0.000    0.000    0.071    0.071 connections.py:564(connect)\n",
       "       22    0.000    0.000    0.114    0.005 base.py:2259(_wrap_pool_connect)\n",
       "        1    0.000    0.000    0.032    0.032 apply.py:228(apply_standard)\n",
       "        4    0.000    0.000    0.000    0.000 blocks.py:335(set)\n",
       "        1    0.000    0.000    0.024    0.024 format.py:582(to_string)\n",
       "        1    0.000    0.000    0.001    0.001 format.py:801(_get_formatted_index)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:261(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:780(visit_label)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2157(_setup_select_stack)\n",
       "        1    0.000    0.000    0.028    0.028 <ipython-input-44-c9fd36f58387>:89(get_docs)\n",
       "        9    0.000    0.000    0.000    0.000 cast.py:1260(maybe_cast_to_integer_array)\n",
       "        9    0.000    0.000    0.000    0.000 strings.py:1795(__init__)\n",
       "        1    0.000    0.000    0.009    0.009 generic.py:2882(to_csv)\n",
       "        1    0.000    0.000    0.025    0.025 connections.py:973(_get_server_information)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:715(__init__)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:2057(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:35(_formatwarnmsg_impl)\n",
       "        6    0.000    0.000    0.000    0.000 parse.py:361(urlparse)\n",
       "        6    0.000    0.000    0.000    0.000 parse.py:409(urlsplit)\n",
       "        4    0.000    0.000    0.003    0.001 managers.py:736(as_array)\n",
       "       88    0.000    0.000    0.000    0.000 managers.py:1578(_consolidate_inplace)\n",
       "       11    0.000    0.000    0.000    0.000 _collections.py:151(union)\n",
       "       11    0.000    0.000    0.000    0.000 compat.py:378(raise_from_cause)\n",
       "       23    0.000    0.000    0.000    0.000 base.py:119(_for_instance)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:355(closed)\n",
       "       11    0.000    0.000    0.002    0.000 base.py:865(_autorollback)\n",
       "        1    0.000    0.000    0.002    0.002 default.py:379(<setcomp>)\n",
       "       22    0.000    0.000    0.000    0.000 queue.py:195(_full)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1278(visit_typeclause)\n",
       "        1    0.000    0.000    0.007    0.007 mysqldb.py:136(_check_unicode_returns)\n",
       "        8    0.000    0.000    0.000    0.000 frame.py:3585(reindexer)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:1553(_binify)\n",
       "       11    0.000    0.000    0.000    0.000 sql.py:74(_convert_params)\n",
       "        1    0.000    0.000    0.071    0.071 connections.py:183(__init__)\n",
       "       31    0.000    0.000    0.000    0.000 cursors.py:332(_clear_result)\n",
       "        1    0.000    0.000    0.109    0.109 base.py:622(__connect)\n",
       "       15    0.000    0.000    0.000    0.000 result.py:864(_cursor_description)\n",
       "        1    0.000    0.000    0.001    0.001 socket.py:731(getaddrinfo)\n",
       "       38    0.000    0.000    0.000    0.000 blocks.py:136(is_view)\n",
       "        4    0.000    0.000    0.000    0.000 langhelpers.py:1136(constructor_copy)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3831(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2687(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 dtypes.py:485(validate_categories)\n",
       "       27    0.000    0.000    0.000    0.000 base.py:697(shape)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:9415(abs)\n",
       "       27    0.000    0.000    0.000    0.000 managers.py:1568(_can_hold_na)\n",
       "        1    0.000    0.000    0.172    0.172 parsers.py:1137(read)\n",
       "       10    0.000    0.000    0.000    0.000 connections.py:469(escape_string)\n",
       "       31    0.000    0.000    0.000    0.000 connections.py:1069(__del__)\n",
       "       11    0.000    0.000    0.000    0.000 cursors.py:299(fetchall)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:1440(adapt_type)\n",
       "       12    0.000    0.000    0.000    0.000 apipkg.py:133(__makeattr)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:221(makefile)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:652(close)\n",
       "       27    0.000    0.000    0.000    0.000 base.py:143(__setattr__)\n",
       "       74    0.000    0.000    0.000    0.000 nanops.py:180(_get_fill_value)\n",
       "        1    0.000    0.000    0.002    0.002 frame.py:4695(sort_values)\n",
       "       36    0.000    0.000    0.000    0.000 indexing.py:2545(convert_missing_indexer)\n",
       "        1    0.000    0.000    0.001    0.001 format.py:739(_get_formatted_column_labels)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:94(_expand_user)\n",
       "       20    0.000    0.000    0.000    0.000 cursors.py:355(_show_warnings)\n",
       "       21    0.000    0.000    0.000    0.000 queue.py:203(_get)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:2054(_quote_free_identifiers)\n",
       "       12    0.000    0.000    0.000    0.000 apply.py:325(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 cast.py:1072(find_common_type)\n",
       "       10    0.000    0.000    0.000    0.000 base.py:2254(union)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:3752(_try_convert_to_int_index)\n",
       "        4    0.000    0.000    0.003    0.001 generic.py:5250(values)\n",
       "       27    0.000    0.000    0.000    0.000 series.py:348(_can_hold_na)\n",
       "       11    0.000    0.000    0.000    0.000 connections.py:448(escape)\n",
       "       22    0.000    0.000    0.000    0.000 attr.py:255(__call__)\n",
       "       15    0.000    0.000    0.000    0.000 result.py:263(<listcomp>)\n",
       "        1    0.000    0.000    0.038    0.038 base.py:2347(initialize)\n",
       "        1    0.000    0.000    0.002    0.002 <frozen importlib._bootstrap_external>:1404(_fill_cache)\n",
       "        9    0.000    0.000    0.000    0.000 accessor.py:167(__get__)\n",
       "        1    0.000    0.000    0.004    0.004 common.py:314(_get_handle)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:544(UnicodeWriter)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:186(scramble_caching_sha2)\n",
       "        9    0.000    0.000    0.000    0.000 cursors.py:280(fetchone)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2959(_froms)\n",
       "        9    0.000    0.000    0.000    0.000 sqltypes.py:140(__init__)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:169(_clone)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:479(_still_open_and_connection_is_valid)\n",
       "        1    0.000    0.000    0.002    0.002 default.py:331(_check_unicode_returns)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2184(_get_server_version_info)\n",
       "        1    0.000    0.000    0.000    0.000 console.py:149(in_ipython_frontend)\n",
       "        1    0.000    0.000    0.000    0.000 cast.py:597(astype_nansafe)\n",
       "       72    0.000    0.000    0.000    0.000 blocks.py:868(<lambda>)\n",
       "        6    0.000    0.000    0.000    0.000 managers.py:530(astype)\n",
       "        1    0.000    0.000    0.005    0.005 format.py:381(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 format.py:992(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:956(_clean_options)\n",
       "       11    0.000    0.000    0.000    0.000 langhelpers.py:59(__enter__)\n",
       "        5    0.000    0.000    0.205    0.041 <ipython-input-30-73f63767e05a>:8(system_semtype_check)\n",
       "        9    0.000    0.000    0.029    0.003 strings.py:2723(strip)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:5457(dtypes)\n",
       "        6    0.000    0.000    0.001    0.000 generic.py:8282(rank)\n",
       "       36    0.000    0.000    0.000    0.000 indexing.py:269(_has_valid_setitem_indexer)\n",
       "       40    0.000    0.000    0.000    0.000 format.py:535(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:76(_is_url)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'writerow' of '_csv.writer' objects}\n",
       "        1    0.000    0.000    0.176    0.176 parsers.py:536(parser_f)\n",
       "        7    0.000    0.000    0.000    0.000 langhelpers.py:253(_inspect_func_args)\n",
       "       11    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
       "       22    0.000    0.000    0.000    0.000 queue.py:199(_put)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:1279(first)\n",
       "        1    0.000    0.000    0.000    0.000 csvs.py:191(_save_header)\n",
       "       37    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
       "        7    0.000    0.000    0.000    0.000 inference.py:381(is_dict_like)\n",
       "        2    0.000    0.000    0.000    0.000 ops.py:1815(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 sorting.py:339(get_group_index_sorter)\n",
       "        9    0.000    0.000    0.026    0.003 strings.py:57(_na_map)\n",
       "        4    0.000    0.000    0.002    0.001 indexing.py:2170(_get_slice_axis)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:648(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:795(show_col_idx_names)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:179(get_filepath_or_buffer)\n",
       "       36    0.000    0.000    0.000    0.000 series.py:856(_is_mixed_type)\n",
       "        1    0.000    0.000    0.002    0.002 parsers.py:813(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1352(__init__)\n",
       "       18    0.000    0.000    0.000    0.000 cursors.py:122(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:864(anon_label)\n",
       "        9    0.000    0.000    0.000    0.000 <string>:1(__init__)\n",
       "        1    0.000    0.000    0.038    0.038 strategies.py:194(first_connect)\n",
       "       55    0.000    0.000    0.000    0.000 base.py:155(_root)\n",
       "       22    0.000    0.000    0.000    0.000 base.py:364(invalidated)\n",
       "       40    0.000    0.000    0.000    0.000 base.py:370(connection)\n",
       "        4    0.000    0.000    0.000    0.000 compiler.py:3477(_requires_quotes)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1316(visit_cast)\n",
       "        7    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "       12    0.000    0.000    0.000    0.000 parse.py:109(_coerce_args)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'setsockopt' of '_socket.socket' objects}\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1817(wrapper)\n",
       "        2    0.000    0.000    0.000    0.000 categorical.py:441(dtype)\n",
       "        6    0.000    0.000    0.001    0.000 algorithms.py:835(rank)\n",
       "       63    0.000    0.000    0.000    0.000 base.py:5398(<genexpr>)\n",
       "        9    0.000    0.000    0.026    0.003 strings.py:1504(str_strip)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:769(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1502(_maybe_dedup_names)\n",
       "       10    0.000    0.000    0.000    0.000 converters.py:68(_escape_unicode)\n",
       "       10    0.000    0.000    0.000    0.000 connections.py:462(literal)\n",
       "       20    0.000    0.000    0.000    0.000 cursors.py:127(<dictcomp>)\n",
       "       21    0.000    0.000    0.000    0.000 langhelpers.py:1145(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:3066(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 type_api.py:269(result_processor)\n",
       "        3    0.000    0.000    0.000    0.000 <string>:1(select)\n",
       "       11    0.000    0.000    0.002    0.000 base.py:180(__exit__)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:274(__init__)\n",
       "       33    0.000    0.000    0.000    0.000 base.py:958(__getattr__)\n",
       "       16    0.000    0.000    0.000    0.000 default.py:943(no_parameters)\n",
       "       26    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "       16    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
       "       44    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "        1    0.000    0.000    0.032    0.032 apply.py:109(get_result)\n",
       "        6    0.000    0.000    0.000    0.000 dtypes.py:225(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 dtypes.py:328(_finalize)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_object_object}\n",
       "        6    0.000    0.000    0.000    0.000 generic.py:277(_construct_axes_dict)\n",
       "       36    0.000    0.000    0.000    0.000 blocks.py:721(_try_coerce_result)\n",
       "        2    0.000    0.000    0.001    0.000 blocks.py:730(to_native_types)\n",
       "        3    0.000    0.000    0.000    0.000 common.py:260(_infer_compression)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:900(_get_options_with_defaults)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2395(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 elements.py:4139(__new__)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2988(_get_display_froms)\n",
       "        1    0.000    0.000    0.038    0.038 attr.py:279(exec_once)\n",
       "        1    0.000    0.000    0.009    0.009 default.py:286(initialize)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1564(_process_anon)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2186(_compose_select_body)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2172(get_isolation_level)\n",
       "       12    0.000    0.000    0.000    0.000 pymysql.py:76(_extract_error_code)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.groupsort_indexer}\n",
       "        2    0.000    0.000    0.000    0.000 categorical.py:394(categories)\n",
       "        4    0.000    0.000    0.000    0.000 categorical.py:668(_get_codes)\n",
       "        1    0.000    0.000    0.000    0.000 sorting.py:387(_reorder_by_uniques)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:2897(_convert_slice_indexer)\n",
       "       36    0.000    0.000    0.000    0.000 blocks.py:874(_is_scalar_indexer)\n",
       "        8    0.000    0.000    0.001    0.000 format.py:1138(_format_strings)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _csv.writer}\n",
       "       11    0.000    0.000    0.000    0.000 sql.py:490(_engine_builder)\n",
       "       11    0.000    0.000    0.000    0.000 langhelpers.py:62(__exit__)\n",
       "        7    0.000    0.000    0.000    0.000 elements.py:705(comparator)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:4062(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 type_api.py:440(dialect_impl)\n",
       "        1    0.000    0.000    0.000    0.000 registry.py:53(_collection_gced)\n",
       "       11    0.000    0.000    0.000    0.000 result.py:1161(_fetchall_impl)\n",
       "        3    0.000    0.000    0.000    0.000 types.py:674(__init__)\n",
       "        1    0.000    0.000    0.005    0.005 csvs.py:272(_save)\n",
       "        1    0.000    0.000    0.000    0.000 interactiveshell.py:698(get_ipython)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.where}\n",
       "        5    0.000    0.000    0.003    0.001 algorithms.py:407(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 sorting.py:177(indexer_from_factorized)\n",
       "        4    0.000    0.000    0.000    0.000 indexing.py:264(_convert_slice_indexer)\n",
       "        6    0.000    0.000    0.000    0.000 blocks.py:532(astype)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:3831(fillna)\n",
       "        1    0.000    0.000    0.071    0.071 __init__.py:88(Connect)\n",
       "        1    0.000    0.000    0.000    0.000 charset.py:18(encoding)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:304(<dictcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 connections.py:890(_process_auth)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:925(__getattr__)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:38(_from_objects)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4299(apply_map)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3641(_columns_plus_names)\n",
       "        3    0.000    0.000    0.001    0.000 base.py:1287(_cursor_execute)\n",
       "      9/3    0.000    0.000    0.001    0.000 compiler.py:349(process)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1542(_truncated_identifier)\n",
       "        9    0.000    0.000    0.000    0.000 default.py:894(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1954(visit_CHAR)\n",
       "        3    0.000    0.000    0.000    0.000 types.py:689(_adapt_string_for_cast)\n",
       "        1    0.000    0.000    0.000    0.000 console.py:47(get_console_size)\n",
       "        6    0.000    0.000    0.000    0.000 dtypes.py:465(validate_ordered)\n",
       "        2    0.000    0.000    0.000    0.000 dtypes.py:521(update_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1050(_format_native_types)\n",
       "        6    0.000    0.000    0.000    0.000 generic.py:279(<dictcomp>)\n",
       "       36    0.000    0.000    0.000    0.000 blocks.py:2718(_can_hold_element)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:225(get_dtypes)\n",
       "       39    0.000    0.000    0.000    0.000 managers.py:1572(is_consolidated)\n",
       "       12    0.000    0.000    0.000    0.000 format.py:1004(_value_formatter)\n",
       "        1    0.000    0.000    0.002    0.002 parsers.py:1120(_make_engine)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1180(_is_potential_multi_index)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:637(write_packet)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:34(scramble_native_password)\n",
       "       11    0.000    0.000    0.000    0.000 protocol.py:94(rewind)\n",
       "        3    0.000    0.000    0.000    0.000 langhelpers.py:897(expire_instance)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:751(_select_iterable)\n",
       "       11    0.000    0.000    0.000    0.000 elements.py:4322(_string_or_unprintable)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:524(adapt)\n",
       "       10    0.000    0.000    0.000    0.000 type_api.py:1430(to_instance)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:94(__getattr__)\n",
       "       22    0.000    0.000    0.000    0.000 queue.py:191(_empty)\n",
       "       11    0.000    0.000    0.000    0.000 default.py:477(set_connection_execution_options)\n",
       "       17    0.000    0.000    0.000    0.000 base.py:1753(attr)\n",
       "        1    0.000    0.000    0.022    0.022 base.py:2750(_detect_casing)\n",
       "        1    0.000    0.000    0.007    0.007 base.py:2794(_detect_sql_mode)\n",
       "        2    0.000    0.000    0.000    0.000 types.py:510(__init__)\n",
       "        1    0.000    0.000    0.205    0.205 <ipython-input-46-f115cb93ab3a>:16(get_valid_systems)\n",
       "        9    0.000    0.000    0.000    0.000 <ipython-input-29-6b0f59a80c87>:51(get_system_type)\n",
       "        1    0.000    0.000    0.000    0.000 weakref.py:356(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 weakref.py:408(__setitem__)\n",
       "        2    0.000    0.000    0.000    0.000 re.py:271(_compile)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _hashlib.new}\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_sha256}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:563(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 inference.py:406(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 dtypes.py:244(_from_values_or_dtype)\n",
       "       24    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_float64}\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1024(to_native_types)\n",
       "       12    0.000    0.000    0.000    0.000 base.py:4698(_validate_indexer)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:5399(<listcomp>)\n",
       "        1    0.000    0.000    0.032    0.032 frame.py:6310(apply)\n",
       "        4    0.000    0.000    0.000    0.000 blocks.py:2011(should_store)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:694(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:1868(_interleaved_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1926(close)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:305(<dictcomp>)\n",
       "        1    0.000    0.000    0.044    0.044 connections.py:401(_send_autocommit_mode)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:48(_my_crypt)\n",
       "       11    0.000    0.000    0.000    0.000 langhelpers.py:56(__init__)\n",
       "        1    0.000    0.000    0.038    0.038 langhelpers.py:1440(go)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2340(literal_column)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:709(in_transaction)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:875(is_valid)\n",
       "        4    0.000    0.000    0.000    0.000 default.py:409(type_descriptor)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2296(_compat_first)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:147(encode)\n",
       "       21    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:284(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:526(__new__)\n",
       "        4    0.000    0.000    0.000    0.000 socket.py:97(_intenum_converter)\n",
       "        3    0.000    0.000    0.000    0.000 socket.py:416(close)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_int8}\n",
       "        2    0.000    0.000    0.000    0.000 _validators.py:325(validate_fillna_kwargs)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1787(na_op)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:1806(hasnans)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:5393(_trim_front)\n",
       "       11    0.000    0.000    0.000    0.000 sql.py:85(_process_parse_dates_argument)\n",
       "       20    0.000    0.000    0.000    0.000 cursors.py:76(_check_executed)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:361(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:54(collate)\n",
       "        3    0.000    0.000    0.001    0.000 elements.py:399(compile)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3944(_set_table)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4184(__new__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4340(_select_iterables)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2120(__init__)\n",
       "        1    0.000    0.000    0.071    0.071 default.py:452(connect)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:399(process)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1318(_generate_generic_binary)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:2082(<listcomp>)\n",
       "       11    0.000    0.000    0.000    0.000 result.py:760(keys)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'split' of 're.Pattern' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _operator.and_}\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:186(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:358(remove)\n",
       "        3    0.000    0.000    0.000    0.000 hashlib.py:139(__hash_new)\n",
       "        6    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:36(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'put' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 config.py:170(get_default_val)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_int16}\n",
       "        7    0.000    0.000    0.000    0.000 cast.py:1112(<genexpr>)\n",
       "       10    0.000    0.000    0.000    0.000 base.py:2238(_get_reconciled_name_object)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:789(show_row_idx_names)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:816(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 format.py:1434(_has_names)\n",
       "        2    0.000    0.000    0.000    0.000 construction.py:509(sanitize_index)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:396(__iter__)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:39(<listcomp>)\n",
       "        3    0.000    0.000    0.001    0.000 elements.py:464(_compiler)\n",
       "        4    0.000    0.000    0.000    0.000 elements.py:4544(_literal_as_binds)\n",
       "        2    0.000    0.000    0.000    0.000 sqltypes.py:411(__init__)\n",
       "        1    0.000    0.000    0.038    0.038 attr.py:291(__call__)\n",
       "        1    0.000    0.000    0.071    0.071 strategies.py:106(connect)\n",
       "        1    0.000    0.000    0.005    0.005 base.py:914(scalar)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:834(visit_column)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1261(visit_binary)\n",
       "        1    0.000    0.000    0.109    0.109 base.py:425(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:901(close)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:1146(_fetchone_impl)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2309(_get_default_schema_name)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2809(_detect_ansiquotes)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:2906(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 pymysql.py:51(supports_server_side_cursors)\n",
       "        1    0.000    0.000    0.002    0.002 apply.py:302(wrap_results)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:323(series_generator)\n",
       "        1    0.000    0.000    0.002    0.002 apply.py:336(wrap_results_for_axis)\n",
       "        9    0.000    0.000    0.000    0.000 <ipython-input-29-6b0f59a80c87>:14(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
       "       11    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "       43    0.000    0.000    0.000    0.000 {method '_is_owned' of '_thread.RLock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1433(<setcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:96(_showwarnmsg)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:419(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 inspect.py:72(isclass)\n",
       "       12    0.000    0.000    0.000    0.000 parse.py:98(_noop)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:406(_decref_socketios)\n",
       "        3    0.000    0.000    0.000    0.000 apply.py:89(columns)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:101(dtypes)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:105(agg_axis)\n",
       "        1    0.000    0.000    0.000    0.000 console.py:90(in_interactive_session)\n",
       "        2    0.000    0.000    0.000    0.000 cast.py:552(coerce_indexer_dtype)\n",
       "        7    0.000    0.000    0.000    0.000 cast.py:1100(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1447(_align_method_SERIES)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:138(_freeze)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:606(_info_repr)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:4710(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:637(_set_axis)\n",
       "        4    0.000    0.000    0.002    0.001 indexing.py:148(_slice)\n",
       "        4    0.000    0.000    0.000    0.000 indexing.py:2700(need_slice)\n",
       "        6    0.000    0.000    0.000    0.000 blocks.py:146(is_categorical_astype)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:524(fillna)\n",
       "        5    0.000    0.000    0.000    0.000 managers.py:1045(value_getitem)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:163(is_s3_url)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:3735(reindex)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:897(close)\n",
       "        6    0.000    0.000    0.000    0.000 parsers.py:1195(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1536(_make_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1814(_do_date_conversions)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1936(_set_noconvert_columns)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3195(_process_date_conversion)\n",
       "        2    0.000    0.000    0.000    0.000 charset.py:43(by_name)\n",
       "        1    0.000    0.000    0.044    0.044 connections.py:383(autocommit)\n",
       "       20    0.000    0.000    0.000    0.000 protocol.py:208(is_load_local_packet)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:733(__missing__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:755(unique_list)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2455(_from_objects)\n",
       "        6    0.000    0.000    0.000    0.000 elements.py:3941(_get_table)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4345(<listcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 type_api.py:60(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:276(_memoized_attr__exec_once_mutex)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:270(_type_memos)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:708(default_from)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1758(_add_to_result_map)\n",
       "       11    0.000    0.000    0.000    0.000 default.py:1089(handle_dbapi_exception)\n",
       "        3    0.000    0.000    0.000    0.000 <ipython-input-28-01a4bf55ac48>:9(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:2407(_supports_cast)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2902(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:16(frame_apply)\n",
       "        2    0.000    0.000    0.000    0.000 <ipython-input-28-01a4bf55ac48>:14(corpus_config)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:20(_showwarnmsg_impl)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:180(search)\n",
       "        1    0.000    0.000    0.000    0.000 linecache.py:15(getline)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1361(debug)\n",
       "        1    0.000    0.000    0.003    0.003 apply.py:97(values)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(is_platform_windows)\n",
       "       10    0.000    0.000    0.000    0.000 dtypes.py:555(categories)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:1140(to_numpy)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:5337(get_values)\n",
       "        2    0.000    0.000    0.000    0.000 range.py:184(_get_data_as_items)\n",
       "        2    0.000    0.000    0.000    0.000 blocks.py:364(fillna)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:226(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.internals.slice_len}\n",
       "        9    0.000    0.000    0.000    0.000 managers.py:1041(value_getitem)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:785(has_column_names)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:737(__array_prepare__)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1176(_is_index_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1329(_validate_parse_dates_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2064(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2066(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 converters.py:12(escape_item)\n",
       "        1    0.000    0.000    0.000    0.000 converters.py:47(escape_bool)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:389(get_autocommit)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:759(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:681(self_group)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3950(_from_objects)\n",
       "        1    0.000    0.000    0.000    0.000 operators.py:1399(is_boolean)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:521(_gen_dialect_impl)\n",
       "        3    0.000    0.000    0.000    0.000 <string>:1(cast)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:410(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:872(visit_collation)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:890(escape_literal_column)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1168(_get_operator_dispatch)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:3579(format_collation)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:3598(format_label)\n",
       "        1    0.000    0.000    0.000    0.000 impl.py:142(_inc_overflow)\n",
       "        2    0.000    0.000    0.000    0.000 result.py:1306(scalar)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1778(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 mysqldb.py:214(_detect_charset)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:332(result_columns)\n",
       "        8    0.000    0.000    0.000    0.000 csvs.py:112(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'split' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'issuperset' of 'set' objects}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'union' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method gc.get_referents}\n",
       "        1    0.000    0.000    0.000    0.000 {function SocketIO.close at 0x109089e18}\n",
       "        1    0.000    0.000    0.000    0.000 linecache.py:37(getlines)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'timestamp' of 'datetime.datetime' objects}\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:93(index)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        2    0.000    0.000    0.000    0.000 config.py:578(_get_registered_option)\n",
       "        8    0.000    0.000    0.000    0.000 dtypes.py:562(ordered)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:1105(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:3867(_has_complex_internals)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:1818(__iter__)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:1904(__array__)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:604(is_mixed_type)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:1884(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:351(should_show_dimensions)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:781(has_index_names)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:347(_validate_integer)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:939(_check_file_or_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3278(_clean_na_values)\n",
       "        1    0.000    0.000    0.000    0.000 charset.py:40(by_id)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:101(lenenc_int)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:96(pack_int24)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:74(_makefile)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:946(_get_auth_plugin_handler)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:964(character_set_name)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:4(byte2int)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:60(get_all_data)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:142(read_string)\n",
       "       23    0.000    0.000    0.000    0.000 _collections.py:145(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:730(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:1271(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:3098(_from_objects)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4559(_interpret_as_column_or_from)\n",
       "        1    0.000    0.000    0.000    0.000 operators.py:1376(is_comparison)\n",
       "        3    0.000    0.000    0.000    0.000 type_api.py:307(_has_column_expression)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:177(__enter__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:352(__str__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:419(type)\n",
       "        1    0.000    0.000    0.109    0.109 base.py:296(_create_connection)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1350(get_select_precolumns)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2381(_is_mariadb)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2385(_is_mysql)\n",
       "       11    0.000    0.000    0.000    0.000 {method 'with_traceback' of 'BaseException' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:117(_formatwarnmsg)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:232(compile)\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:394(_checknetloc)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.000    0.000 inference.py:160(is_file_like)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:1097(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:1107(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 ops.py:1832(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:1785(_isnan)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:4077(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:7600(_get_agg_axis)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:112(_validate_header_arg)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:171(is_gcs_url)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:377(_validate_names)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1162(_create_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1274(_validate_usecols_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1423(_has_complex_date_col)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:1530(_maybe_make_multi_index_columns)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3157(_make_date_converter)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:11(int2byte)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:196(is_auth_switch_request)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3002(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3663(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:340(for_modify)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2080(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2367(_warn_for_known_db_issues)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:328(result_index)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "def main():\n",
    "    '''\n",
    "        corpora: i2b2, mipacq, fv017\n",
    "        analyses: entity only (exact span), cui by document, full (aka (entity and cui on exaact span/exact cui)\n",
    "        systems: ctakes, biomedicus, clamp, metamap, quick_umls\n",
    "        \n",
    "        TODO -> Vectorization (entity only) -> done:\n",
    "                add switch for use of TN on single system performance evaluations -> done\n",
    "                add switch for overlap matching versus exact span -> done\n",
    "             -> Other tasks besides concept extraction\n",
    "        \n",
    "    ''' \n",
    "    analysisConf =  AnalysisConfig()\n",
    "    print(analysisConf.systems, analysisConf.corpus_config())\n",
    "    \n",
    "    if (rtype == 1):\n",
    "        print(semtypes, systems)\n",
    "        if filter_semtype:\n",
    "            for semtype in semtypes:\n",
    "                test = get_valid_systems(systems, semtype)\n",
    "                print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "                generate_metrics(analysis_type, corpus, filter_semtype, semtype)\n",
    "            \n",
    "        else:\n",
    "            generate_metrics(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    elif (rtype == 2):\n",
    "        print('run_type:', run_type)\n",
    "        if filter_semtype:\n",
    "            print(semtypes)\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype)\n",
    "    elif (rtype == 3):\n",
    "        t = ['concept_jaccard_score_false']\n",
    "        test_systems(analysis_type, analysisConf.systems, corpus)  \n",
    "        test_count(analysis_type, corpus)\n",
    "        test_ensemble(analysis_type, corpus)\n",
    "    elif (rtype == 4):\n",
    "        if filter_semtype:\n",
    "            majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            majority_vote(systems, analysis_type, corpus, run_type, filter_semtype)\n",
    "    elif (rtype == 5):\n",
    "        \n",
    "        # control filter_semtype in get_sys_data, get_ref_n and generate_metrics. TODO consolidate. \n",
    "        # # run single ad hoc statement\n",
    "        statement = '((ctakes&biomedicus)|metamap)'\n",
    "\n",
    "        def add_hoc(analysis_type, corpus, statement):\n",
    "            sys = get_merge_data(statement, analysis_type, corpus, run_type, filter_semtype)\n",
    "            sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "            sys['label'] = 'concept'\n",
    "\n",
    "            ref = get_reference_vector(analysis_type, corpus, filter_semtype)\n",
    "            sys = vectorized_annotations(sys)\n",
    "            sys = np.asarray(flatten_list(list(sys)), dtype=np.int32)\n",
    "\n",
    "            return ref, sys\n",
    "\n",
    "        ref, sys = add_hoc(analysis_type, corpus, statement)\n",
    "        \n",
    "        # query by term:\n",
    "        \n",
    "        # import spacy\n",
    "        # nlp = spacy.load('en')\n",
    "\n",
    "        # sql = \"select distinct note_id, sofa from concepts.sofas where corpus = 'fairview'\"\n",
    "\n",
    "        # docs = pd.read_sql(sql, con=engine)\n",
    "\n",
    "        # d = {}\n",
    "\n",
    "        # for row in docs.itertuples():\n",
    "        #     d[row.note_id] = row.sofa\n",
    "\n",
    "        # print(len(d))\n",
    "\n",
    "        # test = matches[matches['note_id'] == '0000200926']\n",
    "        # print(len(test))\n",
    "\n",
    "        # doc = nlp(d['0000200926'])\n",
    "\n",
    "        # for row in test.itertuples():\n",
    "        #     my_str = [token.text.strip('\\n').lower() for token in doc if token.idx >= (row.begin) and token.idx <= (row.end)]\n",
    "        #     if 'diabetes' in my_str:\n",
    "        #         print(my_str)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    %prun main()\n",
    "    print('done!')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tests to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTS -> ensemble:\n",
    "# def test_match_consistency(matches, ref_only, ref_n, sys):\n",
    "#     \"\"\"test for reference only/match set consistency:\n",
    "#         params: match, system and reference only sets\"\"\"\n",
    "   \n",
    "#     print('len', len(sys), len(matches), len(matches.union(sys)), len(matches.intersection(sys)))\n",
    "#     assert len(matches.union(ref_only)) == ref_n, 'Reference annotation mismatch union'\n",
    "#     assert len(matches.intersection(sys)) == len(matches), 'System annotation mismatch intersect'\n",
    "#     assert len(matches.union(sys)) == len(sys), 'System annotation mismatch union'\n",
    "#     assert len(matches.intersection(ref_only)) == 0, 'Reference annotation mismatch intersect'\n",
    "\n",
    "# def test_systems(analysis_type, systems, corpus):\n",
    "#     sys = df_to_set(get_sys_data(systems[0], analysis_type, corpus), analysis_type)\n",
    "#     test_match_consistency(*get_system_matches(systems[0], analysis_type, corpus), get_ref_n(analysis_type), sys)\n",
    "#     print('Match consistency:', len(sys),get_ref_n(analysis_type))\n",
    "\n",
    "# def test_metrics(ref, sys_m, match_m):\n",
    "#     test = True\n",
    "#     reference_n = len(ref)\n",
    "#     system_n = len(sys_m)\n",
    "\n",
    "#     print('Test metrics:', type(reference_n), type(system_n), type(match_m))\n",
    "\n",
    "#     reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, match_m).get_ref_sys()\n",
    "#     F, recall, precision, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics()\n",
    "#     F_, recall_, precision_, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics(test)\n",
    "\n",
    "#     assert F[1] == F_, 'F1 issue'\n",
    "#     assert recall[1] == recall_, 'recall issue'\n",
    "#     assert precision[1] == precision_, 'precision issue'\n",
    "#     print(F[1], F_)\n",
    "#     print(recall[1], recall_)\n",
    "#     print(precision[1], precision_)\n",
    "\n",
    "# def test_count(analysis_type, corpus):\n",
    "#     # test match counts:\n",
    "#     ctakes, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     clamp, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "\n",
    "#     print('count:', len(mm.intersection(b9.intersection(clamp.intersection(ctakes)))))\n",
    "    \n",
    "# def test_ensemble(analysis_type, corpus):\n",
    "    \n",
    "#     print('ensemble:')\n",
    "#     # Get mixed system_n\n",
    "#     ref_ann, data = get_metric_data(analysis_type, corpus)\n",
    "\n",
    "#     names = ['ctakes', 'biomedicus', 'metamap', 'clamp']\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['begin', 'end', 'note_id']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['cui', 'note_id']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "#     biomedicus = data[data[\"system\"]=='biomedicus'][cols_to_keep].copy()\n",
    "#     ctakes = data[data[\"system\"]=='ctakes'][cols_to_keep].copy()\n",
    "#     clamp = data[data[\"system\"]=='clamp'][cols_to_keep].copy()\n",
    "#     metamap = data[data[\"system\"]=='metamap'][cols_to_keep].copy()\n",
    "#     quickumls = data[data[\"system\"]=='quick_umls'][cols_to_keep].copy()\n",
    "\n",
    "#     print('systems:', len(biomedicus), len(clamp), len(ctakes), len(metamap), len(quickumls))\n",
    "\n",
    "#     b9 = set()\n",
    "#     cl = set()\n",
    "#     ct = set()\n",
    "#     mm = set()\n",
    "#     qu = set()\n",
    "\n",
    "#     b9 = df_to_set(get_sys_data('biomedicus', analysis_type, corpus), analysis_type)\n",
    "#     print(len(b9))\n",
    "\n",
    "#     ct = df_to_set(get_sys_data('ctakes', analysis_type, corpus), analysis_type)\n",
    "#     print(len(ct))\n",
    "\n",
    "#     cl = df_to_set(get_sys_data('clamp', analysis_type, corpus), analysis_type)\n",
    "#     print(len(cl))\n",
    "\n",
    "#     mm = df_to_set(get_sys_data('metamap', analysis_type, corpus), analysis_type)\n",
    "#     print(len(mm))\n",
    "\n",
    "#     qu = df_to_set(get_sys_data('quick_umls', analysis_type, corpus), analysis_type)\n",
    "#     print(len(qu))\n",
    "    \n",
    "#     print('various merges:')\n",
    "#     print(len(b9), len(cl), len(ct), len(mm), len(qu))\n",
    "#     print(len(mm.intersection(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.union(ct)))))\n",
    "#     print(len(b9.intersection(ct)))\n",
    "\n",
    "#     sys_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('sys_m:', len(sys_m))\n",
    "\n",
    "#     # Get match merges:\n",
    "#     ct, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     cl, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "#     qu, _ = get_system_matches('quick_umls', analysis_type, corpus)\n",
    "\n",
    "#     match_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('match_m:', len(match_m))\n",
    "#     # reference df to set\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['end', 'start','file']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['value','file']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['end', 'start', 'value','file']\n",
    "\n",
    "#     ref = df_to_set(ref_ann[cols_to_keep], analysis_type, 'ref')\n",
    "\n",
    "#     print('ref:', len(ref))\n",
    "\n",
    "#     # test difference:\n",
    "#     print('FP:', len(sys_m - match_m), len(sys_m - ref))\n",
    "#     assert len(sys_m - match_m) == len(sys_m - ref), 'FP mismatch'\n",
    "#     print('FN:', len(ref - match_m), len(ref - sys_m))\n",
    "#     assert len(ref - match_m) == len(ref - sys_m), 'FN mismatch'\n",
    "    \n",
    "#     test_metrics(ref, sys_m, match_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
