{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Copyright (c) 2019 Regents of the University of Minnesota.\n",
    " \n",
    "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    " \n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import math\n",
    "import pymysql\n",
    "import time \n",
    "import functools as ft\n",
    "import glob   \n",
    "import operator as op\n",
    "import shelve\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, permutations\n",
    "from sqlalchemy.engine import create_engine\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from scipy import stats  \n",
    "from scipy.stats.mstats import gmean\n",
    "from pythonds.basic.stack import Stack\n",
    "from pythonds.trees.binaryTree import BinaryTree\n",
    "from collections import defaultdict\n",
    "from typing import List, Set, Tuple "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cell below contains the configurable parameters to ensure that our ensemble explorer runs properaly on your machine. Please read carfully through steps (1-7) before running the rest of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-1: CHOOSE YOUR CORPUS\n",
    "# TODO: allow for list of corpora\n",
    "corpus = 'i2b2' #options include 'fairview', 'mipacq' OR 'i2b2'\n",
    "\n",
    "# STEP-2: CHOOSE YOUR DATA DIRECTORY; this is where output data will be saved on your machine\n",
    "data_directory = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/' \n",
    "\n",
    "# STEP-3: CHOOSE WHICH SYSTEMS YOU'D LIKE TO PROCESS THE CORPUS\n",
    "\n",
    "systems = ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
    "\n",
    "# STEP-4: CHOOSE TYPE OF RUN\n",
    "rtype = 2      # OPTIONS INCLUDE: 1->Single systems; 2->Ensemble; 3->Tests; 4-> MM Test\n",
    "               # The Ensemble includes ['ctakes','biomedicus','clamp','metamap','quick_umls']\n",
    "    \n",
    "# STEP-5: CHOOSE WHAT TYPE OF ANALYSIS YOU'D LIKE TO RUN ON THE CORPUS\n",
    "analysis_type = 'entity' #options include 'entity' OR 'full'\n",
    "\n",
    "# STEP-(6A): ENTER DETAILS FOR ACCESSING MANUAL ANNOTATION DATA\n",
    "database_type = 'mysql+pymysql' # We use mysql+pymql as default\n",
    "database_username = 'gms'\n",
    "database_password = 'nej123' \n",
    "database_url = 'localhost' # HINT: use localhost if you're running database on your local machine\n",
    "database_name = 'concepts' # Enter database name\n",
    "table_name = corpus + '_all' # Enter the table within the database where your reference data is stored\n",
    "\n",
    "# STEP-(6B): ENTER DIRECTORY FOR ACCESSING SYSTEM ANNOTATION DATA\n",
    "system_annotation = 'analytical_'+corpus+'.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "\n",
    "# STEP-7: WE'LL CREATE A 'SYSTEM OUTPUT'DIRECTORY FOR YOU INSIDE THE DIRECTORY YOU SPECIFIED IN (STEP 2)\n",
    "single_sys_dir = Path(data_directory + \"single_system_out\")\n",
    "single_sys_dir.mkdir(parents=True, exist_ok=True)\n",
    "dir_out = Path(data_directory + 'single_system_out/')\n",
    "\n",
    "# STEP-8: CREATE A DB CONNECTION POOL\n",
    "engine_request = str(database_type)+'://'+database_username+':'+database_password+\"@\"+database_url+'/'+database_name\n",
    "engine = create_engine(engine_request, pool_pre_ping=True, pool_size=20, max_overflow=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config class for analysis\n",
    "class AnalysisConfig():\n",
    "    \"\"\"\n",
    "    Configuration object:\n",
    "    systems to use\n",
    "    notes by corpus\n",
    "    paths by output, gold and system location\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self = self    \n",
    "        self.systems = systems\n",
    "        self.data_dir = data_directory\n",
    "    \n",
    "    def corpus_config(self): \n",
    "        usys_data = system_annotation\n",
    "        ref_data = database_name+'.'+table_name\n",
    "        return usys_data, ref_data\n",
    "        \n",
    "\n",
    "analysisConf =  AnalysisConfig()\n",
    "usys, ref = analysisConf.corpus_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for systems\n",
    "class AnnotationSystems():\n",
    "    \"\"\"   \n",
    "    System annotations of interest for UMLS concept extraction\n",
    "    NB: ctakes combines all \"mentions\" annotation types\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"   \n",
    "        \n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\"]\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\"]\n",
    "        self.ctakes_types = ['ctakes_mentions']\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\"]\n",
    "        self.quick_umls_types = ['concept_jaccard_score_False']\n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "        \n",
    "        elif system == \"quick_umls\":\n",
    "            types = self.quick_umls_types\n",
    "            \n",
    "        return types, view\n",
    "    \n",
    "annSys = AnnotationSystems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np # access to Numpy from Python layer\n",
    "import math\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"\n",
    "    metrics class:\n",
    "    returns an instance with confusion matrix metrics\n",
    "    \"\"\"\n",
    "    def __init__(self, system_only, gold_only, gold_system_match, system_n, neither = 0): # neither: no sys or manual annotation\n",
    "\n",
    "        self = self    \n",
    "        self.system_only = system_only\n",
    "        self.gold_only = gold_only\n",
    "        self.gold_system_match = gold_system_match\n",
    "        self.system_n = system_n\n",
    "        self.neither = neither\n",
    "        \n",
    "    def get_confusion_metrics(self, corpus = None, test = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        compute confusion matrix measures, as per  \n",
    "        https://stats.stackexchange.com/questions/51296/how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\n",
    "        \"\"\"\n",
    "        cdef:\n",
    "            int TP, FP, FN\n",
    "            double TM\n",
    "\n",
    "        TP = self.gold_system_match\n",
    "        FP = self.system_only\n",
    "        FN = self.gold_only\n",
    "        \n",
    "        TM = TP/math.sqrt(self.system_n) # TigMetric\n",
    "       \n",
    "        if not test:\n",
    "            \n",
    "            if corpus == 'casi':\n",
    "                recall = TP/(TP + FN)\n",
    "                precision = TP/(TP + FP)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "            else:\n",
    "                if self.neither == 0:\n",
    "                    confusion = [[0, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                else:\n",
    "                    confusion = [[self.neither, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                c = np.asarray(confusion)\n",
    "                recall = np.diag(c) / np.sum(c, axis = 1)\n",
    "                precision = np.diag(c) / np.sum(c, axis = 0)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            F = 2*(precision*recall)/(precision + recall)\n",
    "        \n",
    "        # Tignanelli Metric\n",
    "        if FN == 0:\n",
    "            TP_FN_R = TP\n",
    "        elif FN > 0:\n",
    "            TP_FN_R = TP/FN\n",
    " \n",
    "        return F, recall, precision, TP, FP, FN, TP_FN_R, TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out(name: str, analysis_type: str, c: object):\n",
    "   \n",
    "    \"\"\"\n",
    "    write matching and reference-only sets to file for use in merging combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    # write output to file\n",
    "    dir_out = analysisConf.data_dir + 'single_system_out/'\n",
    "    with open(dir_out + name + '_' + analysis_type + '_' + c.corpus + '_matches.txt', 'w') as f:\n",
    "        for item in list(c.matches):\n",
    "            f.write(\"%s\\n\" % str(item))\n",
    "\n",
    "    # write to file\n",
    "    with open(dir_out + name + '_' + analysis_type + '_' + c.corpus + '_ref_only.txt', 'w') as f:\n",
    "        for item in list(c.false_negatives):\n",
    "            f.write(\"%s\\n\" % str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_set(df, analysis_type = 'entity', df_type = 'sys', corpus = None):\n",
    "    \n",
    "    # get values for creation of series of type tuple\n",
    "    if 'entity' in analysis_type: \n",
    "        if corpus == 'casi':\n",
    "            arg = df.case, df.overlap\n",
    "        else:    \n",
    "            if df_type == 'sys':\n",
    "                arg = df.begin, df.end, df.note_id\n",
    "            else:\n",
    "                arg = df.start, df.end, df.file\n",
    "            \n",
    "    elif 'cui' in analysis_type:\n",
    "        if df_type == 'sys':\n",
    "            arg = df.cui, df.note_id\n",
    "        else:\n",
    "            arg = df.value, df.file\n",
    "    elif 'full' in analysis_type:\n",
    "        if df_type == 'sys':\n",
    "            arg = df.begin, df.end, df.cui, df.note_id\n",
    "        else:\n",
    "            arg = df.start, df.end, df.value, df.file\n",
    "    \n",
    "    return set(list(zip(*arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "\n",
    "from __main__ import write_out, df_to_set, engine\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "def get_cooccurences(ref, sys, analysis_type: str, corpus: str, single_sys = True, name = None):\n",
    "    \"\"\"\n",
    "    get coocurences between system and reference; exact match; TODO: add relaxed\n",
    "    \"\"\"\n",
    "    # cooccurences\n",
    "    class Coocurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = set()\n",
    "            self.false_negatives = set()\n",
    "            self.corpus = corpus\n",
    "            self.cases = set(ref[\"file\"].tolist()) # cases to label \n",
    "\n",
    "    c = Coocurences()\n",
    "    \n",
    "    if corpus != 'casi':\n",
    "        if 'entity' in analysis_type and single_sys: # mipacq n -> 16793\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            ref = ref[['start', 'end', 'file']].drop_duplicates()\n",
    "            sys.name = name\n",
    "        elif 'cui' in analysis_type and single_sys: # mipacq n -> 10799\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            # do not overestimate FP\n",
    "            sys = sys[~sys['cui'].isnull()] \n",
    "            ref = ref[['value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "            sys.name = name\n",
    "        elif 'full' in analysis_type and single_sys: # mipacq n -> 17393\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            sys = sys[~sys['cui'].isnull()]\n",
    "            ref = ref[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "            sys.name = name\n",
    "\n",
    "        # matches via inner join\n",
    "        matches = pd.merge(sys, ref, how = 'inner', left_on=['begin','end','note_id'], right_on = ['start','end','file']) \n",
    "        # reference-only via left outer join\n",
    "        fn = pd.merge(ref, sys, how = 'left', left_on=['start','end','file'], right_on = ['begin','end','note_id']) \n",
    "\n",
    "        fn = fn[fn['begin'].isnull()] # get as outer join with no match\n",
    "\n",
    "        if 'entity' in analysis_type and single_sys:\n",
    "            cols_to_keep = ['start', 'end', 'file']\n",
    "        else:\n",
    "            cols_to_keep = ['start', 'end', 'value', 'file']\n",
    "\n",
    "        matches = matches[cols_to_keep]\n",
    "        fn = fn[cols_to_keep]\n",
    "\n",
    "        # use for metrics \n",
    "        c.matches = c.matches.union(df_to_set(matches, analysis_type, 'ref'))\n",
    "        c.false_negatives = c.false_negatives.union(df_to_set(fn, analysis_type, 'ref'))\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        c.ref_only = len(c.false_negatives)\n",
    "        \n",
    "    else:\n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where overlap = 1 and `system` = %(sys.name)s\"  \n",
    "        \n",
    "        matches = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where (overlap = 0 or overlap is null) and `system` = %(sys.name)s\"  \n",
    "        \n",
    "        fn = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        c.matches = df_to_set(matches, 'entity', 'sys', 'casi')\n",
    "        c.fn = df_to_set(fn, 'entity', 'sys', 'casi')\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(matches) + len(fn)\n",
    "        c.ref_n = len(matches) + len(fn)\n",
    "        c.ref_only = len(fn)\n",
    "        \n",
    "    # sanity check\n",
    "    if len(ref) - c.ref_system_match < 0:\n",
    "        print('Error: ref_system_match > len(ref)!')\n",
    "    if len(ref) != c.ref_system_match + c.ref_only:\n",
    "        print('Error: ref count mismatch!')\n",
    "   \n",
    "    # save TP/FN\n",
    "    if single_sys and corpus != 'casi':\n",
    "        print(analysis_type)\n",
    "        write_out(sys.name, analysis_type, c)\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython \n",
    "\n",
    "#from __main__ import write_out\n",
    "\n",
    "#import numpy as np # access to Numpy from Python layer\n",
    "def label_vector(doc: str, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    #print(ann, doc, labels)\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.begin, a.end) for a in ann if a.label == lab]\n",
    "            \n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v\n",
    "\n",
    "# test confusion matrix elements for vectorized annotation set; includes TN\n",
    "def confused(sys1, ann1):\n",
    "    TP = np.sum(np.logical_and(sys1 >= 1, ann1 == sys1 ))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(sys1 == 0, ann1 == 0))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(sys1 >= 1, ann1 == 0))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(sys1 == 0, ann1 >= 1))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "def get_cooccurences_vec(ref, sys, analysis_type: str, corpus: str, single_sys = True, name = None):\n",
    "    \"\"\"\n",
    "    get coocurences between system and reference; exact match; TODO: add relaxed\n",
    "    \"\"\"\n",
    "    # test cooccurences\n",
    "    class Coocurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = set()\n",
    "            self.false_negatives = set()\n",
    "            self.corpus = corpus\n",
    "            self.cases = set(ref[\"file\"].tolist()) # cases to label \n",
    "\n",
    "    c = Coocurences()\n",
    "    \n",
    "    # vectorization and i-o labeling\n",
    "    def test_io():\n",
    "        test = c.cases\n",
    "        if analysis_type == 'entity':\n",
    "            docs = [(x, len(open(\"/Users/gms/development/nlp/nlpie/data/ensembling-u01/i2b2/source_data/test_data/\" + x + \".txt\", 'r').read())) for x in test]\n",
    "\n",
    "        ann = ref.copy()\n",
    "        ann = ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"}).copy()\n",
    "        cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "        if analysis_type == 'entity':\n",
    "            labels = [\"concept\"]\n",
    "            ann[\"label\"] = 'concept'\n",
    "            ann = ann[cols_to_keep].copy()\n",
    "\n",
    "        sys_ = sys.rename(index=str, columns={\"note_id\": \"case\"}).copy()\n",
    "        \n",
    "        # need for enttity-only\n",
    "        if analysis_type == 'entity':\n",
    "            sys_[\"label\"] = 'concept'\n",
    "        \n",
    "        sys_ = sys_[cols_to_keep]\n",
    "       \n",
    "        tp = []\n",
    "        tn = []\n",
    "        fp = []\n",
    "        fn = []\n",
    "        cvals = []\n",
    "        out = []\n",
    "        t = []\n",
    "        d = defaultdict(list)\n",
    "        \n",
    "        for n in range(len(docs)):\n",
    "            a1 = [i for i in ann[ann[\"case\"] == docs[n][0]].copy().itertuples(index=False)]\n",
    "            s1 = [i for i in sys_[sys_[\"case\"] == docs[n][0]].copy().itertuples(index=False)]\n",
    "\n",
    "            ann1 = label_vector(docs[n][1], a1, labels)\n",
    "            sys1 = label_vector(docs[n][1], s1, labels)\n",
    "            \n",
    "            TP, TN, FP, FN = confused(sys1, ann1)\n",
    "            cvals.append([TP, TN, FP, FN])\n",
    "                 \n",
    "            d['sys'].append(list([int(i) for i in sys1]))\n",
    "            d['oracle'].append(list([int(i) for i in ann1]))\n",
    "            d['case'].append(docs[n][0])\n",
    "            \n",
    "            '''\n",
    "            print(\"tn:\", np.intersect1d(np.where(ann1 == 0)[0], np.where(sys1 == 0)[0]),  \n",
    "                  \"tp:\", np.intersect1d(np.where(ann1 == 1)[0], np.where(sys1 == 1)[0]), \n",
    "                  \"fn:\", np.intersect1d(np.where(ann1 == 1)[0], np.where(sys1 == 0)[0]), \n",
    "                  \"fp:\", np.intersect1d(np.where(ann1 == 0)[0], np.where(sys1 == 1)[0]))\n",
    "            '''\n",
    "        d['labels'] = labels\n",
    "        \n",
    "        corp = shelve.open('/Users/gms/Desktop/' + sys.name + '_' + corpus + '.dat')\n",
    "        \n",
    "        for k in d:\n",
    "            corp[k] = d[k]\n",
    "        \n",
    "        corp.close()\n",
    "        return cvals\n",
    "    \n",
    "    if corpus == 'i2b2':\n",
    "        TP, TN, FP, FN = np.sum(test_io(), axis=0)\n",
    "        F, recall, precision, TP, FP, FN, TP_FN_R, TM = Metrics(FP, FN, TP, len(sys), TN).get_confusion_metrics() #no TN\n",
    "        print('test_io():', TP, TN, FP, FN, np.mean(F), np.mean(recall), np.mean(precision))\n",
    "    \n",
    "    # non-vectorized:\n",
    "    if corpus != 'casi':\n",
    "        if 'entity' in analysis_type and single_sys: # mipacq n -> 16793\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            ref = ref[['start', 'end', 'file']].drop_duplicates()\n",
    "            sys.name = name\n",
    "        elif 'cui' in analysis_type and single_sys: # mipacq n -> 10799\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            # do not overestimate FP\n",
    "            sys = sys[~sys['cui'].isnull()] \n",
    "            ref = ref[['value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "            sys.name = name\n",
    "        elif 'full' in analysis_type and single_sys: # mipacq n -> 17393\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            sys = sys[~sys['cui'].isnull()]\n",
    "            ref = ref[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "            sys.name = name\n",
    "\n",
    "        # matches via inner join\n",
    "        matches = pd.merge(sys, ref, how = 'inner', left_on=['begin','end','note_id'], right_on = ['start','end','file']) \n",
    "        # reference-only via left outer join\n",
    "        fn = pd.merge(ref, sys, how = 'left', left_on=['start','end','file'], right_on = ['begin','end','note_id']) \n",
    "\n",
    "        fn = fn[fn['begin'].isnull()] # get as outer join with no match\n",
    "\n",
    "        if 'entity' in analysis_type and single_sys:\n",
    "            cols_to_keep = ['start', 'end', 'file']\n",
    "        else:\n",
    "            cols_to_keep = ['start', 'end', 'value', 'file']\n",
    "\n",
    "        matches = matches[cols_to_keep]\n",
    "        fn = fn[cols_to_keep]\n",
    "\n",
    "        # use for metrics \n",
    "        c.matches = c.matches.union(df_to_set(matches, analysis_type, 'ref'))\n",
    "        c.false_negatives = c.false_negatives.union(df_to_set(fn, analysis_type, 'ref'))\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        c.ref_only = len(c.false_negatives)\n",
    "        \n",
    "    else:\n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where overlap = 1 and `system` = %(sys.name)s\"  \n",
    "        \n",
    "        matches = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where (overlap = 0 or overlap is null) and `system` = %(sys.name)s\"  \n",
    "        \n",
    "        fn = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        c.matches = df_to_set(matches, 'entity', 'sys', 'casi')\n",
    "        c.fn = df_to_set(fn, 'entity', 'sys', 'casi')\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(matches) + len(fn)\n",
    "        c.ref_n = len(matches) + len(fn)\n",
    "        c.ref_only = len(fn)\n",
    "        \n",
    "    # sanity check\n",
    "    if len(ref) - c.ref_system_match < 0:\n",
    "        print('Error: ref_system_match > len(ref)!')\n",
    "    if len(ref) != c.ref_system_match + c.ref_only:\n",
    "        print('Error: ref count mismatch!')\n",
    "   \n",
    "    # save TP/FN\n",
    "    if single_sys and corpus != 'casi':\n",
    "        print(analysis_type)\n",
    "        write_out(sys.name, analysis_type, c)\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging test for i-o labeled data\n",
    "import numpy as np\n",
    "import shelve\n",
    "# load shelve\n",
    "def read_shelve():\n",
    "    corp = shelve.open('/Users/gms/Desktop/test.dat')\n",
    "\n",
    "    return corp\n",
    "        \n",
    "#test = read_shelve()\n",
    "\n",
    "def test_merge_vector(test):\n",
    "    # get sample for testing\n",
    "    for case in test['case'][3:5]:\n",
    "        for i in range(len(test['case'][3:5])):\n",
    "            if i == 3:\n",
    "                t0 = test['oracle'][3][0:750]\n",
    "            else:\n",
    "                t1 = test['oracle'][4][0:750]\n",
    "\n",
    "            #print('case:', case, test['sys'][i], test['oracle'][i], confused(np.array(test['sys'][i]), np.array(test['oracle'][i])))\n",
    "        #print(t0, t1)\n",
    "\n",
    "    t0 = np.array(test['oracle'][3][0:750])\n",
    "    t1 = np.array(test['oracle'][5][0:750])\n",
    "\n",
    "    l0 = list(t0)\n",
    "    l1 = list(t1)\n",
    "    \n",
    "    l0 = [0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0] \n",
    "    l1 = [0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
    "    \n",
    "    print(l0, l1)\n",
    "\n",
    "    def intersection(lst1, lst2): \n",
    "        out = list()\n",
    "        if isinstance(lst1, set) and isinstance(lst2, set):\n",
    "            out = (set(lst1) & set(lst2))\n",
    "        elif isinstance(lst1, set) and isinstance(lst2, np.int64):\n",
    "            out = (set(lst1) & set([lst2]))\n",
    "        elif isinstance(lst1, np.int64) and isinstance(lst2, set):\n",
    "            out = (set([lst1]) & set(lst2))\n",
    "        elif isinstance(lst1, np.int64) and isinstance(lst2, np.int64):\n",
    "            out = (set([lst1]) & set([lst2]))\n",
    "        #if len(out) > 1:\n",
    "        return out\n",
    "        #elif len(out) == 1:\n",
    "        #    return out[0]\n",
    "        #else:\n",
    "        #    return 0\n",
    "\n",
    "    def union(lst1, lst2): \n",
    "        out = list()\n",
    "        if isinstance(lst1, set) and isinstance(lst2, set):\n",
    "            out = set(lst1) | set(lst2)\n",
    "        elif isinstance(lst1, set) and isinstance(lst2, np.int64):\n",
    "            out = set(lst1) | set([lst2])\n",
    "        elif isinstance(lst1, np.int64) and isinstance(lst2, set):\n",
    "            out = set([lst1]) | set(lst2)\n",
    "        elif isinstance(lst1, np.int64) and isinstance(lst2, np.int64):\n",
    "            out = set([lst1]) | set([lst2])\n",
    "        #if len(out) == 1:\n",
    "        #    #out = out[0]\n",
    "        return out\n",
    "\n",
    "    # union and intersect\n",
    "    def umerges(l0, l1):\n",
    "        #un = [0]*len(l0)\n",
    "        #for i in range(len(l0)):\n",
    "        #    un[i] = union(l0[i], l1[i])\n",
    "\n",
    "        return [union(l0[i], l1[i]) for i in range(len(l0))]\n",
    "\n",
    "    %timeit un = umerges(l0, l1)\n",
    "    \n",
    "    x = umerges(l0, l1)\n",
    "    \n",
    "\n",
    "    #l2 = [1, {1, 4}, {3}, {2, 4}, {1}, 0, 2, 3, {0, 8}, {1, 8}]\n",
    "    \n",
    "    #print(umerges(x, l2))\n",
    "    \n",
    "    def imerges(l0, l1):\n",
    "        #inter = [0]*len(l0)\n",
    "        #for i in range(len(l0)):\n",
    "        \n",
    "\n",
    "        return [intersection(l0[i], l1[i]) for i in range(len(l0))]\n",
    "    \n",
    "    %timeit x = imerges(l0, l1)\n",
    "    \n",
    "    '''\n",
    "    union = [\n",
    "        ( [set(x) | set(y)] if isinstance(x, list) and isinstance(y, list)\n",
    "          else [set(x) | set([y])] if isinstance(x, list) and isinstance(y, int)\n",
    "          else [set([x]) | set(y)] if isinstance(x, int) and isinstance(y, list)\n",
    "          else [set([x]) | set([y])])\n",
    "\n",
    "         for x, y in zip(l0, l1)\n",
    "    ]\n",
    "\n",
    "    # unpack map object\n",
    "    #*y, = list(map(list, zip(*union)))\n",
    "    #%timeit list(map(list, zip(*union)))\n",
    "\n",
    "    intersection = [\n",
    "        ( [set(x) & set(y)] if isinstance(x, list) and isinstance(y, list)\n",
    "          else [set(x) & set([y])] if isinstance(x, list) and isinstance(y, int)\n",
    "          else [set([x]) & set(y)] if isinstance(x, int) and isinstance(y, list)\n",
    "          else [set([x]) & set([y])])\n",
    "          for x, y in zip(l0, l1)\n",
    "\n",
    "    ]\n",
    "\n",
    "    #*x, = list(map(list, zip(*intersection)))\n",
    "    #%timeit list(map(list, zip(*intersection)))\n",
    "    '''\n",
    "#test_merge_vector(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blah -=\n",
    "# https://kawahara.ca/how-to-compute-truefalse-positives-and-truefalse-negatives-in-python-for-binary-classification-problems/\n",
    "def confusing(sys1, ann1):\n",
    "    TP = np.sum(np.logical_and(sys1 == 1, ann1 == sys1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(sys1 == 0, ann1 == 0))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(sys1 == 1, ann1 == 0))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(np.logical_or(sys1 == 0, sys1 is None), ann1 == 1))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "#%%cython\n",
    "#import numpy as np # access to Numpy from Python layer\n",
    "#import time\n",
    "#from __main__ import read_shelve\n",
    "def imerge(l0, l1):\n",
    "\n",
    "    return [\n",
    "        ( [\n",
    "            set(x) & set(y)] if isinstance(x, list) and  isinstance(y, list)\n",
    "            else [set(x) & set([y])] if isinstance(x, list) and  isinstance(y, np.int64)\n",
    "            else [set(x) & y] if isinstance(x, list) and isinstance(y, set)\n",
    "            else [x & y] if isinstance(x, set) and isinstance(y, set)\n",
    "            else [x & set(y)] if isinstance(x, set) and isinstance(y, list)\n",
    "            else [x & set([y])] if isinstance(x, set) and isinstance(y, np.int64)\n",
    "            else [set([x]) & set(y)] if isinstance(x, np.int64) and  isinstance(y, list)\n",
    "            else [set([x]) & y] if isinstance(x, np.int64) and isinstance(y, set)\n",
    "            else [set([x]) & set([y])])\n",
    "        for x, y in zip(l0, l1)\n",
    "    ]\n",
    "\n",
    "def umerge(l0, l1):\n",
    "\n",
    "    return [\n",
    "        ( [\n",
    "            set(x) | set(y)] if isinstance(x, list) and  isinstance(y, list)\n",
    "            else [set(x) | set([y])] if isinstance(x, list) and  isinstance(y, np.int64)\n",
    "            else [set(x) | y] if isinstance(x, list) and isinstance(y, set)\n",
    "            else [x | y] if isinstance(x, set) and isinstance(y, set)\n",
    "            else [x | set(y)] if isinstance(x, set) and isinstance(y, list)\n",
    "            else [x | set([y])] if isinstance(x, set) and isinstance(y, np.int64)\n",
    "            else [set([x]) | y] if isinstance(x, np.int64) and isinstance(y, set)\n",
    "            else [set([x]) | set(y)] if isinstance(x, np.int64) and  isinstance(y, list)\n",
    "            else [set([x]) | set([y])])\n",
    "        for x, y in zip(l0, l1)\n",
    "    ]\n",
    "\n",
    "def imerge_int(l0, l1):\n",
    "    return [\n",
    "        ( [\n",
    "            set(x) & set(y)] if isinstance(x, list) and  isinstance(y, list)\n",
    "            else [set(x) & set([y])] if isinstance(x, list) and isinstance(y, int)\n",
    "            else [set(x) & y] if isinstance(x, list) and isinstance(y, set)\n",
    "            else [x & y] if isinstance(x, set) and isinstance(y, set)\n",
    "            else [x & set(y)] if isinstance(x, set) and isinstance(y, list)\n",
    "            else [x & set([y])] if isinstance(x, set) and isinstance(y, int)\n",
    "            else [set([x]) & set(y)] if isinstance(x, int) and  isinstance(y, list)\n",
    "            else [set([x]) & y] if isinstance(x, int) and isinstance(y, set)\n",
    "            else [set([x]) & set([y])])\n",
    "        for x, y in zip(l0, l1)\n",
    "    ]\n",
    "\n",
    "def umerge_int(l0, l1):\n",
    "    return [\n",
    "        ( [\n",
    "            set(x) | set(y)] if isinstance(x, list) and  isinstance(y, list)\n",
    "            else [set(x) | set([y])] if isinstance(x, list) and  isinstance(y, int)\n",
    "            else [set(x) | y] if isinstance(x, list) and isinstance(y, set)\n",
    "            else [x | y] if isinstance(x, set) and isinstance(y, set)\n",
    "            else [x | set(y)] if isinstance(x, set) and isinstance(y, list)\n",
    "            else [x | set([y])] if isinstance(x, set) and isinstance(y, int)\n",
    "            else [set([x]) | y] if isinstance(x, int) and isinstance(y, set)\n",
    "            else [set([x]) | set(y)] if isinstance(x, int) and  isinstance(y, list)\n",
    "            else [set([x]) | set([y])])\n",
    "        for x, y in zip(l0, l1)\n",
    "    ]\n",
    "\n",
    "def test_merge_shelve():\n",
    "    ctakes = shelve.open('/Users/gms/Desktop/ctakes_' + corpus + '.dat')\n",
    "    clamp = shelve.open('/Users/gms/Desktop/clamp_' + corpus + '.dat')\n",
    "    mm = shelve.open('/Users/gms/Desktop/metamap_' + corpus + '.dat')\n",
    "\n",
    "    print(test['case'][0:2])\n",
    "\n",
    "    #t0 = np.array(test['oracle'][3][0:750])\n",
    "    #t1 = np.array(test['oracle'][5][0:750])\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    sys = []\n",
    "    oracles = []\n",
    "    confuzz = []\n",
    "    for i in range(len(ctakes['case'])):\n",
    "        t0 = np.array(ctakes['sys'][i])\n",
    "        t1 = np.array(clamp['sys'][i])\n",
    "        t2 = np.array(mm['sys'][i])\n",
    "        oracle = np.array(ctakes['oracle'][i])\n",
    "\n",
    "        #print(ctakes['case'][i])\n",
    "\n",
    "        l0 = list(t0)\n",
    "        l1 = list(t1)\n",
    "        l2 = list(t2)\n",
    "\n",
    "        z = *map(list, zip(*umerge(l0, l1))),\n",
    "\n",
    "        #%time  *map(list, zip(*umerge(l0, l1))),\n",
    "        #%time  *map(list, zip(*umerge(z[0], l1))),\n",
    "\n",
    "        t = *map(list, zip(*umerge(z[0], l2))),\n",
    "\n",
    "        from functools import reduce \n",
    "        import itertools\n",
    "        import operator\n",
    "\n",
    "        test = [list(i) for i in t[0]]\n",
    "\n",
    "        replaced = [[none] if len(wd) == 0  else wd for wd in t[0]]\n",
    "\n",
    "        replaced = [[1] if wd == {0, 1}  else wd for wd in replaced]\n",
    "\n",
    "\n",
    "        sys.append(replaced)\n",
    "\n",
    "        tp, tn, fp, fn = confusing(np.array(list(itertools.chain.from_iterable(replaced))), oracle)\n",
    "\n",
    "        confuzz.append((tp, tn, fp, fn))\n",
    "        f, recall, precision, tp, fp, fn, tp_fn_r, tm = Metrics(fp, fn, tp, len(oracle), tn).get_confusion_metrics() #no tn\n",
    "    print(' --- ')\n",
    "\n",
    "    print(len(list(itertools.chain.from_iterable(oracles))), len(list(itertools.chain.from_iterable(sys))))\n",
    "    print(list(map(sum, zip(*confuzz))))\n",
    "    z = list(map(sum, zip(*confuzz)))\n",
    "    # tp, tn, fp, fn -> (fp, fn, tp, len(oracle), tn)\n",
    "    f, recall, precision, tp, fp, fn, tp_fn_r, tm = Metrics(z[2], z[3], z[0], len(list(itertools.chain.from_iterable(sys))), z[1]).get_confusion_metrics() #no tn\n",
    "    print('test_io():', tp, tn, fp, fn, np.mean(f), np.mean(recall), np.mean(precision))\n",
    "    elapsed = (time.perf_counter() - start)\n",
    "    print('time 1:', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metric_data(analysis_type: str, corpus: str):\n",
    "   \n",
    "    usys_file, ref_table = AnalysisConfig().corpus_config()\n",
    "    systems = AnalysisConfig().systems\n",
    "    \n",
    "    sys_ann = pd.read_csv(analysisConf.data_dir + usys_file, dtype={'note_id': str})\n",
    "    \n",
    "    sql = \"SELECT * FROM \" + ref_table  \n",
    "    \n",
    "    ref_ann = pd.read_sql(sql, con=engine)\n",
    "    sys_ann = sys_ann.drop_duplicates()\n",
    "    \n",
    "    return ref_ann, sys_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of 2.\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(analysis_type: str, corpus: str, single_sys = None):\n",
    "    start = time.time()\n",
    "\n",
    "    systems = AnalysisConfig().systems\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    ref_ann, sys_ann = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    for sys in systems:\n",
    "            types, _ = AnnotationSystems().get_system_type(sys) # system types for iterable\n",
    "            for t in types:\n",
    "                print(t)\n",
    "                system = pd.DataFrame()\n",
    "                \n",
    "                system_annotations = sys_ann.copy()\n",
    "                \n",
    "                system = system_annotations[system_annotations['type'] == str(t)]\n",
    "            \n",
    "                if sys == 'quick_umls':\n",
    "                    system = system[system.score.astype(float) >= .8]\n",
    "                \n",
    "                if sys == 'metamap':\n",
    "                    system = system[system.score.abs().astype(int) >= 800]\n",
    "                \n",
    "#                 if sys == 'biomedicus':\n",
    "#                     system = system[system.score.abs().astype(int) >= 0.6]\n",
    "            \n",
    "                system = system.drop_duplicates()\n",
    "                system.name = sys\n",
    "                \n",
    "                c = get_cooccurences(ref_ann, system, analysis_type, corpus, True, system.name) # get matches, FN, etc.\n",
    "                \n",
    "                print(c.ref_n, c.ref_only, c.system_n, c.system_only, c.ref_system_match)\n",
    "                \n",
    "            if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "                F, recall, precision, TP, FP, FN, TP_FN_R, TM = Metrics(c.system_only, c.ref_only, c.ref_system_match, c.system_n).get_confusion_metrics(corpus)\n",
    "                \n",
    "                if corpus == 'casi':\n",
    "                    if sys == 'biomedicus':\n",
    "                        t = 'biomedicus.v2.Acronym'\n",
    "                        \n",
    "                    d = {'system': sys, \n",
    "                         'type': t, \n",
    "                         'F': F, \n",
    "                         'precision': precision, \n",
    "                         'recall': recall, \n",
    "                         'FN': FN, \n",
    "                         'TP/FN': TP_FN_R,\n",
    "                         'n_gold': c.ref_n, \n",
    "                         'n_sys': c.system_n, \n",
    "                         'TM': TM}\n",
    "                else:\n",
    "                    d = {'system': sys, \n",
    "                         'type': t, \n",
    "                         'F': F[1], \n",
    "                         'precision': precision[1], \n",
    "                         'recall': recall[1], \n",
    "                         'TP': TP, \n",
    "                         'FN': FN, \n",
    "                         'FP': FP, \n",
    "                         'TP/FN': TP_FN_R,\n",
    "                         'n_gold': c.ref_n, \n",
    "                         'n_sys': c.system_n, \n",
    "                         'TM': TM}\n",
    "\n",
    "                data = pd.DataFrame(d,  index=[0])\n",
    "                metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "                metrics.drop_duplicates(keep='last', inplace=True)\n",
    "            else:\n",
    "                print(\"NO EXACT MATCHES FOR\", t)\n",
    "            elapsed = (time.time() - start)\n",
    "            print(\"elapsed:\", sys, elapsed)\n",
    "     \n",
    "    elapsed = (time.time() - start)\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    if single_sys is None:\n",
    "        file_name = 'metrics_'\n",
    "    \n",
    "    metrics.to_csv(analysisConf.data_dir + corpus + '_' + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "    \n",
    "    print(\"total elapsed time:\", elapsed) \n",
    "\n",
    "# use to iterate through mm scores\n",
    "def generate_metrics_mm(analysis_type: str, corpus: str, single_sys = None):\n",
    "    start = time.time()\n",
    "    #systems = [\"biomedicus\",\"ctakes\",\"metamap\",\"clamp\",\"quick_umls\"]\n",
    "    systems = AnalysisConfig().systems\n",
    "    #systems = [\"quick_umls\"]\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    ref_ann, sys_ann = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    sys_ann = sys_ann[(sys_ann.score.notnull()) & (sys_ann['system'] == 'metamap')]\n",
    "    sys_ann = sys_ann[['begin', 'end', 'note_id', 'system', 'score']].drop_duplicates()\n",
    "    sys_ann.score = sys_ann.score.astype(int)\n",
    "    \n",
    "    for sys in systems:\n",
    "        types, __ = AnnotationSystems().get_system_type(sys) # system types for iterable\n",
    "        for t in types:\n",
    "            print(t)\n",
    "\n",
    "            for i in range(500, 1050, 50): \n",
    "\n",
    "                sys_ann = sys_ann[(sys_ann[\"score\"] >= i)].copy()\n",
    "\n",
    "                sys_ann.name = sys + str(i)\n",
    "\n",
    "                c = get_cooccurences(ref_ann, sys_ann, analysis_type, corpus, True, sys_ann.name) # get matches, FN, etc.\n",
    "\n",
    "                print(c.ref_n, c.ref_only, c.system_n, c.system_only, c.ref_system_match)\n",
    "\n",
    "                #print(i, len(system))\n",
    "\n",
    "                if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "                    F, recall, precision, TP, FP, FN, TP_FN_R, TM = Metrics(c.system_only, c.ref_only, c.ref_system_match, c.system_n).get_confusion_metrics()\n",
    "                    d = {'system': sys + '_score_' + str(i), \n",
    "                         'type': t, \n",
    "                         'F': F[1], \n",
    "                         'precision': precision[1], \n",
    "                         'recall': recall[1], \n",
    "                         'TP': TP, \n",
    "                         'FN': FN, \n",
    "                         'FP': FP, \n",
    "                         'TP/FN': TP_FN_R,\n",
    "                         'n_gold': c.ref_n, \n",
    "                         'n_sys': c.system_n, \n",
    "                         'TM': TM}\n",
    "\n",
    "                    data = pd.DataFrame(d,  index=[0])\n",
    "                    metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "                    metrics.drop_duplicates(keep='last', inplace=True)\n",
    "                else:\n",
    "                    print(\"NO EXACT MATCHES FOR\", t)\n",
    "                elapsed = (time.time() - start)\n",
    "                print(\"elapsed:\", sys, elapsed)\n",
    "     \n",
    "    elapsed = (time.time() - start)\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    # UIMA or QuickUMLS\n",
    "    if single_sys is None:\n",
    "        file_name = 'mm_metrics_'\n",
    "    metrics.to_csv(analysisConf.data_dir + corpus + '_' + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "    \n",
    "    print(\"total elapsed time:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in system matches from file\n",
    "def get_ref_n(analysis_type: str, corpus) -> int:\n",
    "    \n",
    "    ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    if corpus == 'casi':\n",
    "        return len(ref_ann)\n",
    "        \n",
    "    else:\n",
    "        # do not overestimate fn\n",
    "        if 'entity' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'file']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type:\n",
    "            ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        elif 'full' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "        return ref_n\n",
    "\n",
    "def get_sys_data(system: str, analysis_type: str, corpus: str) -> pd.DataFrame:\n",
    "   \n",
    "    _, data = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    out = data[data['system'] == system].copy()\n",
    "    \n",
    "    if corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap'] \n",
    "        #cols_to_keep = ['case', 'begin', 'end'] \n",
    "        out = out[cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    else:\n",
    "        out = data[data['system']== system].copy()\n",
    "\n",
    "        if system == 'quick_umls':\n",
    "            out = out[(out.score.astype(float) >= 0.8) & (out[\"type\"] == 'concept_jaccard_score_False')]\n",
    "        \n",
    "        if system == 'metamap':\n",
    "            out = out[out.score.abs().astype(int) >= 800]\n",
    "        \n",
    "#         if system == 'biomedicus':\n",
    "#             out = out[out.score.abs().astype(int) >= 0.6]\n",
    "            \n",
    "\n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "        elif 'cui' in analysis_type:\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "        elif 'full' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "        out = out[cols_to_keep]\n",
    "\n",
    "        return out.drop_duplicates()\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_system_matches(system: str, analysis_type: str, corpus: str):\n",
    "   \n",
    "    if corpus == 'casi':\n",
    "        \n",
    "        sql = \"select `case`, overlap from test.amia_2019_cases where overlap = 1 and `system` = %(system)s\"  \n",
    "        data_matches = df_to_set(pd.read_sql(sql, params={\"system\":system}, con=engine), 'entity', 'sys', 'casi')\n",
    "        \n",
    "        sql = \"select `case`, overlap from test.amia_2019_cases where (overlap = 0 or overlap is null) and `system` = %(system)s\"  \n",
    "        data_fn = df_to_set(pd.read_sql(sql, params={\"system\":system}, con=engine), 'entity', 'sys', 'casi')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        dir_test = analysisConf.data_dir + 'single_system_out/'\n",
    "\n",
    "        file = dir_test + system + '_' + analysis_type + '_' + corpus + '_matches.txt'\n",
    "        data_matches = set(literal_eval(line.strip()) for line in open(file))\n",
    "\n",
    "        file = dir_test + system + '_' + analysis_type + '_' + corpus + '_ref_only.txt'\n",
    "        data_fn = set(literal_eval(line.strip()) for line in open(file)) \n",
    "\n",
    "    return data_matches, data_fn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GENERATE merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTotals(object):\n",
    "    \"\"\" \n",
    "    returns an instance with merged match set numbers using either union or intersection of elements in set \n",
    "    \"\"\"\n",
    "    def __init__(self, ref_n, sys_n, match_set):\n",
    "\n",
    "        self = self    \n",
    "        self.ref_ann = ref_n\n",
    "        self.sys_n = sys_n\n",
    "        self.match_set = match_set\n",
    "\n",
    "    def get_ref_sys(self):\n",
    "\n",
    "        ref_only = self.ref_ann - len(self.match_set)\n",
    "        sys_only = self.sys_n - len(self.match_set)\n",
    "\n",
    "        return ref_only, sys_only, len(self.match_set), self.match_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactor generate_metrics()\n",
    "\n",
    "def merge_eval(ref_only: int, system_only: int, ref_system_match: int, system_n: int, ref_n: int) -> dict:\n",
    "    \"\"\"\n",
    "    Generate confusion matrix params\n",
    "    :params: ref_only, system_only, reference_system_match -> sets\n",
    "    matches, system_n, reference_n -> counts\n",
    "    :return: dictionary object\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if ref_only + ref_system_match != ref_n:\n",
    "        print('ERROR!')\n",
    "\n",
    "    # get evaluation metrics\n",
    "    d = {}\n",
    "    \n",
    "    F, recall, precision, TP, FP, FN, TP_FN_R, TM  = Metrics(system_only, ref_only, ref_system_match, system_n).get_confusion_metrics()\n",
    "\n",
    "    d = {\n",
    "         'F': F[1], \n",
    "         'precision': precision[1], \n",
    "         'recall': recall[1], \n",
    "         'TP': TP, \n",
    "         'FN': FN, \n",
    "         'FP': FP, \n",
    "         'TP/FN': TP_FN_R,\n",
    "         'n_gold': ref_n, \n",
    "         'n_sys': system_n, \n",
    "         'TM': TM\n",
    "    }\n",
    "    \n",
    "    \n",
    "    if system_n - FP != TP:\n",
    "        print('inconsistent system n!')\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def process_sentence(pt, sentence, analysis_type, corpus):\n",
    "    \"\"\"\n",
    "    Recursively evaluate parse tree, \n",
    "    with check for existence before build\n",
    "       :param sentence: to process\n",
    "       :return class of merged annotations, boolean operated system df \n",
    "    \"\"\"\n",
    "    \n",
    "    class Results(object):\n",
    "        def __init__(self):\n",
    "            self.results = set()\n",
    "            #self.operations = []\n",
    "            self.system_merges = pd.DataFrame()\n",
    "            \n",
    "    r = Results()\n",
    "    \n",
    "    if 'entity' in analysis_type and corpus != 'casi': \n",
    "        cols_to_keep = ['begin', 'end', 'note_id'] # entity only\n",
    "    elif 'full' in analysis_type: \n",
    "        cols_to_keep = ['cui', 'begin', 'end', 'note_id'] # entity only\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['cui', 'note_id'] # entity only\n",
    "    elif corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap']\n",
    "    \n",
    "    def evaluate(parseTree):\n",
    "        oper = {'&': op.and_, '|': op.or_}\n",
    "        \n",
    "        if parseTree:\n",
    "            leftC = gevent.spawn(evaluate, parseTree.getLeftChild())\n",
    "            rightC = gevent.spawn(evaluate, parseTree.getRightChild())\n",
    "            \n",
    "            if leftC.get() and rightC.get():\n",
    "                query = set()\n",
    "                system_query = pd.DataFrame()\n",
    "                fn = oper[parseTree.getRootVal()]\n",
    "                \n",
    "                if isinstance(leftC.get(), str):\n",
    "                    # get system as leaf node \n",
    "                    left, _ = get_system_matches(leftC.get(), analysis_type, corpus)\n",
    "                    left_sys = get_sys_data(leftC.get(), analysis_type, corpus)\n",
    "                \n",
    "                elif isinstance(leftC.get(), tuple):\n",
    "                    left = leftC.get()[0]\n",
    "                    l_sys = leftC.get()[1]\n",
    "                \n",
    "                if isinstance(rightC.get(), str):\n",
    "                    # get system as leaf node\n",
    "                    right, _ = get_system_matches(rightC.get(), analysis_type, corpus)\n",
    "                    right_sys = get_sys_data(rightC.get(), analysis_type, corpus)\n",
    "                    \n",
    "                elif isinstance(rightC.get(), tuple):\n",
    "                    right = rightC.get()[0]\n",
    "                    r_sys = rightC.get()[1]\n",
    "                    \n",
    "                # create match set based on boolean operation\n",
    "                match_set = fn(left, right)\n",
    "               \n",
    "                if corpus != 'casi':\n",
    "                    if fn == op.or_:\n",
    "                        r.results = r.results.union(match_set)\n",
    "\n",
    "                        if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                            frames = [left_sys, right_sys]\n",
    "                            df = pd.concat(frames,  ignore_index=True)\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                        elif isinstance(leftC.get(), str) and isinstance(rightC.get(), tuple):\n",
    "                            frames = [left_sys, r_sys]\n",
    "                            df = pd.concat(frames,  ignore_index=True)\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                        elif isinstance(leftC.get(), tuple) and isinstance(rightC.get(), str):\n",
    "                            frames = [l_sys, right_sys]\n",
    "                            df = pd.concat(frames,  ignore_index=True)\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                        elif isinstance(leftC.get(), tuple) and isinstance(rightC.get(), tuple):\n",
    "                            frames = [l_sys, r_sys]\n",
    "                            df = pd.concat(frames,  ignore_index=True)\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    if fn == op.and_:\n",
    "                        if len(r.results) == 0:\n",
    "                            r.results = match_set\n",
    "                        r.results = r.results.intersection(match_set)\n",
    "\n",
    "                        if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                            df = left_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                        elif isinstance(leftC.get(), str) and isinstance(rightC.get(), tuple):\n",
    "                            df = left_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                        elif isinstance(leftC.get(), tuple) and isinstance(rightC.get(), str):\n",
    "                            df = l_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                        elif isinstance(leftC.get(), tuple) and isinstance(rightC.get(), tuple):\n",
    "                            df = l_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                else:\n",
    "                    if fn == op.or_:\n",
    "                        r.results = r.results.union(match_set)\n",
    "\n",
    "                        if isinstance(leftC, str) and isinstance(rightC, str):\n",
    "                            df = left_sys.append(right_sys)\n",
    "                            df = df.drop_duplicates()\n",
    "\n",
    "                        elif isinstance(leftC, str) and isinstance(rightC, tuple):\n",
    "                            df = left_sys.append(r_sys)\n",
    "                            df = df.drop_duplicates()\n",
    "\n",
    "                        elif isinstance(leftC, tuple) and isinstance(rightC, str):\n",
    "                            df = right_sys.append(l_sys)\n",
    "                            df = df.drop_duplicates()\n",
    "\n",
    "                        elif isinstance(leftC, tuple) and isinstance(rightC, tuple):\n",
    "                            df = l_sys.append(r_sys)\n",
    "                            df = df.drop_duplicates()\n",
    "\n",
    "                    if fn == op.and_:\n",
    "                        if len(r.results) == 0:\n",
    "                            r.results = match_set\n",
    "                        r.results = r.results.intersection(match_set)\n",
    "\n",
    "                        if isinstance(leftC, str) and isinstance(rightC, str):\n",
    "                            df = left_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df.drop_duplicates()\n",
    "\n",
    "                        elif isinstance(leftC, str) and isinstance(rightC, tuple):\n",
    "                            df = left_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df.drop_duplicates()\n",
    "\n",
    "                        elif isinstance(leftC, tuple) and isinstance(rightC, str):\n",
    "                            df = l_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df.drop_duplicates()\n",
    "\n",
    "                        elif isinstance(leftC, tuple) and isinstance(rightC, tuple):\n",
    "                            df = l_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                            df = df.drop_duplicates()\n",
    "                \n",
    "                # get matched results\n",
    "                query.update(r.results)\n",
    "                \n",
    "                # get combined system results\n",
    "                r.system_merges = df\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    system_query = system_query.append(df)\n",
    "                else:\n",
    "                    print('wtf!')\n",
    "                    \n",
    "                return query, system_query\n",
    "            else:\n",
    "                return parseTree.getRootVal()\n",
    "    \n",
    "    if sentence.n_or > 0 or sentence.n_and > 0:\n",
    "        evaluate(pt)  \n",
    "    \n",
    "    # trivial case\n",
    "    elif sentence.n_or == 0 and sentence.n_and == 0:\n",
    "        r.results, _ = get_system_matches(sentence.sentence, analysis_type, corpus)\n",
    "        r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus)\n",
    "        #print('trivial:', sentence.sentence, len(r.results), len(r.system_merges))\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Incoming Boolean sentences are parsed into a binary tree.\n",
    "\n",
    "Test expressions to parse:\n",
    "\n",
    "sentence = '((((A&B)|C)|D)&E)'\n",
    "\n",
    "sentence = '(E&(D|(C|(A&B))))'\n",
    "\n",
    "sentence = '(((A|(B&C))|(D&(E&F)))|(H&I))'\n",
    "\n",
    "\"\"\"\n",
    "# build parse tree from passed sentence\n",
    "# using grammatical rules of Boolean logic\n",
    "def buildParseTree(fpexp):\n",
    "    \"\"\"\n",
    "       Iteratively build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "       :param fpexp: sentence to parse\n",
    "       :return eTree: parse tree representation\n",
    "       Incoming Boolean sentences are parsed into a binary tree.\n",
    "       Test expressions to parse:\n",
    "       sentence = '(A&B)'\n",
    "       sentence = '(A|B)'\n",
    "       sentence = '((A|B)&C)'\n",
    "       \n",
    "    \"\"\"\n",
    "    fplist = fpexp.split()\n",
    "    pStack = Stack()\n",
    "    eTree = BinaryTree('')\n",
    "    pStack.push(eTree)\n",
    "    currentTree = eTree\n",
    "\n",
    "    for i in fplist:\n",
    "\n",
    "        if i == '(':\n",
    "            currentTree.insertLeft('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getLeftChild()\n",
    "        elif i not in ['&', '|', ')']:\n",
    "            currentTree.setRootVal(i)\n",
    "            parent = pStack.pop()\n",
    "            currentTree = parent\n",
    "        elif i in ['&', '|']:\n",
    "            currentTree.setRootVal(i)\n",
    "            currentTree.insertRight('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getRightChild()\n",
    "        elif i == ')':\n",
    "            currentTree = pStack.pop()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return eTree\n",
    "\n",
    "def make_parse_tree(payload):\n",
    "    \"\"\"\n",
    "    Ensure data to create tree are in standard form\n",
    "    :param sentence: sentence to preprocess\n",
    "    :return pt, parse tree graph\n",
    "            sentence, processed sentence to build tree\n",
    "            a: order\n",
    "    \"\"\"\n",
    "    def preprocess_sentence(sentence):\n",
    "        # prepare statement for case when a boolean AND/OR is given\n",
    "        sentence = payload.replace('(', ' ( '). \\\n",
    "            replace(')', ' ) '). \\\n",
    "            replace('&', ' & '). \\\n",
    "            replace('|', ' | '). \\\n",
    "            replace('  ', ' ')\n",
    "        return sentence\n",
    "\n",
    "    sentence = preprocess_sentence(payload)\n",
    "    print(sentence)\n",
    "    \n",
    "    pt = buildParseTree(sentence)\n",
    "    #pt.postorder() \n",
    "    \n",
    "    return pt\n",
    "\n",
    "class Sentence(object):\n",
    "\n",
    "    def __init__(self, sentence):\n",
    "        self = self\n",
    "        self.n_and = sentence.count('&')\n",
    "        self.n_or = sentence.count('|')\n",
    "        self.sentence = sentence\n",
    "    \n",
    "def get_metrics(boolean_expression: str, analysis_type: str, corpus: str):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "\n",
    "    r = process_sentence(pt, sentence, analysis_type, corpus)\n",
    "    \n",
    "    #print('len sys merges:', len(r.system_merges))\n",
    "    system_n = len(r.system_merges)\n",
    "    reference_n = get_ref_n(analysis_type, corpus)\n",
    "\n",
    "    reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, r.results).get_ref_sys()\n",
    "\n",
    "    # get overall TP/TF and various other counts for running confusion matrix metric analysis\n",
    "    return merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all combinations of given list of annotators:\n",
    "def expressions(l, n):\n",
    "    for (operations, *operands), operators in product(\n",
    "            combinations(l, n), product(('&', '|'), repeat=n - 1)):\n",
    "        for operation in zip(operators, operands):\n",
    "            operations = [operations, *operation]\n",
    "        yield operations\n",
    "        \n",
    "def run_ensemble(l, analysis_type, corpus):\n",
    "\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    print('CORPUS---->', corpus)\n",
    "    \n",
    "    #for i in l:\n",
    "    #    d = get_metrics(i, analysis_type, corpus)\n",
    "    \n",
    "    #for s in list(permutations(l)):\n",
    "    for i in range(1, len(l)+1):\n",
    "        test = list(expressions(l, i))\n",
    "        for t in test:\n",
    "            if i > 1:\n",
    "                # format Boolean sentence for parse tree \n",
    "                t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "            d = get_metrics(t, analysis_type, corpus)\n",
    "            d['merge'] = t\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0]) ]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "    \n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    file_name = corpus + '_all_merge_metrics_'\n",
    "        \n",
    "    geometric_mean(metrics).to_csv(analysisConf.data_dir + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "    print(geometric_mean(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTS -> ensemble:\n",
    "def test_match_consistency(matches, ref_only, ref_n, sys):\n",
    "    \"\"\"test for reference only/match set consistency:\n",
    "        params: match, system and reference only sets\"\"\"\n",
    "   \n",
    "    print('len', len(sys), len(matches), len(matches.union(sys)), len(matches.intersection(sys)))\n",
    "    assert len(matches.union(ref_only)) == ref_n, 'Reference annotation mismatch union'\n",
    "    assert len(matches.intersection(sys)) == len(matches), 'System annotation mismatch intersect'\n",
    "    assert len(matches.union(sys)) == len(sys), 'System annotation mismatch union'\n",
    "    assert len(matches.intersection(ref_only)) == 0, 'Reference annotation mismatch intersect'\n",
    "\n",
    "def test_systems(analysis_type, systems, corpus):\n",
    "    sys = df_to_set(get_sys_data(systems[0], analysis_type, corpus), analysis_type)\n",
    "    test_match_consistency(*get_system_matches(systems[0], analysis_type, corpus), get_ref_n(analysis_type), sys)\n",
    "    print('Match consistency:', len(sys),get_ref_n(analysis_type))\n",
    "\n",
    "def test_metrics(ref, sys_m, match_m):\n",
    "    test = True\n",
    "    reference_n = len(ref)\n",
    "    system_n = len(sys_m)\n",
    "\n",
    "    print('Test metrics:', type(reference_n), type(system_n), type(match_m))\n",
    "\n",
    "    reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, match_m).get_ref_sys()\n",
    "    F, recall, precision, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics()\n",
    "    F_, recall_, precision_, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics(test)\n",
    "\n",
    "    assert F[1] == F_, 'F1 issue'\n",
    "    assert recall[1] == recall_, 'recall issue'\n",
    "    assert precision[1] == precision_, 'precision issue'\n",
    "    print(F[1], F_)\n",
    "    print(recall[1], recall_)\n",
    "    print(precision[1], precision_)\n",
    "\n",
    "def test_count(analysis_type, corpus):\n",
    "    # test match counts:\n",
    "    ctakes, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "    clamp, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "    b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "    mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "\n",
    "    print('count:', len(mm.intersection(b9.intersection(clamp.intersection(ctakes)))))\n",
    "    \n",
    "def test_ensemble(analysis_type, corpus):\n",
    "    \n",
    "    print('ensemble:')\n",
    "    # Get mixed system_n\n",
    "    ref_ann, data = get_metric_data(analysis_type, corpus)\n",
    "\n",
    "    names = ['ctakes', 'biomedicus', 'metamap', 'clamp']\n",
    "    if 'entity' in analysis_type: \n",
    "        cols_to_keep = ['begin', 'end', 'note_id']\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['cui', 'note_id']\n",
    "    elif 'full' in analysis_type:\n",
    "        cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "    biomedicus = data[data[\"system\"]=='biomedicus'][cols_to_keep].copy()\n",
    "    ctakes = data[data[\"system\"]=='ctakes'][cols_to_keep].copy()\n",
    "    clamp = data[data[\"system\"]=='clamp'][cols_to_keep].copy()\n",
    "    metamap = data[data[\"system\"]=='metamap'][cols_to_keep].copy()\n",
    "    quickumls = data[data[\"system\"]=='quick_umls'][cols_to_keep].copy()\n",
    "\n",
    "    print('systems:', len(biomedicus), len(clamp), len(ctakes), len(metamap), len(quickumls))\n",
    "\n",
    "    b9 = set()\n",
    "    cl = set()\n",
    "    ct = set()\n",
    "    mm = set()\n",
    "    qu = set()\n",
    "\n",
    "    b9 = df_to_set(get_sys_data('biomedicus', analysis_type, corpus), analysis_type)\n",
    "    print(len(b9))\n",
    "\n",
    "    ct = df_to_set(get_sys_data('ctakes', analysis_type, corpus), analysis_type)\n",
    "    print(len(ct))\n",
    "\n",
    "    cl = df_to_set(get_sys_data('clamp', analysis_type, corpus), analysis_type)\n",
    "    print(len(cl))\n",
    "\n",
    "    mm = df_to_set(get_sys_data('metamap', analysis_type, corpus), analysis_type)\n",
    "    print(len(mm))\n",
    "\n",
    "    qu = df_to_set(get_sys_data('quick_umls', analysis_type, corpus), analysis_type)\n",
    "    print(len(qu))\n",
    "    \n",
    "    print('various merges:')\n",
    "    print(len(b9), len(cl), len(ct), len(mm), len(qu))\n",
    "    print(len(mm.intersection(b9.intersection(cl.intersection(ct)))))\n",
    "    print(len(mm.union(b9.intersection(cl.intersection(ct)))))\n",
    "    print(len(mm.union(b9.union(cl.intersection(ct)))))\n",
    "    print(len(mm.union(b9.union(cl.union(ct)))))\n",
    "    print(len(b9.intersection(ct)))\n",
    "\n",
    "    sys_m = b9.intersection(ct.intersection(qu))\n",
    "    print('sys_m:', len(sys_m))\n",
    "\n",
    "    # Get match merges:\n",
    "    ct, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "    cl, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "    b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "    mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "    qu, _ = get_system_matches('quick_umls', analysis_type, corpus)\n",
    "\n",
    "    match_m = b9.intersection(ct.intersection(qu))\n",
    "    print('match_m:', len(match_m))\n",
    "    # reference df to set\n",
    "    if 'entity' in analysis_type: \n",
    "        cols_to_keep = ['end', 'start','file']\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['value','file']\n",
    "    elif 'full' in analysis_type:\n",
    "        cols_to_keep = ['end', 'start', 'value','file']\n",
    "\n",
    "    ref = df_to_set(ref_ann[cols_to_keep], analysis_type, 'ref')\n",
    "\n",
    "    print('ref:', len(ref))\n",
    "\n",
    "    # test difference:\n",
    "    print('FP:', len(sys_m - match_m), len(sys_m - ref))\n",
    "    assert len(sys_m - match_m) == len(sys_m - ref), 'FP mismatch'\n",
    "    print('FN:', len(ref - match_m), len(ref - sys_m))\n",
    "    assert len(ref - match_m) == len(ref - sys_m), 'FN mismatch'\n",
    "    \n",
    "    test_metrics(ref, sys_m, match_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'] ('analytical_i2b2.csv', 'concepts.i2b2_all')\n",
      "corpus: i2b2 systems ('ctakes', 'biomedicus', 'metamap', 'clamp', 'quick_umls')\n",
      "CORPUS----> i2b2\n",
      "ctakes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biomedicus\n",
      "metamap\n",
      "clamp\n",
      "quick_umls\n",
      " ( ctakes & biomedicus ) \n",
      " ( ctakes | biomedicus ) \n",
      " ( ctakes & metamap ) \n",
      " ( ctakes | metamap ) \n",
      " ( ctakes & clamp ) \n",
      " ( ctakes | clamp ) \n",
      " ( ctakes & quick_umls ) \n",
      " ( ctakes | quick_umls ) \n",
      " ( biomedicus & metamap ) \n",
      " ( biomedicus | metamap ) \n",
      " ( biomedicus & clamp ) \n",
      " ( biomedicus | clamp ) \n",
      " ( biomedicus & quick_umls ) \n",
      " ( biomedicus | quick_umls ) \n",
      " ( metamap & clamp ) \n",
      " ( metamap | clamp ) \n",
      " ( metamap & quick_umls ) \n",
      " ( metamap | quick_umls ) \n",
      " ( clamp & quick_umls ) \n",
      " ( clamp | quick_umls ) \n",
      " ( ( ctakes & biomedicus ) & metamap ) \n",
      " ( ( ctakes & biomedicus ) | metamap ) \n",
      " ( ( ctakes | biomedicus ) & metamap ) \n",
      " ( ( ctakes | biomedicus ) | metamap ) \n",
      " ( ( ctakes & biomedicus ) & clamp ) \n",
      " ( ( ctakes & biomedicus ) | clamp ) \n",
      " ( ( ctakes | biomedicus ) & clamp ) \n",
      " ( ( ctakes | biomedicus ) | clamp ) \n",
      " ( ( ctakes & biomedicus ) & quick_umls ) \n",
      " ( ( ctakes & biomedicus ) | quick_umls ) \n",
      " ( ( ctakes | biomedicus ) & quick_umls ) \n",
      " ( ( ctakes | biomedicus ) | quick_umls ) \n",
      " ( ( ctakes & metamap ) & clamp ) \n",
      " ( ( ctakes & metamap ) | clamp ) \n",
      " ( ( ctakes | metamap ) & clamp ) \n",
      " ( ( ctakes | metamap ) | clamp ) \n",
      " ( ( ctakes & metamap ) & quick_umls ) \n",
      " ( ( ctakes & metamap ) | quick_umls ) \n",
      " ( ( ctakes | metamap ) & quick_umls ) \n",
      " ( ( ctakes | metamap ) | quick_umls ) \n",
      " ( ( ctakes & clamp ) & quick_umls ) \n",
      " ( ( ctakes & clamp ) | quick_umls ) \n",
      " ( ( ctakes | clamp ) & quick_umls ) \n",
      " ( ( ctakes | clamp ) | quick_umls ) \n",
      " ( ( biomedicus & metamap ) & clamp ) \n",
      " ( ( biomedicus & metamap ) | clamp ) \n",
      " ( ( biomedicus | metamap ) & clamp ) \n",
      " ( ( biomedicus | metamap ) | clamp ) \n",
      " ( ( biomedicus & metamap ) & quick_umls ) \n",
      " ( ( biomedicus & metamap ) | quick_umls ) \n",
      " ( ( biomedicus | metamap ) & quick_umls ) \n",
      " ( ( biomedicus | metamap ) | quick_umls ) \n",
      " ( ( biomedicus & clamp ) & quick_umls ) \n",
      " ( ( biomedicus & clamp ) | quick_umls ) \n",
      " ( ( biomedicus | clamp ) & quick_umls ) \n",
      " ( ( biomedicus | clamp ) | quick_umls ) \n",
      " ( ( metamap & clamp ) & quick_umls ) \n",
      " ( ( metamap & clamp ) | quick_umls ) \n",
      " ( ( metamap | clamp ) & quick_umls ) \n",
      " ( ( metamap | clamp ) | quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) & metamap ) & clamp ) \n",
      " ( ( ( ctakes & biomedicus ) & metamap ) | clamp ) \n",
      " ( ( ( ctakes & biomedicus ) | metamap ) & clamp ) \n",
      " ( ( ( ctakes & biomedicus ) | metamap ) | clamp ) \n",
      " ( ( ( ctakes | biomedicus ) & metamap ) & clamp ) \n",
      " ( ( ( ctakes | biomedicus ) & metamap ) | clamp ) \n",
      " ( ( ( ctakes | biomedicus ) | metamap ) & clamp ) \n",
      " ( ( ( ctakes | biomedicus ) | metamap ) | clamp ) \n",
      " ( ( ( ctakes & biomedicus ) & metamap ) & quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) & metamap ) | quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) | metamap ) & quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) | metamap ) | quick_umls ) \n",
      " ( ( ( ctakes | biomedicus ) & metamap ) & quick_umls ) \n",
      " ( ( ( ctakes | biomedicus ) & metamap ) | quick_umls ) \n",
      " ( ( ( ctakes | biomedicus ) | metamap ) & quick_umls ) \n",
      " ( ( ( ctakes | biomedicus ) | metamap ) | quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) & clamp ) & quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) & clamp ) | quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) | clamp ) & quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) | clamp ) | quick_umls ) \n",
      " ( ( ( ctakes | biomedicus ) & clamp ) & quick_umls ) \n",
      " ( ( ( ctakes | biomedicus ) & clamp ) | quick_umls ) \n",
      " ( ( ( ctakes | biomedicus ) | clamp ) & quick_umls ) \n",
      " ( ( ( ctakes | biomedicus ) | clamp ) | quick_umls ) \n",
      " ( ( ( ctakes & metamap ) & clamp ) & quick_umls ) \n",
      " ( ( ( ctakes & metamap ) & clamp ) | quick_umls ) \n",
      " ( ( ( ctakes & metamap ) | clamp ) & quick_umls ) \n",
      " ( ( ( ctakes & metamap ) | clamp ) | quick_umls ) \n",
      " ( ( ( ctakes | metamap ) & clamp ) & quick_umls ) \n",
      " ( ( ( ctakes | metamap ) & clamp ) | quick_umls ) \n",
      " ( ( ( ctakes | metamap ) | clamp ) & quick_umls ) \n",
      " ( ( ( ctakes | metamap ) | clamp ) | quick_umls ) \n",
      " ( ( ( biomedicus & metamap ) & clamp ) & quick_umls ) \n",
      " ( ( ( biomedicus & metamap ) & clamp ) | quick_umls ) \n",
      " ( ( ( biomedicus & metamap ) | clamp ) & quick_umls ) \n",
      " ( ( ( biomedicus & metamap ) | clamp ) | quick_umls ) \n",
      " ( ( ( biomedicus | metamap ) & clamp ) & quick_umls ) \n",
      " ( ( ( biomedicus | metamap ) & clamp ) | quick_umls ) \n",
      " ( ( ( biomedicus | metamap ) | clamp ) & quick_umls ) \n",
      " ( ( ( biomedicus | metamap ) | clamp ) | quick_umls ) \n",
      " ( ( ( ( ctakes & biomedicus ) & metamap ) & clamp ) & quick_umls ) \n",
      " ( ( ( ( ctakes & biomedicus ) & metamap ) & clamp ) | quick_umls ) \n",
      " ( ( ( ( ctakes & biomedicus ) & metamap ) | clamp ) & quick_umls ) \n",
      " ( ( ( ( ctakes & biomedicus ) & metamap ) | clamp ) | quick_umls ) \n",
      " ( ( ( ( ctakes & biomedicus ) | metamap ) & clamp ) & quick_umls ) \n",
      " ( ( ( ( ctakes & biomedicus ) | metamap ) & clamp ) | quick_umls ) \n",
      " ( ( ( ( ctakes & biomedicus ) | metamap ) | clamp ) & quick_umls ) \n",
      " ( ( ( ( ctakes & biomedicus ) | metamap ) | clamp ) | quick_umls ) \n",
      " ( ( ( ( ctakes | biomedicus ) & metamap ) & clamp ) & quick_umls ) \n",
      " ( ( ( ( ctakes | biomedicus ) & metamap ) & clamp ) | quick_umls ) \n",
      " ( ( ( ( ctakes | biomedicus ) & metamap ) | clamp ) & quick_umls ) \n",
      " ( ( ( ( ctakes | biomedicus ) & metamap ) | clamp ) | quick_umls ) \n",
      " ( ( ( ( ctakes | biomedicus ) | metamap ) & clamp ) & quick_umls ) \n",
      " ( ( ( ( ctakes | biomedicus ) | metamap ) & clamp ) | quick_umls ) \n",
      " ( ( ( ( ctakes | biomedicus ) | metamap ) | clamp ) & quick_umls ) \n",
      " ( ( ( ( ctakes | biomedicus ) | metamap ) | clamp ) | quick_umls ) \n",
      "            F  precision    recall     TP     FN      FP     TP/FN  n_gold  \\\n",
      "0    0.276356   0.229595  0.347038  10543  19837   35377  0.531482   30380   \n",
      "1    0.281404   0.205023  0.448486  13625  16755   52831  0.813190   30380   \n",
      "2    0.199989   0.139957  0.350197  10639  19741   65377  0.538929   30380   \n",
      "3    0.574143   0.461737  0.758887  23055   7325   26876  3.147440   30380   \n",
      "4    0.263119   0.184838  0.456419  13866  16514   61151  0.839651   30380   \n",
      "5    0.288557   0.265201  0.316425   9613  20767   26635  0.462898   30380   \n",
      "6    0.273313   0.191191  0.479098  14555  15825   61573  0.919747   30380   \n",
      "7    0.256058   0.348811  0.202271   6145  24235   11472  0.253559   30380   \n",
      "8    0.223268   0.144144  0.494964  15037  15343   89282  0.980056   30380   \n",
      "9    0.428387   0.618217  0.327749   9957  20423    6149  0.487539   30380   \n",
      "10   0.429348   0.296457  0.778176  23641   6739   56104  3.508087   30380   \n",
      "11   0.280859   0.261297  0.303588   9223  21157   26074  0.435931   30380   \n",
      "12   0.261782   0.177324  0.499868  15186  15194   70454  0.999473   30380   \n",
      "13   0.278433   0.289397  0.268269   8150  22230   20012  0.366622   30380   \n",
      "14   0.222738   0.140968  0.530415  16114  14266   98196  1.129539   30380   \n",
      "15   0.505094   0.622068  0.425148  12916  17464    7847  0.739579   30380   \n",
      "16   0.377194   0.248515  0.782225  23764   6616   71860  3.591898   30380   \n",
      "17   0.292804   0.235683  0.386471  11741  18639   38076  0.629916   30380   \n",
      "18   0.258121   0.171838  0.518433  15750  14630   75906  1.076555   30380   \n",
      "19   0.437137   0.633602  0.333673  10137  20243    5862  0.500766   30380   \n",
      "20   0.335742   0.214256  0.775411  23557   6823   86391  3.452587   30380   \n",
      "21   0.277906   0.285575  0.270639   8222  22158   20569  0.371062   30380   \n",
      "22   0.213377   0.133203  0.535978  16283  14097  105959  1.155068   30380   \n",
      "23   0.510344   0.663803  0.414516  12593  17787    6378  0.707989   30380   \n",
      "24   0.356828   0.229559  0.800790  24328   6052   81649  4.019828   30380   \n",
      "25   0.246832   0.385940  0.181435   5512  24868    8770  0.221650   30380   \n",
      "26   0.229663   0.150436  0.485188  14740  15640   83242  0.942455   30380   \n",
      "27   0.283886   0.278852  0.289105   8783  21597   22714  0.406677   30380   \n",
      "28   0.217325   0.136025  0.540191  16411  13969  104236  1.174816   30380   \n",
      "29   0.409393   0.647717  0.299276   9092  21288    4945  0.427095   30380   \n",
      "..        ...        ...       ...    ...    ...     ...       ...     ...   \n",
      "91   0.449834   0.481786  0.421856  12816  17564   13785  0.729674   30380   \n",
      "92   0.352171   0.225581  0.802535  24381   5999   83700  4.064177   30380   \n",
      "93   0.485474   0.683233  0.376498  11438  18942    5303  0.603843   30380   \n",
      "94   0.295062   0.201859  0.548157  16653  13727   65845  1.213157   30380   \n",
      "95   0.319143   0.252590  0.433311  13164  17216   38952  0.764638   30380   \n",
      "96   0.268061   0.160656  0.808723  24569   5811  128360  4.228016   30380   \n",
      "97   0.354760   0.750718  0.232258   7056  23324    2343  0.302521   30380   \n",
      "98   0.273447   0.190854  0.482061  14645  15735   62089  0.930728   30380   \n",
      "99   0.421862   0.420202  0.423535  12867  17513   17754  0.734711   30380   \n",
      "100  0.343823   0.218805  0.802140  24369   6011   87004  4.054068   30380   \n",
      "101  0.498725   0.673649  0.395918  12028  18352    5827  0.655405   30380   \n",
      "102  0.301375   0.205970  0.561422  17056  13324   65752  1.280096   30380   \n",
      "103  0.296401   0.224934  0.434431  13198  17182   45477  0.768129   30380   \n",
      "104  0.265696   0.158897  0.810369  24619   5761  130318  4.273390   30380   \n",
      "105  0.270128   0.799773  0.162508   4937  25443    1236  0.194042   30380   \n",
      "106  0.267632   0.187457  0.467643  14207  16173   61581  0.878439   30380   \n",
      "107  0.459146   0.503854  0.421725  12812  17568   12616  0.729281   30380   \n",
      "108  0.354756   0.227807  0.801284  24343   6037   82515  4.032301   30380   \n",
      "109  0.482253   0.686550  0.371659  11291  19089    5155  0.591492   30380   \n",
      "110  0.294994   0.202368  0.543976  16526  13854   65137  1.192868   30380   \n",
      "111  0.327015   0.262706  0.433015  13155  17225   36920  0.763716   30380   \n",
      "112  0.272617   0.163959  0.808262  24555   5825  125208  4.215451   30380   \n",
      "113  0.364976   0.748316  0.241343   7332  23048    2466  0.318119   30380   \n",
      "114  0.277927   0.193597  0.492429  14960  15420   62314  0.970169   30380   \n",
      "115  0.414032   0.404825  0.423667  12871  17509   18923  0.735108   30380   \n",
      "116  0.341414   0.216766  0.803390  24407   5973   88189  4.086221   30380   \n",
      "117  0.501751   0.670799  0.400757  12175  18205    5975  0.668772   30380   \n",
      "118  0.301395   0.205433  0.565602  17183  13197   66460  1.302038   30380   \n",
      "119  0.289958   0.217521  0.434727  13207  17173   47509  0.769056   30380   \n",
      "120  0.261382   0.155803  0.810829  24633   5747  133470  4.286236   30380   \n",
      "\n",
      "      n_sys          TM                                              merge  \\\n",
      "0     45920   49.199792                                             ctakes   \n",
      "1     66456   52.852972                                         biomedicus   \n",
      "2     76016   38.587647                                            metamap   \n",
      "3     49931  103.176311                                              clamp   \n",
      "4     75017   50.625736                                         quick_umls   \n",
      "5     36248   50.491342                                (ctakes&biomedicus)   \n",
      "6     76128   52.752130                                (ctakes|biomedicus)   \n",
      "7     17617   46.297326                                   (ctakes&metamap)   \n",
      "8    104319   46.556411                                   (ctakes|metamap)   \n",
      "9     16106   78.457535                                     (ctakes&clamp)   \n",
      "10    79745   83.717088                                     (ctakes|clamp)   \n",
      "11    35297   49.091162                                (ctakes&quick_umls)   \n",
      "12    85640   51.892556                                (ctakes|quick_umls)   \n",
      "13    28162   48.565276                               (biomedicus&metamap)   \n",
      "14   114310   47.660791                               (biomedicus|metamap)   \n",
      "15    20763   89.636107                                 (biomedicus&clamp)   \n",
      "16    95624   76.848623                                 (biomedicus|clamp)   \n",
      "17    49817   52.603701                            (biomedicus&quick_umls)   \n",
      "18    91656   52.023565                            (biomedicus|quick_umls)   \n",
      "19    15999   80.142526                                    (metamap&clamp)   \n",
      "20   109948   71.043822                                    (metamap|clamp)   \n",
      "21    28791   48.456171                               (metamap&quick_umls)   \n",
      "22   122242   46.571926                               (metamap|quick_umls)   \n",
      "23    18971   91.429026                                 (clamp&quick_umls)   \n",
      "24   105977   74.730966                                 (clamp|quick_umls)   \n",
      "25    14282   46.122697                      ((ctakes&biomedicus)&metamap)   \n",
      "26    97982   47.089528                      ((ctakes&biomedicus)|metamap)   \n",
      "27    31497   49.488955                      ((ctakes|biomedicus)&metamap)   \n",
      "28   120647   47.247277                      ((ctakes|biomedicus)|metamap)   \n",
      "29    14037   76.740085                        ((ctakes&biomedicus)&clamp)   \n",
      "..      ...         ...                                                ...   \n",
      "91    26601   78.578461              (((ctakes&metamap)|clamp)&quick_umls)   \n",
      "92   108081   74.161215              (((ctakes&metamap)|clamp)|quick_umls)   \n",
      "93    16741   88.401451              (((ctakes|metamap)&clamp)&quick_umls)   \n",
      "94    82498   57.979007              (((ctakes|metamap)&clamp)|quick_umls)   \n",
      "95    52116   57.663677              (((ctakes|metamap)|clamp)&quick_umls)   \n",
      "96   152929   62.826455              (((ctakes|metamap)|clamp)|quick_umls)   \n",
      "97     9399   72.780955          (((biomedicus&metamap)&clamp)&quick_umls)   \n",
      "98    76734   52.868314          (((biomedicus&metamap)&clamp)|quick_umls)   \n",
      "99    30621   73.530516          (((biomedicus&metamap)|clamp)&quick_umls)   \n",
      "100  111373   73.020995          (((biomedicus&metamap)|clamp)|quick_umls)   \n",
      "101   17855   90.014711          (((biomedicus|metamap)&clamp)&quick_umls)   \n",
      "102   82808   59.270834          (((biomedicus|metamap)&clamp)|quick_umls)   \n",
      "103   58675   54.485580          (((biomedicus|metamap)|clamp)&quick_umls)   \n",
      "104  154937   62.545035          (((biomedicus|metamap)|clamp)|quick_umls)   \n",
      "105    6173   62.836934  ((((ctakes&biomedicus)&metamap)&clamp)&quick_u...   \n",
      "106   75788   51.606233  ((((ctakes&biomedicus)&metamap)&clamp)|quick_u...   \n",
      "107   25428   80.345365  ((((ctakes&biomedicus)&metamap)|clamp)&quick_u...   \n",
      "108  106858   74.468152  ((((ctakes&biomedicus)&metamap)|clamp)|quick_u...   \n",
      "109   16446   88.044507  ((((ctakes&biomedicus)|metamap)&clamp)&quick_u...   \n",
      "110   81663   57.830252  ((((ctakes&biomedicus)|metamap)&clamp)|quick_u...   \n",
      "111   50075   58.786875  ((((ctakes&biomedicus)|metamap)|clamp)&quick_u...   \n",
      "112  149763   63.450883  ((((ctakes&biomedicus)|metamap)|clamp)|quick_u...   \n",
      "113    9798   74.071943  ((((ctakes|biomedicus)&metamap)&clamp)&quick_u...   \n",
      "114   77274   53.816431  ((((ctakes|biomedicus)&metamap)&clamp)|quick_u...   \n",
      "115   31794   72.183794  ((((ctakes|biomedicus)&metamap)|clamp)&quick_u...   \n",
      "116  112596   72.736587  ((((ctakes|biomedicus)&metamap)|clamp)|quick_u...   \n",
      "117   18150   90.371326  ((((ctakes|biomedicus)|metamap)&clamp)&quick_u...   \n",
      "118   83643   59.413370  ((((ctakes|biomedicus)|metamap)&clamp)|quick_u...   \n",
      "119   60716   53.598496  ((((ctakes|biomedicus)|metamap)|clamp)&quick_u...   \n",
      "120  158103   61.950847  ((((ctakes|biomedicus)|metamap)|clamp)|quick_u...   \n",
      "\n",
      "     F1 rank  TP/FN rank  TM rank       Gmean  \n",
      "0       86.0        95.0    104.0   97.811924  \n",
      "1       80.0        66.0     81.0   73.850969  \n",
      "2      121.0        94.0    121.0  108.155522  \n",
      "3        1.0        28.0      1.0    4.397252  \n",
      "4      102.0        64.0     98.0   81.454263  \n",
      "5       69.0        98.0    101.0   95.524645  \n",
      "6       90.0        58.0     83.0   71.417958  \n",
      "7      107.0       114.0    117.0  114.514567  \n",
      "8      113.0        50.0    116.0   79.570940  \n",
      "9       24.0        97.0     24.0   44.647144  \n",
      "10      23.0        21.0     20.0   20.758294  \n",
      "11      81.0        99.0    105.0   99.382341  \n",
      "12     103.0        47.0     94.0   69.782881  \n",
      "13      82.0       107.0    106.0  103.449946  \n",
      "14     114.0        40.0    109.0   70.160800  \n",
      "15      10.0        75.0     13.0   27.514245  \n",
      "16      35.0        20.0     26.0   23.915293  \n",
      "17      64.0        89.0     85.0   84.062392  \n",
      "18     106.0        43.0     91.0   66.329241  \n",
      "19      22.0        96.0     22.0   42.344774  \n",
      "20      47.0        23.0     45.0   33.555378  \n",
      "21      84.0       106.0    107.0  103.727305  \n",
      "22     118.0        38.0    115.0   70.501907  \n",
      "23       9.0        83.0      7.0   21.604771  \n",
      "24      38.0        14.0     31.0   22.271485  \n",
      "25     109.0       116.0    118.0  116.079106  \n",
      "26     112.0        52.0    113.0   79.953661  \n",
      "27      75.0       102.0    103.0   99.002383  \n",
      "28     115.0        37.0    112.0   68.660749  \n",
      "29      27.0       100.0     29.0   49.875122  \n",
      "..       ...         ...      ...         ...  \n",
      "91      21.0        79.0     23.0   39.401744  \n",
      "92      42.0        10.0     35.0   20.467177  \n",
      "93      14.0        91.0     15.0   33.169571  \n",
      "94      62.0        35.0     66.0   49.441688  \n",
      "95      51.0        71.0     69.0   67.573711  \n",
      "96      95.0         3.0     60.0   16.675943  \n",
      "97      40.0       113.0     40.0   63.461837  \n",
      "98      89.0        56.0     80.0   69.085852  \n",
      "99      25.0        78.0     38.0   49.932538  \n",
      "100     44.0        11.5     39.0   22.970314  \n",
      "101     12.0        86.0     12.0   28.795341  \n",
      "102     58.0        32.0     64.0   46.519886  \n",
      "103     61.0        68.0     74.0   69.757039  \n",
      "104    100.0         2.0     61.0   14.108903  \n",
      "105     94.0       121.0     59.0   85.499614  \n",
      "106     97.0        62.0     95.0   78.769704  \n",
      "107     20.0        80.0     21.0   37.846845  \n",
      "108     41.0        13.0     32.0   22.041426  \n",
      "109     15.0        92.0     17.0   35.508930  \n",
      "110     63.0        36.0     67.0   50.490018  \n",
      "111     49.0        72.0     65.0   65.920417  \n",
      "112     92.0         4.0     56.0   18.312740  \n",
      "113     36.0       111.0     36.0   59.380648  \n",
      "114     83.0        51.0     77.0   64.653390  \n",
      "115     26.0        77.0     43.0   52.679975  \n",
      "116     45.0         9.0     41.0   21.114990  \n",
      "117     11.0        85.0     10.0   26.162200  \n",
      "118     57.0        31.0     63.0   45.460220  \n",
      "119     66.0        67.0     79.0   71.969779  \n",
      "120    104.0         1.0     62.0   10.488982  \n",
      "\n",
      "[121 rows x 15 columns]\n",
      "corpus: i2b2 systems ('ctakes', 'biomedicus', 'metamap', 'quick_umls', 'clamp')\n",
      "CORPUS----> i2b2\n",
      "ctakes\n",
      "biomedicus\n",
      "metamap\n",
      "quick_umls\n",
      "clamp\n",
      " ( ctakes & biomedicus ) \n",
      " ( ctakes | biomedicus ) \n",
      " ( ctakes & metamap ) \n",
      " ( ctakes | metamap ) \n",
      " ( ctakes & quick_umls ) \n",
      " ( ctakes | quick_umls ) \n",
      " ( ctakes & clamp ) \n",
      " ( ctakes | clamp ) \n",
      " ( biomedicus & metamap ) \n",
      " ( biomedicus | metamap ) \n",
      " ( biomedicus & quick_umls ) \n",
      " ( biomedicus | quick_umls ) \n",
      " ( biomedicus & clamp ) \n",
      " ( biomedicus | clamp ) \n",
      " ( metamap & quick_umls ) \n",
      " ( metamap | quick_umls ) \n",
      " ( metamap & clamp ) \n",
      " ( metamap | clamp ) \n",
      " ( quick_umls & clamp ) \n",
      " ( quick_umls | clamp ) \n",
      " ( ( ctakes & biomedicus ) & metamap ) \n",
      " ( ( ctakes & biomedicus ) | metamap ) \n",
      " ( ( ctakes | biomedicus ) & metamap ) \n",
      " ( ( ctakes | biomedicus ) | metamap ) \n",
      " ( ( ctakes & biomedicus ) & quick_umls ) \n",
      " ( ( ctakes & biomedicus ) | quick_umls ) \n",
      " ( ( ctakes | biomedicus ) & quick_umls ) \n",
      " ( ( ctakes | biomedicus ) | quick_umls ) \n",
      " ( ( ctakes & biomedicus ) & clamp ) \n",
      " ( ( ctakes & biomedicus ) | clamp ) \n",
      " ( ( ctakes | biomedicus ) & clamp ) \n",
      " ( ( ctakes | biomedicus ) | clamp ) \n",
      " ( ( ctakes & metamap ) & quick_umls ) \n",
      " ( ( ctakes & metamap ) | quick_umls ) \n",
      " ( ( ctakes | metamap ) & quick_umls ) \n",
      " ( ( ctakes | metamap ) | quick_umls ) \n",
      " ( ( ctakes & metamap ) & clamp ) \n",
      " ( ( ctakes & metamap ) | clamp ) \n",
      " ( ( ctakes | metamap ) & clamp ) \n",
      " ( ( ctakes | metamap ) | clamp ) \n",
      " ( ( ctakes & quick_umls ) & clamp ) \n",
      " ( ( ctakes & quick_umls ) | clamp ) \n",
      " ( ( ctakes | quick_umls ) & clamp ) \n",
      " ( ( ctakes | quick_umls ) | clamp ) \n",
      " ( ( biomedicus & metamap ) & quick_umls ) \n",
      " ( ( biomedicus & metamap ) | quick_umls ) \n",
      " ( ( biomedicus | metamap ) & quick_umls ) \n",
      " ( ( biomedicus | metamap ) | quick_umls ) \n",
      " ( ( biomedicus & metamap ) & clamp ) \n",
      " ( ( biomedicus & metamap ) | clamp ) \n",
      " ( ( biomedicus | metamap ) & clamp ) \n",
      " ( ( biomedicus | metamap ) | clamp ) \n",
      " ( ( biomedicus & quick_umls ) & clamp ) \n",
      " ( ( biomedicus & quick_umls ) | clamp ) \n",
      " ( ( biomedicus | quick_umls ) & clamp ) \n",
      " ( ( biomedicus | quick_umls ) | clamp ) \n",
      " ( ( metamap & quick_umls ) & clamp ) \n",
      " ( ( metamap & quick_umls ) | clamp ) \n",
      " ( ( metamap | quick_umls ) & clamp ) \n",
      " ( ( metamap | quick_umls ) | clamp ) \n",
      " ( ( ( ctakes & biomedicus ) & metamap ) & quick_umls ) \n",
      " ( ( ( ctakes & biomedicus ) & metamap ) | quick_umls ) \n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "def partly_unordered_permutations(lst, k):\n",
    "    elems = set(lst)\n",
    "    for c in combinations(lst, k):\n",
    "        for d in permutations(elems - set(c)):\n",
    "            yield c + d\n",
    "            \n",
    "def main():\n",
    "    \n",
    "    #rtype = int(input(\"Run: 1->Single systems; 2->Ensemble; 3->Tests; 4-> MM Test\"))\n",
    "   \n",
    "    '''\n",
    "        corpora: i2b2, mipacq, fv017\n",
    "        analyses: entity only (exact span), cui by document, full (aka (entity and cui on exaact span/exact cui)\n",
    "        systems: ctakes, biomedicus, clamp, metamap, quick_umls\n",
    "        \n",
    "        TODO -> Vectorization (entity only and full):\n",
    "                add switch for use of TN on single system performance evaluations \n",
    "                add switch for overlap matching versus exact span\n",
    "             -> Other tasks besides concept extraction\n",
    "        \n",
    "    ''' \n",
    "    analysisConf =  AnalysisConfig()\n",
    "    print(analysisConf.systems, analysisConf.corpus_config())\n",
    "    \n",
    "    if (rtype == 1):\n",
    "        generate_metrics(analysis_type, corpus)\n",
    "    elif (rtype == 2):\n",
    "        \n",
    "        systems = ['ctakes','biomedicus','clamp','metamap','quick_umls']\n",
    "        \n",
    "        #for corpus in corpora:\n",
    "        for l in partly_unordered_permutations(systems, 2):\n",
    "            print('corpus:', corpus, 'systems', l)\n",
    "            run_ensemble(l, analysis_type, corpus) \n",
    "            \n",
    "    elif (rtype == 3):\n",
    "        systems = ['biomedicus']\n",
    "        t = ['concept_jaccard_score_false']\n",
    "        test_systems(analysis_type, systems, corpus)  \n",
    "        test_count(analysis_type, corpus)\n",
    "        test_ensemble(analysis_type, corpus)\n",
    "    elif (rtype == 4):\n",
    "        generate_metrics_test(analysis_type, corpus)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    %prun main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
