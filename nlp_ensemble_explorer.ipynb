{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  Copyright (c) 2019 Regents of the University of Minnesota.\n",
    " \n",
    "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    " \n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    " \n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1996,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pymysql\n",
    "import time \n",
    "import functools as ft\n",
    "import glob, os   \n",
    "import operator as op\n",
    "import shelve\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, permutations\n",
    "from sqlalchemy.engine import create_engine\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from scipy import stats  \n",
    "from scipy.stats.mstats import gmean\n",
    "from pythonds.basic.stack import Stack\n",
    "from pythonds.trees.binaryTree import BinaryTree\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from typing import List, Set, Tuple "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cell below contains the configurable parameters to ensure that our ensemble explorer runs properaly on your machine. \n",
    "Please read carfully through steps (1-11) before running the rest of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1997,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP-1: CHOOSE YOUR CORPUS\n",
    "# TODO: get working with list of corpora\n",
    "#corpora = ['mipacq','i2b2','fairview'] #options for concept extraction include 'fairview', 'mipacq' OR 'i2b2'\n",
    "\n",
    "corpus = 'fairview'\n",
    "#corpora = ['i2b2','fairview']\n",
    "\n",
    "# STEP-2: CHOOSE YOUR DATA DIRECTORY; this is where output data will be saved on your machine\n",
    "data_directory = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/' \n",
    "\n",
    "# STEP-3: CHOOSE WHICH SYSTEMS YOU'D LIKE TO EVALUATE AGAINST THE CORPUS REFERENCE SET\n",
    "systems = ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['biomedicus', 'clamp']\n",
    "#systems = ['clamp', 'quick_umls', 'biomedicus']\n",
    "\n",
    "# STEP-4: CHOOSE TYPE OF RUN\n",
    "rtype = 1      # OPTIONS INCLUDE: 1->Single systems; 2->Ensemble; 3->Tests; 4 -> majority vote \n",
    "               # The Ensemble can include the max system set ['ctakes','biomedicus','clamp','metamap','quick_umls']\n",
    "    \n",
    "# STEP-5: CHOOSE WHAT TYPE OF ANALYSIS YOU'D LIKE TO RUN ON THE CORPUS\n",
    "analysis_type = 'entity' #options include 'entity' OR 'full'\n",
    "\n",
    "# STEP-(6A): ENTER DETAILS FOR ACCESSING MANUAL ANNOTATION DATA\n",
    "database_type = 'mysql+pymysql' # We use mysql+pymql as default\n",
    "database_username = 'gms'\n",
    "database_password = 'nej123' \n",
    "database_url = 'localhost' # HINT: use localhost if you're running database on your local machine\n",
    "database_name = 'concepts' # Enter database name\n",
    "\n",
    "def ref_data(corpus):\n",
    "    return corpus + '_all' # Enter the table within the database where your reference data is stored\n",
    "\n",
    "table_name = ref_data(corpus)\n",
    "\n",
    "# STEP-(6B): ENTER DETAILS FOR ACCESSING SYSTEM ANNOTATION DATA\n",
    "\n",
    "def sys_data(corpus):\n",
    "    return 'analytical_'+corpus+'.csv' # OPTIONS include 'analytical_cui_mipacq_concepts.csv' OR 'analytical_cui_i2b2_concepts.csv' \n",
    "\n",
    "system_annotation = sys_data(corpus)\n",
    "\n",
    "# STEP-7: CREATE A DB CONNECTION POOL\n",
    "engine_request = str(database_type)+'://'+database_username+':'+database_password+\"@\"+database_url+'/'+database_name\n",
    "engine = create_engine(engine_request, pool_pre_ping=True, pool_size=20, max_overflow=30)\n",
    "\n",
    "# STEP-(8A): FILTER BY SEMTYPE\n",
    "filter_semtype = True\n",
    "\n",
    "# STEP-(8B): IF STEP-(8A) == True -> GET REFERENCE SEMTYPES\n",
    "\n",
    "### Fairview -> ['drug', 'finding', 'anatomy', 'procedure']\n",
    "### i2b2 -> ['test, treatment', 'problem']\n",
    "### MiPACQ -> ['procedures', 'disorders, sign_symptom', 'anatomy', 'chemicals_and_drugs']\n",
    "\n",
    "# semtypes = ['Anatomy']\n",
    "def ref_semtypes(filter_semtype, corpus):\n",
    "    if filter_semtype:\n",
    "        if corpus == 'fairview':\n",
    "            semtypes = ['Drug', 'Finding', 'Anatomy', 'Procedure']\n",
    "        elif corpus == 'i2b2':\n",
    "            semtypes = ['test,treatment', 'problem']\n",
    "        elif corpus == 'mipacq':\n",
    "            semtypes = ['Procedures', 'Disorders,Sign_Symptom', 'Anatomy', 'Chemicals_and_drugs']\n",
    "        \n",
    "        return semtypes\n",
    "\n",
    "semtypes = ref_semtypes(filter_semtype, corpus)\n",
    "\n",
    "# STEP-9: Set data directory/table for source documents for vectorization\n",
    "src_table = 'sofa'\n",
    "\n",
    "# STEP-10: Specificy match type from {'exact', 'overlap'}\n",
    "run_type = 'exact'\n",
    "\n",
    "# STEP-11: Specify expression type for run (TODO: run all at once; make less kludgey)\n",
    "expression_type = 'nested' # type of merge expression: nested ((A&B)|C), paired ((A&B)|(C&D)), nested_with_singleton ((A&B)|((C&D)|E)) \n",
    "# -> NB: len(systems) for pair must be >= 4, and for nested_with_singleton == 5\n",
    "\n",
    "# STEP-12: Specify type of ensemble: merge or vote\n",
    "ensemble_type = 'merge'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "****** TODO \n",
    "-> add 'semtype' to output file name -> done\n",
    "-> filter for case when a system has no equivalent semtypes for a given reference -> done: still need to validate that all semtypes in corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1998,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config class for analysis\n",
    "class AnalysisConfig():\n",
    "    \"\"\"\n",
    "    Configuration object:\n",
    "    systems to use\n",
    "    notes by corpus\n",
    "    paths by output, gold and system location\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self = self    \n",
    "        self.systems = systems\n",
    "        self.data_dir = data_directory\n",
    "    \n",
    "    def corpus_config(self): \n",
    "        usys_data = system_annotation\n",
    "        ref_data = database_name+'.'+table_name\n",
    "        return usys_data, ref_data\n",
    "\n",
    "analysisConf =  AnalysisConfig()\n",
    "#usys, ref = analysisConf.corpus_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1999,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticTypes(object):\n",
    "    '''\n",
    "    Filter semantic types based on: https://metamap.nlm.nih.gov/SemanticTypesAndGroups.shtml\n",
    "    :params: semtypes list from corpus, system to query\n",
    "    :return: list of equivalent system semtypes \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, semtypes, corpus):\n",
    "        self = self\n",
    "        \n",
    "        sql = \"SELECT st.tui, abbreviation, clamp_name, ctakes_name FROM concepts.semantic_groups sg join semantic_types st on sg.tui = st.tui where \" + corpus + \"_name in ({})\"\\\n",
    "           .format(', '.join(['%s' for _ in semtypes]))  \n",
    "        \n",
    "        stypes = pd.read_sql(sql, params=[semtypes], con=engine) \n",
    "       \n",
    "        if len(stypes['tui'].tolist()) > 0:\n",
    "            self.biomedicus_types = set(stypes['tui'].tolist())\n",
    "            self.qumls_types = set(stypes['tui'].tolist())\n",
    "        else:\n",
    "            self.biomedicus_types = None\n",
    "            self.qumls_types = None\n",
    "        \n",
    "        if stypes['clamp_name'].dropna(inplace=True) or len(stypes['clamp_name']) == 0:\n",
    "            self.clamp_types = None\n",
    "        else:\n",
    "            self.clamp_types = set(stypes['clamp_name'].tolist()[0].split(','))\n",
    "            \n",
    "        if len(stypes['ctakes_name'].tolist()) > 0:\n",
    "            self.ctakes_types = set(stypes['ctakes_name'].tolist()[0].split(','))\n",
    "        else:\n",
    "            self.ctakes_types = None\n",
    "            \n",
    "        if len(stypes['abbreviation'].tolist()) > 0:\n",
    "            self.metamap_types = set(stypes['abbreviation'].tolist())\n",
    "        else:\n",
    "            self.metamap_types = None\n",
    "            \n",
    "        self.reference_types =  set(semtypes)\n",
    "    \n",
    "    def get_system_type(self, system):  \n",
    "        \n",
    "        if system == 'biomedicus':\n",
    "            semtypes = self.biomedicus_types\n",
    "        elif system == 'ctakes':\n",
    "            semtypes = self.ctakes_types\n",
    "        elif system == 'clamp':\n",
    "            semtypes = self.clamp_types\n",
    "        elif system == 'metamap':\n",
    "            semtypes = self.metamap_types\n",
    "        elif system == 'quick_umls':\n",
    "            semtypes = self.qumls_types\n",
    "        elif system == 'reference':\n",
    "            semtypes = self.reference_types\n",
    "            \n",
    "        return semtypes\n",
    "    \n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('biomedicus'))\n",
    "# print(SemanticTypes(['Drug'], corpus).get_system_type('quick_umls'))\n",
    "# print(SemanticTypes(['Anatomy'], corpus).get_system_type('clamp'))\n",
    "#print(SemanticTypes(['test,treatment'], 'i2b2').get_system_type('clamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2000,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semtypes = ['test,treatment']\n",
    "# semtypes = ['problem']\n",
    "# corpus = 'i2b2'\n",
    "# sys = 'clamp'\n",
    "\n",
    "# is semantic type in particular system\n",
    "def system_semtype_check(sys, semtype, corpus):\n",
    "    st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "    if st:\n",
    "        return sys\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# print(system_semtype_check(sys, semtypes, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2001,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for systems\n",
    "class AnnotationSystems():\n",
    "    \"\"\"   \n",
    "    System annotations of interest for UMLS concept extraction\n",
    "    NB: ctakes combines all \"mentions\" annotation types\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"   \n",
    "        \n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\"]\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\"]\n",
    "        self.ctakes_types = [\"ctakes_mentions\"]\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\"]\n",
    "        self.qumls_types = [\"concept_jaccard_score_False\"]\n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "        \n",
    "        elif system == \"quick_umls\":\n",
    "            types = self.qumls_types\n",
    "            \n",
    "        return types, view\n",
    "    \n",
    "annSys = AnnotationSystems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2002,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2003,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np # access to Numpy from Python layer\n",
    "import math\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"\n",
    "    metrics class:\n",
    "    returns an instance with confusion matrix metrics\n",
    "    \"\"\"\n",
    "    def __init__(self, system_only, gold_only, gold_system_match, system_n, neither = 0): # neither: no sys or manual annotation\n",
    "\n",
    "        self = self    \n",
    "        self.system_only = system_only\n",
    "        self.gold_only = gold_only\n",
    "        self.gold_system_match = gold_system_match\n",
    "        self.system_n = system_n\n",
    "        self.neither = neither\n",
    "        \n",
    "    def get_confusion_metrics(self, corpus = None, test = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        compute confusion matrix measures, as per  \n",
    "        https://stats.stackexchange.com/questions/51296/how-do-you-calculate-precision-and-recall-for-multiclass-classification-using-co\n",
    "        \"\"\"\n",
    "        cdef:\n",
    "            int TP, FP, FN\n",
    "            double TM\n",
    "\n",
    "        TP = self.gold_system_match\n",
    "        FP = self.system_only\n",
    "        FN = self.gold_only\n",
    "        \n",
    "        TM = TP/math.sqrt(self.system_n) # TigMetric\n",
    "       \n",
    "        if not test:\n",
    "            \n",
    "            if corpus == 'casi':\n",
    "                recall = TP/(TP + FN)\n",
    "                precision = TP/(TP + FP)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "            else:\n",
    "                if self.neither == 0:\n",
    "                    confusion = [[0, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                else:\n",
    "                    confusion = [[self.neither, self.system_only],[self.gold_only,self.gold_system_match]]\n",
    "                c = np.asarray(confusion)\n",
    "                recall = np.diag(c) / np.sum(c, axis = 1)\n",
    "                precision = np.diag(c) / np.sum(c, axis = 0)\n",
    "                F = 2*(precision*recall)/(precision + recall)\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall = TP/(TP+FN)\n",
    "            F = 2*(precision*recall)/(precision + recall)\n",
    "        \n",
    "        # Tignanelli Metric\n",
    "        if FN == 0:\n",
    "            TP_FN_R = TP\n",
    "        elif FN > 0:\n",
    "            TP_FN_R = TP/FN\n",
    " \n",
    "        return F, recall, precision, TP, FP, FN, TP_FN_R, TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2004,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_set(df, analysis_type = 'entity', df_type = 'sys', corpus = None):\n",
    "    \n",
    "    # get values for creation of series of type tuple\n",
    "    if 'entity' in analysis_type: \n",
    "        if corpus == 'casi':\n",
    "            arg = df.case, df.overlap\n",
    "        else:    \n",
    "            if df_type == 'sys':\n",
    "                arg = df.begin, df.end, df.note_id\n",
    "            else:\n",
    "                #arg = df.start, df.end, df.file\n",
    "                arg = df.begin, df.end, df.case\n",
    "            \n",
    "    elif 'cui' in analysis_type:\n",
    "        if df_type == 'sys':\n",
    "            arg = df.cui, df.note_id\n",
    "        else:\n",
    "            arg = df.value, df.file\n",
    "    elif 'full' in analysis_type:\n",
    "        if df_type == 'sys':\n",
    "            arg = df.begin, df.end, df.cui, df.note_id\n",
    "        else:\n",
    "            arg = df.start, df.end, df.value, df.file\n",
    "    \n",
    "    return set(list(zip(*arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2005,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython \n",
    "\n",
    "from __main__ import df_to_set, engine\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "def get_cooccurences(ref, sys, analysis_type: str, corpus: str):\n",
    "    \"\"\"\n",
    "    get cooccurences between system and reference; exact match; TODO: add relaxed -> done in single system evals during ensemble run\n",
    "    \"\"\"\n",
    "    # cooccurences\n",
    "    class Cooccurences(object):\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.ref_system_match = 0\n",
    "            self.ref_only = 0\n",
    "            self.system_only = 0\n",
    "            self.system_n = 0\n",
    "            self.ref_n = 0\n",
    "            self.matches = set()\n",
    "            self.false_negatives = set()\n",
    "            self.corpus = corpus\n",
    "\n",
    "    c = Cooccurences()\n",
    "    \n",
    "    if c.corpus != 'casi':\n",
    "        if 'entity' in analysis_type: \n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            #ref = ref[['start', 'end', 'file']].drop_duplicates()\n",
    "            ref = ref[['begin', 'end', 'case']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type: \n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            # do not overestimate FP\n",
    "            sys = sys[~sys['cui'].isnull()] \n",
    "            ref = ref[['value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "        elif 'full' in analysis_type: \n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "            sys = sys[cols_to_keep].drop_duplicates()\n",
    "            sys = sys[~sys['cui'].isnull()]\n",
    "            ref = ref[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "            ref = ref[~ref['value'].isnull()]\n",
    "\n",
    "        # matches via inner join\n",
    "        tp = pd.merge(sys, ref, how = 'inner', left_on=['begin','end','note_id'], right_on = ['begin','end','case']) \n",
    "        \n",
    "        # reference-only via left outer join\n",
    "        fn = pd.merge(ref, sys, how = 'left', left_on=['begin','end','case'], right_on = ['begin','end','note_id'], indicator=True) \n",
    "        fn = fn[fn[\"_merge\"] != \"both\"]\n",
    "\n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'case']\n",
    "        else:\n",
    "            cols_to_keep = ['start', 'end', 'value', 'file']\n",
    "\n",
    "        tp = tp[cols_to_keep]\n",
    "        fn = fn[cols_to_keep]\n",
    "\n",
    "        # use for metrics \n",
    "        c.matches = c.matches.union(df_to_set(tp, analysis_type, 'ref'))\n",
    "        c.false_negatives = c.false_negatives.union(df_to_set(fn, analysis_type, 'ref'))\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches) # fp\n",
    "        c.system_n = len(sys)\n",
    "        c.ref_n = len(ref)\n",
    "        c.ref_only = len(c.false_negatives)\n",
    "        \n",
    "    else:\n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where overlap = 1 and `system` = %(sys.name)s\"  \n",
    "        tp = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        sql = \"select `case` from test.amia_2019_analytical_v where (overlap = 0 or overlap is null) and `system` = %(sys.name)s\"  \n",
    "        fn = pd.read_sql(sql, params={\"sys.name\":sys.name}, con=engine)\n",
    "        \n",
    "        c.matches = df_to_set(tp, 'entity', 'sys', 'casi')\n",
    "        c.fn = df_to_set(fn, 'entity', 'sys', 'casi')\n",
    "        c.ref_system_match = len(c.matches)\n",
    "        c.system_only = len(sys) - len(c.matches)\n",
    "        c.system_n = len(tp) + len(fn)\n",
    "        c.ref_n = len(tp) + len(fn)\n",
    "        c.ref_only = len(fn)\n",
    "        \n",
    "    # sanity check\n",
    "    if len(ref) - c.ref_system_match < 0:\n",
    "        print('Error: ref_system_match > len(ref)!')\n",
    "    if len(ref) != c.ref_system_match + c.ref_only:\n",
    "        print('Error: ref count mismatch!', len(ref), c.ref_system_match, c.ref_only)\n",
    "   \n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2006,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vector(doc: str, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.begin, a.end) for a in ann if a.label == lab]\n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v\n",
    "\n",
    "# test confusion matrix elements for vectorized annotation set; includes TN\n",
    "# https://kawahara.ca/how-to-compute-truefalse-positives-and-truefalse-negatives-in-python-for-binary-classification-problems/\n",
    "def confused(sys1, ann1):\n",
    "    TP = np.sum(np.logical_and(ann1 == 1, sys1 == 1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(ann1 == 0, sys1 == 0))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(ann1 == 0, sys1 == 1))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(ann1 == 1, sys1 == 0))\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def vectorized_cooccurences(r: object, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> np.int64:\n",
    "    docs = get_docs(corpus)\n",
    "    if filter_semtype:\n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    else: \n",
    "        ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    sys = get_sys_ann(r)\n",
    "    cvals = []\n",
    "    labels = [\"concept\"]\n",
    "\n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        s1 = list(sys.loc[sys[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        ann1 = label_vector(docs[n][1], a1, labels)\n",
    "        sys1 = label_vector(docs[n][1], s1, labels)\n",
    "\n",
    "        TP, TN, FP, FN = confused(sys1, ann1)\n",
    "        cvals.append([TP, TN, FP, FN])\n",
    "\n",
    "    return np.sum(cvals, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2007,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_dict(ref_only: int, system_only: int, ref_system_match: int, system_n: int, ref_n: int) -> dict:\n",
    "    \"\"\"\n",
    "    Generate dictionary of confusion matrix params and measures\n",
    "    :params: ref_only, system_only, reference_system_match -> sets\n",
    "    matches, system_n, reference_n -> counts\n",
    "    :return: dictionary object\n",
    "    \"\"\"\n",
    "\n",
    "    if ref_only + ref_system_match != ref_n:\n",
    "        print('ERROR!')\n",
    "\n",
    "    # get evaluation metrics\n",
    "    F, recall, precision, TP, FP, FN, TP_FN_R, TM  = Metrics(system_only, ref_only, ref_system_match, system_n).get_confusion_metrics()\n",
    "\n",
    "    d = {\n",
    "         'F': F[1], \n",
    "         'precision': precision[1], \n",
    "         'recall': recall[1], \n",
    "         'TP': TP, \n",
    "         'FN': FN, \n",
    "         'FP': FP, \n",
    "         'TP/FN': TP_FN_R,\n",
    "         'n_gold': ref_n, \n",
    "         'n_sys': system_n, \n",
    "         'TM': TM\n",
    "    }\n",
    "    \n",
    "    if system_n - FP != TP:\n",
    "        print('inconsistent system n!')\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2008,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metric_data(analysis_type: str, corpus: str):\n",
    "   \n",
    "    usys_file, ref_table = AnalysisConfig().corpus_config()\n",
    "    systems = AnalysisConfig().systems\n",
    "    \n",
    "    sys_ann = pd.read_csv(analysisConf.data_dir + usys_file, dtype={'note_id': str})\n",
    "    \n",
    "    sql = \"SELECT * FROM \" + ref_table  \n",
    "    \n",
    "    ref_ann = pd.read_sql(sql, con=engine)\n",
    "    sys_ann = sys_ann.drop_duplicates()\n",
    "    \n",
    "    return ref_ann, sys_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2009,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of rank averages\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2010,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(analysis_type: str, corpus: str, filter_semtype, semtype = None):\n",
    "    start = time.time()\n",
    "\n",
    "    systems = AnalysisConfig().systems\n",
    "    metrics = pd.DataFrame()\n",
    "\n",
    "    __, sys_ann = get_metric_data(analysis_type, corpus)\n",
    "    c = None\n",
    "    \n",
    "    for sys in systems:\n",
    "       \n",
    "        if filter_semtype and semtype:\n",
    "            ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "            \n",
    "        system_annotations = sys_ann[sys_ann['system'] == sys].copy()\n",
    "\n",
    "        if filter_semtype:\n",
    "            st = SemanticTypes([semtype], corpus).get_system_type(sys)\n",
    "\n",
    "            if st: \n",
    "                system_annotations = sys_ann[sys_ann['semtypes'].isin(st)].copy()\n",
    "        else:\n",
    "            system_annotations = sys_ann.copy()\n",
    "\n",
    "        if (filter_semtype and st) or filter_semtype is False:\n",
    "            system = system_annotations.copy()\n",
    "\n",
    "            if sys == 'quick_umls':\n",
    "                system = system[system.score.astype(float) >= .8]\n",
    "\n",
    "            if sys == 'metamap':\n",
    "                system = system.fillna(0)\n",
    "                system = system[system.score.abs().astype(int) >= 800]\n",
    "\n",
    "            system = system.drop_duplicates()\n",
    "\n",
    "            ref_ann = ref_ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "            c = get_cooccurences(ref_ann, system, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "            \n",
    "            if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "                # get dictionary of confusion matrix metrics\n",
    "                d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "                d['system'] = sys\n",
    "\n",
    "                data = pd.DataFrame(d,  index=[0])\n",
    "                metrics = pd.concat([metrics, data], ignore_index=True)\n",
    "                metrics.drop_duplicates(keep='last', inplace=True)\n",
    "            else:\n",
    "                print(\"NO EXACT MATCHES FOR\", sys)\n",
    "            elapsed = (time.time() - start)\n",
    "            print(\"elapsed:\", sys, elapsed)\n",
    "   \n",
    "    if c:\n",
    "        elapsed = (time.time() - start)\n",
    "        print(geometric_mean(metrics))\n",
    "\n",
    "        now = datetime.now()\n",
    "        timestamp = datetime.timestamp(now)\n",
    "\n",
    "        file_name = 'metrics_'\n",
    "\n",
    "        metrics.to_csv(analysisConf.data_dir + corpus + '_' + file_name + analysis_type + '_' + str(timestamp) + '.csv')\n",
    "\n",
    "        print(\"total elapsed time:\", elapsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2011,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_n(analysis_type: str, corpus: str, filter_semtype) -> int:\n",
    "    \n",
    "    ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ref_ann = ref_ann[ref_ann['semtype'].isin(SemanticTypes(semtypes, corpus).get_system_type('reference'))]\n",
    "            \n",
    "    if corpus == 'casi':\n",
    "        return len(ref_ann)\n",
    "        \n",
    "    else:\n",
    "        # do not overestimate fn\n",
    "        if 'entity' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'file']].drop_duplicates()\n",
    "        elif 'cui' in analysis_type:\n",
    "            ref_ann = ref_ann[['value', 'file']].drop_duplicates()\n",
    "        elif 'full' in analysis_type:\n",
    "            ref_ann = ref_ann[['start', 'end', 'value', 'file']].drop_duplicates()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ref_n = len(ref_ann.drop_duplicates())\n",
    "\n",
    "        return ref_n\n",
    "    \n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_data(system: str, analysis_type: str, corpus: str, filter_semtype, semtype = None) -> pd.DataFrame:\n",
    "   \n",
    "    _, data = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "    out = data[data['system'] == system].copy()\n",
    "    \n",
    "    if filter_semtype:\n",
    "        st = SemanticTypes([semtype], corpus).get_system_type(system)\n",
    "    \n",
    "    if corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap'] \n",
    "        out = out[cols_to_keep].drop_duplicates()\n",
    "        return out\n",
    "        \n",
    "    else:\n",
    "        if filter_semtype:\n",
    "            out = out[out['semtypes'].isin(st)].copy()\n",
    "            \n",
    "        else:\n",
    "            out = out[out['system']== system].copy()\n",
    "        \n",
    "        if system == 'quick_umls':\n",
    "            out = out[(out.score.astype(float) >= 0.8) & (out[\"type\"] == 'concept_jaccard_score_False')]\n",
    "            # fix for leading spacxe on semantic type field\n",
    "            out = out.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) \n",
    "        \n",
    "        if system == 'metamap':\n",
    "            out = out[out.score.abs().astype(int) >= 800]\n",
    "            \n",
    "        if 'entity' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'note_id']\n",
    "        elif 'cui' in analysis_type:\n",
    "            cols_to_keep = ['cui', 'note_id']\n",
    "        elif 'full' in analysis_type:\n",
    "            cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "        #out = out[cols_to_keep]\n",
    "\n",
    "        return out.drop_duplicates()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GENERATE merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2012,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTotals(object):\n",
    "    \"\"\" \n",
    "    returns an instance with merged match set numbers using either union or intersection of elements in set \n",
    "    \"\"\"\n",
    "    def __init__(self, ref_n, sys_n, match_set):\n",
    "\n",
    "        self = self    \n",
    "        self.ref_ann = ref_n\n",
    "        self.sys_n = sys_n\n",
    "        self.match_set = match_set\n",
    "\n",
    "    def get_ref_sys(self):\n",
    "\n",
    "        ref_only = self.ref_ann - len(self.match_set)\n",
    "        sys_only = self.sys_n - len(self.match_set)\n",
    "\n",
    "        return ref_only, sys_only, len(self.match_set), self.match_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2013,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ft.lru_cache(maxsize=None)\n",
    "def process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Recursively evaluate parse tree, \n",
    "    with check for existence before build\n",
    "       :param sentence: to process\n",
    "       :return class of merged annotations, boolean operated system df \n",
    "    \"\"\"\n",
    "    \n",
    "    class Results(object):\n",
    "        def __init__(self):\n",
    "            self.results = set()\n",
    "            self.system_merges = pd.DataFrame()\n",
    "            \n",
    "    r = Results()\n",
    "    \n",
    "    if 'entity' in analysis_type and corpus != 'casi': \n",
    "        cols_to_keep = ['begin', 'end', 'note_id'] # entity only\n",
    "    elif 'full' in analysis_type: \n",
    "        cols_to_keep = ['cui', 'begin', 'end', 'note_id'] # entity only\n",
    "    elif 'cui' in analysis_type:\n",
    "        cols_to_keep = ['cui', 'note_id'] # entity only\n",
    "    elif corpus == 'casi':\n",
    "        cols_to_keep = ['case', 'overlap']\n",
    "    \n",
    "    def evaluate(parseTree):\n",
    "        oper = {'&': op.and_, '|': op.or_}\n",
    "        \n",
    "        if parseTree:\n",
    "            leftC = gevent.spawn(evaluate, parseTree.getLeftChild())\n",
    "            rightC = gevent.spawn(evaluate, parseTree.getRightChild())\n",
    "            \n",
    "            if leftC.get() is not None and rightC.get() is not None:\n",
    "                system_query = pd.DataFrame()\n",
    "                fn = oper[parseTree.getRootVal()]\n",
    "                \n",
    "                if isinstance(leftC.get(), str):\n",
    "                    # get system as leaf node \n",
    "                    if filter_semtype:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        left_sys = get_sys_data(leftC.get(), analysis_type, corpus, filter_semtype)\n",
    "                \n",
    "                elif isinstance(leftC.get(), pd.DataFrame):\n",
    "                    l_sys = leftC.get()\n",
    "                \n",
    "                if isinstance(rightC.get(), str):\n",
    "                    # get system as leaf node\n",
    "                    if filter_semtype:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        right_sys = get_sys_data(rightC.get(), analysis_type, corpus, filter_semtype)\n",
    "                    \n",
    "                elif isinstance(rightC.get(), pd.DataFrame):\n",
    "                    r_sys = rightC.get()\n",
    "                    \n",
    "                if fn == op.or_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        frames = [left_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [left_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        frames = [l_sys, right_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        frames = [l_sys, r_sys]\n",
    "                        df = pd.concat(frames,  ignore_index=True)\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                if fn == op.and_:\n",
    "\n",
    "                    if isinstance(leftC.get(), str) and isinstance(rightC.get(), str):\n",
    "                        df = left_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), str) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        df = left_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), str):\n",
    "                        df = l_sys.merge(right_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "\n",
    "                    elif isinstance(leftC.get(), pd.DataFrame) and isinstance(rightC.get(), pd.DataFrame):\n",
    "                        df = l_sys.merge(r_sys, on=cols_to_keep, how='inner')\n",
    "                        df = df[cols_to_keep].drop_duplicates(subset=cols_to_keep)\n",
    "                \n",
    "                # get combined system results\n",
    "                r.system_merges = df\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    system_query = system_query.append(df)\n",
    "                else:\n",
    "                    print('wtf!')\n",
    "                    \n",
    "                return system_query\n",
    "            else:\n",
    "                return parseTree.getRootVal()\n",
    "    \n",
    "    if sentence.n_or > 0 or sentence.n_and > 0:\n",
    "        evaluate(pt)  \n",
    "    \n",
    "    # trivial case\n",
    "    elif sentence.n_or == 0 and sentence.n_and == 0:\n",
    "        if filter_semtype:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            r.system_merges = get_sys_data(sentence.sentence, analysis_type, corpus, filter_semtype)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2014,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Incoming Boolean sentences are parsed into a binary tree.\n",
    "\n",
    "Test expressions to parse:\n",
    "\n",
    "sentence = '((((A&B)|C)|D)&E)'\n",
    "\n",
    "sentence = '(E&(D|(C|(A&B))))'\n",
    "\n",
    "sentence = '(((A|(B&C))|(D&(E&F)))|(H&I))'\n",
    "\n",
    "\"\"\"\n",
    "# build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "def buildParseTree(fpexp):\n",
    "    \"\"\"\n",
    "       Iteratively build parse tree from passed sentence using grammatical rules of Boolean logic\n",
    "       :param fpexp: sentence to parse\n",
    "       :return eTree: parse tree representation\n",
    "       Incoming Boolean sentences are parsed into a binary tree.\n",
    "       Test expressions to parse:\n",
    "       sentence = '(A&B)'\n",
    "       sentence = '(A|B)'\n",
    "       sentence = '((A|B)&C)'\n",
    "       \n",
    "    \"\"\"\n",
    "    fplist = fpexp.split()\n",
    "    pStack = Stack()\n",
    "    eTree = BinaryTree('')\n",
    "    pStack.push(eTree)\n",
    "    currentTree = eTree\n",
    "\n",
    "    for i in fplist:\n",
    "\n",
    "        if i == '(':\n",
    "            currentTree.insertLeft('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getLeftChild()\n",
    "        elif i not in ['&', '|', ')']:\n",
    "            currentTree.setRootVal(i)\n",
    "            parent = pStack.pop()\n",
    "            currentTree = parent\n",
    "        elif i in ['&', '|']:\n",
    "            currentTree.setRootVal(i)\n",
    "            currentTree.insertRight('')\n",
    "            pStack.push(currentTree)\n",
    "            currentTree = currentTree.getRightChild()\n",
    "        elif i == ')':\n",
    "            currentTree = pStack.pop()\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    return eTree\n",
    "\n",
    "def make_parse_tree(payload):\n",
    "    \"\"\"\n",
    "    Ensure data to create tree are in correct form\n",
    "    :param sentence: sentence to preprocess\n",
    "    :return pt, parse tree graph\n",
    "            sentence, processed sentence to build tree\n",
    "            a: order\n",
    "    \"\"\"\n",
    "    def preprocess_sentence(sentence):\n",
    "        # prepare statement for case when a boolean AND/OR is given\n",
    "        sentence = payload.replace('(', ' ( '). \\\n",
    "            replace(')', ' ) '). \\\n",
    "            replace('&', ' & '). \\\n",
    "            replace('|', ' | '). \\\n",
    "            replace('  ', ' ')\n",
    "        return sentence\n",
    "\n",
    "    sentence = preprocess_sentence(payload)\n",
    "    print(sentence)\n",
    "    \n",
    "    pt = buildParseTree(sentence)\n",
    "    #pt.postorder() \n",
    "    \n",
    "    return pt\n",
    "\n",
    "class Sentence(object):\n",
    "    '''\n",
    "    Details about boolean expression -> number operators and expression\n",
    "    '''\n",
    "    def __init__(self, sentence):\n",
    "        self = self\n",
    "        self.n_and = sentence.count('&')\n",
    "        self.n_or = sentence.count('|')\n",
    "        self.sentence = sentence\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_docs(corpus):\n",
    "    sql = 'select distinct note_id, sofa from sofas where corpus = %(corpus)s order by note_id'\n",
    "    df = pd.read_sql(sql, params={\"corpus\":corpus}, con=engine)\n",
    "    df.drop_duplicates()\n",
    "    df['len_doc'] = df['sofa'].apply(len)\n",
    "    \n",
    "    subset = df[['note_id', 'len_doc']]\n",
    "    docs = [tuple(x) for x in subset.to_numpy()]\n",
    "    \n",
    "    return docs\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_ref_ann(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    if filter_semtype:\n",
    "        if ',' in semtype:\n",
    "            semtype = semtype.split(',')\n",
    "        else:\n",
    "            semtype = [semtype]\n",
    "        \n",
    "    ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    ann = ann.rename(index=str, columns={\"start\": \"begin\", \"file\": \"case\"})\n",
    "    \n",
    "    if filter_semtype:\n",
    "        ann = ann[ann['semtype'].isin(semtype)]\n",
    "        \n",
    "    ann[\"label\"] = 'concept'\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ann = ann[cols_to_keep]\n",
    "    \n",
    "    return ann\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_sys_ann(r):\n",
    "    sys = r.system_merges    \n",
    "    sys = sys.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "    sys[\"label\"] = 'concept'\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys = sys[cols_to_keep]\n",
    "\n",
    "    return sys\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def get_metrics(boolean_expression: str, analysis_type: str, corpus: str, run_type: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = Sentence(boolean_expression)   \n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "    \n",
    "    if filter_semtype:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    else:\n",
    "        r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    # vectorize merges using i-o labeling\n",
    "    if run_type == 'overlap':\n",
    "        if filter_semtype:\n",
    "            TP, TN, FP, FN = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype, semtype)\n",
    "        else:\n",
    "            TP, TN, FP, FN = vectorized_cooccurences(r, analysis_type, corpus, filter_semtype)\n",
    "\n",
    "        # TODO: validate against ann1/sys1 where val = 1\n",
    "        # total by number chars\n",
    "        system_n = TP + FP\n",
    "        reference_n = TP + FN\n",
    "\n",
    "        d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "        \n",
    "        d['TN'] = TN\n",
    "        \n",
    "        # return full metrics\n",
    "        return d\n",
    "\n",
    "    elif run_type == 'exact':\n",
    "        # total by number spans\n",
    "        \n",
    "        if filter_semtype:\n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "        else: \n",
    "            ann = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "        c = get_cooccurences(ann, r.system_merges, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "        if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "            # get dictionary of confusion matrix metrics\n",
    "            d = cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n)\n",
    "        else:\n",
    "            d = None\n",
    "            \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2015,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all combinations of given list of annotators:\n",
    "def partly_unordered_permutations(lst, k):\n",
    "    elems = set(lst)\n",
    "    for c in combinations(lst, k):\n",
    "        for d in permutations(elems - set(c)):\n",
    "            yield c + d\n",
    "            \n",
    "def expressions(l, n):\n",
    "    for (operations, *operands), operators in product(\n",
    "            combinations(l, n), product(('&', '|'), repeat=n - 1)):\n",
    "        for operation in zip(operators, operands):\n",
    "            operations = [operations, *operation]\n",
    "        yield operations\n",
    "\n",
    "# get list of systems with a semantic type in grouping\n",
    "def get_valid_systems(systems, semtype):\n",
    "    test = []\n",
    "    for sys in systems:\n",
    "        st = system_semtype_check(sys, semtype, corpus)\n",
    "        if st:\n",
    "            test.append(sys)\n",
    "\n",
    "    return test\n",
    "\n",
    "# permute system combinations and evaluate system merges for performance\n",
    "def run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type, semtype = None):\n",
    "    metrics = pd.DataFrame()\n",
    "    \n",
    "    if expression_type == 'nested':\n",
    "        for l in partly_unordered_permutations(systems, 2):\n",
    "            print('processing merge combo:', l)\n",
    "            for i in range(1, len(l)+1):\n",
    "                test = list(expressions(l, i))\n",
    "                for t in test:\n",
    "                    if i > 1:\n",
    "                        # format Boolean sentence for parse tree \n",
    "                        t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                    if filter_semtype:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "                    else:\n",
    "                        d = get_metrics(t, analysis_type, corpus, run_type, filter_semtype)\n",
    "\n",
    "                    d['merge'] = t\n",
    "                    d['n_terms'] = i\n",
    "\n",
    "                    frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "                    metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                    \n",
    "    elif expression_type == 'nested_with_singleton' and len(systems) == 5:\n",
    "        # form (((a&b)|c)&(d|e))\n",
    "        \n",
    "        nested = list(expressions(systems, 3))\n",
    "        test = list(expressions(systems, 2))\n",
    "        to_do_terms = []\n",
    "    \n",
    "        for n in nested:\n",
    "            # format Boolean sentence for parse tree \n",
    "            n = '(' + \" \".join(str(x) for x in n).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "            for t in test:\n",
    "                t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "\n",
    "                new_and = '(' + n +'&'+ t + ')'\n",
    "                new_or = '(' + n +'|'+ t + ')'\n",
    "\n",
    "                if new_and.count('biomedicus') != 2 and new_and.count('clamp') != 2 and new_and.count('ctakes') != 2 and new_and.count('metamap') != 2 and new_and.count('quick_umls') != 2:\n",
    "\n",
    "                    if new_and.count('&') != 4 and new_or.count('|') != 4:\n",
    "                        #print(new_and)\n",
    "                        #print(new_or)\n",
    "                        to_do_terms.append(new_or)\n",
    "                        to_do_terms.append(new_and)\n",
    "        \n",
    "        print('nested_with_singleton', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "                        \n",
    "    elif expression_type == 'paired':\n",
    "        m = list(expressions(systems, 2))\n",
    "        test = list(expressions(m, 2))\n",
    "\n",
    "        to_do_terms = []\n",
    "        for t in test:\n",
    "            # format Boolean sentence for parse tree \n",
    "            t = '(' + \" \".join(str(x) for x in t).replace('[','(').replace(']',')').replace(\"'\",\"\").replace(\",\",\"\").replace(\" \",\"\") + ')'\n",
    "            if t.count('biomedicus') != 2 and t.count('clamp') != 2 and t.count('ctakes') != 2 and t.count('metamap') != 2 and t.count('quick_umls') != 2:\n",
    "                if t.count('&') != 3 and t.count('|') != 3:\n",
    "                    to_do_terms.append(t)\n",
    "                    if len(systems) == 5:\n",
    "                        for i in systems:\n",
    "                            if i not in t:\n",
    "                                #print('('+t+'&'+i+')')\n",
    "                                #print('('+t+'|'+i+')')\n",
    "                                new_and = '('+t+'&'+i+')'\n",
    "                                new_or = '('+t+'|'+i+')'\n",
    "                                to_do_terms.append(new_and)\n",
    "                                to_do_terms.append(new_or)\n",
    "                            \n",
    "        print('paired', len(to_do_terms))\n",
    "        for term in to_do_terms:\n",
    "            if filter_semtype:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype, semtype)\n",
    "            else:\n",
    "                d = get_metrics(term, analysis_type, corpus, run_type, filter_semtype)\n",
    "                \n",
    "            n = term.count('&')\n",
    "            m = term.count('|')\n",
    "            d['merge'] = term\n",
    "            d['n_terms'] = m + n + 1\n",
    "\n",
    "            frames = [metrics, pd.DataFrame(d, index=[0])]\n",
    "            metrics = pd.concat(frames, ignore_index=True, sort=False) \n",
    "        \n",
    "    return metrics\n",
    "\n",
    "# write to file\n",
    "def generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype = None):\n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    \n",
    "    file_name = corpus + '_all_'\n",
    "   \n",
    "    # drop exact matches:\n",
    "    metrics = metrics.drop_duplicates()\n",
    "    \n",
    "    if ensemble_type == 'merge':\n",
    "        metrics = metrics.sort_values(by=['n_terms', 'merge'])\n",
    "        file_name += 'merge_'\n",
    "    elif ensemble_type == 'vote':\n",
    "        file_name += 'vote_'\n",
    "    \n",
    "    #metrics = metrics.drop_duplicates(subset=['TP', 'FN', 'FP', 'n_sys', 'precision', 'recall', 'F', 'TM', 'TP/FN', 'TM', 'n_terms'])\n",
    "\n",
    "    file = file_name + analysis_type + '_' + run_type +'_'\n",
    "    \n",
    "    if filter_semtype:\n",
    "        file += semtype\n",
    "        \n",
    "    \n",
    "    geometric_mean(metrics).to_csv(analysisConf.data_dir + file + str(timestamp) + '.csv')\n",
    "    print(geometric_mean(metrics))\n",
    "    \n",
    "# control ensemble run\n",
    "def ensemble_control(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            metrics = run_ensemble(test, analysis_type, corpus, filter_semtype, expression_type, semtype)\n",
    "            if (expression_type == 'nested_with_singleton' and len(test) == 5) or expression_type in ['nested', 'paired']:\n",
    "                generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "    else:\n",
    "        metrics = run_ensemble(systems, analysis_type, corpus, filter_semtype, expression_type)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2016,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad hoc query\n",
    "def get_merge_data(boolean_expression: str, analysis_type: str, corpus: str, filter_semtype, semtype = None):\n",
    "    \"\"\"\n",
    "    Traverse binary parse tree representation of Boolean sentence\n",
    "        :params: boolean expression in form of '(<annotator_engine_name1><boolean operator><annotator_engine_name2>)'\n",
    "                 analysis_type (string value of: 'entity', 'cui', 'full') used to filter set of reference and system annotations \n",
    "        :return: dictionary with values needed for confusion matrix\n",
    "    \"\"\"\n",
    "    sentence = Sentence(boolean_expression)   \n",
    "\n",
    "    pt = make_parse_tree(sentence.sentence)\n",
    "\n",
    "    r = process_sentence(pt, sentence, analysis_type, corpus, filter_semtype, semtype)\n",
    "    \n",
    "    system_n = len(r.system_merges)\n",
    "    reference_n = get_ref_n(analysis_type, corpus, filter_semtype)\n",
    "\n",
    "    reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, r.results).get_ref_sys()\n",
    "\n",
    "    print('cm', cm_dict(reference_only, system_only, reference_system_match, system_n, reference_n))\n",
    "    # get matched data from merge\n",
    "    return r.system_merges # merge_eval(reference_only, system_only, reference_system_match, system_n, reference_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2017,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority vote for overlap\n",
    "def vectorized_annotations(ann):\n",
    "    \n",
    "    docs = get_docs(corpus)\n",
    "    labels = [\"concept\"]\n",
    "    out= []\n",
    "    \n",
    "    for n in range(len(docs)):\n",
    "        a1 = list(ann.loc[ann[\"case\"] == docs[n][0]].itertuples(index=False))\n",
    "        a = label_vector(docs[n][1], a1, labels)\n",
    "        out.append(a)\n",
    "\n",
    "    return out\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def majority_ensemble(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    \n",
    "    d = {}\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    sys_test = []\n",
    "    \n",
    "    for system in systems:\n",
    "        sys_ann = get_sys_data(system, analysis_type, corpus, filter_semtype, semtype)\n",
    "        df = sys_ann.copy()\n",
    "        df['label'] = 'concept'\n",
    "        df = df.rename(index=str, columns={\"note_id\": \"case\"})\n",
    "        sys = df[df['system']==system][cols_to_keep].copy()\n",
    "        test = vectorized_annotations(sys)\n",
    "        d[system] = flatten_list(test) \n",
    "        sys_test.append(d[system])\n",
    "\n",
    "    output = sum(np.array(sys_test))\n",
    "    \n",
    "    n = int(len(systems) / 2)\n",
    "    #print(n)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        vote = np.where(output > n, 1, 0)\n",
    "    else:\n",
    "        vote = np.where(output > n, 1, \n",
    "         (np.where(output == n, random.choice(0, 1), 0)))\n",
    "        \n",
    "    return vote\n",
    "\n",
    "def reference(analysis_type, corpus, filter_semtype, semtype = None):\n",
    "    ref_ann = get_ref_ann(analysis_type, corpus, filter_semtype, semtype)\n",
    "    #ref_ann, _ = get_metric_data(analysis_type, corpus)\n",
    "    \n",
    "\n",
    "    df = ref_ann.copy()\n",
    "    df = df.drop_duplicates(subset=['begin','end','case'])\n",
    "    df['label'] = 'concept'\n",
    "    #cases = set(df['case'].to_list())\n",
    "    #df = df1.rename(index=str, columns={\"file\": \"case\", \"start\": \"begin\"})\n",
    "\n",
    "    cols_to_keep = ['begin', 'end', 'case', 'label']\n",
    "    ref = df[cols_to_keep].copy()\n",
    "    test = vectorized_annotations(ref)\n",
    "    ref =  np.asarray(flatten_list(test), dtype=np.int32) \n",
    "\n",
    "    return ref\n",
    "\n",
    "def majority_vote_out(ref, vote, corpus):    \n",
    "    TP, TN, FP, FN = confused(ref, vote)\n",
    "    print(TP, TN, FP, FN)\n",
    "    system_n = TP + FP\n",
    "    reference_n = TP + FN\n",
    "\n",
    "    d = cm_dict(FN, FP, TP, system_n, reference_n)\n",
    "\n",
    "    d['TN'] = TN\n",
    "    d['corpus'] = corpus\n",
    "    print(d)\n",
    "    \n",
    "    metrics = pd.DataFrame(d, index=[0])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# control ensemble run\n",
    "def majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes = None):\n",
    "    print(semtypes, systems)\n",
    "    if filter_semtype:\n",
    "        for semtype in semtypes:\n",
    "            test = get_valid_systems(systems, semtype)\n",
    "            print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "            ref = reference(analysis_type, corpus, filter_semtype, semtype)\n",
    "            vote = majority_ensemble(test, analysis_type, corpus, filter_semtype, semtype)\n",
    "            metrics = majority_vote_out(ref, vote, corpus)\n",
    "            metrics['systems'] = ','.join(test)\n",
    "            generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype, semtype)\n",
    "            print(metrics)\n",
    "    else:\n",
    "        # ref = reference()\n",
    "        ref = reference(analysis_type, corpus, filter_semtype)\n",
    "        vote = majority_ensemble(systems, analysis_type, corpus, filter_semtype)\n",
    "        metrics = majority_vote_out(ref, vote, corpus)\n",
    "        generate_ensemble_metrics(metrics, analysis_type, corpus, ensemble_type, filter_semtype)\n",
    "        metrics['systems'] = ','.join(test)\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2018,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'] ('analytical_fairview.csv', 'concepts.fairview_all')\n",
      "['Drug', 'Finding', 'Anatomy', 'Procedure'] ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
      "SYSYEMS FOR SEMTYPE Drug ARE ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed: biomedicus 5.065356016159058\n",
      "elapsed: clamp 5.283382892608643\n",
      "elapsed: ctakes 5.56670880317688\n",
      "elapsed: metamap 6.029689073562622\n",
      "elapsed: quick_umls 6.431399822235107\n",
      "          F  precision    recall     TP    FN     FP     TP/FN  n_gold  n_sys  \\\n",
      "0  0.270155   0.167579  0.696466   8967  3908  44542  2.294524   12875  53509   \n",
      "1  0.465124   0.371062  0.623068   8022  4853  13597  1.652998   12875  21619   \n",
      "2  0.244983   0.144660  0.799301  10291  2584  60848  3.982585   12875  71139   \n",
      "3  0.125736   0.083839  0.251340   3236  9639  35362  0.335719   12875  38598   \n",
      "4  0.287164   0.183049  0.665942   8574  4301  38266  1.993490   12875  46840   \n",
      "\n",
      "          TM      system  F1 rank  TP/FN rank  TM rank     Gmean  \n",
      "0  38.764461  biomedicus      3.0         2.0      3.0  2.620741  \n",
      "1  54.558806       clamp      1.0         4.0      1.0  1.587401  \n",
      "2  38.583685      ctakes      4.0         1.0      4.0  2.519842  \n",
      "3  16.471233     metamap      5.0         5.0      5.0  5.000000  \n",
      "4  39.616403  quick_umls      2.0         3.0      2.0  2.289428  \n",
      "total elapsed time: 6.431551933288574\n",
      "SYSYEMS FOR SEMTYPE Finding ARE ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
      "elapsed: biomedicus 0.8655059337615967\n",
      "elapsed: clamp 1.1588268280029297\n",
      "elapsed: ctakes 1.494933843612671\n",
      "elapsed: metamap 1.9693069458007812\n",
      "elapsed: quick_umls 2.576211929321289\n",
      "          F  precision    recall     TP     FN      FP     TP/FN  n_gold  \\\n",
      "0  0.161824   0.095173  0.539983  10595   9026  100729  1.173831   19621   \n",
      "1  0.331748   0.267938  0.435452   8544  11077   23344  0.771328   19621   \n",
      "2  0.240192   0.157398  0.506753   9943   9678   53228  1.027382   19621   \n",
      "3  0.230863   0.165524  0.381428   7484  12137   37730  0.616627   19621   \n",
      "4  0.163461   0.097424  0.507365   9955   9666   92227  1.029899   19621   \n",
      "\n",
      "    n_sys         TM      system  F1 rank  TP/FN rank  TM rank     Gmean  \n",
      "0  111324  31.754594  biomedicus      5.0         1.0      4.0  2.714418  \n",
      "1   31888  47.846216       clamp      1.0         4.0      1.0  1.587401  \n",
      "2   63171  39.560208      ctakes      2.0         3.0      2.0  2.289428  \n",
      "3   45214  35.196325     metamap      3.0         5.0      3.0  3.556893  \n",
      "4  102182  31.142542  quick_umls      4.0         2.0      5.0  3.419952  \n",
      "total elapsed time: 2.5763299465179443\n",
      "SYSYEMS FOR SEMTYPE Anatomy ARE ['biomedicus', 'ctakes', 'metamap', 'quick_umls']\n",
      "elapsed: biomedicus 0.5421137809753418\n",
      "elapsed: ctakes 0.854212760925293\n",
      "elapsed: metamap 1.2410550117492676\n",
      "elapsed: quick_umls 1.635321855545044\n",
      "          F  precision    recall    TP    FN     FP     TP/FN  n_gold  n_sys  \\\n",
      "0  0.198295   0.114600  0.735289  4536  1633  35045  2.777710    6169  39581   \n",
      "1  0.312858   0.197821  0.747609  4612  1557  18702  2.962107    6169  23314   \n",
      "2  0.216661   0.156443  0.352245  2173  3996  11717  0.543794    6169  13890   \n",
      "3  0.200089   0.116021  0.726536  4482  1687  34149  2.656787    6169  38631   \n",
      "\n",
      "          TM      system  F1 rank  TP/FN rank  TM rank     Gmean  \n",
      "0  22.799728  biomedicus      4.0         2.0      3.0  2.884499  \n",
      "1  30.205143      ctakes      1.0         1.0      1.0  1.000000  \n",
      "2  18.437779     metamap      2.0         4.0      4.0  3.174802  \n",
      "3  22.803624  quick_umls      3.0         3.0      2.0  2.620741  \n",
      "total elapsed time: 1.6354517936706543\n",
      "SYSYEMS FOR SEMTYPE Procedure ARE ['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls']\n",
      "elapsed: biomedicus 0.4895927906036377\n",
      "elapsed: clamp 0.7002859115600586\n",
      "elapsed: ctakes 0.9149818420410156\n",
      "elapsed: metamap 1.3076777458190918\n",
      "elapsed: quick_umls 1.640974760055542\n",
      "          F  precision    recall   TP    FN     FP     TP/FN  n_gold  n_sys  \\\n",
      "0  0.034084   0.017593  0.544127  894   749  49922  1.193591    1643  50816   \n",
      "1  0.047888   0.025536  0.384054  631  1012  24079  0.623518    1643  24710   \n",
      "2  0.080259   0.044037  0.452222  743   900  16129  0.825556    1643  16872   \n",
      "3  0.037434   0.019676  0.384054  631  1012  31439  0.623518    1643  32070   \n",
      "4  0.037523   0.019478  0.510043  838   805  42185  1.040994    1643  43023   \n",
      "\n",
      "         TM      system  F1 rank  TP/FN rank  TM rank     Gmean  \n",
      "0  3.965859  biomedicus      5.0         1.0      4.0  2.714418  \n",
      "1  4.014144       clamp      2.0         4.5      3.0  3.000000  \n",
      "2  5.720125      ctakes      1.0         3.0      1.0  1.442250  \n",
      "3  3.523545     metamap      4.0         4.5      5.0  4.481405  \n",
      "4  4.040114  quick_umls      3.0         2.0      2.0  2.289428  \n",
      "total elapsed time: 1.6411018371582031\n",
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         3789575 function calls (3775583 primitive calls) in 12.470 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    1.743    1.743    1.753    1.753 {method 'read' of 'pandas._libs.parsers.TextReader' objects}\n",
       "       20    1.579    0.079    1.579    0.079 {pandas._libs.ops.scalar_compare}\n",
       "      950    1.177    0.001    1.177    0.001 {method 'copy' of 'numpy.ndarray' objects}\n",
       "       23    0.940    0.041    0.940    0.041 {pandas._libs.hashtable.ismember_object}\n",
       "      157    0.497    0.003    0.497    0.003 {method 'factorize' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
       "      231    0.397    0.002    0.397    0.002 {method 'factorize' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "        4    0.363    0.091    0.363    0.091 {built-in method gc.collect}\n",
       "        4    0.334    0.083   12.335    3.084 <ipython-input-2010-ebad6c4d1bd3>:1(generate_metrics)\n",
       "      501    0.318    0.001    0.318    0.001 {method 'recv_into' of '_socket.socket' objects}\n",
       "     1571    0.306    0.000    0.314    0.000 {pandas._libs.lib.infer_dtype}\n",
       "      228    0.285    0.001    0.286    0.001 {method 'factorize' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "     3844    0.254    0.000    0.254    0.000 {built-in method numpy.empty}\n",
       "       77    0.218    0.003    0.218    0.003 {pandas._libs.hashtable.duplicated_int64}\n",
       "        3    0.214    0.071    0.214    0.071 {method 'get_labels_groupby' of 'pandas._libs.hashtable.Int64HashTable' objects}\n",
       "      128    0.208    0.002    0.208    0.002 {pandas._libs.algos.take_2d_axis1_object_object}\n",
       "      227    0.168    0.001    0.168    0.001 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
       "    45039    0.160    0.000    0.509    0.000 connections.py:1195(_read_row_from_packet)\n",
       "    91547    0.154    0.000    0.154    0.000 {method 'settimeout' of '_socket.socket' objects}\n",
       "      102    0.143    0.001    0.175    0.002 managers.py:1841(_stack_arrays)\n",
       "    45622    0.100    0.000    0.757    0.000 connections.py:648(_read_packet)\n",
       "       38    0.095    0.002    0.105    0.003 <ipython-input-2004-cbcab9c60c9a>:1(df_to_set)\n",
       "    91244    0.093    0.000    0.608    0.000 connections.py:687(_read_bytes)\n",
       "       76    0.087    0.001    0.087    0.001 {method 'factorize' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "   225649    0.087    0.000    0.100    0.000 protocol.py:63(read)\n",
       "      104    0.085    0.001    0.085    0.001 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
       "       77    0.084    0.001    0.338    0.004 sorting.py:20(get_group_index)\n",
       "   225759    0.082    0.000    0.290    0.000 protocol.py:168(read_length_coded_string)\n",
       "       46    0.079    0.002    0.079    0.002 managers.py:2004(<listcomp>)\n",
       "       77    0.078    0.001    2.305    0.030 frame.py:4605(drop_duplicates)\n",
       "      262    0.068    0.000    0.068    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "      284    0.065    0.000    0.065    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
       "   226223    0.060    0.000    0.109    0.000 protocol.py:150(read_length_encoded_integer)\n",
       "235349/235267    0.056    0.000    0.099    0.000 {built-in method builtins.isinstance}\n",
       "       50    0.050    0.001    1.006    0.020 connections.py:1182(_read_rowdata_packet)\n",
       "   226224    0.048    0.000    0.048    0.000 protocol.py:117(read_uint8)\n",
       "   225329    0.042    0.000    0.042    0.000 {method 'decode' of 'bytes' objects}\n",
       "      503    0.038    0.000    1.292    0.003 algorithms.py:559(factorize)\n",
       "      214    0.038    0.000    0.078    0.000 blocks.py:3131(_merge_blocks)\n",
       "      669    0.036    0.000    0.036    0.000 {built-in method numpy.concatenate}\n",
       "      186    0.035    0.000    0.035    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
       "    91244    0.034    0.000    0.354    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
       "380240/369335    0.034    0.000    0.039    0.000 {built-in method builtins.len}\n",
       "      227    0.030    0.000    0.033    0.000 indexing.py:2575(maybe_convert_indices)\n",
       "        1    0.029    0.029    4.467    4.467 <ipython-input-2008-ee20452e93e4>:1(get_metric_data)\n",
       "    99641    0.029    0.000    0.040    0.000 generic.py:7(_check)\n",
       "     1707    0.029    0.000    0.029    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "      503    0.028    0.000    0.031    0.000 sorting.py:55(maybe_lift)\n",
       "      115    0.026    0.000    0.026    0.000 {method 'factorize' of 'pandas._libs.hashtable.Float64HashTable' objects}\n",
       "       19    0.025    0.001    0.030    0.002 {pandas._libs.join.left_outer_join}\n",
       "      232    0.024    0.000    0.024    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
       "    16093    0.023    0.000    0.060    0.000 dtypes.py:68(find)\n",
       "        1    0.022    0.022    2.034    2.034 parsers.py:403(_read)\n",
       "        1    0.022    0.022   12.471   12.471 <ipython-input-2018-9a3b21a44d95>:2(main)\n",
       "      209    0.022    0.000    0.022    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
       "     3916    0.022    0.000    0.022    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "   275022    0.022    0.000    0.022    0.000 {method 'append' of 'list' objects}\n",
       "     4458    0.022    0.000    0.028    0.000 generic.py:5069(__setattr__)\n",
       "       19    0.021    0.001    1.416    0.075 <ipython-input-2005-3c8f524af9e9>:7(get_cooccurences)\n",
       "       19    0.020    0.001    0.024    0.001 {pandas._libs.join.inner_join}\n",
       "154069/154066    0.020    0.000    0.022    0.000 {built-in method builtins.getattr}\n",
       "     1380    0.020    0.000    0.800    0.001 algorithms.py:1544(take_nd)\n",
       "    21505    0.019    0.000    0.043    0.000 common.py:1845(_is_dtype_type)\n",
       "10157/9789    0.019    0.000    0.025    0.000 {built-in method numpy.array}\n",
       "    19568    0.019    0.000    0.030    0.000 {method 'format' of 'str' objects}\n",
       "      503    0.017    0.000    1.150    0.002 algorithms.py:434(_factorize_array)\n",
       "    34469    0.017    0.000    0.017    0.000 {built-in method builtins.hasattr}\n",
       "    24196    0.017    0.000    0.072    0.000 base.py:75(is_dtype)\n",
       " 1147/950    0.016    0.000    0.122    0.000 base.py:253(__new__)\n",
       "       38    0.015    0.000    0.018    0.000 merge.py:1701(_get_join_keys)\n",
       "      362    0.015    0.000    0.018    0.000 cast.py:1193(construct_1d_object_array_from_listlike)\n",
       "      227    0.014    0.000    0.918    0.004 managers.py:1329(take)\n",
       "     7750    0.014    0.000    0.034    0.000 _dtype.py:319(_name_get)\n",
       "       41    0.014    0.000    0.014    0.000 __init__.py:131(lmap)\n",
       "    15506    0.013    0.000    0.064    0.000 common.py:1702(is_extension_array_dtype)\n",
       "    45089    0.013    0.000    0.022    0.000 connections.py:1137(_check_packet_is_eof)\n",
       "    45623    0.013    0.000    0.023    0.000 protocol.py:214(check_error)\n",
       "       77    0.013    0.000    1.921    0.025 frame.py:4639(duplicated)\n",
       "      732    0.012    0.000    0.030    0.000 managers.py:186(_rebuild_blknos_and_blklocs)\n",
       "    45667    0.012    0.000    0.012    0.000 {built-in method _struct.unpack}\n",
       "    82062    0.012    0.000    0.012    0.000 {built-in method builtins.issubclass}\n",
       "    45622    0.011    0.000    0.011    0.000 protocol.py:56(__init__)\n",
       "    45623    0.010    0.000    0.010    0.000 protocol.py:211(is_error_packet)\n",
       "       19    0.010    0.001    0.010    0.001 {method 'lookup' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
       "      125    0.009    0.000    0.009    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
       "    12199    0.009    0.000    0.027    0.000 common.py:1981(pandas_dtype)\n",
       "     1155    0.009    0.000    1.116    0.001 frame.py:2893(__getitem__)\n",
       "       38    0.009    0.000    0.474    0.012 merge.py:730(_get_join_indexers)\n",
       "    45189    0.008    0.000    0.008    0.000 protocol.py:190(is_eof_packet)\n",
       "    15592    0.008    0.000    0.012    0.000 numerictypes.py:293(issubclass_)\n",
       "       20    0.008    0.000    1.586    0.079 ops.py:1591(_comp_method_OBJECT_ARRAY)\n",
       "     7796    0.007    0.000    0.020    0.000 numerictypes.py:365(issubdtype)\n",
       "      152    0.007    0.000    0.387    0.003 merge.py:1617(_factorize_keys)\n",
       "     3283    0.007    0.000    0.019    0.000 blocks.py:78(__init__)\n",
       "        4    0.007    0.002    0.512    0.128 <ipython-input-2014-7d334860507d>:101(get_ref_ann)\n",
       "     1380    0.007    0.000    0.019    0.000 algorithms.py:1417(_get_take_nd_function)\n",
       "     4454    0.007    0.000    0.015    0.000 common.py:160(is_sparse)\n",
       "1543/1542    0.007    0.000    0.050    0.000 series.py:152(__init__)\n",
       "     2151    0.006    0.000    0.006    0.000 {built-in method numpy.arange}\n",
       "       38    0.006    0.000    0.466    0.012 merge.py:1104(_get_join_indexers)\n",
       "     1109    0.006    0.000    0.020    0.000 cast.py:255(maybe_promote)\n",
       "    12716    0.006    0.000    0.019    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
       "      300    0.006    0.000    0.006    0.000 {method 'sendall' of '_socket.socket' objects}\n",
       "     3283    0.006    0.000    0.055    0.000 blocks.py:3080(make_block)\n",
       "     1134    0.006    0.000    0.019    0.000 managers.py:963(iget)\n",
       "       41    0.005    0.000    1.500    0.037 sql.py:317(read_sql)\n",
       "     1375    0.005    0.000    0.034    0.000 blocks.py:3034(get_block_type)\n",
       "    13248    0.005    0.000    0.014    0.000 integer.py:80(construct_from_string)\n",
       "     4028    0.005    0.000    0.016    0.000 dtypes.py:973(is_dtype)\n",
       "     1668    0.005    0.000    0.012    0.000 base.py:504(_simple_new)\n",
       "       41    0.005    0.000    0.005    0.000 {pandas._libs.lib.to_object_array_tuples}\n",
       "     2130    0.005    0.000    0.005    0.000 {pandas._libs.algos.ensure_int64}\n",
       "      212    0.005    0.000    0.048    0.000 managers.py:1019(set)\n",
       "       41    0.005    0.000    0.005    0.000 {method 'union' of 'set' objects}\n",
       "     4074    0.005    0.000    0.044    0.000 common.py:1578(is_bool_dtype)\n",
       "    10248    0.005    0.000    0.036    0.000 common.py:434(is_datetime64tz_dtype)\n",
       "     6966    0.005    0.000    0.022    0.000 common.py:1809(_get_dtype)\n",
       "     5415    0.004    0.000    0.017    0.000 common.py:131(is_object_dtype)\n",
       "       45    0.004    0.000    0.004    0.000 result.py:1192(<listcomp>)\n",
       "     1157    0.004    0.000    0.009    0.000 {pandas._libs.algos.ensure_object}\n",
       "     2526    0.004    0.000    0.004    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
       "     2568    0.004    0.000    0.011    0.000 managers.py:139(shape)\n",
       "       77    0.004    0.000    0.004    0.000 {built-in method _operator.inv}\n",
       "     4217    0.004    0.000    0.015    0.000 dtypes.py:827(is_dtype)\n",
       "      178    0.004    0.000    0.004    0.000 {built-in method posix.stat}\n",
       "     1740    0.004    0.000    0.011    0.000 _dtype.py:46(__str__)\n",
       "     3302    0.004    0.000    0.007    0.000 blocks.py:199(mgr_locs)\n",
       "     7056    0.004    0.000    0.024    0.000 common.py:572(is_categorical_dtype)\n",
       "     1853    0.004    0.000    0.008    0.000 dtypes.py:786(construct_from_string)\n",
       "      628    0.004    0.000    0.749    0.001 blocks.py:1217(take_nd)\n",
       "      123    0.004    0.000    0.004    0.000 {pandas._libs.lib.array_equivalent_object}\n",
       "     1542    0.004    0.000    0.017    0.000 managers.py:1443(__init__)\n",
       "      247    0.004    0.000    0.017    0.000 concat.py:261(get_empty_dtype_and_na)\n",
       "      667    0.004    0.000    0.124    0.000 construction.py:537(sanitize_array)\n",
       "     1615    0.004    0.000    0.058    0.000 generic.py:3056(_get_item_cache)\n",
       "       40    0.004    0.000    0.004    0.000 numeric.py:2551(array_equal)\n",
       "     9491    0.004    0.000    0.005    0.000 base.py:652(__len__)\n",
       "      388    0.003    0.000    0.003    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
       "    14893    0.003    0.000    0.005    0.000 common.py:119(<lambda>)\n",
       "     2099    0.003    0.000    0.003    0.000 generic.py:127(__init__)\n",
       "     3069    0.003    0.000    0.007    0.000 dtypes.py:672(construct_from_string)\n",
       "       38    0.003    0.000    0.767    0.020 merge.py:541(get_result)\n",
       "      198    0.003    0.000    0.003    0.000 socket.py:337(send)\n",
       "      663    0.003    0.000    0.063    0.000 managers.py:97(__init__)\n",
       "     3484    0.003    0.000    0.009    0.000 inference.py:253(is_list_like)\n",
       "     2643    0.003    0.000    0.005    0.000 base.py:3918(__contains__)\n",
       "     5199    0.003    0.000    0.003    0.000 {built-in method _abc._abc_instancecheck}\n",
       "     1074    0.003    0.000    0.027    0.000 managers.py:934(get)\n",
       "      142    0.003    0.000    0.028    0.000 {pandas._libs.lib.clean_index_list}\n",
       "     3231    0.003    0.000    0.013    0.000 common.py:403(is_datetime64_dtype)\n",
       "      141    0.003    0.000    0.062    0.000 managers.py:1241(_slice_take_blocks_ax0)\n",
       "    14893    0.003    0.000    0.003    0.000 common.py:117(classes)\n",
       "7178/6818    0.003    0.000    0.024    0.000 numeric.py:469(asarray)\n",
       "     1685    0.003    0.000    0.009    0.000 base.py:3940(__getitem__)\n",
       "     1102    0.003    0.000    0.025    0.000 algorithms.py:38(_ensure_data)\n",
       "       38    0.003    0.000    0.847    0.022 merge.py:37(merge)\n",
       "     4343    0.003    0.000    0.004    0.000 {pandas._libs.lib.is_scalar}\n",
       "     2291    0.003    0.000    0.020    0.000 blocks.py:225(make_block_same_class)\n",
       "     1543    0.003    0.000    0.004    0.000 series.py:354(_set_axis)\n",
       "      291    0.003    0.000    1.280    0.004 managers.py:318(apply)\n",
       "     1171    0.003    0.000    0.011    0.000 blocks.py:2626(__init__)\n",
       "2167/2045    0.003    0.000    0.011    0.000 generic.py:5053(__getattr__)\n",
       "       57    0.003    0.000    0.113    0.002 managers.py:2029(concatenate_block_managers)\n",
       "     1059    0.003    0.000    0.024    0.000 common.py:222(asarray_tuplesafe)\n",
       "      376    0.003    0.000    0.044    0.000 missing.py:183(_isna_ndarraylike)\n",
       "     3784    0.003    0.000    0.058    0.000 base.py:5318(ensure_index)\n",
       "       41    0.003    0.000    0.093    0.002 frame.py:1430(from_records)\n",
       "      312    0.002    0.000    0.003    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
       "     6612    0.002    0.000    0.003    0.000 common.py:127(<lambda>)\n",
       "      110    0.002    0.000    0.004    0.000 concat.py:22(get_mgr_concatenation_plan)\n",
       "      385    0.002    0.000    0.006    0.000 base.py:1658(is_unique)\n",
       "     1054    0.002    0.000    0.024    0.000 base.py:4051(equals)\n",
       "     5011    0.002    0.000    0.019    0.000 common.py:536(is_interval_dtype)\n",
       "     1753    0.002    0.000    0.002    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
       "      556    0.002    0.000    0.300    0.001 frame.py:378(__init__)\n",
       "     1816    0.002    0.000    0.021    0.000 blocks.py:312(ftype)\n",
       "  572/146    0.002    0.000    0.023    0.000 <frozen importlib._bootstrap>:978(_find_and_load)\n",
       "      658    0.002    0.000    0.010    0.000 base.py:566(_shallow_copy)\n",
       "     1946    0.002    0.000    0.004    0.000 series.py:392(name)\n",
       "       41    0.002    0.000    0.106    0.003 sql.py:136(_wrap_result)\n",
       "     1074    0.002    0.000    0.023    0.000 frame.py:3342(_box_item_values)\n",
       "     1853    0.002    0.000    0.004    0.000 dtypes.py:929(construct_from_string)\n",
       "      503    0.002    0.000    0.078    0.000 algorithms.py:132(_reconstruct_data)\n",
       "     3173    0.002    0.000    0.010    0.000 common.py:472(is_timedelta64_dtype)\n",
       "     4217    0.002    0.000    0.017    0.000 common.py:503(is_period_dtype)\n",
       "     1855    0.002    0.000    0.049    0.000 missing.py:105(_isna_new)\n",
       "     3086    0.002    0.000    0.020    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
       "      208    0.002    0.000    0.952    0.005 generic.py:3323(_take)\n",
       "     9692    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}\n",
       "     3350    0.002    0.000    0.007    0.000 base.py:3608(values)\n",
       "      623    0.002    0.000    0.013    0.000 cast.py:953(maybe_cast_to_datetime)\n",
       "       69    0.002    0.000    0.192    0.003 managers.py:1696(form_blocks)\n",
       "     2739    0.002    0.000    0.006    0.000 common.py:1545(is_float_dtype)\n",
       "       42    0.002    0.000    0.100    0.002 managers.py:524(fillna)\n",
       "      452    0.002    0.000    0.007    0.000 managers.py:306(_verify_integrity)\n",
       "      312    0.002    0.000    0.043    0.000 base.py:2715(get_indexer)\n",
       "     3577    0.002    0.000    0.002    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
       "      759    0.002    0.000    0.004    0.000 blocks.py:3100(_extend_blocks)\n",
       "        3    0.002    0.001    0.220    0.073 sorting.py:366(compress_group_index)\n",
       "      438    0.002    0.000    0.005    0.000 cast.py:832(maybe_castable)\n",
       "     5199    0.002    0.000    0.005    0.000 abc.py:137(__instancecheck__)\n",
       "       28    0.002    0.000    0.002    0.000 {built-in method numpy.putmask}\n",
       "     1134    0.002    0.000    0.017    0.000 frame.py:3349(_box_col_values)\n",
       "     2646    0.002    0.000    0.007    0.000 common.py:923(is_signed_integer_dtype)\n",
       "      322    0.002    0.000    0.003    0.000 concat.py:117(needs_filling)\n",
       "     7704    0.002    0.000    0.007    0.000 managers.py:141(<genexpr>)\n",
       "      178    0.002    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:1356(find_spec)\n",
       "     2227    0.002    0.000    0.002    0.000 {method 'match' of 're.Pattern' objects}\n",
       "     2288    0.002    0.000    0.002    0.000 dtypes.py:452(construct_from_string)\n",
       "     2449    0.002    0.000    0.006    0.000 base.py:2650(get_loc)\n",
       "      686    0.002    0.000    0.024    0.000 managers.py:599(_consolidate_check)\n",
       "     1953    0.002    0.000    0.002    0.000 generic.py:349(_get_axis_number)\n",
       "      503    0.002    0.000    1.297    0.003 frame.py:4666(f)\n",
       "     8384    0.002    0.000    0.002    0.000 blocks.py:195(mgr_locs)\n",
       "      248    0.002    0.000    0.003    0.000 numeric.py:676(require)\n",
       "      133    0.002    0.000    0.033    0.000 categorical.py:317(__init__)\n",
       "      146    0.002    0.000    0.012    0.000 <frozen importlib._bootstrap>:882(_find_spec)\n",
       "      284    0.002    0.000    0.804    0.003 managers.py:1198(reindex_indexer)\n",
       "     1708    0.002    0.000    0.006    0.000 common.py:868(is_integer_dtype)\n",
       "      786    0.002    0.000    0.042    0.000 frame.py:742(iteritems)\n",
       "     1534    0.002    0.000    0.002    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "      207    0.002    0.000    0.003    0.000 protocol.py:283(__init__)\n",
       "     1880    0.002    0.000    0.002    0.000 generic.py:363(_get_axis_name)\n",
       "       12    0.002    0.000    0.002    0.000 {pandas._libs.algos.rank_1d_float64}\n",
       "     1803    0.002    0.000    0.002    0.000 series.py:399(name)\n",
       "     3283    0.002    0.000    0.002    0.000 blocks.py:89(_check_ndim)\n",
       "      572    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap>:157(_get_module_lock)\n",
       "      547    0.002    0.000    0.008    0.000 cast.py:846(maybe_infer_to_datetimelike)\n",
       "     1136    0.001    0.000    0.001    0.000 _internal.py:886(npy_ctypes_check)\n",
       "      568    0.001    0.000    0.013    0.000 missing.py:360(array_equivalent)\n",
       "       77    0.001    0.000    0.003    0.000 index_tricks.py:316(__getitem__)\n",
       "     3086    0.001    0.000    0.018    0.000 _methods.py:42(_any)\n",
       "     1740    0.001    0.000    0.002    0.000 __init__.py:221(iteritems)\n",
       "       19    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_2d_axis0_int8_float64}\n",
       "       46    0.001    0.000    0.162    0.004 managers.py:159(rename_axis)\n",
       "      322    0.001    0.000    0.035    0.000 concat.py:165(get_reindexed_values)\n",
       "     4174    0.001    0.000    0.002    0.000 managers.py:143(ndim)\n",
       "      298    0.001    0.000    0.010    0.000 connections.py:744(_execute_command)\n",
       "      556    0.001    0.000    0.006    0.000 common.py:93(is_bool_indexer)\n",
       "      648    0.001    0.000    0.020    0.000 construction.py:684(_try_cast)\n",
       "     2044    0.001    0.000    0.002    0.000 managers.py:1549(internal_values)\n",
       "     1657    0.001    0.000    0.004    0.000 {pandas._libs.lib.values_from_object}\n",
       "     6252    0.001    0.000    0.001    0.000 {method 'startswith' of 'str' objects}\n",
       "      501    0.001    0.000    0.320    0.001 socket.py:575(readinto)\n",
       "     6612    0.001    0.000    0.001    0.000 common.py:122(classes_and_not_datetimelike)\n",
       "     2241    0.001    0.000    0.011    0.000 common.py:262(is_categorical)\n",
       "       76    0.001    0.000    0.002    0.000 base.py:1587(is_monotonic_increasing)\n",
       "  572/146    0.001    0.000    0.020    0.000 <frozen importlib._bootstrap>:948(_find_and_load_unlocked)\n",
       "     5183    0.001    0.000    0.001    0.000 blocks.py:308(dtype)\n",
       "        1    0.001    0.001    0.001    0.001 parsers.py:1830(__init__)\n",
       "      352    0.001    0.000    0.014    0.000 concat.py:137(is_na)\n",
       "     1978    0.001    0.000    0.004    0.000 common.py:980(is_unsigned_integer_dtype)\n",
       "      491    0.001    0.000    1.152    0.002 blocks.py:749(copy)\n",
       "       40    0.001    0.000    0.211    0.005 <ipython-input-1999-cd2ed8d3f7ce>:8(__init__)\n",
       "     1134    0.001    0.000    0.003    0.000 generic.py:3070(_set_as_cached)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method _socket.getaddrinfo}\n",
       "       77    0.001    0.000    0.032    0.000 managers.py:1134(insert)\n",
       "     1814    0.001    0.000    0.015    0.000 common.py:1078(is_datetime64_any_dtype)\n",
       "     1663    0.001    0.000    0.004    0.000 generic.py:377(_get_axis)\n",
       "       57    0.001    0.000    0.002    0.000 function_base.py:4220(delete)\n",
       "      283    0.001    0.000    0.024    0.000 base.py:584(_shallow_copy_with_infer)\n",
       "     2843    0.001    0.000    0.002    0.000 inference.py:438(is_hashable)\n",
       "      291    0.001    0.000    0.007    0.000 base.py:1117(__iter__)\n",
       "     1656    0.001    0.000    0.002    0.000 sparse.py:196(construct_from_string)\n",
       "     1420    0.001    0.000    0.003    0.000 common.py:746(is_dtype_equal)\n",
       "      246    0.001    0.000    0.083    0.000 base.py:784(take)\n",
       "     1930    0.001    0.000    0.002    0.000 {built-in method builtins.max}\n",
       "      553    0.001    0.000    0.217    0.000 algorithms.py:217(_get_data_algo)\n",
       "     4558    0.001    0.000    0.001    0.000 managers.py:1488(_block)\n",
       "      674    0.001    0.000    0.003    0.000 blocks.py:128(_consolidate_key)\n",
       "      172    0.001    0.000    0.009    0.000 frame.py:3565(_sanitize_column)\n",
       "     1056    0.001    0.000    0.002    0.000 base.py:547(_get_attributes_dict)\n",
       "      509    0.001    0.000    0.002    0.000 base.py:643(_engine)\n",
       "     1574    0.001    0.000    0.002    0.000 managers.py:1522(dtype)\n",
       "      686    0.001    0.000    0.022    0.000 managers.py:600(<listcomp>)\n",
       "        4    0.001    0.000    0.002    0.000 generic.py:9415(abs)\n",
       "      228    0.001    0.000    0.012    0.000 generic.py:1657(_get_label_or_level_values)\n",
       "     5658    0.001    0.000    0.001    0.000 {built-in method builtins.hash}\n",
       "      808    0.001    0.000    0.002    0.000 generic.py:5036(__finalize__)\n",
       "     3536    0.001    0.000    0.001    0.000 managers.py:206(items)\n",
       "      663    0.001    0.000    0.002    0.000 managers.py:98(<listcomp>)\n",
       "      147    0.001    0.000    0.715    0.005 managers.py:1233(<listcomp>)\n",
       "     2044    0.001    0.000    0.003    0.000 series.py:476(_values)\n",
       "      155    0.001    0.000    0.005    0.000 base.py:786(array)\n",
       "       19    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_2d_axis0_int8_int8}\n",
       "      244    0.001    0.000    0.004    0.000 numeric.py:34(__new__)\n",
       "      132    0.001    0.000    0.006    0.000 concat.py:20(get_dtype_kinds)\n",
       "     1737    0.001    0.000    0.001    0.000 base.py:633(_reset_identity)\n",
       "      374    0.001    0.000    0.002    0.000 numeric.py:2656(seterr)\n",
       "      498    0.001    0.000    0.001    0.000 numerictypes.py:578(_can_coerce_all)\n",
       "      247    0.001    0.000    0.073    0.000 concat.py:230(concatenate_join_units)\n",
       "       19    0.001    0.000    0.002    0.000 <ipython-input-2007-996dcf9791ab>:1(cm_dict)\n",
       "      221    0.001    0.000    0.003    0.000 fromnumeric.py:69(_wrapreduction)\n",
       "      580    0.001    0.000    0.035    0.000 frame.py:4685(<genexpr>)\n",
       "       41    0.001    0.000    0.011    0.000 base.py:1343(_handle_dbapi_exception)\n",
       "     1096    0.001    0.000    0.001    0.000 blocks.py:332(iget)\n",
       "     1637    0.001    0.000    0.001    0.000 common.py:144(cast_scalar_indexer)\n",
       "      572    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:78(acquire)\n",
       "     1855    0.001    0.000    0.050    0.000 missing.py:25(isna)\n",
       "      934    0.001    0.000    0.005    0.000 base.py:963(_ndarray_values)\n",
       "      128    0.001    0.000    0.948    0.007 frame.py:2952(_getitem_bool_array)\n",
       "       80    0.001    0.000    0.047    0.001 indexing.py:1271(_convert_to_indexer)\n",
       "       47    0.001    0.000    1.602    0.034 ops.py:1660(wrapper)\n",
       "       69    0.001    0.000    0.084    0.001 managers.py:1887(_consolidate)\n",
       "1437/1436    0.001    0.000    0.019    0.000 {built-in method builtins.all}\n",
       "      439    0.001    0.000    0.001    0.000 protocol.py:180(read_struct)\n",
       "      304    0.001    0.000    0.002    0.000 generic.py:1546(_is_label_reference)\n",
       "     1004    0.001    0.000    0.001    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "     1040    0.001    0.000    0.088    0.000 managers.py:927(_consolidate_inplace)\n",
       "     2283    0.001    0.000    0.001    0.000 {method 'rpartition' of 'str' objects}\n",
       "      157    0.001    0.000    1.134    0.007 generic.py:5699(copy)\n",
       "      503    0.001    0.000    1.292    0.003 _decorators.py:146(wrapper)\n",
       "   540/40    0.001    0.000    0.001    0.000 arrayprint.py:716(recurser)\n",
       "      828    0.001    0.000    0.009    0.000 common.py:1643(is_extension_type)\n",
       "      203    0.001    0.000    1.182    0.006 managers.py:710(copy)\n",
       "      939    0.001    0.000    0.001    0.000 range.py:510(__len__)\n",
       "       80    0.001    0.000    0.042    0.001 indexing.py:1108(_get_listlike_indexer)\n",
       "       86    0.001    0.000    1.333    0.016 base.py:1163(_execute_context)\n",
       "      380    0.001    0.000    0.002    0.000 indexing.py:2450(convert_to_index_sliceable)\n",
       "     1969    0.001    0.000    0.001    0.000 {built-in method __new__ of type object at 0x105424778}\n",
       "      323    0.001    0.000    0.001    0.000 concat.py:425(combine_concat_plans)\n",
       "     1056    0.001    0.000    0.001    0.000 base.py:551(<dictcomp>)\n",
       "      572    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:103(release)\n",
       "     1574    0.001    0.000    0.002    0.000 series.py:406(dtype)\n",
       "        8    0.001    0.000    0.001    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
       "      900    0.001    0.000    0.003    0.000 common.py:1784(_is_dtype)\n",
       "      207    0.001    0.000    0.031    0.000 connections.py:393(_read_ok_packet)\n",
       "       50    0.001    0.000    0.007    0.000 connections.py:1213(_get_descriptions)\n",
       "      374    0.001    0.000    0.001    0.000 numeric.py:2758(geterr)\n",
       "      172    0.001    0.000    0.421    0.002 frame.py:3356(__setitem__)\n",
       "       82    0.001    0.000    0.034    0.000 base.py:748(_checkout)\n",
       "      614    0.001    0.000    0.015    0.000 concat.py:379(<genexpr>)\n",
       "      264    0.001    0.000    0.017    0.000 numeric.py:67(_shallow_copy)\n",
       "      345    0.001    0.000    0.001    0.000 shape_base.py:83(atleast_2d)\n",
       "      572    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:58(__init__)\n",
       "       23    0.001    0.000    0.210    0.009 generic.py:960(rename)\n",
       "     1657    0.001    0.000    0.001    0.000 managers.py:308(<genexpr>)\n",
       "     2320    0.001    0.000    0.001    0.000 format.py:301(len)\n",
       "      155    0.001    0.000    0.002    0.000 numpy_.py:35(__init__)\n",
       "      262    0.001    0.000    0.017    0.000 concat.py:367(is_uniform_join_units)\n",
       "      342    0.001    0.000    0.002    0.000 generic.py:1513(_is_level_reference)\n",
       "      182    0.001    0.000    0.003    0.000 protocol.py:237(_parse_field_descriptor)\n",
       "      601    0.001    0.000    0.008    0.000 common.py:702(is_datetimelike)\n",
       "      146    0.001    0.000    0.009    0.000 <frozen importlib._bootstrap_external>:1240(_get_spec)\n",
       "      300    0.001    0.000    0.008    0.000 connections.py:710(_write_bytes)\n",
       "      359    0.001    0.000    0.001    0.000 {method 'clear' of 'dict' objects}\n",
       "     1495    0.001    0.000    0.001    0.000 common.py:316(apply_if_callable)\n",
       "     1054    0.001    0.000    0.001    0.000 base.py:613(is_)\n",
       "     1648    0.001    0.000    0.001    0.000 generic.py:450(ndim)\n",
       "     3214    0.001    0.000    0.001    0.000 {method 'items' of 'dict' objects}\n",
       "      528    0.001    0.000    0.001    0.000 generic.py:144(_init_mgr)\n",
       "       38    0.001    0.000    0.074    0.002 merge.py:777(_get_merge_keys)\n",
       "      137    0.001    0.000    0.015    0.000 base.py:3089(reindex)\n",
       "      406    0.001    0.000    0.007    0.000 base.py:700(view)\n",
       "      373    0.001    0.000    0.054    0.000 generic.py:5122(_protect_consolidate)\n",
       "     1543    0.001    0.000    0.001    0.000 series.py:382(_set_subtyp)\n",
       "      890    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:56(_path_join)\n",
       "     1098    0.001    0.000    0.004    0.000 inference.py:304(is_array_like)\n",
       "      613    0.001    0.000    0.002    0.000 {built-in method builtins.sum}\n",
       "       38    0.001    0.000    0.002    0.000 merge.py:647(_maybe_add_join_keys)\n",
       "      548    0.001    0.000    0.002    0.000 config.py:78(_get_single_key)\n",
       "      249    0.001    0.000    0.002    0.000 numerictypes.py:602(find_common_type)\n",
       "      228    0.001    0.000    0.001    0.000 generic.py:1607(_check_label_or_level_ambiguity)\n",
       "      986    0.001    0.000    0.001    0.000 {built-in method builtins.min}\n",
       "      293    0.001    0.000    0.001    0.000 cast.py:341(infer_dtype_from_scalar)\n",
       "      312    0.001    0.000    0.002    0.000 base.py:4459(_maybe_promote)\n",
       "     3078    0.001    0.000    0.001    0.000 {pandas._libs.lib.is_float}\n",
       "      172    0.001    0.000    0.419    0.002 frame.py:3433(_set_item)\n",
       "       36    0.001    0.000    0.005    0.000 format.py:1045(get_result_as_array)\n",
       "     1479    0.001    0.000    0.001    0.000 {built-in method pandas._libs.missing.checknull}\n",
       "       58    0.001    0.000    0.061    0.001 generic.py:4113(reindex)\n",
       "       42    0.001    0.000    0.103    0.002 generic.py:5948(fillna)\n",
       "       38    0.001    0.000    0.012    0.000 base.py:2357(intersection)\n",
       "       83    0.001    0.000    0.002    0.000 base.py:69(__init__)\n",
       "     1656    0.001    0.000    0.001    0.000 {method 'search' of 're.Pattern' objects}\n",
       "       80    0.001    0.000    0.002    0.000 indexing.py:1209(_validate_read_indexer)\n",
       "      172    0.001    0.000    0.046    0.000 generic.py:3171(_set_item)\n",
       "      310    0.001    0.000    0.006    0.000 base.py:1096(tolist)\n",
       "       57    0.001    0.000    0.013    0.000 base.py:4939(drop)\n",
       "       19    0.001    0.000    0.117    0.006 merge.py:598(_indicator_post_merge)\n",
       "     1873    0.001    0.000    0.001    0.000 {built-in method builtins.iter}\n",
       "       46    0.001    0.000    0.008    0.000 blocks.py:536(_astype)\n",
       "      373    0.001    0.000    0.054    0.000 generic.py:5135(f)\n",
       "      592    0.001    0.000    0.001    0.000 managers.py:1546(external_values)\n",
       "       38    0.001    0.000    0.077    0.002 merge.py:474(__init__)\n",
       "      858    0.001    0.000    0.002    0.000 frame.py:937(__len__)\n",
       "      890    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:58(<listcomp>)\n",
       "       96    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_2d_axis1_float64_float64}\n",
       "      572    0.001    0.000    0.004    0.000 <frozen importlib._bootstrap>:147(__enter__)\n",
       "      155    0.001    0.000    0.002    0.000 numpy_.py:127(__init__)\n",
       "      198    0.001    0.000    0.004    0.000 iostream.py:195(schedule)\n",
       "       57    0.001    0.000    0.027    0.000 generic.py:4469(_reindex_with_indexers)\n",
       "      329    0.001    0.000    0.001    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
       "       28    0.001    0.000    1.588    0.057 ops.py:1615(na_op)\n",
       "       69    0.001    0.000    0.115    0.002 construction.py:254(_homogenize)\n",
       "        4    0.001    0.000    0.001    0.000 {built-in method io.open}\n",
       "      179    0.001    0.000    0.005    0.000 iostream.py:382(write)\n",
       "       36    0.001    0.000    0.004    0.000 format.py:1060(format_values_with)\n",
       "       57    0.000    0.000    0.076    0.001 generic.py:3787(_drop_axis)\n",
       "     1129    0.000    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
       "      249    0.000    0.000    0.000    0.000 numerictypes.py:654(<listcomp>)\n",
       "     1136    0.000    0.000    0.002    0.000 base.py:3663(get_values)\n",
       "       77    0.000    0.000    0.004    0.000 managers.py:2008(_fast_count_smallints)\n",
       "      667    0.000    0.000    0.002    0.000 arrays.py:7(extract_array)\n",
       "     1374    0.000    0.000    0.002    0.000 managers.py:591(is_consolidated)\n",
       "       88    0.000    0.000    0.001    0.000 blocks.py:3145(<listcomp>)\n",
       "      209    0.000    0.000    0.004    0.000 cast.py:1151(construct_1d_arraylike_from_scalar)\n",
       "        4    0.000    0.000    0.007    0.002 blocks.py:2641(convert)\n",
       "      172    0.000    0.000    0.001    0.000 base.py:3926(contains)\n",
       "       91    0.000    0.000    1.318    0.014 connections.py:508(query)\n",
       "      107    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "      916    0.000    0.000    0.003    0.000 {built-in method builtins.any}\n",
       "      322    0.000    0.000    0.005    0.000 concat.py:126(dtype)\n",
       "      168    0.000    0.000    0.008    0.000 indexing.py:2475(check_bool_indexer)\n",
       "       82    0.000    0.000    0.018    0.000 base.py:481(checkout)\n",
       "      526    0.000    0.000    0.004    0.000 base.py:646(<lambda>)\n",
       "      938    0.000    0.000    0.000    0.000 frame.py:474(axes)\n",
       "      124    0.000    0.000    0.021    0.000 connections.py:422(rollback)\n",
       "       41    0.000    0.000    0.001    0.000 schema.py:3753(__init__)\n",
       "      572    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:176(cb)\n",
       "       86    0.000    0.000    0.001    0.000 default.py:862(_init_statement)\n",
       "  427/143    0.000    0.000    0.018    0.000 {built-in method builtins.__import__}\n",
       "       94    0.000    0.000    0.006    0.000 concat.py:101(_concat_compat)\n",
       "     1109    0.000    0.000    0.002    0.000 numeric.py:541(asanyarray)\n",
       "      151    0.000    0.000    0.010    0.000 series.py:669(__array__)\n",
       "       49    0.000    0.000    0.003    0.000 construction.py:284(extract_index)\n",
       "     1088    0.000    0.000    0.000    0.000 config.py:561(_get_deprecated_option)\n",
       "      208    0.000    0.000    0.001    0.000 managers.py:1556(get_values)\n",
       "      312    0.000    0.000    0.004    0.000 base.py:1669(is_boolean)\n",
       "     1306    0.000    0.000    0.000    0.000 blocks.py:304(shape)\n",
       "       42    0.000    0.000    0.003    0.000 cast.py:597(astype_nansafe)\n",
       "       91    0.000    0.000    1.320    0.015 cursors.py:151(execute)\n",
       "       40    0.000    0.000    0.004    0.000 {method 'get_value' of 'pandas._libs.index.IndexEngine' objects}\n",
       "     1145    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
       "      334    0.000    0.000    0.001    0.000 generic.py:381(_get_block_manager_axis)\n",
       "       77    0.000    0.000    0.023    0.000 base.py:4919(insert)\n",
       "       64    0.000    0.000    0.004    0.000 indexing.py:960(_getitem_lowerdim)\n",
       "       64    0.000    0.000    0.011    0.000 format.py:848(format_array)\n",
       "     2320    0.000    0.000    0.001    0.000 __init__.py:291(strlen)\n",
       "      500    0.000    0.000    0.001    0.000 arrayprint.py:693(_extendLine)\n",
       "     1847    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
       "      540    0.000    0.000    0.001    0.000 config.py:546(_get_root)\n",
       "       97    0.000    0.000    0.007    0.000 generic.py:3840(_update_inplace)\n",
       "       82    0.000    0.000    0.001    0.000 queue.py:135(get)\n",
       "     3130    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
       "       77    0.000    0.000    0.013    0.000 generic.py:1439(__neg__)\n",
       "       81    0.000    0.000    0.001    0.000 generic.py:297(_construct_axes_from_arguments)\n",
       "        4    0.000    0.000    0.022    0.006 format.py:503(_to_str_columns)\n",
       "      592    0.000    0.000    0.001    0.000 series.py:434(values)\n",
       "       19    0.000    0.000    0.003    0.000 concat.py:237(__init__)\n",
       "      373    0.000    0.000    0.055    0.000 generic.py:5132(_consolidate_inplace)\n",
       "       41    0.000    0.000    0.028    0.001 construction.py:429(_list_to_arrays)\n",
       "       40    0.000    0.000    0.005    0.000 base.py:4342(get_value)\n",
       "      501    0.000    0.000    0.001    0.000 {method '_checkReadable' of '_io._IOBase' objects}\n",
       "       19    0.000    0.000    0.006    0.000 base.py:2254(union)\n",
       "       40    0.000    0.000    0.015    0.000 series.py:865(__getitem__)\n",
       "      114    0.000    0.000    0.002    0.000 blocks.py:2933(__init__)\n",
       "      127    0.000    0.000    0.002    0.000 {built-in method builtins.sorted}\n",
       "       19    0.000    0.000    0.000    0.000 base.py:221(_inner_indexer)\n",
       "      406    0.000    0.000    0.008    0.000 managers.py:729(<lambda>)\n",
       "      128    0.000    0.000    0.003    0.000 format.py:1384(_make_fixed_width)\n",
       "       19    0.000    0.000    0.073    0.004 merge.py:574(_indicator_pre_merge)\n",
       "      373    0.000    0.000    0.050    0.000 managers.py:911(consolidate)\n",
       "      540    0.000    0.000    0.002    0.000 config.py:96(_get_option)\n",
       "       38    0.000    0.000    0.478    0.013 merge.py:737(_get_join_info)\n",
       "      141    0.000    0.000    0.001    0.000 managers.py:2015(_preprocess_slice_or_indexer)\n",
       "       23    0.000    0.000    0.947    0.041 series.py:3947(isin)\n",
       "       19    0.000    0.000    0.040    0.002 concat.py:383(get_result)\n",
       "      124    0.000    0.000    0.021    0.000 base.py:2223(do_rollback)\n",
       "       41    0.000    0.000    0.023    0.001 base.py:2312(has_table)\n",
       "      308    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "      473    0.000    0.000    0.007    0.000 base.py:1729(inferred_type)\n",
       "     2104    0.000    0.000    0.000    0.000 blocks.py:165(internal_values)\n",
       "      559    0.000    0.000    0.003    0.000 common.py:605(is_string_dtype)\n",
       "       82    0.000    0.000    0.014    0.000 connections.py:532(ping)\n",
       "      464    0.000    0.000    0.000    0.000 protocol.py:186(is_ok_packet)\n",
       "      578    0.000    0.000    0.001    0.000 inference.py:121(is_iterator)\n",
       "       81    0.000    0.000    0.008    0.000 series.py:730(__array_wrap__)\n",
       "     1058    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
       "      171    0.000    0.000    0.001    0.000 format.py:1019(base_formatter)\n",
       "       80    0.000    0.000    0.000    0.000 sorting.py:47(_int64_cut_off)\n",
       "      559    0.000    0.000    0.002    0.000 common.py:634(condition)\n",
       "       38    0.000    0.000    0.000    0.000 blocks.py:335(set)\n",
       "      305    0.000    0.000    0.001    0.000 common.py:1198(is_datetime_or_timedelta_dtype)\n",
       "     1183    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
       "      357    0.000    0.000    0.000    0.000 {pandas._libs.internals.get_blkno_placements}\n",
       "      248    0.000    0.000    0.000    0.000 numeric.py:748(<setcomp>)\n",
       "      608    0.000    0.000    0.001    0.000 generic.py:1576(<genexpr>)\n",
       "       89    0.000    0.000    0.001    0.000 cursors.py:116(_escape_args)\n",
       "      152    0.000    0.000    0.006    0.000 dtypes.py:244(_from_values_or_dtype)\n",
       "       82    0.000    0.000    0.036    0.000 base.py:2223(_contextual_connect)\n",
       "      163    0.000    0.000    0.000    0.000 threading.py:335(notify)\n",
       "       82    0.000    0.000    0.001    0.000 queue.py:92(put)\n",
       "       38    0.000    0.000    0.002    0.000 merge.py:889(_maybe_coerce_merge_keys)\n",
       "       69    0.000    0.000    0.322    0.005 construction.py:43(arrays_to_mgr)\n",
       "      503    0.000    0.000    0.003    0.000 algorithms.py:163(_ensure_arraylike)\n",
       "       80    0.000    0.000    0.001    0.000 indexing.py:256(_convert_scalar_indexer)\n",
       "      228    0.000    0.000    0.007    0.000 generic.py:3461(xs)\n",
       "       19    0.000    0.000    0.000    0.000 {built-in method _operator.add}\n",
       "       57    0.000    0.000    0.009    0.000 dtypes.py:485(validate_categories)\n",
       "     1064    0.000    0.000    0.000    0.000 base.py:676(dtype)\n",
       "      357    0.000    0.000    0.001    0.000 generic.py:3149(_clear_item_cache)\n",
       "        4    0.000    0.000    0.000    0.000 {pandas._libs.writers.write_csv_rows}\n",
       "      137    0.000    0.000    0.003    0.000 fromnumeric.py:2664(prod)\n",
       "       46    0.000    0.000    0.110    0.002 managers.py:1988(_transform_index)\n",
       "       41    0.000    0.000    0.001    0.000 sql.py:972(__init__)\n",
       "      304    0.000    0.000    0.003    0.000 common.py:1431(needs_i8_conversion)\n",
       "       28    0.000    0.000    0.296    0.011 construction.py:170(init_dict)\n",
       "      374    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
       "       19    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
       "       33    0.000    0.000    0.030    0.001 {built-in method builtins.print}\n",
       "       77    0.000    0.000    0.004    0.000 base.py:2445(difference)\n",
       "      165    0.000    0.000    0.022    0.000 construction.py:495(convert)\n",
       "      168    0.000    0.000    0.000    0.000 generic.py:3175(_set_is_copy)\n",
       "      674    0.000    0.000    0.003    0.000 managers.py:1893(<lambda>)\n",
       "       60    0.000    0.000    0.017    0.000 format.py:702(_format_col)\n",
       "       41    0.000    0.000    0.000    0.000 base.py:2260(is_disconnect)\n",
       "      572    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:151(__exit__)\n",
       "      154    0.000    0.000    0.001    0.000 function_base.py:4641(append)\n",
       "      247    0.000    0.000    0.035    0.000 concat.py:240(<listcomp>)\n",
       "      494    0.000    0.000    0.000    0.000 concat.py:391(<genexpr>)\n",
       "       69    0.000    0.000    0.199    0.003 managers.py:1663(create_block_manager_from_arrays)\n",
       "       91    0.000    0.000    1.314    0.014 connections.py:720(_read_query_result)\n",
       "       46    0.000    0.000    0.012    0.000 generic.py:5581(astype)\n",
       "       61    0.000    0.000    0.001    0.000 range.py:69(__new__)\n",
       "       38    0.000    0.000    0.004    0.000 concat.py:486(_concat_index_asobject)\n",
       "      187    0.000    0.000    0.000    0.000 numeric.py:3054(__init__)\n",
       "      383    0.000    0.000    0.001    0.000 managers.py:1844(_asarray_compat)\n",
       "      259    0.000    0.000    0.001    0.000 managers.py:174(_is_single_block)\n",
       "     1666    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
       "       61    0.000    0.000    0.000    0.000 {built-in method numpy.copyto}\n",
       "      462    0.000    0.000    0.001    0.000 generic.py:1895(<genexpr>)\n",
       "       50    0.000    0.000    1.013    0.020 connections.py:1149(_read_result_packet)\n",
       "       82    0.000    0.000    0.001    0.000 base.py:507(checkin)\n",
       "      600    0.000    0.000    0.000    0.000 base.py:1237(_get_names)\n",
       "      791    0.000    0.000    0.000    0.000 blocks.py:191(fill_value)\n",
       "       45    0.000    0.000    0.001    0.000 result.py:215(__init__)\n",
       "       69    0.000    0.000    0.000    0.000 range.py:136(_simple_new)\n",
       "      120    0.000    0.000    0.001    0.000 base.py:2849(_convert_scalar_indexer)\n",
       "      187    0.000    0.000    0.001    0.000 numeric.py:3063(__exit__)\n",
       "     1428    0.000    0.000    0.001    0.000 base.py:3632(_values)\n",
       "      890    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:222(_verbose_message)\n",
       "       86    0.000    0.000    1.333    0.016 base.py:1138(_execute_text)\n",
       "      385    0.000    0.000    0.002    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "      107    0.000    0.000    0.001    0.000 frame.py:3585(reindexer)\n",
       "       57    0.000    0.000    0.079    0.001 generic.py:3759(drop)\n",
       "      133    0.000    0.000    0.001    0.000 dtypes.py:521(update_dtype)\n",
       "     1830    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
       "       38    0.000    0.000    0.061    0.002 generic.py:1729(_drop_labels_or_levels)\n",
       "       40    0.000    0.000    0.002    0.000 arrayprint.py:480(_array2string)\n",
       "      414    0.000    0.000    0.001    0.000 cast.py:1218(construct_1d_ndarray_preserving_na)\n",
       "     1728    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
       "      261    0.000    0.000    0.003    0.000 missing.py:259(notna)\n",
       "       41    0.000    0.000    0.001    0.000 exc.py:390(instance)\n",
       "       68    0.000    0.000    0.006    0.000 range.py:272(_shallow_copy)\n",
       "       19    0.000    0.000    0.000    0.000 categorical.py:56(f)\n",
       "       19    0.000    0.000    0.023    0.001 categorical.py:2560(_get_codes_for_values)\n",
       "       40    0.000    0.000    0.003    0.000 arrayprint.py:518(array2string)\n",
       "       80    0.000    0.000    0.000    0.000 _validators.py:230(validate_axis_style_args)\n",
       "       97    0.000    0.000    0.004    0.000 generic.py:3115(_maybe_update_cacher)\n",
       "       40    0.000    0.000    0.022    0.001 series.py:4221(dropna)\n",
       "       41    0.000    0.000    0.000    0.000 err.py:100(raise_mysql_exception)\n",
       "      614    0.000    0.000    0.000    0.000 concat.py:376(<genexpr>)\n",
       "       19    0.000    0.000    0.001    0.000 categorical.py:597(from_codes)\n",
       "       91    0.000    0.000    1.318    0.014 cursors.py:324(_query)\n",
       "        4    0.000    0.000    0.003    0.001 csvs.py:290(_save_chunk)\n",
       "       77    0.000    0.000    0.015    0.000 base.py:3830(_coerce_scalar_to_index)\n",
       "       41    0.000    0.000    0.011    0.000 sql.py:115(_parse_date_columns)\n",
       "       82    0.000    0.000    0.016    0.000 base.py:869(close)\n",
       "       57    0.000    0.000    0.062    0.001 frame.py:3794(reindex)\n",
       "       82    0.000    0.000    0.015    0.000 base.py:645(_finalize_fairy)\n",
       "       50    0.000    0.000    0.060    0.001 blocks.py:364(fillna)\n",
       "      280    0.000    0.000    0.001    0.000 common.py:1472(is_numeric_dtype)\n",
       "      248    0.000    0.000    0.000    0.000 protocol.py:86(advance)\n",
       "       41    0.000    0.000    0.042    0.001 construction.py:382(to_arrays)\n",
       "       82    0.000    0.000    0.014    0.000 base.py:845(_reset)\n",
       "     1728    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
       "      572    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:143(__init__)\n",
       "       23    0.000    0.000    0.943    0.041 algorithms.py:370(isin)\n",
       "      376    0.000    0.000    0.001    0.000 blocks.py:175(get_values)\n",
       "       76    0.000    0.000    0.001    0.000 categorical.py:464(copy)\n",
       "       19    0.000    0.000    0.001    0.000 base.py:3752(_try_convert_to_int_index)\n",
       "      146    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:873(_find_spec_legacy)\n",
       "      187    0.000    0.000    0.002    0.000 numeric.py:3058(__enter__)\n",
       "      370    0.000    0.000    0.000    0.000 missing.py:530(clean_reindex_fill_method)\n",
       "       41    0.000    0.000    0.021    0.001 managers.py:1810(_multi_blockify)\n",
       "      124    0.000    0.000    0.001    0.000 format.py:356(_get_formatter)\n",
       "      203    0.000    0.000    0.008    0.000 managers.py:730(<listcomp>)\n",
       "      198    0.000    0.000    0.001    0.000 threading.py:1080(is_alive)\n",
       "     1392    0.000    0.000    0.000    0.000 numeric.py:113(is_all_dates)\n",
       "       41    0.000    0.000    0.059    0.001 base.py:2133(run_callable)\n",
       "      311    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
       "      114    0.000    0.000    0.000    0.000 blocks.py:1549(__init__)\n",
       "       91    0.000    0.000    0.001    0.000 cursors.py:135(mogrify)\n",
       "       57    0.000    0.000    0.031    0.001 frame.py:3754(_reindex_columns)\n",
       "      439    0.000    0.000    0.000    0.000 {method 'unpack_from' of 'Struct' objects}\n",
       "      112    0.000    0.000    0.001    0.000 langhelpers.py:852(__get__)\n",
       "       41    0.000    0.000    0.000    0.000 exc.py:462(__init__)\n",
       "       60    0.000    0.000    0.001    0.000 base.py:5408(default_index)\n",
       "       91    0.000    0.000    1.314    0.014 connections.py:1073(read)\n",
       "     1522    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "      128    0.000    0.000    0.001    0.000 generic.py:1814(__hash__)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'writelines' of '_io._IOBase' objects}\n",
       "      155    0.000    0.000    0.000    0.000 common.py:1118(is_datetime64_ns_dtype)\n",
       "      748    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
       "      270    0.000    0.000    0.000    0.000 weakref.py:395(__getitem__)\n",
       "     1464    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
       "      146    0.000    0.000    0.010    0.000 <frozen importlib._bootstrap_external>:1272(find_spec)\n",
       "      222    0.000    0.000    0.000    0.000 result.py:461(_colnames_from_description)\n",
       "       30    0.000    0.000    0.000    0.000 blocks.py:2689(set)\n",
       "       40    0.000    0.000    0.007    0.000 managers.py:1506(get_slice)\n",
       "      247    0.000    0.000    0.000    0.000 attr.py:267(__bool__)\n",
       "     1184    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "      323    0.000    0.000    0.000    0.000 _validators.py:221(validate_bool_kwarg)\n",
       "       27    0.000    0.000    0.020    0.001 blocks.py:927(putmask)\n",
       "      255    0.000    0.000    0.000    0.000 managers.py:291(__len__)\n",
       "      154    0.000    0.000    0.001    0.000 generic.py:1848(empty)\n",
       "      618    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
       "      309    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "      468    0.000    0.000    0.000    0.000 frame.py:361(_constructor)\n",
       "       60    0.000    0.000    0.002    0.000 frame.py:2829(_ixs)\n",
       "      208    0.000    0.000    0.001    0.000 series.py:490(get_values)\n",
       "       41    0.000    0.000    1.434    0.035 sql.py:1055(read_query)\n",
       "       57    0.000    0.000    0.031    0.001 frame.py:3729(_reindex_axes)\n",
       "      247    0.000    0.000    0.001    0.000 concat.py:388(is_uniform_reindex)\n",
       "      221    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
       "       64    0.000    0.000    0.008    0.000 indexing.py:1485(__getitem__)\n",
       "      222    0.000    0.000    0.000    0.000 result.py:560(_merge_cols_by_none)\n",
       "       95    0.000    0.000    0.000    0.000 managers.py:1098(<genexpr>)\n",
       "      182    0.000    0.000    0.000    0.000 protocol.py:253(description)\n",
       "       70    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
       "      471    0.000    0.000    0.000    0.000 managers.py:706(nblocks)\n",
       "       19    0.000    0.000    0.005    0.000 ops.py:1536(wrapper)\n",
       "      608    0.000    0.000    0.001    0.000 format.py:1401(just)\n",
       "      104    0.000    0.000    0.000    0.000 ops.py:43(get_op_result_name)\n",
       "      897    0.000    0.000    0.000    0.000 format.py:1418(_is_number)\n",
       "       41    0.000    0.000    0.001    0.000 base.py:183(execution_options)\n",
       "       82    0.000    0.000    0.017    0.000 impl.py:111(_do_get)\n",
       "      152    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_int8}\n",
       "       83    0.000    0.000    0.000    0.000 base.py:77(__init__)\n",
       "      502    0.000    0.000    0.000    0.000 socket.py:614(readable)\n",
       "      182    0.000    0.000    0.000    0.000 cursors.py:89(_nextset)\n",
       "       41    0.000    0.000    0.008    0.000 base.py:729(_rollback_impl)\n",
       "       41    0.000    0.000    0.000    0.000 result.py:588(_key_fallback)\n",
       "     1126    0.000    0.000    0.000    0.000 base.py:1396(nlevels)\n",
       "      584    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:855(__enter__)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'connect' of '_socket.socket' objects}\n",
       "      208    0.000    0.000    0.000    0.000 blocks.py:184(to_dense)\n",
       "      154    0.000    0.000    0.001    0.000 fromnumeric.py:1583(ravel)\n",
       "       88    0.000    0.000    0.035    0.000 shape_base.py:229(vstack)\n",
       "       80    0.000    0.000    0.027    0.000 base.py:4447(get_indexer_for)\n",
       "      364    0.000    0.000    0.000    0.000 protocol.py:264(get_column_length)\n",
       "  426/142    0.000    0.000    0.018    0.000 <frozen importlib._bootstrap>:211(_call_with_frames_removed)\n",
       "       41    0.000    0.000    0.002    0.000 sql.py:508(pandasSQL_builder)\n",
       "      146    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:369(__init__)\n",
       "      540    0.000    0.000    0.003    0.000 config.py:226(__call__)\n",
       "       41    0.000    0.000    0.001    0.000 pymysql.py:64(is_disconnect)\n",
       "      178    0.000    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:74(_path_stat)\n",
       "     1073    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
       "      584    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:859(__exit__)\n",
       "       57    0.000    0.000    0.003    0.000 base.py:4909(delete)\n",
       "       69    0.000    0.000    0.000    0.000 blocks.py:1971(_can_hold_element)\n",
       "      207    0.000    0.000    0.000    0.000 protocol.py:297(__getattr__)\n",
       "       41    0.000    0.000    0.059    0.001 sql.py:1197(has_table)\n",
       "       83    0.000    0.000    0.001    0.000 base.py:295(__get__)\n",
       "      356    0.000    0.000    0.000    0.000 concat.py:104(__init__)\n",
       "       40    0.000    0.000    0.000    0.000 arrayprint.py:358(_get_formatdict)\n",
       "       12    0.000    0.000    0.001    0.000 printing.py:15(adjoin)\n",
       "       80    0.000    0.000    0.001    0.000 base.py:2965(_convert_listlike_indexer)\n",
       "       23    0.000    0.000    0.210    0.009 frame.py:3942(rename)\n",
       "      736    0.000    0.000    0.001    0.000 format.py:1392(<genexpr>)\n",
       "      385    0.000    0.000    0.002    0.000 _methods.py:45(_all)\n",
       "      116    0.000    0.000    0.002    0.000 generic.py:4341(<genexpr>)\n",
       "       19    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_int8_int8}\n",
       "      269    0.000    0.000    0.363    0.001 generic.py:3205(_check_setitem_copy)\n",
       "      114    0.000    0.000    0.001    0.000 blocks.py:1679(__init__)\n",
       "      182    0.000    0.000    0.003    0.000 protocol.py:233(__init__)\n",
       "      182    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1203(_path_importer_cache)\n",
       "       38    0.000    0.000    0.006    0.000 base.py:3988(append)\n",
       "      179    0.000    0.000    0.000    0.000 iostream.py:307(_is_master_process)\n",
       "       91    0.000    0.000    0.000    0.000 connections.py:1053(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 compat.py:123(reraise)\n",
       "       83    0.000    0.000    0.000    0.000 _collections.py:140(__new__)\n",
       "      329    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
       "       86    0.000    0.000    1.334    0.016 base.py:922(execute)\n",
       "       45    0.000    0.000    0.002    0.000 result.py:740(_init_metadata)\n",
       "       19    0.000    0.000    0.001    0.000 expressions.py:71(_can_use_numexpr)\n",
       "       40    0.000    0.000    0.017    0.000 missing.py:522(remove_na_arraylike)\n",
       "      501    0.000    0.000    0.000    0.000 {method '_checkClosed' of '_io._IOBase' objects}\n",
       "      260    0.000    0.000    0.001    0.000 indexing.py:2689(is_list_like_indexer)\n",
       "       61    0.000    0.000    0.160    0.003 managers.py:1796(_simple_blockify)\n",
       "       80    0.000    0.000    0.272    0.003 _decorators.py:195(wrapper)\n",
       "       64    0.000    0.000    0.005    0.000 indexing.py:2205(_getitem_axis)\n",
       "       86    0.000    0.000    0.001    0.000 default.py:1034(create_cursor)\n",
       "       40    0.000    0.000    0.000    0.000 arrayprint.py:411(_get_format_function)\n",
       "      540    0.000    0.000    0.000    0.000 config.py:602(_warn_if_deprecated)\n",
       "      282    0.000    0.000    0.000    0.000 generic.py:426(_info_axis)\n",
       "       53    0.000    0.000    0.001    0.000 deprecations.py:117(warned)\n",
       "      107    0.000    0.000    0.001    0.000 format.py:1421(_cond)\n",
       "       19    0.000    0.000    0.001    0.000 ops.py:1502(na_op)\n",
       "      130    0.000    0.000    0.001    0.000 base.py:1681(is_object)\n",
       "       38    0.000    0.000    0.004    0.000 base.py:2354(_wrap_setop_result)\n",
       "       38    0.000    0.000    0.008    0.000 series.py:3831(fillna)\n",
       "       86    0.000    0.000    0.000    0.000 {built-in method sqlalchemy.cutils._distill_params}\n",
       "       76    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_bool_array}\n",
       "      122    0.000    0.000    0.002    0.000 base.py:3975(_can_hold_identifiers_and_holds_name)\n",
       "       57    0.000    0.000    0.079    0.001 frame.py:3819(drop)\n",
       "       82    0.000    0.000    0.000    0.000 base.py:123(_join)\n",
       "       40    0.000    0.000    0.008    0.000 series.py:975(_get_values)\n",
       "       38    0.000    0.000    0.001    0.000 merge.py:614(_maybe_restore_index_levels)\n",
       "      134    0.000    0.000    0.001    0.000 base.py:2590(_assert_can_do_setop)\n",
       "       64    0.000    0.000    0.001    0.000 indexing.py:217(_has_valid_tuple)\n",
       "       82    0.000    0.000    0.034    0.000 base.py:345(connect)\n",
       "       70    0.000    0.000    0.000    0.000 base.py:1736(is_all_dates)\n",
       "      244    0.000    0.000    0.000    0.000 base.py:3806(_coerce_to_ndarray)\n",
       "      152    0.000    0.000    0.001    0.000 generic.py:1844(__contains__)\n",
       "       91    0.000    0.000    0.000    0.000 cursors.py:40(__init__)\n",
       "       83    0.000    0.000    0.000    0.000 base.py:116(_for_class)\n",
       "      630    0.000    0.000    0.000    0.000 numerictypes.py:587(<listcomp>)\n",
       "      122    0.000    0.000    0.007    0.000 base.py:802(_assert_take_fillable)\n",
       "      151    0.000    0.000    0.004    0.000 numpy_.py:170(__array__)\n",
       "       40    0.000    0.000    0.002    0.000 arrayprint.py:463(wrapper)\n",
       "       45    0.000    0.000    0.001    0.000 result.py:441(<listcomp>)\n",
       "       82    0.000    0.000    0.015    0.000 mysqldb.py:120(do_ping)\n",
       "       12    0.000    0.000    0.000    0.000 function_base.py:1149(diff)\n",
       "       82    0.000    0.000    0.000    0.000 log.py:56(_should_log_debug)\n",
       "       82    0.000    0.000    0.015    0.000 base.py:831(_checkin)\n",
       "      548    0.000    0.000    0.000    0.000 config.py:528(_select_options)\n",
       "      172    0.000    0.000    0.000    0.000 frame.py:3416(_ensure_valid_index)\n",
       "       40    0.000    0.000    0.008    0.000 series.py:913(_get_with)\n",
       "      539    0.000    0.000    0.000    0.000 concat.py:381(<genexpr>)\n",
       "      461    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "      152    0.000    0.000    0.000    0.000 cast.py:552(coerce_indexer_dtype)\n",
       "        4    0.000    0.000    0.016    0.004 {_cython_magic_38d1145b1a6902525e6166a88bdde578.geometric_mean}\n",
       "       64    0.000    0.000    0.000    0.000 indexing.py:2089(_is_scalar_access)\n",
       "        4    0.000    0.000    0.007    0.002 blocks.py:414(split_and_operate)\n",
       "       46    0.000    0.000    0.008    0.000 managers.py:530(astype)\n",
       "       45    0.000    0.000    0.000    0.000 default.py:947(should_autocommit)\n",
       "       38    0.000    0.000    0.012    0.000 managers.py:1959(items_overlap_with_suffix)\n",
       "       79    0.000    0.000    0.000    0.000 printing.py:156(pprint_thing)\n",
       "      592    0.000    0.000    0.000    0.000 blocks.py:161(external_values)\n",
       "      306    0.000    0.000    0.000    0.000 series.py:338(_constructor)\n",
       "       41    0.000    0.000    0.000    0.000 sql.py:45(_is_sqlalchemy_connectable)\n",
       "      177    0.000    0.000    0.000    0.000 type_api.py:483(_cached_result_processor)\n",
       "      548    0.000    0.000    0.000    0.000 config.py:589(_translate_key)\n",
       "      107    0.000    0.000    0.000    0.000 format.py:1422(<listcomp>)\n",
       "       46    0.000    0.000    0.000    0.000 managers.py:147(set_axis)\n",
       "      152    0.000    0.000    0.000    0.000 {method 'add' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "      166    0.000    0.000    0.000    0.000 __init__.py:1619(isEnabledFor)\n",
       "       88    0.000    0.000    0.001    0.000 fromnumeric.py:942(argsort)\n",
       "      155    0.000    0.000    0.000    0.000 common.py:1167(is_timedelta64_ns_dtype)\n",
       "       40    0.000    0.000    0.000    0.000 arrayprint.py:69(_make_options_dict)\n",
       "      180    0.000    0.000    0.000    0.000 printing.py:59(<listcomp>)\n",
       "      128    0.000    0.000    0.001    0.000 indexing.py:2056(_validate_key)\n",
       "       83    0.000    0.000    0.000    0.000 log.py:59(_should_log_info)\n",
       "       57    0.000    0.000    0.000    0.000 generic.py:4378(_needs_reindex_multi)\n",
       "       46    0.000    0.000    0.001    0.000 blocks.py:709(_try_coerce_args)\n",
       "      164    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "      198    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "       65    0.000    0.000    0.000    0.000 inference.py:381(is_dict_like)\n",
       "      128    0.000    0.000    0.001    0.000 format.py:1407(<listcomp>)\n",
       "       82    0.000    0.000    0.000    0.000 base.py:580(get_connection)\n",
       "      158    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "      268    0.000    0.000    0.000    0.000 printing.py:50(justify)\n",
       "      122    0.000    0.000    0.000    0.000 range.py:89(ensure_int)\n",
       "       18    0.000    0.000    0.000    0.000 common.py:120(_stringify_path)\n",
       "      177    0.000    0.000    0.000    0.000 default.py:1051(get_result_processor)\n",
       "       40    0.000    0.000    0.000    0.000 numeric.py:203(_convert_scalar_indexer)\n",
       "      247    0.000    0.000    0.000    0.000 blocks.py:255(__len__)\n",
       "       57    0.000    0.000    0.004    0.000 managers.py:2041(<listcomp>)\n",
       "       50    0.000    0.000    0.000    0.000 protocol.py:308(__init__)\n",
       "       42    0.000    0.000    0.000    0.000 _validators.py:325(validate_fillna_kwargs)\n",
       "       88    0.000    0.000    0.001    0.000 shape_base.py:283(<listcomp>)\n",
       "      551    0.000    0.000    0.000    0.000 categorical.py:441(dtype)\n",
       "       40    0.000    0.000    0.003    0.000 generic.py:3093(_maybe_cache_changed)\n",
       "       41    0.000    0.000    0.013    0.000 result.py:1195(fetchall)\n",
       "       86    0.000    0.000    0.000    0.000 default.py:1002(_use_server_side_cursor)\n",
       "      198    0.000    0.000    0.000    0.000 threading.py:1038(_wait_for_tstate_lock)\n",
       "       89    0.000    0.000    1.319    0.015 default.py:551(do_execute)\n",
       "       88    0.000    0.000    0.000    0.000 shape_base.py:220(_warn_for_nonsequence)\n",
       "      461    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
       "       88    0.000    0.000    0.001    0.000 fromnumeric.py:54(_wrapfunc)\n",
       "       38    0.000    0.000    0.000    0.000 merge.py:1704(<lambda>)\n",
       "       41    0.000    0.000    0.000    0.000 exc.py:328(__init__)\n",
       "       38    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
       "       40    0.000    0.000    0.003    0.000 arrayprint.py:1499(_array_str_implementation)\n",
       "       79    0.000    0.000    0.000    0.000 printing.py:185(as_escaped_unicode)\n",
       "       41    0.000    0.000    1.313    0.032 base.py:2149(execute)\n",
       "       76    0.000    0.000    0.001    0.000 generic.py:1578(_is_label_or_level_reference)\n",
       "       50    0.000    0.000    0.000    0.000 cursors.py:341(_do_get_result)\n",
       "      630    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "      268    0.000    0.000    0.001    0.000 format.py:304(justify)\n",
       "       41    0.000    0.000    0.000    0.000 base.py:2054(_quote_free_identifiers)\n",
       "       40    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "       61    0.000    0.000    0.001    0.000 numeric.py:175(ones)\n",
       "      186    0.000    0.000    0.000    0.000 common.py:1513(is_string_like_dtype)\n",
       "       23    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_object_object}\n",
       "      178    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:36(_relax_case)\n",
       "       80    0.000    0.000    0.000    0.000 common.py:199(count_not_none)\n",
       "       64    0.000    0.000    0.009    0.000 format.py:927(get_result)\n",
       "       38    0.000    0.000    0.000    0.000 sorting.py:124(is_int64_overflow_possible)\n",
       "       38    0.000    0.000    0.006    0.000 base.py:4017(_concat)\n",
       "      192    0.000    0.000    0.000    0.000 indexing.py:1487(<genexpr>)\n",
       "       20    0.000    0.000    0.005    0.000 blocks.py:2669(f)\n",
       "       91    0.000    0.000    0.000    0.000 connections.py:481(cursor)\n",
       "      208    0.000    0.000    0.000    0.000 protocol.py:77(read_all)\n",
       "      125    0.000    0.000    0.000    0.000 inference.py:470(is_sequence)\n",
       "       57    0.000    0.000    0.009    0.000 dtypes.py:328(_finalize)\n",
       "       40    0.000    0.000    0.000    0.000 blocks.py:266(_slice)\n",
       "      198    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
       "        4    0.000    0.000    0.000    0.000 {pandas._libs.lib.map_infer}\n",
       "       40    0.000    0.000    0.005    0.000 range.py:520(__getitem__)\n",
       "      146    0.000    0.000    0.000    0.000 {built-in method _imp.is_frozen}\n",
       "       38    0.000    0.000    0.000    0.000 twodim_base.py:216(diag)\n",
       "      370    0.000    0.000    0.000    0.000 missing.py:71(clean_fill_method)\n",
       "       36    0.000    0.000    0.001    0.000 format.py:1078(<listcomp>)\n",
       "       20    0.000    0.000    0.004    0.000 cast.py:770(soft_convert_objects)\n",
       "       45    0.000    0.000    0.002    0.000 result.py:714(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 compat.py:378(raise_from_cause)\n",
       "       45    0.000    0.000    0.009    0.000 result.py:869(_soft_close)\n",
       "       71    0.000    0.000    0.000    0.000 format.py:1427(<listcomp>)\n",
       "       41    0.000    0.000    0.000    0.000 base.py:2057(<listcomp>)\n",
       "      327    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "       19    0.000    0.000    0.000    0.000 categorical.py:2490(__init__)\n",
       "       41    0.000    0.000    0.008    0.000 base.py:865(_autorollback)\n",
       "       19    0.000    0.000    0.002    0.000 ops.py:1512(safe_na_op)\n",
       "       57    0.000    0.000    0.001    0.000 common.py:246(index_labels_to_array)\n",
       "      414    0.000    0.000    0.000    0.000 cursors.py:71(_get_db)\n",
       "       38    0.000    0.000    0.000    0.000 copy.py:66(copy)\n",
       "      146    0.000    0.000    0.000    0.000 six.py:184(find_module)\n",
       "       82    0.000    0.000    0.016    0.000 base.py:987(close)\n",
       "      268    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
       "       77    0.000    0.000    0.000    0.000 {built-in method numpy.bincount}\n",
       "      114    0.000    0.000    0.000    0.000 merge.py:1731(_should_fill)\n",
       "       94    0.000    0.000    0.000    0.000 concat.py:151(<listcomp>)\n",
       "      120    0.000    0.000    0.000    0.000 indexing.py:2116(_validate_integer)\n",
       "       41    0.000    0.000    0.000    0.000 _collections.py:151(union)\n",
       "       76    0.000    0.000    0.000    0.000 blocks.py:2633(is_bool)\n",
       "      210    0.000    0.000    0.000    0.000 concat.py:450(_next_or_none)\n",
       "       19    0.000    0.000    0.043    0.002 concat.py:24(concat)\n",
       "       41    0.000    0.000    0.000    0.000 sql.py:74(_convert_params)\n",
       "       19    0.000    0.000    0.006    0.000 categorical.py:2517(_delegate_method)\n",
       "       19    0.000    0.000    0.002    0.000 algorithms.py:1450(take)\n",
       "       46    0.000    0.000    0.008    0.000 blocks.py:532(astype)\n",
       "       24    0.000    0.000    0.000    0.000 format.py:1140(<listcomp>)\n",
       "      483    0.000    0.000    0.000    0.000 format.py:1423(<genexpr>)\n",
       "       82    0.000    0.000    0.000    0.000 base.py:261(__init__)\n",
       "       60    0.000    0.000    0.001    0.000 range.py:180(_int64index)\n",
       "        4    0.000    0.000    0.001    0.000 format.py:651(<listcomp>)\n",
       "      168    0.000    0.000    0.001    0.000 series.py:591(__len__)\n",
       "      182    0.000    0.000    0.000    0.000 cursors.py:106(nextset)\n",
       "       43    0.000    0.000    0.000    0.000 compiler.py:3464(quote_identifier)\n",
       "       82    0.000    0.000    0.000    0.000 base.py:949(cursor)\n",
       "       41    0.000    0.000    0.022    0.001 construction.py:501(<listcomp>)\n",
       "       19    0.000    0.000    0.002    0.000 concat.py:440(_get_new_axes)\n",
       "      532    0.000    0.000    0.000    0.000 dtypes.py:555(categories)\n",
       "      403    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "      114    0.000    0.000    0.000    0.000 categorical.py:140(_maybe_to_categorical)\n",
       "       19    0.000    0.000    0.003    0.000 categorical.py:1801(take_nd)\n",
       "      104    0.000    0.000    0.000    0.000 base.py:658(__array__)\n",
       "       64    0.000    0.000    0.008    0.000 indexing.py:2141(_getitem_tuple)\n",
       "      291    0.000    0.000    0.000    0.000 managers.py:376(<dictcomp>)\n",
       "      345    0.000    0.000    0.000    0.000 format.py:541(<genexpr>)\n",
       "       82    0.000    0.000    0.001    0.000 impl.py:102(_do_return_conn)\n",
       "       82    0.000    0.000    0.000    0.000 queue.py:199(_put)\n",
       "       80    0.000    0.000    0.001    0.000 base.py:1672(is_integer)\n",
       "      304    0.000    0.000    0.000    0.000 generic.py:1567(<listcomp>)\n",
       "       68    0.000    0.000    0.001    0.000 format.py:338(_get_adjustment)\n",
       "       19    0.000    0.000    0.001    0.000 concat.py:475(_get_concat_axis)\n",
       "       91    0.000    0.000    0.000    0.000 cursors.py:51(close)\n",
       "       19    0.000    0.000    0.000    0.000 <ipython-input-2005-3c8f524af9e9>:14(__init__)\n",
       "       19    0.000    0.000    0.002    0.000 ops.py:1166(dispatch_to_index_op)\n",
       "       94    0.000    0.000    0.000    0.000 concat.py:126(<listcomp>)\n",
       "       20    0.000    0.000    0.001    0.000 blocks.py:1982(to_native_types)\n",
       "       41    0.000    0.000    0.022    0.001 construction.py:484(_convert_object_array)\n",
       "       41    0.000    0.000    0.000    0.000 exc.py:24(__init__)\n",
       "       82    0.000    0.000    0.001    0.000 base.py:366(_return_conn)\n",
       "       19    0.000    0.000    0.001    0.000 expressions.py:63(_evaluate_standard)\n",
       "       80    0.000    0.000    0.001    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "      187    0.000    0.000    0.000    0.000 inference.py:406(<genexpr>)\n",
       "       41    0.000    0.000    0.000    0.000 connections.py:448(escape)\n",
       "       86    0.000    0.000    0.000    0.000 base.py:1327(_safe_close_cursor)\n",
       "       41    0.000    0.000    0.023    0.001 base.py:1591(run_callable)\n",
       "       81    0.000    0.000    0.000    0.000 queue.py:203(_get)\n",
       "       23    0.000    0.000    0.940    0.041 algorithms.py:407(<lambda>)\n",
       "       64    0.000    0.000    0.003    0.000 range.py:176(_data)\n",
       "       57    0.000    0.000    0.000    0.000 blocks.py:2051(should_store)\n",
       "       40    0.000    0.000    0.000    0.000 connections.py:469(escape_string)\n",
       "       45    0.000    0.000    0.001    0.000 result.py:334(_merge_cursor_description)\n",
       "       43    0.000    0.000    0.000    0.000 compiler.py:3425(_escape_identifier)\n",
       "       38    0.000    0.000    0.001    0.000 fromnumeric.py:1966(sum)\n",
       "       19    0.000    0.000    0.000    0.000 sorting.py:407(safe_sort)\n",
       "      194    0.000    0.000    0.000    0.000 base.py:475(<genexpr>)\n",
       "      228    0.000    0.000    0.000    0.000 generic.py:1693(<listcomp>)\n",
       "       74    0.000    0.000    0.003    0.000 blocks.py:213(make_block)\n",
       "       45    0.000    0.000    0.002    0.000 default.py:1092(get_result_proxy)\n",
       "      146    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:792(find_spec)\n",
       "      186    0.000    0.000    0.000    0.000 common.py:1542(<lambda>)\n",
       "       77    0.000    0.000    0.000    0.000 base.py:759(size)\n",
       "      188    0.000    0.000    0.000    0.000 concat.py:136(<genexpr>)\n",
       "       82    0.000    0.000    0.034    0.000 base.py:2259(_wrap_pool_connect)\n",
       "       45    0.000    0.000    0.004    0.000 result.py:1178(process_rows)\n",
       "        4    0.000    0.000    0.001    0.000 csvs.py:30(__init__)\n",
       "       88    0.000    0.000    0.000    0.000 printing.py:55(<listcomp>)\n",
       "       12    0.000    0.000    0.003    0.000 generic.py:8324(ranker)\n",
       "        2    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
       "       46    0.000    0.000    0.001    0.000 fromnumeric.py:2083(any)\n",
       "       19    0.000    0.000    0.005    0.000 categorical.py:425(categories)\n",
       "       38    0.000    0.000    0.000    0.000 fromnumeric.py:1395(diagonal)\n",
       "       38    0.000    0.000    0.001    0.000 common.py:1320(is_datetimelike_v_numeric)\n",
       "      152    0.000    0.000    0.000    0.000 common.py:273(maybe_make_list)\n",
       "       36    0.000    0.000    0.001    0.000 format.py:1412(_trim_zeros)\n",
       "       19    0.000    0.000    0.005    0.000 categorical.py:857(rename_categories)\n",
       "       19    0.000    0.000    0.000    0.000 concat.py:84(_get_frame_result_type)\n",
       "      188    0.000    0.000    0.000    0.000 concat.py:120(is_nonempty)\n",
       "       15    0.000    0.000    0.001    0.000 api.py:128(_union_indexes)\n",
       "       41    0.000    0.000    0.000    0.000 schema.py:4027(_bind_to)\n",
       "       83    0.000    0.000    0.001    0.000 base.py:119(_for_instance)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'close' of 'pandas._libs.parsers.TextReader' objects}\n",
       "      486    0.000    0.000    0.000    0.000 {method 'ljust' of 'str' objects}\n",
       "      117    0.000    0.000    0.000    0.000 base.py:4683(_maybe_cast_indexer)\n",
       "        4    0.000    0.000    0.002    0.001 format.py:739(_get_formatted_column_labels)\n",
       "       64    0.000    0.000    0.000    0.000 format.py:912(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 protocol.py:122(read_uint16)\n",
       "       64    0.000    0.000    0.000    0.000 indexing.py:229(_is_nested_tuple_indexer)\n",
       "       82    0.000    0.000    0.000    0.000 base.py:715(__init__)\n",
       "       82    0.000    0.000    0.000    0.000 queue.py:195(_full)\n",
       "      179    0.000    0.000    0.001    0.000 iostream.py:320(_schedule_flush)\n",
       "       76    0.000    0.000    0.000    0.000 merge.py:1738(_any)\n",
       "        4    0.000    0.000    0.000    0.000 csvs.py:191(_save_header)\n",
       "       41    0.000    0.000    0.000    0.000 {built-in method _struct.unpack_from}\n",
       "       76    0.000    0.000    0.002    0.000 base.py:1580(is_monotonic)\n",
       "       19    0.000    0.000    0.000    0.000 indexing.py:2619(validate_indices)\n",
       "       38    0.000    0.000    0.000    0.000 blocks.py:1577(iget)\n",
       "      133    0.000    0.000    0.000    0.000 categorical.py:1920(__len__)\n",
       "       97    0.000    0.000    0.000    0.000 base.py:100(_reset_cache)\n",
       "       19    0.000    0.000    0.004    0.000 blocks.py:1765(take_nd)\n",
       "        4    0.000    0.000    0.002    0.000 format.py:642(_join_multiline)\n",
       "       41    0.000    0.000    0.000    0.000 cursors.py:299(fetchall)\n",
       "       40    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}\n",
       "       57    0.000    0.000    0.000    0.000 {built-in method numpy.can_cast}\n",
       "       19    0.000    0.000    0.000    0.000 categorical.py:668(_get_codes)\n",
       "       80    0.000    0.000    0.001    0.000 base.py:2999(_convert_arr_indexer)\n",
       "      137    0.000    0.000    0.000    0.000 base.py:5381(_ensure_has_len)\n",
       "        4    0.000    0.000    0.001    0.000 format.py:931(_format_strings)\n",
       "       41    0.000    0.000    0.000    0.000 base.py:169(_clone)\n",
       "       41    0.000    0.000    0.000    0.000 base.py:479(_still_open_and_connection_is_valid)\n",
       "      249    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
       "      280    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "      500    0.000    0.000    0.000    0.000 arrayprint.py:1154(__call__)\n",
       "      128    0.000    0.000    0.000    0.000 indexing.py:2695(is_label_like)\n",
       "       40    0.000    0.000    0.000    0.000 blocks.py:3183(_safe_reshape)\n",
       "      114    0.000    0.000    0.000    0.000 merge.py:799(<lambda>)\n",
       "       46    0.000    0.000    0.000    0.000 common.py:457(_get_rename_function)\n",
       "       77    0.000    0.000    0.000    0.000 base.py:978(empty)\n",
       "       41    0.000    0.000    1.313    0.032 sql.py:988(execute)\n",
       "       76    0.000    0.000    0.000    0.000 dtypes.py:120(__str__)\n",
       "       36    0.000    0.000    0.005    0.000 format.py:1128(_format_strings)\n",
       "       20    0.000    0.000    0.112    0.006 <ipython-input-2000-7842a37f643d>:7(system_semtype_check)\n",
       "       19    0.000    0.000    0.000    0.000 categorical.py:2596(_recode_for_categories)\n",
       "       19    0.000    0.000    0.001    0.000 concat.py:464(_get_comb_axis)\n",
       "      164    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "       40    0.000    0.000    0.002    0.000 arrayprint.py:707(_formatArray)\n",
       "      228    0.000    0.000    0.000    0.000 generic.py:1627(<listcomp>)\n",
       "       38    0.000    0.000    0.000    0.000 generic.py:5140(_consolidate)\n",
       "       30    0.000    0.000    0.000    0.000 blocks.py:2736(should_store)\n",
       "      164    0.000    0.000    0.000    0.000 managers.py:1513(index)\n",
       "       40    0.000    0.000    0.000    0.000 arrayprint.py:365(<lambda>)\n",
       "       57    0.000    0.000    0.009    0.000 dtypes.py:225(__init__)\n",
       "      240    0.000    0.000    0.000    0.000 common.py:201(<genexpr>)\n",
       "       38    0.000    0.000    0.004    0.000 base.py:4025(_concat_same_dtype)\n",
       "       81    0.000    0.000    0.000    0.000 generic.py:334(<dictcomp>)\n",
       "       80    0.000    0.000    0.000    0.000 indexing.py:2676(is_nested_tuple)\n",
       "        4    0.000    0.000    0.007    0.002 csvs.py:130(save)\n",
       "       42    0.000    0.000    0.001    0.000 cast.py:1123(cast_scalar_to_array)\n",
       "       38    0.000    0.000    0.001    0.000 base.py:1806(hasnans)\n",
       "      242    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_float64}\n",
       "       69    0.000    0.000    0.000    0.000 cast.py:473(maybe_infer_dtype_type)\n",
       "      408    0.000    0.000    0.000    0.000 format.py:1424(<genexpr>)\n",
       "       38    0.000    0.000    0.000    0.000 merge.py:1011(_validate_specification)\n",
       "       57    0.000    0.000    0.000    0.000 ops.py:66(_maybe_match_name)\n",
       "      102    0.000    0.000    0.000    0.000 managers.py:1850(_shape_compat)\n",
       "       36    0.000    0.000    0.000    0.000 format.py:1430(<listcomp>)\n",
       "       91    0.000    0.000    0.000    0.000 cursors.py:332(_clear_result)\n",
       "       45    0.000    0.000    0.002    0.000 default.py:1108(_setup_crud_result_proxy)\n",
       "       42    0.000    0.000    0.000    0.000 pymysql.py:76(_extract_error_code)\n",
       "       58    0.000    0.000    0.001    0.000 base.py:4071(identical)\n",
       "       68    0.000    0.000    0.000    0.000 format.py:298(__init__)\n",
       "      123    0.000    0.000    0.000    0.000 base.py:958(__getattr__)\n",
       "       45    0.000    0.000    0.000    0.000 result.py:266(<listcomp>)\n",
       "       38    0.000    0.000    0.000    0.000 {method 'diagonal' of 'numpy.ndarray' objects}\n",
       "       80    0.000    0.000    0.001    0.000 _methods.py:34(_sum)\n",
       "      134    0.000    0.000    0.000    0.000 base.py:2249(_validate_sort_keyword)\n",
       "      192    0.000    0.000    0.000    0.000 indexing.py:230(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:973(_get_server_information)\n",
       "       80    0.000    0.000    0.000    0.000 cursors.py:122(<genexpr>)\n",
       "      102    0.000    0.000    0.001    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "       34    0.000    0.000    0.002    0.000 generic.py:178(_validate_dtype)\n",
       "       19    0.000    0.000    0.001    0.000 api.py:87(_get_combined_index)\n",
       "       60    0.000    0.000    0.002    0.000 indexing.py:143(_get_loc)\n",
       "       88    0.000    0.000    0.000    0.000 blocks.py:3146(<listcomp>)\n",
       "       76    0.000    0.000    0.000    0.000 managers.py:1045(value_getitem)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:1553(_binify)\n",
       "       82    0.000    0.000    0.000    0.000 attr.py:255(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 _methods.py:58(_mean)\n",
       "       38    0.000    0.000    0.000    0.000 dtypes.py:465(validate_ordered)\n",
       "       27    0.000    0.000    0.000    0.000 common.py:212(dict_keys_to_ordered_list)\n",
       "       40    0.000    0.000    0.004    0.000 series.py:388(_update_inplace)\n",
       "       41    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
       "        8    0.000    0.000    0.001    0.000 base.py:998(_format_with_header)\n",
       "       38    0.000    0.000    0.000    0.000 concat.py:503(<listcomp>)\n",
       "        4    0.000    0.000    0.007    0.002 generic.py:2882(to_csv)\n",
       "       38    0.000    0.000    0.001    0.000 generic.py:1765(<listcomp>)\n",
       "       38    0.000    0.000    0.000    0.000 generic.py:1775(<listcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 api.py:73(_get_distinct_objs)\n",
       "       36    0.000    0.000    0.000    0.000 format.py:992(__init__)\n",
       "      180    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
       "       69    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
       "       15    0.000    0.000    0.000    0.000 api.py:262(<setcomp>)\n",
       "       27    0.000    0.000    0.001    0.000 blocks.py:391(<listcomp>)\n",
       "       23    0.000    0.000    0.000    0.000 construction.py:509(sanitize_index)\n",
       "       45    0.000    0.000    0.000    0.000 base.py:1174(should_autocommit_text)\n",
       "       36    0.000    0.000    0.000    0.000 apipkg.py:133(__makeattr)\n",
       "       19    0.000    0.000    0.001    0.000 expressions.py:192(evaluate)\n",
       "       82    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
       "      342    0.000    0.000    0.000    0.000 dtypes.py:562(ordered)\n",
       "       60    0.000    0.000    0.000    0.000 managers.py:1552(formatting_values)\n",
       "       65    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "      132    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
       "       19    0.000    0.000    0.002    0.000 ops.py:1468(_construct_result)\n",
       "       57    0.000    0.000    0.000    0.000 base.py:143(__setattr__)\n",
       "       76    0.000    0.000    0.000    0.000 blocks.py:1910(_ftype)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:381(__init__)\n",
       "       41    0.000    0.000    0.000    0.000 langhelpers.py:62(__exit__)\n",
       "       46    0.000    0.000    0.000    0.000 inspect.py:72(isclass)\n",
       "       15    0.000    0.000    0.000    0.000 parse.py:409(urlsplit)\n",
       "       38    0.000    0.000    0.000    0.000 base.py:4012(<setcomp>)\n",
       "      188    0.000    0.000    0.000    0.000 concat.py:137(<genexpr>)\n",
       "       38    0.000    0.000    0.000    0.000 frame.py:491(shape)\n",
       "        4    0.000    0.000    0.025    0.006 frame.py:614(__unicode__)\n",
       "       15    0.000    0.000    0.000    0.000 blocks.py:323(concat_same_type)\n",
       "       57    0.000    0.000    0.000    0.000 blocks.py:1571(shape)\n",
       "       40    0.000    0.000    0.000    0.000 connections.py:462(literal)\n",
       "       19    0.000    0.000    0.001    0.000 expressions.py:96(_evaluate_numexpr)\n",
       "       15    0.000    0.000    0.000    0.000 parse.py:361(urlparse)\n",
       "       88    0.000    0.000    0.000    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
       "       23    0.000    0.000    0.000    0.000 __init__.py:125(lrange)\n",
       "       27    0.000    0.000    0.000    0.000 construction.py:210(<listcomp>)\n",
       "      207    0.000    0.000    0.000    0.000 format.py:1107(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:769(<listcomp>)\n",
       "       40    0.000    0.000    0.000    0.000 series.py:348(_can_hold_na)\n",
       "       40    0.000    0.000    0.000    0.000 converters.py:68(_escape_unicode)\n",
       "       50    0.000    0.000    0.000    0.000 cursors.py:355(_show_warnings)\n",
       "      249    0.000    0.000    0.000    0.000 numerictypes.py:655(<listcomp>)\n",
       "      155    0.000    0.000    0.000    0.000 common.py:1195(<lambda>)\n",
       "       19    0.000    0.000    0.000    0.000 accessor.py:167(__get__)\n",
       "       12    0.000    0.000    0.003    0.000 generic.py:8282(rank)\n",
       "       19    0.000    0.000    0.001    0.000 api.py:44(_get_objs_combined_axis)\n",
       "      197    0.000    0.000    0.000    0.000 managers.py:1814(<lambda>)\n",
       "       82    0.000    0.000    0.000    0.000 base.py:364(invalidated)\n",
       "       40    0.000    0.000    0.000    0.000 arrayprint.py:1149(__init__)\n",
       "        4    0.000    0.000    0.002    0.000 generic.py:3155(_slice)\n",
       "       41    0.000    0.000    0.000    0.000 protocol.py:94(rewind)\n",
       "       41    0.000    0.000    0.000    0.000 langhelpers.py:59(__enter__)\n",
       "       41    0.000    0.000    0.007    0.000 base.py:180(__exit__)\n",
       "       82    0.000    0.000    0.000    0.000 base.py:355(closed)\n",
       "        4    0.000    0.000    0.113    0.028 <ipython-input-2015-648145736ddf>:16(get_valid_systems)\n",
       "       46    0.000    0.000    0.000    0.000 blocks.py:146(is_categorical_astype)\n",
       "       60    0.000    0.000    0.000    0.000 series.py:483(_formatting_values)\n",
       "       19    0.000    0.000    0.000    0.000 concat.py:309(<listcomp>)\n",
       "      114    0.000    0.000    0.000    0.000 blocks.py:1683(_maybe_coerce_values)\n",
       "       12    0.000    0.000    0.001    0.000 format.py:307(adjoin)\n",
       "     14/4    0.000    0.000    0.000    0.000 langhelpers.py:273(get_cls_kwargs)\n",
       "       82    0.000    0.000    0.000    0.000 queue.py:191(_empty)\n",
       "      198    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
       "       68    0.000    0.000    0.000    0.000 common.py:279(is_null_slice)\n",
       "       80    0.000    0.000    0.000    0.000 base.py:3035(_convert_list_indexer)\n",
       "       20    0.000    0.000    0.002    0.000 blocks.py:435(make_a_block)\n",
       "       40    0.000    0.000    0.000    0.000 blocks.py:3118(_block_shape)\n",
       "        8    0.000    0.000    0.001    0.000 blocks.py:730(to_native_types)\n",
       "        4    0.000    0.000    0.024    0.006 format.py:582(to_string)\n",
       "       41    0.000    0.000    0.000    0.000 langhelpers.py:56(__init__)\n",
       "       40    0.000    0.000    0.000    0.000 default.py:894(<listcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 ops.py:101(maybe_upcast_for_op)\n",
       "      106    0.000    0.000    0.000    0.000 common.py:183(_any_not_none)\n",
       "       27    0.000    0.000    0.000    0.000 common.py:94(_expand_user)\n",
       "        4    0.000    0.000    0.003    0.001 common.py:314(_get_handle)\n",
       "       76    0.000    0.000    0.000    0.000 merge.py:1742(validate_operand)\n",
       "      205    0.000    0.000    0.000    0.000 base.py:155(_root)\n",
       "       19    0.000    0.000    0.000    0.000 expressions.py:173(_bool_arith_check)\n",
       "      146    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:719(find_spec)\n",
       "      102    0.000    0.000    0.001    0.000 _methods.py:26(_amax)\n",
       "       38    0.000    0.000    0.000    0.000 generic.py:1778(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'writerow' of '_csv.writer' objects}\n",
       "       50    0.000    0.000    0.000    0.000 protocol.py:208(is_load_local_packet)\n",
       "       41    0.000    0.000    0.000    0.000 result.py:1161(_fetchall_impl)\n",
       "        4    0.000    0.000    0.000    0.000 stats.py:256(gmean)\n",
       "      154    0.000    0.000    0.000    0.000 fromnumeric.py:2847(ndim)\n",
       "       30    0.000    0.000    0.000    0.000 common.py:1752(is_complex_dtype)\n",
       "       19    0.000    0.000    0.006    0.000 accessor.py:90(f)\n",
       "       91    0.000    0.000    0.000    0.000 connections.py:1069(__del__)\n",
       "       40    0.000    0.000    0.000    0.000 <ipython-input-1999-cd2ed8d3f7ce>:40(get_system_type)\n",
       "       19    0.000    0.000    0.000    0.000 {built-in method _operator.ne}\n",
       "       40    0.000    0.000    0.000    0.000 arrayprint.py:74(<dictcomp>)\n",
       "       61    0.000    0.000    0.000    0.000 common.py:175(_all_none)\n",
       "        8    0.000    0.000    0.001    0.000 base.py:1050(_format_native_types)\n",
       "       15    0.000    0.000    0.000    0.000 api.py:243(_get_consensus_names)\n",
       "      114    0.000    0.000    0.000    0.000 format.py:1139(<lambda>)\n",
       "       19    0.000    0.000    0.000    0.000 {method 'map_locations' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
       "        4    0.000    0.000    0.024    0.006 frame.py:678(to_string)\n",
       "        4    0.000    0.000    0.096    0.024 frame.py:4027(fillna)\n",
       "      114    0.000    0.000    0.000    0.000 merge.py:800(<lambda>)\n",
       "      163    0.000    0.000    0.000    0.000 {method '_is_owned' of '_thread.RLock' objects}\n",
       "       40    0.000    0.000    0.000    0.000 base.py:697(shape)\n",
       "       19    0.000    0.000    0.000    0.000 generic.py:337(_from_axes)\n",
       "       41    0.000    0.000    0.000    0.000 sql.py:490(_engine_builder)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:786(_request_authentication)\n",
       "     20/3    0.000    0.000    0.001    0.000 visitors.py:85(_compiler_dispatch)\n",
       "       38    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "       38    0.000    0.000    0.000    0.000 concat.py:496(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _csv.writer}\n",
       "       46    0.000    0.000    0.000    0.000 default.py:943(no_parameters)\n",
       "        1    0.000    0.000    0.000    0.000 {function socket.close at 0x10622e488}\n",
       "       19    0.000    0.000    0.000    0.000 ops.py:1447(_align_method_SERIES)\n",
       "       38    0.000    0.000    0.000    0.000 concat.py:92(<genexpr>)\n",
       "       15    0.000    0.000    0.000    0.000 api.py:205(_sanitize_and_check)\n",
       "        4    0.000    0.000    0.001    0.000 format.py:801(_get_formatted_index)\n",
       "       10    0.000    0.000    0.000    0.000 elements.py:717(__getattr__)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:1999(visit_select)\n",
       "       40    0.000    0.000    0.000    0.000 <ipython-input-1999-cd2ed8d3f7ce>:12(<listcomp>)\n",
       "       12    0.000    0.000    0.000    0.000 printing.py:36(<listcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 categorical.py:2497(_validate)\n",
       "      150    0.000    0.000    0.000    0.000 base.py:704(ndim)\n",
       "      168    0.000    0.000    0.000    0.000 managers.py:1578(_consolidate_inplace)\n",
       "        1    0.000    0.000    1.753    1.753 parsers.py:1993(read)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1761(_label_select_column)\n",
       "       41    0.000    0.000    0.000    0.000 result.py:760(keys)\n",
       "        4    0.000    0.000    0.003    0.001 csvs.py:272(_save)\n",
       "       19    0.000    0.000    0.000    0.000 blocks.py:1592(set)\n",
       "       19    0.000    0.000    0.000    0.000 blocks.py:2011(should_store)\n",
       "      120    0.000    0.000    0.000    0.000 format.py:535(<genexpr>)\n",
       "      130    0.000    0.000    0.000    0.000 base.py:370(connection)\n",
       "       41    0.000    0.000    0.000    0.000 base.py:709(in_transaction)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "       80    0.000    0.000    0.000    0.000 indexing.py:937(_convert_for_reindex)\n",
       "       60    0.000    0.000    0.000    0.000 blocks.py:171(formatting_values)\n",
       "        4    0.000    0.000    0.002    0.000 managers.py:684(get_slice)\n",
       "       49    0.000    0.000    0.000    0.000 cursors.py:127(<dictcomp>)\n",
       "       45    0.000    0.000    0.000    0.000 result.py:263(<listcomp>)\n",
       "       41    0.000    0.000    0.000    0.000 default.py:477(set_connection_execution_options)\n",
       "      186    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
       "       19    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "       38    0.000    0.000    0.000    0.000 categorical.py:434(ordered)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:1010(<listcomp>)\n",
       "       24    0.000    0.000    0.000    0.000 format.py:1138(_format_strings)\n",
       "       19    0.000    0.000    0.000    0.000 blocks.py:1706(fill_value)\n",
       "       19    0.000    0.000    0.000    0.000 format.py:945(_format)\n",
       "       36    0.000    0.000    0.000    0.000 format.py:1004(_value_formatter)\n",
       "        1    0.000    0.000    0.007    0.007 connections.py:564(connect)\n",
       "       38    0.000    0.000    0.000    0.000 _methods.py:30(_amin)\n",
       "        1    0.000    0.000    2.010    2.010 parsers.py:1137(read)\n",
       "        1    0.000    0.000    0.007    0.007 connections.py:183(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method now}\n",
       "       12    0.000    0.000    0.000    0.000 generic.py:277(_construct_axes_dict)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:431(_chk_truncate)\n",
       "        1    0.000    0.000   12.471   12.471 {built-in method builtins.exec}\n",
       "       30    0.000    0.000    0.000    0.000 parse.py:109(_coerce_args)\n",
       "        1    0.000    0.000    0.002    0.002 socket.py:691(create_connection)\n",
       "      114    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Int64Factorizer' objects}\n",
       "        4    0.000    0.000    0.000    0.000 console.py:149(in_ipython_frontend)\n",
       "       76    0.000    0.000    0.000    0.000 dtypes.py:117(__unicode__)\n",
       "       10    0.000    0.000    0.000    0.000 cast.py:1260(maybe_cast_to_integer_array)\n",
       "       38    0.000    0.000    0.000    0.000 categorical.py:394(categories)\n",
       "        8    0.000    0.000    0.001    0.000 base.py:1024(to_native_types)\n",
       "        4    0.000    0.000    0.001    0.000 generic.py:5457(dtypes)\n",
       "       19    0.000    0.000    0.000    0.000 blocks.py:1589(should_store)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:179(get_filepath_or_buffer)\n",
       "       41    0.000    0.000    0.000    0.000 elements.py:4322(_string_or_unprintable)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:500(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 console.py:47(get_console_size)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:780(visit_label)\n",
       "       19    0.000    0.000    0.000    0.000 expressions.py:163(_has_bool_dtype)\n",
       "       96    0.000    0.000    0.000    0.000 common.py:464(f)\n",
       "       38    0.000    0.000    0.000    0.000 categorical.py:496(ndim)\n",
       "       19    0.000    0.000    0.000    0.000 api.py:67(<listcomp>)\n",
       "       40    0.000    0.000    0.000    0.000 managers.py:1568(_can_hold_na)\n",
       "        1    0.000    0.000    2.034    2.034 parsers.py:536(parser_f)\n",
       "       41    0.000    0.000    0.000    0.000 sql.py:85(_process_parse_dates_argument)\n",
       "        1    0.000    0.000    0.016    0.016 base.py:622(__connect)\n",
       "        3    0.000    0.000    0.002    0.001 default.py:342(check_unicode)\n",
       "       69    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
       "       81    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
       "       19    0.000    0.000    0.000    0.000 common.py:162(_not_none)\n",
       "       12    0.000    0.000    0.002    0.000 algorithms.py:835(rank)\n",
       "       19    0.000    0.000    0.000    0.000 concat.py:434(_get_result_dim)\n",
       "       50    0.000    0.000    0.000    0.000 cursors.py:76(_check_executed)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2687(__init__)\n",
       "        1    0.000    0.000    0.005    0.005 mysqldb.py:136(_check_unicode_returns)\n",
       "       19    0.000    0.000    0.000    0.000 <ipython-input-2005-3c8f524af9e9>:12(Cooccurences)\n",
       "       57    0.000    0.000    0.000    0.000 common.py:164(<genexpr>)\n",
       "        8    0.000    0.000    0.001    0.000 base.py:983(format)\n",
       "       57    0.000    0.000    0.000    0.000 base.py:3072(_can_reindex)\n",
       "       38    0.000    0.000    0.000    0.000 concat.py:93(<genexpr>)\n",
       "       61    0.000    0.000    0.000    0.000 range.py:165(_validate_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 managers.py:736(as_array)\n",
       "        5    0.000    0.000    0.000    0.000 types.py:69(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 csvs.py:112(<genexpr>)\n",
       "       84    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:221(makefile)\n",
       "       76    0.000    0.000    0.000    0.000 categorical.py:452(_constructor)\n",
       "       38    0.000    0.000    0.000    0.000 base.py:540(_constructor)\n",
       "       19    0.000    0.000    0.001    0.000 base.py:1785(_isnan)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:5393(_trim_front)\n",
       "       38    0.000    0.000    0.000    0.000 {method 'append' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "       41    0.000    0.000    0.000    0.000 base.py:875(is_valid)\n",
       "      111    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
       "       19    0.000    0.000    0.000    0.000 common.py:784(is_dtype_union_equal)\n",
       "        4    0.000    0.000    0.000    0.000 langhelpers.py:1136(constructor_copy)\n",
       "        8    0.000    0.000    0.000    0.000 type_api.py:505(_dialect_info)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:1440(adapt_type)\n",
       "       45    0.000    0.000    0.000    0.000 result.py:864(_cursor_description)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'setsockopt' of '_socket.socket' objects}\n",
       "       38    0.000    0.000    0.000    0.000 concat.py:97(<genexpr>)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:260(_infer_compression)\n",
       "       53    0.000    0.000    0.000    0.000 concat.py:510(<genexpr>)\n",
       "       44    0.000    0.000    0.000    0.000 elements.py:4139(__new__)\n",
       "        1    0.000    0.000    0.007    0.007 default.py:286(initialize)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2157(_setup_select_stack)\n",
       "       23    0.000    0.000    0.000    0.000 blocks.py:477(_maybe_downcast)\n",
       "        4    0.000    0.000    0.007    0.002 blocks.py:2715(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 managers.py:225(get_dtypes)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:76(_is_url)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:186(scramble_caching_sha2)\n",
       "        9    0.000    0.000    0.000    0.000 cursors.py:280(fetchone)\n",
       "       83    0.000    0.000    0.000    0.000 _collections.py:145(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 compiler.py:3477(_requires_quotes)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:1279(first)\n",
       "        1    0.000    0.000    0.009    0.009 base.py:2347(initialize)\n",
       "       77    0.000    0.000    0.000    0.000 printing.py:62(_join_unicode)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:2897(_convert_slice_indexer)\n",
       "       15    0.000    0.000    0.000    0.000 api.py:226(<setcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 format.py:943(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:900(_get_options_with_defaults)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:956(_clean_options)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1352(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1502(_maybe_dedup_names)\n",
       "        1    0.000    0.000    0.002    0.002 default.py:331(_check_unicode_returns)\n",
       "       41    0.000    0.000    0.000    0.000 default.py:1089(handle_dbapi_exception)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1278(visit_typeclause)\n",
       "        7    0.000    0.000    0.000    0.000 <ipython-input-1998-01a4bf55ac48>:9(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 frame.py:606(_info_repr)\n",
       "       12    0.000    0.000    0.000    0.000 generic.py:279(<dictcomp>)\n",
       "        4    0.000    0.000    0.002    0.000 indexing.py:2170(_get_slice_axis)\n",
       "        4    0.000    0.000    0.007    0.002 blocks.py:2709(_maybe_downcast)\n",
       "        8    0.000    0.000    0.000    0.000 format.py:781(has_index_names)\n",
       "        8    0.000    0.000    0.000    0.000 format.py:789(show_row_idx_names)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1180(_is_potential_multi_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1926(close)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:864(anon_label)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2959(_froms)\n",
       "        9    0.000    0.000    0.000    0.000 <string>:1(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1316(visit_cast)\n",
       "        3    0.000    0.000    0.000    0.000 types.py:689(_adapt_string_for_cast)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:35(_formatwarnmsg_impl)\n",
       "        4    0.000    0.000    0.000    0.000 indexing.py:264(_convert_slice_indexer)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:2721(_try_coerce_args)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:816(<listcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 concat.py:507(<listcomp>)\n",
       "        7    0.000    0.000    0.000    0.000 langhelpers.py:253(_inspect_func_args)\n",
       "        6    0.000    0.000    0.000    0.000 type_api.py:440(dialect_impl)\n",
       "        9    0.000    0.000    0.000    0.000 sqltypes.py:140(__init__)\n",
       "        1    0.000    0.000    0.009    0.009 attr.py:279(exec_once)\n",
       "       41    0.000    0.000    0.000    0.000 base.py:177(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2172(get_isolation_level)\n",
       "       41    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
       "        1    0.000    0.000    0.001    0.001 socket.py:731(getaddrinfo)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
       "       38    0.000    0.000    0.000    0.000 {method 'get_count' of 'pandas._libs.hashtable.Factorizer' objects}\n",
       "        4    0.000    0.000    0.025    0.006 base.py:48(__str__)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:648(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:271(_init_dict)\n",
       "        1    0.000    0.000    0.007    0.007 __init__.py:88(Connect)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3831(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2988(_get_display_froms)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3641(_columns_plus_names)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:94(__getattr__)\n",
       "        1    0.000    0.000    0.009    0.009 strategies.py:194(first_connect)\n",
       "        3    0.000    0.000    0.001    0.000 compiler.py:274(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1564(_process_anon)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2186(_compose_select_body)\n",
       "        6    0.000    0.000    0.000    0.000 compiler.py:3529(quote)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2184(_get_server_version_info)\n",
       "        4    0.000    0.000    0.000    0.000 generic.py:5250(values)\n",
       "        8    0.000    0.000    0.000    0.000 range.py:184(_get_data_as_items)\n",
       "       39    0.000    0.000    0.000    0.000 managers.py:1572(is_consolidated)\n",
       "       45    0.000    0.000    0.000    0.000 concat.py:383(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:544(UnicodeWriter)\n",
       "        4    0.000    0.000    0.000    0.000 series.py:737(__array_prepare__)\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:1120(_make_engine)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:34(scramble_native_password)\n",
       "        1    0.000    0.000    0.000    0.000 langhelpers.py:925(__getattr__)\n",
       "        7    0.000    0.000    0.000    0.000 elements.py:705(comparator)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:3066(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 <string>:1(select)\n",
       "        3    0.000    0.000    0.001    0.000 base.py:1287(_cursor_execute)\n",
       "      9/3    0.000    0.000    0.001    0.000 compiler.py:349(process)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1542(_truncated_identifier)\n",
       "       41    0.000    0.000    0.000    0.000 {method 'with_traceback' of 'BaseException' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:563(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 _methods.py:48(_count_reduce_items)\n",
       "       19    0.000    0.000    0.000    0.000 dtypes.py:234(_from_categorical_dtype)\n",
       "       19    0.000    0.000    0.000    0.000 missing.py:534(fill_zeros)\n",
       "       19    0.000    0.000    0.000    0.000 base.py:138(_freeze)\n",
       "        4    0.000    0.000    0.000    0.000 managers.py:226(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 managers.py:627(is_view)\n",
       "       12    0.000    0.000    0.000    0.000 format.py:1434(_has_names)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:3600(_reduce)\n",
       "        1    0.000    0.000    0.001    0.001 parsers.py:813(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 charset.py:40(by_id)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:304(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:305(<dictcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:637(write_packet)\n",
       "        3    0.000    0.000    0.000    0.000 langhelpers.py:897(expire_instance)\n",
       "       21    0.000    0.000    0.000    0.000 langhelpers.py:1145(<genexpr>)\n",
       "        1    0.000    0.000    0.009    0.009 langhelpers.py:1440(go)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2395(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:524(adapt)\n",
       "        1    0.000    0.000    0.001    0.001 base.py:2750(_detect_casing)\n",
       "        2    0.000    0.000    0.000    0.000 types.py:510(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 types.py:674(__init__)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "        8    0.000    0.000    0.000    0.000 weakref.py:435(__contains__)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _hashlib.new}\n",
       "        8    0.000    0.000    0.000    0.000 config.py:170(get_default_val)\n",
       "        4    0.000    0.000    0.000    0.000 console.py:90(in_interactive_session)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:203(_get_values)\n",
       "       31    0.000    0.000    0.000    0.000 base.py:5398(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 generic.py:1818(__iter__)\n",
       "        4    0.000    0.000    0.000    0.000 generic.py:3110(_is_view)\n",
       "        4    0.000    0.000    0.002    0.000 indexing.py:148(_slice)\n",
       "       27    0.000    0.000    0.000    0.000 blocks.py:721(_try_coerce_result)\n",
       "       19    0.000    0.000    0.000    0.000 managers.py:1035(value_getitem)\n",
       "       15    0.000    0.000    0.000    0.000 managers.py:2058(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4299(apply_map)\n",
       "       10    0.000    0.000    0.000    0.000 type_api.py:1430(to_instance)\n",
       "        4    0.000    0.000    0.000    0.000 default.py:409(type_descriptor)\n",
       "       17    0.000    0.000    0.000    0.000 base.py:1753(attr)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1747(_extend_string)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1954(visit_CHAR)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'split' of 're.Pattern' objects}\n",
       "        1    0.000    0.000    0.000    0.000 weakref.py:356(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_sha256}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "       15    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'timestamp' of 'datetime.datetime' objects}\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:412(_real_close)\n",
       "       19    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
       "        4    0.000    0.000    0.000    0.000 generic.py:5337(get_values)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:11018(logical_func)\n",
       "       15    0.000    0.000    0.000    0.000 blocks.py:327(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 blocks.py:2666(<dictcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 blocks.py:2941(_holder)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:785(has_column_names)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:163(is_s3_url)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:171(is_gcs_url)\n",
       "        2    0.000    0.000    0.000    0.000 charset.py:43(by_name)\n",
       "        1    0.000    0.000    0.004    0.004 connections.py:401(_send_autocommit_mode)\n",
       "        1    0.000    0.000    0.000    0.000 _auth.py:48(_my_crypt)\n",
       "        1    0.000    0.000    0.000    0.000 util.py:4(byte2int)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:361(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:39(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:38(_from_objects)\n",
       "        3    0.000    0.000    0.001    0.000 elements.py:399(compile)\n",
       "        3    0.000    0.000    0.001    0.000 elements.py:464(_compiler)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4184(__new__)\n",
       "        4    0.000    0.000    0.000    0.000 elements.py:4544(_literal_as_binds)\n",
       "        2    0.000    0.000    0.000    0.000 sqltypes.py:411(__init__)\n",
       "        1    0.000    0.000    0.007    0.007 strategies.py:106(connect)\n",
       "        1    0.000    0.000    0.007    0.007 default.py:452(connect)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:834(visit_column)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:890(escape_literal_column)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1261(visit_binary)\n",
       "        1    0.000    0.000    0.002    0.002 default.py:379(<setcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 base.py:2794(_detect_sql_mode)\n",
       "        2    0.000    0.000    0.000    0.000 <ipython-input-1998-01a4bf55ac48>:14(corpus_config)\n",
       "        1    0.000    0.000   12.471   12.471 <string>:1(<module>)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method gc.get_referents}\n",
       "       19    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
       "        4    0.000    0.000    0.000    0.000 codecs.py:186(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:20(_showwarnmsg_impl)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:419(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 weakref.py:358(remove)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:526(__new__)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:227(itervalues)\n",
       "        8    0.000    0.000    0.000    0.000 config.py:578(_get_registered_option)\n",
       "       12    0.000    0.000    0.000    0.000 base.py:4698(_validate_indexer)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:5399(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 range.py:330(equals)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:351(should_show_dimensions)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:897(close)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:890(_process_auth)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:755(unique_list)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:54(collate)\n",
       "        2    0.000    0.000    0.000    0.000 elements.py:681(self_group)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2340(literal_column)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:2120(__init__)\n",
       "        1    0.000    0.000    0.009    0.009 attr.py:291(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1318(_generate_generic_binary)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2082(<listcomp>)\n",
       "        1    0.000    0.000    0.016    0.016 base.py:425(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2296(_compat_first)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:2906(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 pymysql.py:51(supports_server_side_cursors)\n",
       "        1    0.000    0.000    0.000    0.000 idna.py:147(encode)\n",
       "       12    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "        4    0.000    0.000    0.000    0.000 weakref.py:408(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 re.py:271(_compile)\n",
       "        4    0.000    0.000    0.000    0.000 enum.py:284(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 socket.py:97(_intenum_converter)\n",
       "        1    0.000    0.000    0.000    0.000 socket.py:416(close)\n",
       "       30    0.000    0.000    0.000    0.000 managers.py:1041(value_getitem)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:795(show_col_idx_names)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:3735(reindex)\n",
       "        6    0.000    0.000    0.000    0.000 parsers.py:1195(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1936(_set_noconvert_columns)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:74(_makefile)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:396(__iter__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3944(_set_table)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4340(_select_iterables)\n",
       "        7    0.000    0.000    0.000    0.000 type_api.py:60(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 type_api.py:307(_has_column_expression)\n",
       "        3    0.000    0.000    0.000    0.000 <string>:1(cast)\n",
       "        1    0.000    0.000    0.003    0.003 base.py:914(scalar)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:399(process)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:3598(format_label)\n",
       "        1    0.000    0.000    0.016    0.016 base.py:296(_create_connection)\n",
       "        1    0.000    0.000    0.000    0.000 impl.py:142(_inc_overflow)\n",
       "        2    0.000    0.000    0.000    0.000 result.py:1306(scalar)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1350(get_select_precolumns)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2309(_get_default_schema_name)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2809(_detect_ansiquotes)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        7    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 re.py:232(compile)\n",
       "        1    0.000    0.000    0.000    0.000 linecache.py:15(getline)\n",
       "        1    0.000    0.000    0.000    0.000 linecache.py:37(getlines)\n",
       "        3    0.000    0.000    0.000    0.000 hashlib.py:139(__hash_new)\n",
       "       30    0.000    0.000    0.000    0.000 parse.py:98(_noop)\n",
       "        4    0.000    0.000    0.000    0.000 interactiveshell.py:698(get_ipython)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:337(nanany)\n",
       "        4    0.000    0.000    0.000    0.000 generic.py:1904(__array__)\n",
       "        4    0.000    0.000    0.000    0.000 blocks.py:136(is_view)\n",
       "        4    0.000    0.000    0.000    0.000 blocks.py:2718(_can_hold_element)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:4209(isnull)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:347(_validate_integer)\n",
       "        3    0.000    0.000    0.000    0.000 parsers.py:1176(_is_index_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1536(_make_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1814(_do_date_conversions)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2064(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3195(_process_date_conversion)\n",
       "        1    0.000    0.000    0.000    0.000 converters.py:12(escape_item)\n",
       "        1    0.000    0.000    0.000    0.000 converters.py:47(escape_bool)\n",
       "        1    0.000    0.000    0.004    0.004 connections.py:383(autocommit)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:389(get_autocommit)\n",
       "        3    0.000    0.000    0.000    0.000 util.py:11(int2byte)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:142(read_string)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:733(__missing__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:1271(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:2455(_from_objects)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:3098(_from_objects)\n",
       "        6    0.000    0.000    0.000    0.000 elements.py:3941(_get_table)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:3950(_from_objects)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4345(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 operators.py:1399(is_boolean)\n",
       "        4    0.000    0.000    0.000    0.000 type_api.py:521(_gen_dialect_impl)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:276(_memoized_attr__exec_once_mutex)\n",
       "        1    0.000    0.000    0.000    0.000 default.py:270(_type_memos)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:1758(_add_to_result_map)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:901(close)\n",
       "        4    0.000    0.000    0.000    0.000 result.py:1146(_fetchone_impl)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:1778(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2381(_is_mariadb)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:2407(_supports_cast)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2902(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 mysqldb.py:214(_detect_charset)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'split' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'issuperset' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:96(_showwarnmsg)\n",
       "        1    0.000    0.000    0.000    0.000 warnings.py:117(_formatwarnmsg)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:1361(debug)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 parse.py:83(clear_cache)\n",
       "        4    0.000    0.000    0.000    0.000 parse.py:394(_checknetloc)\n",
       "        4    0.000    0.000    0.000    0.000 __init__.py:275(u)\n",
       "        1    0.000    0.000    0.000    0.000 __init__.py:457(is_platform_windows)\n",
       "        1    0.000    0.000    0.000    0.000 inference.py:160(is_file_like)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:180(_get_fill_value)\n",
       "        1    0.000    0.000    0.000    0.000 nanops.py:270(_na_ok_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:4077(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:7083(isnull)\n",
       "        4    0.000    0.000    0.000    0.000 blocks.py:132(_is_single_block)\n",
       "        4    0.000    0.000    0.000    0.000 indexing.py:2700(need_slice)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method pandas._libs.internals.slice_len}\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:939(_check_file_or_buffer)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1329(_validate_parse_dates_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1423(_has_complex_date_col)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:2066(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3278(_clean_na_values)\n",
       "        1    0.000    0.000    0.000    0.000 charset.py:18(encoding)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:101(lenenc_int)\n",
       "        2    0.000    0.000    0.000    0.000 connections.py:96(pack_int24)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:946(_get_auth_plugin_handler)\n",
       "        1    0.000    0.000    0.000    0.000 connections.py:964(character_set_name)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:730(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 _collections.py:759(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:4559(_interpret_as_column_or_from)\n",
       "        1    0.000    0.000    0.000    0.000 operators.py:1376(is_comparison)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:410(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:419(type)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:708(default_from)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:872(visit_collation)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:1168(_get_operator_dispatch)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:2080(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2385(_is_mysql)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 function.py:40(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 common.py:112(_validate_header_arg)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:377(_validate_names)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1162(_create_index)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:1274(_validate_usecols_arg)\n",
       "        2    0.000    0.000    0.000    0.000 parsers.py:1530(_maybe_make_multi_index_columns)\n",
       "        1    0.000    0.000    0.000    0.000 parsers.py:3157(_make_date_converter)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:60(get_all_data)\n",
       "        1    0.000    0.000    0.000    0.000 protocol.py:196(is_auth_switch_request)\n",
       "        3    0.000    0.000    0.000    0.000 elements.py:751(_select_iterable)\n",
       "        1    0.000    0.000    0.000    0.000 elements.py:4062(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 type_api.py:269(result_processor)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3002(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 selectable.py:3663(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 attr.py:340(for_modify)\n",
       "        3    0.000    0.000    0.000    0.000 compiler.py:352(__str__)\n",
       "        1    0.000    0.000    0.000    0.000 compiler.py:3579(format_collation)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:2367(_warn_for_known_db_issues)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "def main():\n",
    "    '''\n",
    "        corpora: i2b2, mipacq, fv017\n",
    "        analyses: entity only (exact span), cui by document, full (aka (entity and cui on exaact span/exact cui)\n",
    "        systems: ctakes, biomedicus, clamp, metamap, quick_umls\n",
    "        \n",
    "        TODO -> Vectorization (entity only) -> done:\n",
    "                add switch for use of TN on single system performance evaluations -> done\n",
    "                add switch for overlap matching versus exact span -> done\n",
    "             -> Other tasks besides concept extraction\n",
    "        \n",
    "    ''' \n",
    "    analysisConf =  AnalysisConfig()\n",
    "    print(analysisConf.systems, analysisConf.corpus_config())\n",
    "    \n",
    "    if (rtype == 1):\n",
    "        print(semtypes, systems)\n",
    "        if filter_semtype:\n",
    "            for semtype in semtypes:\n",
    "                test = get_valid_systems(systems, semtype)\n",
    "                print('SYSYEMS FOR SEMTYPE', semtype, 'ARE', test)\n",
    "                generate_metrics(analysis_type, corpus, filter_semtype, semtype)\n",
    "            \n",
    "        else:\n",
    "            generate_metrics(analysis_type, corpus, filter_semtype)\n",
    "        \n",
    "    elif (rtype == 2):\n",
    "        print('run_type:', run_type)\n",
    "        # TODO -> list of corpora!\n",
    "#         for corpus in corpora: \n",
    "#             table_name = ref_data(corpus)\n",
    "#             system_annotation = sys_data(corpus)\n",
    "#             semtypes = ref_semtypes(filter_semtype, corpus)\n",
    "#             analysisConf =  AnalysisConfig()\n",
    "#             usys, ref = analysisConf.corpus_config(system_annotation, table_name)\n",
    "#             print('Using:', usys, ref)\n",
    "        if filter_semtype:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        else:\n",
    "            ensemble_control(analysisConf.systems, analysis_type, corpus, run_type, filter_semtype)\n",
    "    elif (rtype == 3):\n",
    "        t = ['concept_jaccard_score_false']\n",
    "        test_systems(analysis_type, analysisConf.systems, corpus)  \n",
    "        test_count(analysis_type, corpus)\n",
    "        test_ensemble(analysis_type, corpus)\n",
    "    elif (rtype == 4):\n",
    "        majority_vote(systems, analysis_type, corpus, run_type, filter_semtype, semtypes)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    %prun main()\n",
    "#    pass\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2019,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2019-7455995749e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref_system_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmajority_exact_vote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2019-7455995749e7>\u001b[0m in \u001b[0;36mmajority_exact_vote\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'note_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ref_ann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysis_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_semtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cooccurences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get matches, FN, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2014-7d334860507d>\u001b[0m in \u001b[0;36mget_ref_ann\u001b[0;34m(analysis_type, corpus, filter_semtype, semtype)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilter_semtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msemtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0msemtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msemtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "def majority_exact(systems, analysis_type, corpus, filter_semtype, semtype = None):\n",
    "   \n",
    "    cols_to_keep = ['begin', 'end', 'note_id', 'system']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for system in systems:\n",
    "        sys = get_sys_data(system, analysis_type, corpus, False)\n",
    "        sys = sys[sys['system'] == system][cols_to_keep].drop_duplicates()\n",
    "        \n",
    "        frames = [df, sys]\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def majority_exact_vote():\n",
    "    sys = majority_exact(systems, analysis_type, corpus, filter_semtype)\n",
    "    sys['span'] = list(zip(sys.begin, sys.end, sys.note_id.astype(str)))\n",
    "    sys['count'] = df.groupby(['span'])['span'].transform('count')\n",
    "\n",
    "    n = int(len(systems) / 2)\n",
    "    if ((len(systems) % 2) != 0):\n",
    "        sys = sys[sys['count'] > n]\n",
    "    else:\n",
    "        # https://stackoverflow.com/questions/23330654/update-a-dataframe-in-pandas-while-iterating-row-by-row\n",
    "        for i in sys.index:\n",
    "            if sys.at[i, 'count'] == n:\n",
    "                sys.at[i, 'count'] = random.choice([1,len(systems)])\n",
    "        sys = sys[sys['count'] > n]\n",
    "\n",
    "    sys = sys.drop_duplicates(subset=['span', 'begin', 'end', 'note_id'])\n",
    "    ref = get_ref_ann(analysis_type, corpus, filter_semtype)\n",
    "\n",
    "    c = get_cooccurences(ref, sys, analysis_type, corpus) # get matches, FN, etc.\n",
    "\n",
    "    if c.ref_system_match > 0: # compute confusion matrix metrics and write to dictionary -> df\n",
    "        # get dictionary of confusion matrix metrics\n",
    "        print(cm_dict(c.ref_only, c.system_only, c.ref_system_match, c.system_n, c.ref_n))\n",
    "\n",
    "majority_exact_vote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control filter_semtype in get_sys_data, get_ref_n and generate_metrics. TODO consolidate. \n",
    " \n",
    "# # run single ad hoc statement\n",
    "statement = '((ctakes&clamp)|(biomedicus&metamap)'\n",
    "analysis_type = 'entity'\n",
    "corpus = 'fairview'\n",
    "matches = get_merge_data(statement, analysis_type, corpus, False)\n",
    "# print(matches)\n",
    "\n",
    "# import spacy\n",
    "# nlp = spacy.load('en')\n",
    "\n",
    "# sql = \"select distinct note_id, sofa from concepts.sofas where corpus = 'fairview'\"\n",
    "\n",
    "# docs = pd.read_sql(sql, con=engine)\n",
    "\n",
    "# d = {}\n",
    "\n",
    "# for row in docs.itertuples():\n",
    "#     d[row.note_id] = row.sofa\n",
    "    \n",
    "# print(len(d))\n",
    "\n",
    "# test = matches[matches['note_id'] == '0000200926']\n",
    "# print(len(test))\n",
    "\n",
    "# doc = nlp(d['0000200926'])\n",
    "\n",
    "# for row in test.itertuples():\n",
    "#     my_str = [token.text.strip('\\n').lower() for token in doc if token.idx >= (row.begin) and token.idx <= (row.end)]\n",
    "#     if 'diabetes' in my_str:\n",
    "#         print(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TESTS -> ensemble:\n",
    "# def test_match_consistency(matches, ref_only, ref_n, sys):\n",
    "#     \"\"\"test for reference only/match set consistency:\n",
    "#         params: match, system and reference only sets\"\"\"\n",
    "   \n",
    "#     print('len', len(sys), len(matches), len(matches.union(sys)), len(matches.intersection(sys)))\n",
    "#     assert len(matches.union(ref_only)) == ref_n, 'Reference annotation mismatch union'\n",
    "#     assert len(matches.intersection(sys)) == len(matches), 'System annotation mismatch intersect'\n",
    "#     assert len(matches.union(sys)) == len(sys), 'System annotation mismatch union'\n",
    "#     assert len(matches.intersection(ref_only)) == 0, 'Reference annotation mismatch intersect'\n",
    "\n",
    "# def test_systems(analysis_type, systems, corpus):\n",
    "#     sys = df_to_set(get_sys_data(systems[0], analysis_type, corpus), analysis_type)\n",
    "#     test_match_consistency(*get_system_matches(systems[0], analysis_type, corpus), get_ref_n(analysis_type), sys)\n",
    "#     print('Match consistency:', len(sys),get_ref_n(analysis_type))\n",
    "\n",
    "# def test_metrics(ref, sys_m, match_m):\n",
    "#     test = True\n",
    "#     reference_n = len(ref)\n",
    "#     system_n = len(sys_m)\n",
    "\n",
    "#     print('Test metrics:', type(reference_n), type(system_n), type(match_m))\n",
    "\n",
    "#     reference_only, system_only, reference_system_match, match_set = SetTotals(reference_n, system_n, match_m).get_ref_sys()\n",
    "#     F, recall, precision, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics()\n",
    "#     F_, recall_, precision_, _, _, _, _, _ = Metrics(system_only, reference_only, reference_system_match, system_n).get_confusion_metrics(test)\n",
    "\n",
    "#     assert F[1] == F_, 'F1 issue'\n",
    "#     assert recall[1] == recall_, 'recall issue'\n",
    "#     assert precision[1] == precision_, 'precision issue'\n",
    "#     print(F[1], F_)\n",
    "#     print(recall[1], recall_)\n",
    "#     print(precision[1], precision_)\n",
    "\n",
    "# def test_count(analysis_type, corpus):\n",
    "#     # test match counts:\n",
    "#     ctakes, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     clamp, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "\n",
    "#     print('count:', len(mm.intersection(b9.intersection(clamp.intersection(ctakes)))))\n",
    "    \n",
    "# def test_ensemble(analysis_type, corpus):\n",
    "    \n",
    "#     print('ensemble:')\n",
    "#     # Get mixed system_n\n",
    "#     ref_ann, data = get_metric_data(analysis_type, corpus)\n",
    "\n",
    "#     names = ['ctakes', 'biomedicus', 'metamap', 'clamp']\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['begin', 'end', 'note_id']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['cui', 'note_id']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['begin', 'end', 'cui', 'note_id']\n",
    "\n",
    "#     biomedicus = data[data[\"system\"]=='biomedicus'][cols_to_keep].copy()\n",
    "#     ctakes = data[data[\"system\"]=='ctakes'][cols_to_keep].copy()\n",
    "#     clamp = data[data[\"system\"]=='clamp'][cols_to_keep].copy()\n",
    "#     metamap = data[data[\"system\"]=='metamap'][cols_to_keep].copy()\n",
    "#     quickumls = data[data[\"system\"]=='quick_umls'][cols_to_keep].copy()\n",
    "\n",
    "#     print('systems:', len(biomedicus), len(clamp), len(ctakes), len(metamap), len(quickumls))\n",
    "\n",
    "#     b9 = set()\n",
    "#     cl = set()\n",
    "#     ct = set()\n",
    "#     mm = set()\n",
    "#     qu = set()\n",
    "\n",
    "#     b9 = df_to_set(get_sys_data('biomedicus', analysis_type, corpus), analysis_type)\n",
    "#     print(len(b9))\n",
    "\n",
    "#     ct = df_to_set(get_sys_data('ctakes', analysis_type, corpus), analysis_type)\n",
    "#     print(len(ct))\n",
    "\n",
    "#     cl = df_to_set(get_sys_data('clamp', analysis_type, corpus), analysis_type)\n",
    "#     print(len(cl))\n",
    "\n",
    "#     mm = df_to_set(get_sys_data('metamap', analysis_type, corpus), analysis_type)\n",
    "#     print(len(mm))\n",
    "\n",
    "#     qu = df_to_set(get_sys_data('quick_umls', analysis_type, corpus), analysis_type)\n",
    "#     print(len(qu))\n",
    "    \n",
    "#     print('various merges:')\n",
    "#     print(len(b9), len(cl), len(ct), len(mm), len(qu))\n",
    "#     print(len(mm.intersection(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.intersection(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.intersection(ct)))))\n",
    "#     print(len(mm.union(b9.union(cl.union(ct)))))\n",
    "#     print(len(b9.intersection(ct)))\n",
    "\n",
    "#     sys_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('sys_m:', len(sys_m))\n",
    "\n",
    "#     # Get match merges:\n",
    "#     ct, _ = get_system_matches('ctakes', analysis_type, corpus)\n",
    "#     cl, _ = get_system_matches('clamp', analysis_type, corpus)\n",
    "#     b9, _ = get_system_matches('biomedicus', analysis_type, corpus)\n",
    "#     mm, _ = get_system_matches('metamap', analysis_type, corpus)\n",
    "#     qu, _ = get_system_matches('quick_umls', analysis_type, corpus)\n",
    "\n",
    "#     match_m = b9.intersection(ct.intersection(qu))\n",
    "#     print('match_m:', len(match_m))\n",
    "#     # reference df to set\n",
    "#     if 'entity' in analysis_type: \n",
    "#         cols_to_keep = ['end', 'start','file']\n",
    "#     elif 'cui' in analysis_type:\n",
    "#         cols_to_keep = ['value','file']\n",
    "#     elif 'full' in analysis_type:\n",
    "#         cols_to_keep = ['end', 'start', 'value','file']\n",
    "\n",
    "#     ref = df_to_set(ref_ann[cols_to_keep], analysis_type, 'ref')\n",
    "\n",
    "#     print('ref:', len(ref))\n",
    "\n",
    "#     # test difference:\n",
    "#     print('FP:', len(sys_m - match_m), len(sys_m - ref))\n",
    "#     assert len(sys_m - match_m) == len(sys_m - ref), 'FP mismatch'\n",
    "#     print('FN:', len(ref - match_m), len(ref - sys_m))\n",
    "#     assert len(ref - match_m) == len(ref - sys_m), 'FN mismatch'\n",
    "    \n",
    "#     test_metrics(ref, sys_m, match_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
