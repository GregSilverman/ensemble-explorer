{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "\n",
    "import re, os, glob, path\n",
    "#from cassis import *\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pymysql\n",
    "from sqlalchemy.engine import create_engine\n",
    "from typing import List, Set, Tuple \n",
    "engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_annotations(sem_type):    \n",
    "#     from sqlalchemy.sql import text\n",
    "    \n",
    "#     sql = \"select * from concepts.fv_iaa where name = \" + sem_type  \n",
    "#     #ref_ann = pd.read_sql(sql, params={\"training_notes\":training_notes}, con=engine)\n",
    "\n",
    "#     annotations = pd.read_sql(sql, con=engine)\n",
    "#     annotations['label'] = 'concept'\n",
    "\n",
    "#     files = []\n",
    "#     cases = set()\n",
    "#     analyze = set()\n",
    "#     for row in annotations.itertuples():\n",
    "#         cases.add(row.case)\n",
    "#         if (row.case, row.annotator) not in files:\n",
    "#             files.append((row.case, row.annotator))\n",
    "\n",
    "#     from collections import Counter\n",
    "\n",
    "#     # id where all 3 annotators marked up case\n",
    "#     counts = Counter(x[0] for x in files)\n",
    "#     for c in cases:\n",
    "#         #print(c, counts[c])\n",
    "#         if counts[c] > 2:\n",
    "#             #print(c, counts[c])\n",
    "#             analyze.add(c)\n",
    "\n",
    "#     analyze.remove('0000327956') # wrong patient for George, see 0001908516\n",
    "#     analyze.remove('0000513005') # char offset due to space at beginning for Angel\n",
    "\n",
    "\n",
    "#     rm = ['0000202738',\n",
    "#     #'0000327956',\n",
    "#     '0000469349',\n",
    "#     #'0000473442',\n",
    "#     #'0000513005',\n",
    "#     '0001053477',\n",
    "#     '0001112285',\n",
    "#     '0001157129',\n",
    "#     '0001908516',\n",
    "#     '0002340241']#,\n",
    "#     #'0002518956']#,\n",
    "#     #'0002634827']\n",
    "\n",
    "#     rm = set(rm)\n",
    "\n",
    "#     for r in rm:\n",
    "#         analyze.remove(r)\n",
    "\n",
    "#     df = annotations[annotations['case'].isin(analyze)].copy()\n",
    "\n",
    "#     #print(len(df))\n",
    "    \n",
    "#     return df, analyze\n",
    "    \n",
    "# #df, analyze = get_annotations(\"'Finding'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(analyze, df):    \n",
    "    docs = [(x, len(open(\"/Users/gms/development/nlp/nlpie/data/ensembling-u01/fairview/iaa/overlaps/\" + x + \".txt\", 'r').read())) for x in analyze]\n",
    "    labels = ['concept']\n",
    "\n",
    "    jen = df[df['annotator'] == 'Jen'].copy()\n",
    "    george = df[df['annotator'] == 'George'].copy()\n",
    "    angel = df[df['annotator'] == 'Angel'].copy()\n",
    "\n",
    "    #print(jen)\n",
    "\n",
    "    print(analyze)\n",
    "    \n",
    "    return jen, george, angel\n",
    "\n",
    "#jen, george, angel = get_data(analyze, df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def label_vector(doc: int, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    #print(ann, doc, labels)\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.start, a.end) for a in ann if a.label == lab]\n",
    "        #print(len(idxs))\n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kappa(ann1, ann2):\n",
    "    # calculating p_o\n",
    "    bio_ann1_flat = np.array(flatten_list(ann1))\n",
    "    bio_ann2_flat = np.array(flatten_list(ann2))\n",
    "        \n",
    "    comp = (bio_ann1_flat == bio_ann2_flat).tolist()\n",
    "    #print(comp)\n",
    "    po = comp.count(True)/len(comp)\n",
    "    \n",
    "    print(\"Observed agreement:\")\n",
    "    print(po)\n",
    "    \n",
    "    #calculating p_e\n",
    "    uniq_elements = np.unique(bio_ann1_flat)\n",
    "    uniq = uniq_elements.size\n",
    "    #print(uniq)\n",
    "    #print(np.unique(bio_ann1_flat))\n",
    "    \n",
    "    bio_ann1_ls = bio_ann1_flat.tolist()\n",
    "    bio_ann2_ls = bio_ann2_flat.tolist()\n",
    "    \n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    \n",
    "    for k in range(uniq):\n",
    "        y1.append(bio_ann1_ls.count(uniq_elements[k]))\n",
    "        y2.append(bio_ann2_ls.count(uniq_elements[k]))\n",
    "    \n",
    "    y3 = [s*t for s,t in zip(y1,y2)]\n",
    "    \n",
    "    pe = sum(y3)/(len(bio_ann1_ls)**2)\n",
    "    \n",
    "    print(\"Expected agreement:\")\n",
    "    print(pe)\n",
    "    \n",
    "    # calculating kappa\n",
    "    kappa = (po-pe)/(1-pe)\n",
    "    \n",
    "    print(\"Cohen's kappa agreement:\")\n",
    "    print(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kappa(jen, george, angel):\n",
    "    ann1 = []\n",
    "    ann2 = []\n",
    "    ann3 = []\n",
    "\n",
    "    cols_to_keep = ['start', 'end', 'case', 'label']\n",
    "    jen = jen[cols_to_keep]\n",
    "    george = george[cols_to_keep]\n",
    "    angel = angel[cols_to_keep]\n",
    "\n",
    "    for n in range(0, len(docs)):\n",
    "        g = [i for i in george[george[\"case\"] == docs[n][0]].copy().itertuples(index=False)]\n",
    "        j = [i for i in jen[jen[\"case\"] == docs[n][0]].copy().itertuples(index=False)]\n",
    "        a = [i for i in angel[angel[\"case\"] == docs[n][0]].copy().itertuples(index=False)]\n",
    "\n",
    "        #print(n, len(j), len(g), docs[n][1], docs[n][0])\n",
    "\n",
    "        ann1.append(label_vector(docs[n][1], j, labels))\n",
    "        #print(len(j), len(g), docs[n][1])\n",
    "        ann2.append(label_vector(docs[n][1], g, labels))\n",
    "        ann3.append(label_vector(docs[n][1], a, labels))\n",
    "\n",
    "\n",
    "    print('Jen and George')\n",
    "    get_kappa(ann1, ann2)\n",
    "    print('--------->')\n",
    "    print('Jen and Angel')\n",
    "    get_kappa(ann1, ann3)\n",
    "    print('--------->')\n",
    "    print('Angel and George')\n",
    "    get_kappa(ann3, ann2)\n",
    "\n",
    "#print_kappa(jen, george, angel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for below \n",
    "\n",
    "    \n",
    "# apply enumerated labels to annotator vector, character-by-character\n",
    "# def label_vector(doc: str, ann, labels) -> np.array:\n",
    "\n",
    "#     #print(ann, doc, labels)\n",
    "#     v = np.zeros(len(doc))\n",
    "\n",
    "#     for (i, lab) in enumerate(labels):\n",
    "#         i += 1  # 0 is reserved for no label, aka 'O'\n",
    "#         idxs = [np.arange(a.start, a.end) for a in ann if a.label == lab]\n",
    "#         idxs = [j for mask in idxs for j in mask]\n",
    "#         v[idxs] = i\n",
    "\n",
    "#     print(list(v))\n",
    "#     return list(v)\n",
    "\n",
    "# # extract attributes from cas Annotation object\n",
    "# def get_ann(fname, dir_test, view_name, t, Span): # return list of annotations and document as string\n",
    "\n",
    "#         with open(dir_test + 'TypeSystem.xml', 'rb') as f:\n",
    "#             typesystem = load_typesystem(f)\n",
    "#         with open(dir_test + fname, 'rb') as f:\n",
    "#             cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "\n",
    "#         view = cas.get_view(view_name)\n",
    "\n",
    "#         d = {}\n",
    "#         ann = []\n",
    "#         labels = set()\n",
    "#         attribs = get_attribs(view.select(t))\n",
    "#         # only parse if type exists in file\n",
    "#         if view.select(t):\n",
    "#             for sentence in view.select(t): \n",
    "#                 for i in range(len(attribs)):\n",
    "#                     key = attribs[i]\n",
    "#                     # helper method to get val for given key\n",
    "#                     val = sentence.__getattribute__(attribs[i])\n",
    "#                     d[key] = val \n",
    "\n",
    "#                     if i == len(attribs) - 1:\n",
    "#                         ann.append( Span(d[\"begin\"], d[\"end\"], d[\"termType\"]))\n",
    "\n",
    "#         return ann, view.sofa_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(sem_type):\n",
    "    sql = \"\"\"select distinct semtypes, concept, annotator, `case` from concepts.fv_all_annotators where annotator in('Jen', 'Angel') and `case` in \n",
    "    ('0000089745',\n",
    "    '0000202738',\n",
    "    '0000220714',\n",
    "    '0000234695',\n",
    "    '0000258427',\n",
    "    '0000327956',\n",
    "    '0000469349',\n",
    "    '0000473442',\n",
    "    -- '0000513005',\n",
    "    '0001053477',\n",
    "    -- '0001112285',\n",
    "    -- '0001157129',\n",
    "    -- '0001908516',\n",
    "    '0002340241',\n",
    "    '0007340048') and concept is not null and semtypes = %(sem_type)s;\"\"\"  \n",
    "    \n",
    "    #ref_ann = pd.read_sql(sql, params={\"training_notes\":training_notes}, con=engine)\n",
    "\n",
    "    return pd.read_sql(sql, params={\"sem_type\":sem_type}, con=engine)\n",
    "\n",
    "    #annotations = annotations[annotations['semtypes'] != 'Finding']\n",
    "                                           \n",
    "sem_types = ['Acronym', 'Anatomy']\n",
    "\n",
    "for sem_type in sem_types:\n",
    "    #print(get_annotations(sem_type))\n",
    "    annotations = get_annotations(sem_type)\n",
    "                                           \n",
    "#print(annotations)\n",
    "\n",
    "#bag_of_concepts['Agree'] = None\n",
    "#bag_of_concepts['Disagree'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def longestSubstring(str1,str2): \n",
    "  \n",
    "    # initialize SequenceMatcher object with  \n",
    "    # input string \n",
    "    seqMatch = SequenceMatcher(None,str1,str2) \n",
    "\n",
    "    # find match of longest sub-string \n",
    "    # output will be like Match(a=0, b=0, size=5) \n",
    "    match = seqMatch.find_longest_match(0, len(str1), 0, len(str2)) \n",
    "\n",
    "    # print longest substring \n",
    "    if (match.size!=0): \n",
    "        #print (str1[match.a: match.a + match.size])  \n",
    "        return str1[match.a: match.a + match.size]\n",
    "    else: \n",
    "        #print ('No longest common sub-string found')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4401 4508\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ann_df(annotations):    \n",
    "    jen = annotations[annotations['annotator'] == 'Jen'].copy()\n",
    "    angel  = annotations[annotations['annotator'] == 'Angel'].copy()\n",
    "    print(len(jen), len(angel))\n",
    "\n",
    "    cases = ('0000089745',\n",
    "    '0000202738',\n",
    "    '0000220714',\n",
    "    '0000234695',\n",
    "    '0000258427',\n",
    "    '0000327956',\n",
    "    '0000469349',\n",
    "    '0000473442',\n",
    "    # '0000513005',\n",
    "    '0001053477',\n",
    "    # '0001112285',\n",
    "    # '0001157129',\n",
    "    # '0001908516',\n",
    "    '0002340241',\n",
    "    '0007340048')\n",
    "\n",
    "    # cases = ['0000089745',\n",
    "    # '0000202738',\n",
    "    # '0000220714',\n",
    "    # # '0000234695',\n",
    "    # '0000258427',\n",
    "    # '0000327956',\n",
    "    # '0000469349',\n",
    "    # # '0000473442',\n",
    "    # # '0000513005',\n",
    "    # '0001053477',\n",
    "    # # '0001112285',\n",
    "    # # '0001157129',\n",
    "    # # '0001908516',\n",
    "    # # '0002340241',\n",
    "    # '0007340048']\n",
    "    \n",
    "    return cases, jen, angel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3082 757 562 4401\n"
     ]
    }
   ],
   "source": [
    "def get_ann1(cases, jen)    \n",
    "    i = 0\n",
    "    k = 0\n",
    "    l = 0\n",
    "    df = pd.DataFrame()\n",
    "    d = dict()\n",
    "    for case in cases:\n",
    "        j = jen[jen['case'] == case]\n",
    "        a = angel[angel['case'] == case]\n",
    "        for jrow in j.itertuples():\n",
    "            match = False\n",
    "            for arow in a.itertuples():\n",
    "                if jrow.semtypes == arow.semtypes and jrow.concept == arow.concept:\n",
    "                    #print(jrow, arow)\n",
    "                    d['semtype'] = jrow.semtypes\n",
    "                    d['concept'] = jrow.concept\n",
    "                    d['common'] = 'yes'\n",
    "                    i +=1\n",
    "                    match = True\n",
    "                    break\n",
    "                elif jrow.semtypes == arow.semtypes and longestSubstring(jrow.concept,arow.concept):\n",
    "                    if len(longestSubstring(jrow.concept,arow.concept)) >= 12:\n",
    "                        #print(arow, jrow)\n",
    "                        k += 1\n",
    "                        d['semtype'] = jrow.semtypes\n",
    "                        d['concept'] = longestSubstring(jrow.concept,arow.concept) #jrow.concept\n",
    "                        d['common'] = 'yes'\n",
    "                        match = True\n",
    "                        break\n",
    "\n",
    "            if not match:\n",
    "                    d['semtype'] = jrow.semtypes\n",
    "                    d['concept'] = jrow.concept\n",
    "                    d['common'] = 'no'\n",
    "                    l += 1\n",
    "\n",
    "            d['annotator'] = 'Jen'\n",
    "            d['case'] = case\n",
    "\n",
    "                #print(d)\n",
    "\n",
    "            temp = pd.DataFrame(d, index=[0])\n",
    "            frames = [ df, temp ]\n",
    "\n",
    "            df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    print(i, k, l, sum([i, k, l]))   \n",
    "    #print(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3163 622 723 4508\n",
      "8909\n"
     ]
    }
   ],
   "source": [
    "def get_ann2(df, cases, jen, angel):\n",
    "    i = 0\n",
    "    k = 0\n",
    "    l = 0\n",
    "    d = dict()\n",
    "    for case in cases:\n",
    "        j = jen[jen['case'] == case]\n",
    "        a = angel[angel['case'] == case]\n",
    "        for arow in a.itertuples():\n",
    "            match = False\n",
    "            for jrow in j.itertuples():\n",
    "                if jrow.semtypes == arow.semtypes and jrow.concept == arow.concept:\n",
    "                    #print(jrow, arow)\n",
    "                    d['semtype'] = arow.semtypes\n",
    "                    d['concept'] = arow.concept\n",
    "                    d['common'] = 'yes'\n",
    "                    i +=1\n",
    "                    match = True\n",
    "                    break\n",
    "                elif arow.semtypes == 'Finding' and jrow.semtypes == arow.semtypes and longestSubstring(jrow.concept,arow.concept):\n",
    "                    if len(longestSubstring(jrow.concept,arow.concept)) >= 12:\n",
    "                        #print(arow, jrow)\n",
    "                        k += 1\n",
    "                        d['semtype'] = arow.semtypes\n",
    "                        d['concept'] = longestSubstring(jrow.concept,arow.concept) #arow.concept\n",
    "                        d['common'] = 'yes'\n",
    "                        match = True\n",
    "                        break\n",
    "\n",
    "            if not match:\n",
    "                    d['semtype'] = arow.semtypes\n",
    "                    d['concept'] = arow.concept\n",
    "                    d['common'] = 'no'\n",
    "                    l += 1\n",
    "\n",
    "            d['annotator'] = 'Angel'\n",
    "            d['case'] = case\n",
    "\n",
    "                #print(d)\n",
    "\n",
    "            temp = pd.DataFrame(d, index=[0])\n",
    "            frames = [ df, temp ]\n",
    "\n",
    "            df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    print(i, k, l, sum([i, k, l]))   \n",
    "    print(len(df))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3839 3785 562 723\n"
     ]
    }
   ],
   "source": [
    "def get_concordances(df)    \n",
    "    jen_agree = df[(df['annotator'] == 'Jen') & (df['common'] == 'yes')].copy()\n",
    "    angel_agree = df[(df['annotator'] == 'Angel') & (df['common'] == 'yes')].copy()\n",
    "\n",
    "    jen_disagree = df[(df['annotator'] == 'Jen') & (df['common'] == 'no')].copy()\n",
    "    angel_disagree = df[(df['annotator'] == 'Angel') & (df['common'] == 'no')].copy()\n",
    "\n",
    "    print(len(jen_agree), len(angel_agree), len(jen_disagree), len(angel_disagree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3783\n",
      "1285\n",
      "5049\n"
     ]
    }
   ],
   "source": [
    "agree_all =  jen_agree.append(angel_agree)\n",
    "print(len(agree_all.drop_duplicates(subset=['concept', 'semtype', 'case'], keep='first')))\n",
    "#print(agree_all.drop_duplicates(subset=['concept', 'semtype', 'case'], keep='first'))\n",
    "\n",
    "disagree_all =  jen_disagree.append(angel_disagree)\n",
    "print(len(disagree_all))\n",
    "\n",
    "bag_of_concepts = df.drop_duplicates(subset=['concept', 'semtype', 'case']).copy()\n",
    "print(len(bag_of_concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agree 3783\n",
      "disagree 1266\n",
      "5049\n"
     ]
    }
   ],
   "source": [
    "agree_mask = (bag_of_concepts.common == 'yes')\n",
    "disagree_mask = (bag_of_concepts.common == 'no')\n",
    "bag_of_concepts['agree'] = None\n",
    "bag_of_concepts['agree'][agree_mask] = 1\n",
    "bag_of_concepts['disagree'] = None\n",
    "bag_of_concepts['disagree'][disagree_mask] = 1\n",
    "\n",
    "print('agree', len(bag_of_concepts[(bag_of_concepts['agree'] == 1)]))\n",
    "\n",
    "print('disagree', len(bag_of_concepts[(bag_of_concepts['disagree'] == 1)]))\n",
    "\n",
    "print(len(bag_of_concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7492572786690433\n",
      "0.020730726776187147\n",
      "0.7439491586359116\n"
     ]
    }
   ],
   "source": [
    "agree =  len(bag_of_concepts[(bag_of_concepts['agree'] == 1)])\n",
    "disagree = len(bag_of_concepts[(bag_of_concepts['disagree'] == 1)])\n",
    "n = len(bag_of_concepts)\n",
    "\n",
    "po = agree/n\n",
    "\n",
    "print(po)\n",
    "\n",
    "# ay1 = len(jen_agree)\n",
    "# ay2 = len(angel_agree)\n",
    "ay1 = len(j)\n",
    "ay2 = len(a)\n",
    "an1 = len(jen_disagree)\n",
    "an2 = len(angel_disagree)\n",
    "\n",
    "p_yes = (ay1/n) * (ay2/n)\n",
    "p_no = (an1/n) * (an2/n)\n",
    "\n",
    "pe = p_yes + p_no\n",
    "\n",
    "print(pe)\n",
    "\n",
    "k = (po - pe) / (1 - pe)\n",
    "\n",
    "print(k)\n",
    "\n",
    "#bag_of_concepts.to_csv(\"~/Desktop/data.csv\")\n",
    "bag_of_concepts[bag_of_concepts['disagree'] == 1].to_csv(\"~/Desktop/dis.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
