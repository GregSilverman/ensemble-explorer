{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "\n",
    "import re, os, glob, path\n",
    "#from cassis import *\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pymysql\n",
    "from sqlalchemy.engine import create_engine\n",
    "from typing import List, Set, Tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(sem_type):    \n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)\n",
    "    from sqlalchemy.sql import text\n",
    "    \n",
    "    sql = \"select * from concepts.fv_iaa where name = \" + sem_type  \n",
    "    #ref_ann = pd.read_sql(sql, params={\"training_notes\":training_notes}, con=engine)\n",
    "\n",
    "    annotations = pd.read_sql(sql, con=engine)\n",
    "    annotations['label'] = 'concept'\n",
    "\n",
    "    files = []\n",
    "    cases = set()\n",
    "    analyze = set()\n",
    "    for row in annotations.itertuples():\n",
    "        cases.add(row.case)\n",
    "        if (row.case, row.annotator) not in files:\n",
    "            files.append((row.case, row.annotator))\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    # id where all 3 annotators marked up case\n",
    "    counts = Counter(x[0] for x in files)\n",
    "    for c in cases:\n",
    "        #print(c, counts[c])\n",
    "        if counts[c] > 2:\n",
    "            #print(c, counts[c])\n",
    "            analyze.add(c)\n",
    "\n",
    "    analyze.remove('0000327956') # wrong patient for George, see 0001908516\n",
    "    analyze.remove('0000513005') # char offset due to space at beginning for Angel\n",
    "\n",
    "\n",
    "    rm = ['0000202738',\n",
    "    #'0000327956',\n",
    "    '0000469349',\n",
    "    #'0000473442',\n",
    "    #'0000513005',\n",
    "    '0001053477',\n",
    "    '0001112285',\n",
    "    '0001157129',\n",
    "    '0001908516',\n",
    "    '0002340241']#,\n",
    "    #'0002518956']#,\n",
    "    #'0002634827']\n",
    "\n",
    "    rm = set(rm)\n",
    "\n",
    "    for r in rm:\n",
    "        analyze.remove(r)\n",
    "\n",
    "    df = annotations[annotations['case'].isin(analyze)].copy()\n",
    "\n",
    "    #print(len(df))\n",
    "    \n",
    "    return df, analyze\n",
    "    \n",
    "df, analyze = get_annotations(\"'Finding'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0007340048', '0000089745', '0000234695', '0000220714', '0000473442', '0000258427'}\n"
     ]
    }
   ],
   "source": [
    "def get_data(analyze, df):    \n",
    "    docs = [(x, len(open(\"/Users/gms/development/nlp/nlpie/data/ensembling-u01/fairview/iaa/overlaps/\" + x + \".txt\", 'r').read())) for x in analyze]\n",
    "    labels = ['concept']\n",
    "\n",
    "    jen = df[df['annotator'] == 'Jen'].copy()\n",
    "    george = df[df['annotator'] == 'George'].copy()\n",
    "    angel = df[df['annotator'] == 'Angel'].copy()\n",
    "\n",
    "    #print(jen)\n",
    "\n",
    "    print(analyze)\n",
    "    \n",
    "    return jen, george, angel\n",
    "\n",
    "jen, george, angel = get_data(analyze, df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def label_vector(doc: int, ann: List[int], labels: List[str]) -> np.array:\n",
    "\n",
    "    #print(ann, doc, labels)\n",
    "\n",
    "    v = np.zeros(doc)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    for (i, lab) in enumerate(labels):\n",
    "        i += 1  # 0 is reserved for no label\n",
    "        idxs = [np.arange(a.start, a.end) for a in ann if a.label == lab]\n",
    "        #print(len(idxs))\n",
    "        idxs = [j for mask in idxs for j in mask]\n",
    "        v[idxs] = i\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kappa(ann1, ann2):\n",
    "    # calculating p_o\n",
    "    bio_ann1_flat = np.array(flatten_list(ann1))\n",
    "    bio_ann2_flat = np.array(flatten_list(ann2))\n",
    "        \n",
    "    comp = (bio_ann1_flat == bio_ann2_flat).tolist()\n",
    "    #print(comp)\n",
    "    po = comp.count(True)/len(comp)\n",
    "    \n",
    "    print(\"Observed agreement:\")\n",
    "    print(po)\n",
    "    \n",
    "    #calculating p_e\n",
    "    uniq_elements = np.unique(bio_ann1_flat)\n",
    "    uniq = uniq_elements.size\n",
    "    #print(uniq)\n",
    "    #print(np.unique(bio_ann1_flat))\n",
    "    \n",
    "    bio_ann1_ls = bio_ann1_flat.tolist()\n",
    "    bio_ann2_ls = bio_ann2_flat.tolist()\n",
    "    \n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    \n",
    "    for k in range(uniq):\n",
    "        y1.append(bio_ann1_ls.count(uniq_elements[k]))\n",
    "        y2.append(bio_ann2_ls.count(uniq_elements[k]))\n",
    "    \n",
    "    y3 = [s*t for s,t in zip(y1,y2)]\n",
    "    \n",
    "    pe = sum(y3)/(len(bio_ann1_ls)**2)\n",
    "    \n",
    "    print(\"Expected agreement:\")\n",
    "    print(pe)\n",
    "    \n",
    "    # calculating kappa\n",
    "    kappa = (po-pe)/(1-pe)\n",
    "    \n",
    "    print(\"Cohen's kappa agreement:\")\n",
    "    print(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jen and George\n",
      "Observed agreement:\n",
      "0.9660825456206985\n",
      "Expected agreement:\n",
      "0.9521479396427107\n",
      "Cohen's kappa agreement:\n",
      "0.2912017972464406\n",
      "--------->\n",
      "Jen and Angel\n",
      "Observed agreement:\n",
      "0.9766827540908701\n",
      "Expected agreement:\n",
      "0.9657371503616597\n",
      "Cohen's kappa agreement:\n",
      "0.3194598185716057\n",
      "--------->\n",
      "Angel and George\n",
      "Observed agreement:\n",
      "0.9754387154810521\n",
      "Expected agreement:\n",
      "0.964759129241481\n",
      "Cohen's kappa agreement:\n",
      "0.30304546992470266\n"
     ]
    }
   ],
   "source": [
    "def print_kappa(jen, george, angel):\n",
    "    ann1 = []\n",
    "    ann2 = []\n",
    "    ann3 = []\n",
    "\n",
    "    cols_to_keep = ['start', 'end', 'case', 'label']\n",
    "    jen = jen[cols_to_keep]\n",
    "    george = george[cols_to_keep]\n",
    "    angel = angel[cols_to_keep]\n",
    "\n",
    "    for n in range(0, len(docs)):\n",
    "        g = [i for i in george[george[\"case\"] == docs[n][0]].copy().itertuples(index=False)]\n",
    "        j = [i for i in jen[jen[\"case\"] == docs[n][0]].copy().itertuples(index=False)]\n",
    "        a = [i for i in angel[angel[\"case\"] == docs[n][0]].copy().itertuples(index=False)]\n",
    "\n",
    "        #print(n, len(j), len(g), docs[n][1], docs[n][0])\n",
    "\n",
    "        ann1.append(label_vector(docs[n][1], j, labels))\n",
    "        #print(len(j), len(g), docs[n][1])\n",
    "        ann2.append(label_vector(docs[n][1], g, labels))\n",
    "        ann3.append(label_vector(docs[n][1], a, labels))\n",
    "\n",
    "\n",
    "    print('Jen and George')\n",
    "    get_kappa(ann1, ann2)\n",
    "    print('--------->')\n",
    "    print('Jen and Angel')\n",
    "    get_kappa(ann1, ann3)\n",
    "    print('--------->')\n",
    "    print('Angel and George')\n",
    "    get_kappa(ann3, ann2)\n",
    "\n",
    "print_kappa(jen, george, angel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for below \n",
    "\n",
    "    \n",
    "# apply enumerated labels to annotator vector, character-by-character\n",
    "# def label_vector(doc: str, ann, labels) -> np.array:\n",
    "\n",
    "#     #print(ann, doc, labels)\n",
    "#     v = np.zeros(len(doc))\n",
    "\n",
    "#     for (i, lab) in enumerate(labels):\n",
    "#         i += 1  # 0 is reserved for no label, aka 'O'\n",
    "#         idxs = [np.arange(a.start, a.end) for a in ann if a.label == lab]\n",
    "#         idxs = [j for mask in idxs for j in mask]\n",
    "#         v[idxs] = i\n",
    "\n",
    "#     print(list(v))\n",
    "#     return list(v)\n",
    "\n",
    "# # extract attributes from cas Annotation object\n",
    "# def get_ann(fname, dir_test, view_name, t, Span): # return list of annotations and document as string\n",
    "\n",
    "#         with open(dir_test + 'TypeSystem.xml', 'rb') as f:\n",
    "#             typesystem = load_typesystem(f)\n",
    "#         with open(dir_test + fname, 'rb') as f:\n",
    "#             cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "\n",
    "#         view = cas.get_view(view_name)\n",
    "\n",
    "#         d = {}\n",
    "#         ann = []\n",
    "#         labels = set()\n",
    "#         attribs = get_attribs(view.select(t))\n",
    "#         # only parse if type exists in file\n",
    "#         if view.select(t):\n",
    "#             for sentence in view.select(t): \n",
    "#                 for i in range(len(attribs)):\n",
    "#                     key = attribs[i]\n",
    "#                     # helper method to get val for given key\n",
    "#                     val = sentence.__getattribute__(attribs[i])\n",
    "#                     d[key] = val \n",
    "\n",
    "#                     if i == len(attribs) - 1:\n",
    "#                         ann.append( Span(d[\"begin\"], d[\"end\"], d[\"termType\"]))\n",
    "\n",
    "#         return ann, view.sofa_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
