{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import re, os, glob, path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pymysql\n",
    "from sqlalchemy.engine import create_engine\n",
    "from typing import List, Set, Tuple \n",
    "engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(sem_type, case):\n",
    "    sql = \"\"\"select distinct semtypes, concept, annotator, start, end, `case` from concepts.fv_all_annotators where annotator in('Jen', 'Angel') and `case` in \n",
    "    ('0000089745',\n",
    "    -- '0000202738',\n",
    "    -- '0000220714',\n",
    "    -- '0000234695',\n",
    "    -- '0000258427',\n",
    "    -- '0000327956',\n",
    "    -- '0000469349',\n",
    "    -- '0000473442',\n",
    "    -- '0000513005',\n",
    "    -- '0001053477',\n",
    "    -- '0001112285',\n",
    "    -- '0001157129',\n",
    "    -- '0001908516',\n",
    "    -- '0002340241',\n",
    "    -- '0007340048') and concept is not null and semtypes = %(sem_type)s;\"\"\"  \n",
    "    \n",
    "    #ref_ann = pd.read_sql(sql, params={\"training_notes\":training_notes}, con=engine)\n",
    "\n",
    "    if sem_type != 'ALL':\n",
    "        return pd.read_sql(sql, params={\"sem_type\":sem_type}, con=engine)\n",
    "    else:\n",
    "#         sql = \"\"\"select distinct semtypes, concept, annotator, start, end, `case` from concepts.fv_all_annotators where annotator in('Jen', 'Angel') and `case` in \n",
    "#          ('0000202738') and concept is not null and semtypes in ('Acronym', 'Anatomy', 'Drug', 'Finding', 'Procedure') and `case` = %(case)s;\"\"\"\n",
    "        sql = \"\"\"select distinct semtypes, concept, annotator, start, end, `case` from concepts.fv_all_annotators where annotator in('Jen', 'Angel') and concept is not null and semtypes in ('Acronym', 'Anatomy', 'Drug', 'Finding', 'Procedure') and `case` = %(case)s;\"\"\"\n",
    "#      '0000202738',\n",
    "#      '0000220714',\n",
    "#      '0000234695',\n",
    "#      '0000258427',\n",
    "#      '0000327956',\n",
    "#      '0000469349',\n",
    "#      '0000473442',\n",
    "#      '0000513005',\n",
    "#      '0001053477',\n",
    "#      '0001112285',\n",
    "#      '0001157129',\n",
    "#      '0001908516',\n",
    "#      '0002340241',\n",
    "#      '0007340048') and concept is not null;\"\"\"   \n",
    "        \n",
    "        return pd.read_sql(sql, params={\"case\":case}, con=engine)\n",
    "\n",
    "    #annotations = annotations[annotations['semtypes'] != 'Finding']\n",
    "                                           \n",
    "# sem_types = ['ALL']\n",
    "\n",
    "# for sem_type in sem_types:\n",
    "#     #print(get_annotations(sem_type))\n",
    "#     annotations = get_annotations(sem_type)\n",
    "#     print(annotations.head())\n",
    "                                           \n",
    "#print(annotations)\n",
    "\n",
    "#bag_of_concepts['Agree'] = None\n",
    "#bag_of_concepts['Disagree'] = None\n",
    "\n",
    "#print(len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longestSubstring(str1,str2): \n",
    "  \n",
    "    # initialize SequenceMatcher object with  \n",
    "    # input string \n",
    "    seqMatch = SequenceMatcher(None,str1,str2) \n",
    "\n",
    "    # find match of longest sub-string \n",
    "    # output will be like Match(a=0, b=0, size=5) \n",
    "    match = seqMatch.find_longest_match(0, len(str1), 0, len(str2)) \n",
    "\n",
    "    # print longest substring \n",
    "    if (match.size!=0): \n",
    "        #print (str1[match.a: match.a + match.size])  \n",
    "        return str1[match.a: match.a + match.size]\n",
    "    else: \n",
    "        #print ('No longest common sub-string found')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases():    \n",
    "    #jen = annotations[annotations['annotator'] == 'Jen'].copy()\n",
    "    #angel  = annotations[annotations['annotator'] == 'Angel'].copy()\n",
    "    #print(len(jen), len(angel))\n",
    "\n",
    "    cases = ('0000089745',\n",
    "    '0000202738',\n",
    "    '0000220714',\n",
    "    '0000234695',\n",
    "    '0000258427',\n",
    "    '0000327956',\n",
    "    '0000469349',\n",
    "    '0000473442',\n",
    "    '0000513005',\n",
    "    '0001053477',\n",
    "    '0001112285',\n",
    "    '0001157129',\n",
    "    '0001908516',\n",
    "    '0002340241',\n",
    "    '0007340048')\n",
    "    \n",
    "    #cases = ['0000202738']\n",
    "\n",
    "    # cases = ['0000089745',\n",
    "    # '0000202738',\n",
    "    # '0000220714',\n",
    "    # # '0000234695',\n",
    "    # '0000258427',\n",
    "    # '0000327956',\n",
    "    # '0000469349',\n",
    "    # # '0000473442',\n",
    "    # # '0000513005',\n",
    "    # '0001053477',\n",
    "    # # '0001112285',\n",
    "    # # '0001157129',\n",
    "    # # '0001908516',\n",
    "    # # '0002340241',\n",
    "    # '0007340048']\n",
    "    \n",
    "    return cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the analytical data set\n",
    "\n",
    "def f(x):    \n",
    "    return longestSubstring(x[0], x[1]) # x[0] + x[1] \n",
    "\n",
    "def get_analytical(annotations, case):\n",
    "    # get annotations by each annotator and comoute span length for each\n",
    "    \n",
    "    annotations = annotations[annotations['case'] == case]\n",
    "    jen = annotations[annotations['annotator'] == 'Jen'].copy()\n",
    "    jen['span_length'] = (jen.end - jen.start).abs()\n",
    "    angel = annotations[annotations['annotator'] == 'Angel'].copy()\n",
    "    angel['span_length'] = (angel.end - angel.start).abs()\n",
    "\n",
    "    #print(' j a:', len(jen), len(angel))\n",
    "\n",
    "    # most wide merge adding in difference between start of span in merge; lenght of span using jen's as reference and concept length of substrings in merge\n",
    "    merge_ann = jen.merge(angel, on=['semtypes', 'case'], how='inner')\n",
    "    merge_ann['sdiff'] = (merge_ann.start_x - merge_ann.start_y).abs()\n",
    "    merge_ann['span_length'] = (merge_ann.end_x - merge_ann.start_x).abs()\n",
    "    merge_ann['cdiff'] = merge_ann[['concept_x','concept_y']].apply(f, axis=1) #longestSubstring(merge_ann['concept_x'],merge_ann['concept_y'])\n",
    "\n",
    "    # filter out nulls\n",
    "    merge_ann = merge_ann[merge_ann['cdiff'].notna()]\n",
    "\n",
    "    # get length of substring match\n",
    "    merge_ann['lcdiff'] = merge_ann['cdiff'].apply(len) #longestSubstring(merge_ann['concept_x'],merge_ann['concept_y'])\n",
    "\n",
    "    # fudge factors on span difference due to GATE weirdness, and spaCy tokenized offsetlookup\n",
    "    test_ann = merge_ann[(merge_ann['sdiff'] <= 120) & ((merge_ann.concept_x == merge_ann.concept_y) | \n",
    "                                                        (merge_ann.lcdiff >= 10))].copy()\n",
    "    \n",
    "    \n",
    "    return test_ann, jen, angel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of text doc for case\n",
    "def get_doc(case):    \n",
    "    doc = (case, len(open(\"/Users/gms/development/nlp/nlpie/data/ensembling-u01/fairview/iaa/overlaps/\" + case + \".txt\", 'r').read()))\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_ann(jen, angel):\n",
    "    # list of spans for each annotator\n",
    "    j = jen[\"span_length\"].tolist()\n",
    "    a = angel[\"span_length\"].tolist()\n",
    "\n",
    "    # agreement using correction\n",
    "    agree = test_ann[\"span_length\"].tolist()\n",
    "    merge_left_j = jen.merge(angel, on=['semtypes', 'case', 'concept'], how='left', indicator=True)\n",
    "    merge_left_a = angel.merge(jen, on=['semtypes', 'case', 'concept'], how='left', indicator=True)\n",
    "\n",
    "    # in j not in a\n",
    "    angel_n = merge_left_j[merge_left_j[\"_merge\"] != \"both\"]\n",
    "    a_n = angel_n[\"span_length_x\"].tolist()\n",
    "\n",
    "    # in a not in j\n",
    "    jen_n = merge_left_a[merge_left_a[\"_merge\"] != \"both\"]\n",
    "    j_n = jen_n[\"span_length_x\"].tolist()\n",
    "\n",
    "    return j, a, a_n, j_n, agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed probablity\n",
    "def get_po(agree, a_n, j_n, n):\n",
    "    agree_y = sum(agree)\n",
    "    agree_n = n - agree_y - sum(a_n) - sum(j_n) \n",
    "    po = (agree_y+agree_n)/n\n",
    "    return po, agree_y, agree_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected probability\n",
    "def get_pe(j, a, agree, agree_y, agree_n, a_n, j_n, n):\n",
    "    p_y = ((sum(j) + sum(agree))*(sum(a) + sum(agree)))/(n*n)\n",
    "    p_n = ((sum(a_n) + agree_n)*(sum(j_n) + agree_n))/(n*n)\n",
    "    pe = p_y + p_n\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000089745\n",
      "0.8381712292817575\n",
      "0000202738\n",
      "0.841641898362267\n",
      "0000220714\n",
      "0.7546343090384929\n",
      "0000234695\n",
      "0.8000261918467336\n",
      "0000258427\n",
      "0.7589860709936912\n",
      "0000327956\n",
      "0.6883016589891192\n",
      "0000469349\n",
      "0.7989276013418658\n",
      "0000473442\n",
      "0.7303693138416523\n",
      "0000513005\n",
      "0.3346710037630778\n",
      "0001053477\n",
      "0.7930298521424476\n",
      "0001112285\n",
      "0.5606686661844429\n",
      "0001157129\n",
      "0.6648456643268196\n",
      "0001908516\n",
      "0.43732832618370865\n",
      "0002340241\n",
      "0.6017584386923462\n",
      "0007340048\n",
      "0.919903102552175\n",
      "[0.8381712292817575, 0.841641898362267, 0.7546343090384929, 0.8000261918467336, 0.7589860709936912, 0.6883016589891192, 0.7989276013418658, 0.7303693138416523, 0.3346710037630778, 0.7930298521424476, 0.5606686661844429, 0.6648456643268196, 0.43732832618370865, 0.6017584386923462, 0.919903102552175]\n",
      "0.7015508885027065\n",
      "36038\n",
      "0.9690913282161535\n"
     ]
    }
   ],
   "source": [
    "sem_types = ['ALL']\n",
    "cases = get_cases()\n",
    "\n",
    "kappa = list()\n",
    "n_ann = list()\n",
    "p_agree = list()\n",
    "\n",
    "for case in cases:\n",
    "    print(case)\n",
    "    annotations = get_annotations('ALL', case)\n",
    "    test_ann, jen, angel = get_analytical(annotations, case)\n",
    "\n",
    "    # get number char in doc\n",
    "    get_doc(case)\n",
    "    docs = get_doc(case)\n",
    "    n = docs\n",
    "\n",
    "    # get annotator sets, with disjoint\n",
    "    j, a, a_n, j_n, agree = get_no_ann(jen, angel)\n",
    "    # get observed p and \n",
    "    po, agree_y, agree_n = get_po(agree, a_n, j_n, n[1])\n",
    "    \n",
    "    pe = get_pe(j, a, agree, agree_y, agree_n, a_n, j_n, n[1])\n",
    "    k = (po - pe)/(1 - pe)\n",
    "    print(k)\n",
    "    kappa.append(k)\n",
    "    n_ann.append(len(annotations))\n",
    "    p_agree.append(po)\n",
    "print(kappa)\n",
    "\n",
    "print(sum(kappa)/len(kappa))\n",
    "print(sum(n_ann))\n",
    "print(sum(p_agree)/len(p_agree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
