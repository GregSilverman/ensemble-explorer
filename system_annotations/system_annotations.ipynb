{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for UIMA systems\n",
    "class AnnotationSystems(object):\n",
    "    \"\"\"\n",
    "    CAS XMI Annotations of interest\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"\n",
    "        \n",
    "        self.biomedicus_dir = \"biomedicus_out/\"\n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\",\n",
    "                                 \"biomedicus.v2.Negated\",\n",
    "                                 \"biomedicus.v2.Acronym\",\n",
    "                                 \"biomedicus.v2.TemporalPhrase\"]\n",
    "        \n",
    "        \n",
    "        #self.clamp_dir = \"clamp_out/\"\n",
    "        self.clamp_dir = \"Annotated_XMI/\"\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\",\n",
    "                            \"edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\"]\n",
    "        \n",
    "        \n",
    "        self.ctakes_dir = \"ctakes_out/\"\n",
    "        self.ctakes_types = [\"org.apache.ctakes.typesystem.type.textsem.DiseaseDisorderMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.MedicationMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.ProcedureMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.SignSymptomMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.AnatomicalSiteMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.DateAnnotation\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.MeasurementAnnotation\"]\n",
    "       \n",
    "        self.metamap_dir = \"metamap_out/\"\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\",\n",
    "                              \"org.metamap.uima.ts.CuiConcept\",\n",
    "                              \"org.metamap.uima.ts.Negation\"]\n",
    "                \n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "            \n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "            output = self.biomedicus_dir\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "            output = self.clamp_dir\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "            output = self.ctakes_dir\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "            output = self.metamap_dir\n",
    "            \n",
    "        return types, view, output\n",
    "    \n",
    "annSys = AnnotationSystems()\n",
    "\n",
    "# extract attributes from cas Annotation object\n",
    "def get_attribs(v):\n",
    "    attribs = []\n",
    "    for sentence in v:\n",
    "        #print(sentence)\n",
    "        for s in sentence.__dir__():\n",
    "            if '__' not in s:\n",
    "                if s not in attribs:\n",
    "                    #print(s)\n",
    "                    attribs.append(s)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    return attribs\n",
    "\n",
    "def get_cols_to_keep(system, t):\n",
    "    \n",
    "    if system == 'biomedicus':\n",
    "        \n",
    "        if 'Temporal' in t:\n",
    "            cols_to_keep = ['begin', 'end', 'system', 'note_id', 'corpus',\n",
    "                            'filename', 'type']\n",
    "            \n",
    "        # umlsconcept\n",
    "        if 'Umls' in t:\n",
    "            cols_to_keep = ['begin', 'confidence', 'cui', 'end', 'source', 'sui', 'tui',\n",
    "                            'type', 'xmiID', 'system', 'note_id', 'corpus',\n",
    "                            'filename']\n",
    "\n",
    "        # acronym\n",
    "        if 'Acronym' in t:\n",
    "            cols_to_keep = ['begin', 'end', 'hasSpaceAfter', 'score', 'text', 'type',\n",
    "                            'xmiID', 'system', 'note_id', 'corpus', 'filename']\n",
    "\n",
    "        # negated\n",
    "        if 'Negated' in t:\n",
    "            cols_to_keep = ['begin', 'cueTerms', 'end', 'type', 'xmiID',\n",
    "                           'system', 'note_id', 'corpus', 'filename', 'modBegin', 'modEnd']\n",
    "        \n",
    "    elif system == 'clamp':\n",
    "        #NE uima\n",
    "        if 'NameEntityUIMA' in t:\n",
    "            cols_to_keep = ['assertion', 'attr1', 'attr2', 'attr3', 'attr4', 'attribute', 'begin',\n",
    "                           'cui', 'end', 'semanticTag', 'type', \n",
    "                           'xmiID', 'system', 'note_id', 'corpus', 'filename', 'umlsCuiDesc', \n",
    "                            'concept_prob', 'sentence_prob']\n",
    "\n",
    "        # relation uima: TODO -> deal with named tuples!\n",
    "        if 'Relation' in t:\n",
    "            cols_to_keep = ['attr1', 'attr2', 'attr3', 'attr4', 'attribute', 'entFrom', 'entTo',\n",
    "                           'semanticTag', 'type', 'xmiID', 'system', 'note_id',\n",
    "                           'corpus', 'filename']\n",
    "        \n",
    "    elif system == 'ctakes':\n",
    "        # disease\n",
    "        if 'Disease' in t:\n",
    "            cols_to_keep = ['alleviatingFactor', 'associatedSignSymptom', 'begin', 'bodyLaterality',\n",
    "                           'bodyLocation', 'bodySide', 'conditional', 'confidence', 'course',\n",
    "                           'discoveryTechnique', 'duration', 'end', 'endTime', 'event',\n",
    "                           'exacerbatingFactor', 'generic', 'historyOf', 'id',\n",
    "                           'ontologyConceptArr', 'polarity', 'relativeTemporalContext', 'severity',\n",
    "                           'startTime', 'subject', 'type', 'typeID', 'uncertainty',\n",
    "                           'xmiID', 'system', 'note_id', 'corpus', 'filename', 'cui', 'tui', 'preferredText']\n",
    "\n",
    "        # medication\n",
    "        if 'Medication' in t:\n",
    "            cols_to_keep = ['begin', 'conditional', 'confidence', 'discoveryTechnique', 'end',\n",
    "                           'endDate', 'event', 'generic', 'historyOf', 'id', 'medicationAllergy',\n",
    "                           'medicationDosage', 'medicationDuration', 'medicationForm',\n",
    "                           'medicationFrequency', 'medicationRoute', 'medicationStatusChange',\n",
    "                           'medicationStrength', 'ontologyConceptArr', 'polarity',\n",
    "                           'relativeTemporalContext', 'startDate', 'subject', 'type',\n",
    "                           'typeID', 'uncertainty', 'xmiID', 'system',\n",
    "                           'note_id', 'corpus', 'filename', 'cui', 'tui', 'preferredText']\n",
    "\n",
    "        # proc\n",
    "        if 'Procedure' in t:\n",
    "            cols_to_keep = ['begin', 'bodyLaterality', 'bodyLocation', 'bodySide', 'conditional',\n",
    "                           'confidence', 'discoveryTechnique', 'duration', 'end', 'endTime',\n",
    "                           'event', 'generic', 'historyOf', 'id', 'method', 'ontologyConceptArr',\n",
    "                           'polarity', 'procedureDevice', 'relativeTemporalContext', \n",
    "                           'startTime', 'subject', 'type', 'typeID', 'uncertainty',\n",
    "                           'xmiID', 'system', 'note_id', 'corpus', 'filename', 'cui', 'tui','preferredText']\n",
    "\n",
    "        # sign\n",
    "        if 'SignSymptom' in t:\n",
    "            cols_to_keep = ['alleviatingFactor', 'begin', 'bodyLaterality', 'bodyLocation',\n",
    "                           'bodySide', 'conditional', 'confidence', 'course', 'discoveryTechnique',\n",
    "                           'duration', 'end', 'endTime', 'event', 'exacerbatingFactor', 'generic',\n",
    "                           'historyOf', 'id', 'ontologyConceptArr', 'polarity',\n",
    "                           'relativeTemporalContext', 'severity', 'startTime', 'subject',\n",
    "                           'type', 'typeID', 'uncertainty', 'xmiID', 'system',\n",
    "                           'note_id', 'corpus', 'filename', 'cui', 'tui', 'preferredText']\n",
    "\n",
    "        # anatomy\n",
    "        if 'Anatomical' in t:\n",
    "            cols_to_keep = ['begin', 'bodyLaterality', 'bodySide', 'conditional', 'confidence',\n",
    "                           'discoveryTechnique', 'end', 'entity', 'generic', 'historyOf', 'id',\n",
    "                           'ontologyConceptArr', 'polarity', 'subject', 'type', 'typeID',\n",
    "                           'uncertainty', 'xmiID', 'system', 'note_id',\n",
    "                           'corpus', 'filename', 'cui', 'tui', 'preferredText']\n",
    "            \n",
    "        if 'Date' in t:\n",
    "            cols_to_keep = ['begin', 'end', 'type', 'confidence', 'discoveryTechnique', 'generic', 'historyOf', 'id', \n",
    "                           'polarity', 'uncertainty', 'xmiID', 'corpus', 'note_id', 'filename', 'system']\n",
    "        \n",
    "        if 'Measurement' in t:\n",
    "            cols_to_keep = ['begin', 'end', 'type', 'confidence', 'discoveryTechnique', 'generic', 'historyOf', 'id', \n",
    "                           'polarity', 'uncertainty', 'xmiID', 'corpus', 'note_id', 'filename', 'system']\n",
    "        \n",
    "    elif system == 'metamap':\n",
    "        #candidate\n",
    "        if 'Candidate' in t:\n",
    "            cols_to_keep = ['begin', 'concept', 'cui', 'end', 'head', 'matchMap', 'matchedwords',\n",
    "                           'overmatch', 'preferred', 'score', 'semanticTypes', 'sources',\n",
    "                           'spans', 'type', 'xmiID', 'system', 'note_id',\n",
    "                           'corpus', 'filename']\n",
    "\n",
    "        #cuiconcept\n",
    "        if 'CuiConcept' in t:\n",
    "            cols_to_keep = ['id', 'negExConcept', 'negExCui', 'type', 'xmiID',\n",
    "                           'system', 'note_id', 'corpus', 'filename']\n",
    "\n",
    "        #negation\n",
    "        if 'Negation' in t:\n",
    "            cols_to_keep = ['begin', 'cuiConcepts', 'end', 'id', 'ncSpans', 'negTrigger', 'negType',\n",
    "                           'ntSpans', 'type', 'xmiID', 'system',\n",
    "                           'note_id', 'corpus', 'filename', 'modBegin', 'modEnd']\n",
    "    \n",
    "    else:\n",
    "        cols_to_keep = []\n",
    "\n",
    "    return cols_to_keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cassis(system, typesystem):\n",
    "   \n",
    "    #tic=timeit.default_timer() \n",
    "\n",
    "    print(system)\n",
    "\n",
    "    # types for metamap\n",
    "\n",
    "    if system == 'metamap':\n",
    "        t = typesystem.create_type(name='org.apache.uima.examples.SourceDocumentInformation', supertypeName='uima.tcas.Annotation')\n",
    "        typesystem.add_feature(t, name='uri', rangeTypeName='uima.cas.String')\n",
    "        typesystem.add_feature(t, name=\"offsetInSource\", rangeTypeName=\"uima.cas.Integer\")\n",
    "        typesystem.add_feature(t, name=\"documentSize\", rangeTypeName=\"uima.cas.Integer\")\n",
    "        typesystem.add_feature(t, name=\"lastSegment\", rangeTypeName=\"uima.cas.Integer\")\n",
    "\n",
    "    # features for ctakes\n",
    "\n",
    "    if system == 'ctakes':\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.structured.Metadata')\n",
    "        typesystem.add_feature(t, name='patientIdentifier', rangeTypeName='uima.cas.String')\n",
    "        \n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.DiseaseDisorderMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        #typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        #typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.SignSymptomMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        #typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        #typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.MedicationMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        #typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        #typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.ProcedureMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        #typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        #typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.AnatomicalSiteMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        #typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        #typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS: clinical_trial2\n",
      "SYSTEM: clamp\n",
      "clamp\n",
      "/Users/gms/development/nlp/nlpie/data/clinical_trial2/bert-output/\n",
      "NCT03865992_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03789175_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03730194_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03830164_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03872375_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT04048616_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03613116_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03841539_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT04072822_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03764761_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT04045132_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03709043_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03645096_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03860792_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "NCT03953157_criteria\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\n",
      "TYPE: edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "# parse system annotations\n",
    "def main():\n",
    "    import os, glob\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    #from superjson import json\n",
    "    \n",
    "    from sqlalchemy.engine import create_engine\n",
    "    from sqlalchemy.sql import text\n",
    "    from cassis import load_typesystem, load_cas_from_xmi\n",
    "\n",
    "    # connection string\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/clinical_trial', pool_pre_ping=True)\n",
    "    #systems = [\"metamap\", \"ctakes\", \"biomedicus\", \"clamp\"]\n",
    "    systems = ['clamp']\n",
    "    \n",
    "    corpora = [\"clinical_trial2\"]\n",
    "    parse_to_sql = True\n",
    "    \n",
    "    i = 0\n",
    "    if parse_to_sql:\n",
    "        \n",
    "        for corpus in corpora:\n",
    "            print(\"CORPUS:\", corpus)\n",
    "\n",
    "            for system in systems:\n",
    "\n",
    "                print(\"SYSTEM:\", system)\n",
    "\n",
    "                types, view_, output = annSys.get_system_type(system)\n",
    "                \n",
    "                dir_test = '/Users/gms/development/nlp/nlpie/scripts/jupyter/ensembling/system_annotations/typesystems/' + system + '/'\n",
    "\n",
    "                with open(dir_test + 'TypeSystem.xml', 'rb') as f:\n",
    "                    typesystem = load_typesystem(f)\n",
    "                \n",
    "                init_cassis(system, typesystem)\n",
    "                \n",
    "                # parse directory\n",
    "                if corpus in [\"i2b2\", \"mipacq\"]:\n",
    "                    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/' + corpus + '/rerun-november-2019/' +  system + '_out/' #data_to_analyze/all/'\n",
    "                \n",
    "                elif corpus == 'fairview':\n",
    "                    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/' + corpus + '/system_annotations/data_in_preprocessed/' +  system + '_out/'#data_to_analyze/all/'\n",
    "               \n",
    "                elif 'clinical_trial' in corpus:\n",
    "                    # if parsing gold standard, change to_sql below to ensure proper target directory\n",
    "                    #directory_to_parse = '/Users/gms/development/nlp/nlpie/data/clinical_trial2/' +  system + '_out/'\n",
    "                    #directory_to_parse = '/Users/gms/development/nlp/nlpie/data/clinical_trial2/gold_standard/'\n",
    "                    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/clinical_trial2/bert-output/'\n",
    "                else:\n",
    "                    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/mimic/'\n",
    "                    \n",
    "                print(directory_to_parse)\n",
    "\n",
    "                for fname in glob.glob(directory_to_parse + '/*.xmi'):\n",
    "                #for fname in glob.glob(directory_to_parse + '/527982345.txt.xmi'):\n",
    "\n",
    "                    file = os.path.basename(fname)\n",
    "                    u = file.split('.')[0]\n",
    "\n",
    "                    print(u)\n",
    "\n",
    "                    # load cas\n",
    "                    with open(directory_to_parse + file, 'rb') as f:\n",
    "                        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "\n",
    "                    # load view\n",
    "                    view = cas.get_view(view_)\n",
    "\n",
    "                    # sofa -> db\n",
    "                    def write_sofa(u):\n",
    "                        d = {}\n",
    "                        d[\"note_id\"] = str(u)\n",
    "                        d[\"sofa\"] = view.sofa_string\n",
    "                        d[\"corpus\"] = corpus\n",
    "\n",
    "                        # does it exist?\n",
    "                        if engine.dialect.has_table(engine, \"sofas\"):\n",
    "                            sql = text(\"SELECT * FROM test.sofas WHERE note_id = :e1\")\n",
    "                            resp = engine.execute(sql, e1=u).fetchall()\n",
    "                        else:\n",
    "                            resp = []\n",
    "\n",
    "                        if len(resp) == 0:            \n",
    "                            #pd.DataFrame(d, index=[0]).to_sql(\"sofas\", engine, if_exists=\"append\")  \n",
    "                            pd.DataFrame(d, index=[0]).to_sql(\"sofas\", engine, if_exists=\"append\")  \n",
    "\n",
    "                    write_sofa(u)\n",
    "\n",
    "                    for t in types:\n",
    "                        print(\"TYPE:\", t)\n",
    "                       \n",
    "                        # get list for filtering df\n",
    "                        cols_to_keep = get_cols_to_keep(system, t)\n",
    "                        \n",
    "                        attribs = get_attribs(view.select(t))\n",
    "                        annotation_type = t\n",
    "                        x = t.split('.')\n",
    "                        table_name = system[0:3] + '_' + x[0] + '_' + x[len(x)-1]\n",
    "\n",
    "                        # Annotation object -> dataframe\n",
    "                        def get_df(v, attribs):\n",
    "                            d = {}\n",
    "                            df = pd.DataFrame()\n",
    "\n",
    "                            # only parse if type exists in file\n",
    "                            if view.select(t):\n",
    "                                for sentence in view.select(t):\n",
    "                                    \n",
    "                                    for i in range(len(attribs)):\n",
    "                                        key = attribs[i]\n",
    "                                        val = sentence.__getattribute__(attribs[i])\n",
    "                                        \n",
    "                                        if system == 'biomedicus' and key == 'cueTerms':\n",
    "                                            if val is not None and val:\n",
    "                                                d['modBegin'] = val[0].begin\n",
    "                                                d['modEnd'] = val[0].end\n",
    "                                                print('ehere!', i, len(attribs), val[0].begin, val[0].end)\n",
    "                                                \n",
    "            \n",
    "                                        \n",
    "                                        if system == 'metamap' and key == 'ntSpans':\n",
    "                                            if val is not None and val:\n",
    "                                                d['modBegin'] = val[0].begin\n",
    "                                                d['modEnd'] = val[0].end\n",
    "    \n",
    "                                        if system == 'clamp' and key == 'attribute':\n",
    "                                            if val is not None and val:\n",
    "                                                if \"umlsCuiDesc\" in json.loads(val):\n",
    "                                                    d['umlsCuiDesc'] = json.loads(val)[\"umlsCuiDesc\"].lower()\n",
    "                                                else:\n",
    "                                                    d['umlsCuiDesc'] = None\n",
    "                                        \n",
    "                                                if \"concept_prob\" in json.loads(val):\n",
    "                                                    d['concept_prob'] = json.loads(val)[\"concept_prob\"]\n",
    "                                                else:\n",
    "                                                    d['concept_prob'] = None\n",
    "                                                \n",
    "                                                if \"sentence_prob\" in json.loads(val):\n",
    "                                                    d['sentence_prob'] = json.loads(val)[\"concept_prob\"]\n",
    "                                                else:\n",
    "                                                    d['sentence_prob'] = None\n",
    "                                                   \n",
    "                                            else:\n",
    "                                                d['umlsCuiDesc'] = None\n",
    "                                                d['concept_prob'] = None\n",
    "                                                d['sentence_prob'] = None\n",
    "                                            \n",
    "                                        if key in ['entFrom', 'entTo']:\n",
    "                                            if val.attribute:\n",
    "                                                attribute = json.loads(val.attribute)\n",
    "                                            else:\n",
    "                                                attribute = None\n",
    "                                                \n",
    "                                            val = json.dumps({\"begin\": val.begin, \"end\": val.end, \"cui\": val.cui, \"attribute\": attribute})\n",
    "                                            \n",
    "                                        if isinstance(val, list):\n",
    "                                            val = ' '.join(map(str,val)) # flatten list to space delimited variable\n",
    "                                        \n",
    "                                        d[key] = val\n",
    "                                       \n",
    "                                        # entire sentence has be iterated through\n",
    "                                        if i == len(attribs) - 1:\n",
    "                                            frames = [ df, pd.DataFrame(d, index=[0]) ]\n",
    "                                            df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "                            df[\"system\"] = system\n",
    "                            df[\"type\"] = annotation_type\n",
    "                            df[\"note_id\"] = u\n",
    "                            df[\"corpus\"] = corpus\n",
    "                            df[\"filename\"] = fname\n",
    "                            return df\n",
    "\n",
    "                        annotations = get_df(view.select(t), attribs)\n",
    "\n",
    "                        # write to database\n",
    "                        if not annotations.empty:\n",
    "                            # handle extraction of elements from named tuple converted to str\n",
    "                            if 'Mention' in t and not annotations.empty:\n",
    "                                # stack string delimited by \") /\" into multiple rows (initially represented by list of named tuples)\n",
    "                                b = pd.DataFrame(annotations.ontologyConceptArr.str.split('\\) o').tolist(), index=annotations.ontologyConceptArr).stack()\n",
    "                                b = b.reset_index()[[0, 'ontologyConceptArr']] # var1 variable is currently labeled 0\n",
    "                                b.columns = ['concept', 'ontologyConceptArr'] # renaming var1\n",
    "                                \n",
    "                                #print(b)\n",
    "\n",
    "                                c = pd.merge(annotations, b)\n",
    "\n",
    "                                c['cui'] = c['concept'].str.extract(pat = 'cui=(.[^,]+)').apply(lambda s:s.str.replace(\"'\", \"\")) \n",
    "                                c['tui'] = c['concept'].str.extract(pat = 'tui=(.[^,]+)').apply(lambda s:s.str.replace(\"'\", \"\")) \n",
    "                                c['preferredText'] = c['concept'].str.extract(pat = 'preferredText=(.[^,]+)').apply(lambda s:s.str.replace(\"'\", \"\"))\n",
    "                            \n",
    "                                annotations = c\n",
    "                            \n",
    "                            annotations = annotations[cols_to_keep]\n",
    "                            #annotations.to_sql(table_name + '_reference', engine, if_exists=\"append\") \n",
    "                            annotations.to_sql(table_name + '_bert', engine, if_exists=\"append\") \n",
    "                            #annotations.to_sql(table_name, engine, if_exists=\"append\") \n",
    "                            #print(annotations.head())    \n",
    "    # write out annotations for non-cui tables\n",
    "    else:\n",
    "        \n",
    "        sys_ann_other = pd.DataFrame()\n",
    "        for system in systems:\n",
    "                \n",
    "            types, view_, output = annSys.get_system_type(system)\n",
    "            print(\"SYSTEM:\", system)\n",
    "           \n",
    "            for t in types:\n",
    "\n",
    "                x = t.split('.')\n",
    "                table_name = system[0:3] + '_' + x[0] + '_' + x[len(x)-1]\n",
    "\n",
    "                sql = \"SELECT * FROM test.\" + table_name \n",
    "                df = pd.read_sql(sql, engine)\n",
    "\n",
    "                cols_to_keep = ['begin', 'end', 'type', 'system', 'note_id', 'corpus', 'filename']\n",
    "                #print(system, t, table_name, list(df[cols_to_keep].columns.values))\n",
    "                \n",
    "                frames = [ sys_ann_other, df[cols_to_keep] ]\n",
    "                sys_ann_other = pd.concat(frames, ignore_index=True)\n",
    "        \n",
    "        print(sys_ann_other.drop_duplicates())\n",
    "        sys_ann_other.drop_duplicates().to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_' + corpus + '.csv')\n",
    "\n",
    "    print(\"done!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                sofa               note_id\n",
      "0   Inclusion Criteria:\\r\\n   -  Chronic kidney d...  NCT03579693_criteria\n",
      "1   Inclusion Criteria:\\r\\n   -  12 to 19 years o...  NCT00962598_criteria\n",
      "2   INCLUSION CRITERIA:\\r\\n Diagnosis of FRDA wit...  NCT00015808_criteria\n",
      "3   Inclusion Criteria:\\r\\n   -  Women with histo...  NCT03865992_criteria\n",
      "4   Inclusion Criteria:\\r\\n   -  NINCDS/ADRDA cri...  NCT01928420_criteria\n",
      "NCT03579693_criteria\n",
      "NCT00962598_criteria\n",
      "NCT00015808_criteria\n",
      "NCT03865992_criteria\n",
      "NCT01928420_criteria\n",
      "NCT00001918_criteria\n",
      "NCT03557684_criteria\n",
      "NCT00067405_criteria\n",
      "NCT00149552_criteria\n",
      "NCT02460783_criteria\n",
      "NCT00416715_criteria\n",
      "NCT00363129_criteria\n",
      "NCT02561754_criteria\n",
      "NCT01105130_criteria\n",
      "NCT00090402_criteria\n",
      "NCT03789175_criteria\n",
      "NCT00001919_criteria\n",
      "NCT00104572_criteria\n",
      "NCT00065169_criteria\n",
      "NCT02036658_criteria\n",
      "NCT00691444_criteria\n",
      "NCT02439255_criteria\n",
      "NCT00872911_criteria\n",
      "NCT03730194_criteria\n",
      "NCT03264300_criteria\n",
      "NCT00205179_criteria\n",
      "NCT00327756_criteria\n",
      "NCT00589498_criteria\n",
      "NCT03830164_criteria\n",
      "NCT00042380_criteria\n",
      "NCT00361374_criteria\n",
      "NCT03472664_criteria\n",
      "NCT00476242_criteria\n",
      "NCT00048815_criteria\n",
      "NCT00007124_criteria\n",
      "NCT01683539_criteria\n",
      "NCT00200785_criteria\n",
      "NCT00238108_criteria\n",
      "NCT01019343_criteria\n",
      "NCT00986596_criteria\n",
      "NCT00663871_criteria\n",
      "NCT00118846_criteria\n",
      "NCT00056225_criteria\n",
      "NCT02021669_criteria\n",
      "NCT00357214_criteria\n",
      "NCT00851981_criteria\n",
      "NCT00712426_criteria\n",
      "NCT00611806_criteria\n",
      "NCT00517036_criteria\n",
      "NCT01098318_criteria\n",
      "NCT00449865_criteria\n",
      "NCT00404872_criteria\n",
      "NCT00200746_criteria\n",
      "NCT00262470_criteria\n",
      "NCT00815854_criteria\n",
      "NCT02838979_criteria\n",
      "NCT03320109_criteria\n",
      "NCT00376987_criteria\n",
      "NCT00312078_criteria\n",
      "NCT01032993_criteria\n",
      "NCT02027636_criteria\n",
      "NCT01669915_criteria\n",
      "NCT03035201_criteria\n",
      "NCT00711971_criteria\n",
      "NCT03872375_criteria\n",
      "NCT00070993_criteria\n",
      "NCT00158171_criteria\n",
      "NCT01904032_criteria\n",
      "NCT00129272_criteria\n",
      "NCT04048616_criteria\n",
      "NCT03613116_criteria\n",
      "NCT00097604_criteria\n",
      "NCT03841539_criteria\n",
      "NCT01723917_criteria\n",
      "NCT02837315_criteria\n",
      "NCT02740153_criteria\n",
      "NCT00051402_criteria\n",
      "NCT00006349_criteria\n",
      "NCT00068458_criteria\n",
      "NCT02795455_criteria\n",
      "NCT00066859_criteria\n",
      "NCT02525731_criteria\n",
      "NCT02854683_criteria\n",
      "NCT01893892_criteria\n",
      "NCT02033941_criteria\n",
      "NCT02840435_criteria\n",
      "NCT03575273_criteria\n",
      "NCT02145949_criteria\n",
      "NCT00091169_criteria\n",
      "NCT04072822_criteria\n",
      "NCT01385137_criteria\n",
      "NCT03764761_criteria\n",
      "NCT00010803_criteria\n",
      "NCT01783522_criteria\n",
      "NCT03427528_criteria\n",
      "NCT00208611_criteria\n",
      "NCT00967005_criteria\n",
      "NCT00120484_criteria\n",
      "NCT00775645_criteria\n",
      "NCT02001714_criteria\n",
      "NCT04045132_criteria\n",
      "NCT03501966_criteria\n",
      "NCT03056794_criteria\n",
      "NCT00055055_criteria\n",
      "NCT00000178_criteria\n",
      "NCT00010699_criteria\n",
      "NCT00120458_criteria\n",
      "NCT02831582_criteria\n",
      "NCT03519009_criteria\n",
      "NCT01809132_criteria\n",
      "NCT00243022_criteria\n",
      "NCT03709043_criteria\n",
      "NCT02057406_criteria\n",
      "NCT01003639_criteria\n",
      "NCT03272399_criteria\n",
      "NCT03482167_criteria\n",
      "NCT01922895_criteria\n",
      "NCT02487745_criteria\n",
      "NCT03645096_criteria\n",
      "NCT00547911_criteria\n",
      "NCT03255031_criteria\n",
      "NCT00645983_criteria\n",
      "NCT01057082_criteria\n",
      "NCT01596634_criteria\n",
      "NCT00070941_criteria\n",
      "NCT00075842_criteria\n",
      "NCT03060096_criteria\n",
      "NCT02484300_criteria\n",
      "NCT03860792_criteria\n",
      "NCT00470418_criteria\n",
      "NCT00608686_criteria\n",
      "NCT02595489_criteria\n",
      "NCT02990091_criteria\n",
      "NCT02044211_criteria\n",
      "NCT01643044_criteria\n",
      "NCT03953157_criteria\n",
      "NCT02700230_criteria\n",
      "NCT00013923_criteria\n",
      "NCT00006180_criteria\n",
      "NCT02986659_criteria\n",
      "NCT01696435_criteria\n",
      "NCT00586222_criteria\n",
      "NCT02072746_criteria\n",
      "NCT00840112_criteria\n",
      "NCT00116857_criteria\n",
      "NCT00538070_criteria\n",
      "NCT02877641_criteria\n",
      "NCT01786239_criteria\n",
      "NCT00040378_criteria\n"
     ]
    }
   ],
   "source": [
    "# write out new data text\n",
    "sql = '''\n",
    "select sofa, note_id from clinical_trial.sofas\n",
    "where corpus='clinical_trial2'\n",
    "\n",
    "'''\n",
    "df = pd.read_sql(sql, engine)\n",
    "# pull 100 cases \n",
    "#rnd = df.apply(lambda x: x.sample(n=100)).uuid.copy()\n",
    "#print(rnd.dropna())\n",
    "\n",
    "#sample = rnd.dropna().to_frame().merge(df, how='inner')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "dir_to_write = '/Users/gms/development/nlp/nlpie/data/clinical_trial2/data_in/'\n",
    "for row in df.itertuples():\n",
    "    print(row.note_id)\n",
    "    f = open(dir_to_write + str(row.note_id) +'.txt', 'w')\n",
    "    f.write(row.sofa)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fini!\n"
     ]
    }
   ],
   "source": [
    "# generate cTAKES TUIs\n",
    "import os, glob\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import json\n",
    "#from superjson import json\n",
    "\n",
    "from sqlalchemy.engine import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "from cassis import load_typesystem, load_cas_from_xmi\n",
    "\n",
    "\n",
    "engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)\n",
    "\n",
    "df = pd.read_sql('SELECT ontologyConceptArr, semtypes from concepts.ctakes_concept',con=engine)\n",
    "df['tui'] = df['ontologyConceptArr'].str.extract(pat = 'tui=(.[^,]+)').apply(lambda s:s.str.replace(\"'\", \"\")) \n",
    "\n",
    "df[['tui', 'semtypes']].drop_duplicates().to_sql(\"ctakes_tui_semtype\", engine, if_exists=\"replace\")\n",
    "print('Fini!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tui ctakes_name semtypes      _merge\n",
      "35  T033         NaN        0  right_only\n",
      "36  T046         NaN        0  right_only\n",
      "37  T184         NaN        0  right_only\n",
      "38  T057         NaN        0  right_only\n",
      "39  T041         NaN        0  right_only\n",
      "40  T056         NaN        0  right_only\n",
      "41  T040         NaN        0  right_only\n",
      "42  T042         NaN        0  right_only\n",
      "43  T034         NaN        0  right_only\n",
      "44  T045         NaN        0  right_only\n",
      "45  T044         NaN        0  right_only\n",
      "46  T043         NaN        0  right_only\n",
      "     tui                                ctakes_name semtypes     _merge\n",
      "0   T017                      AnatomicalSiteMention      NaN  left_only\n",
      "4   T031                      AnatomicalSiteMention      NaN  left_only\n",
      "8   T018                      AnatomicalSiteMention      NaN  left_only\n",
      "15  T103                          MedicationMention      NaN  left_only\n",
      "16  T120                          MedicationMention      NaN  left_only\n",
      "17  T104                          MedicationMention      NaN  left_only\n",
      "29  T192                          MedicationMention      NaN  left_only\n",
      "31  T080                                   temporal      NaN  left_only\n",
      "32  T081                                   temporal      NaN  left_only\n",
      "33  T079                                   temporal      NaN  left_only\n",
      "39  T050  DiseaseDisorderMention,SignSymptomMention      NaN  left_only\n",
      "40  T033  DiseaseDisorderMention,SignSymptomMention      NaN  left_only\n",
      "44  T046  DiseaseDisorderMention,SignSymptomMention      NaN  left_only\n",
      "45  T184  DiseaseDisorderMention,SignSymptomMention      NaN  left_only\n",
      "46  T034                                measurement      NaN  left_only\n",
      "48  T065                           ProcedureMention      NaN  left_only\n",
      "49  T058                           ProcedureMention      NaN  left_only\n",
      "51  T063                           ProcedureMention      NaN  left_only\n",
      "52  T062                           ProcedureMention      NaN  left_only\n"
     ]
    }
   ],
   "source": [
    "# tui consistency check wrt semantic groups\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy.engine import create_engine\n",
    "sql = '''SELECT tui,\n",
    "CASE\n",
    "    WHEN semtypes in ('DiseaseDisorderMention','SignSymptomMention') \n",
    "    THEN concat ('DiseaseDisorderMention,SignSymptomMention')\n",
    "    ELSE semtypes\n",
    "END as semtypes\n",
    "FROM concepts.ctakes_tui_semtype;'''\n",
    "\n",
    "engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)\n",
    "\n",
    "new = pd.read_sql(sql, con=engine)\n",
    "\n",
    "sql = 'select distinct tui, ctakes_name from semantic_groups where ctakes_name is not null'\n",
    "old = pd.read_sql(sql, con=engine)\n",
    "\n",
    "test = pd.merge(old, new, how = 'right', left_on=['tui','ctakes_name'], right_on = ['tui','semtypes'], indicator=True) \n",
    "test = test[test[\"_merge\"] != \"both\"]\n",
    "print((test))\n",
    "\n",
    "test = pd.merge(old, new, how = 'left', left_on=['tui','ctakes_name'], right_on = ['tui','semtypes'], indicator=True) \n",
    "test = test[test[\"_merge\"] != \"both\"]\n",
    "print((test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsql = \"SELECT * FROM test.cta_disease\"\\ntable_name = \\'cTAKES_disease\\'\\n\\nmk_ctakes_concepts(sql, table_name)\\n\\nsql = \"SELECT * FROM test.cta_med\"\\ntable_name = \\'cTAKES_medication\\'\\n\\nmk_ctakes_concepts(sql, table_name)\\n\\n\\nsql = \"SELECT * FROM test.cta_proc\"\\ntable_name = \\'cTAKES_procedure\\'\\nmk_ctakes_concepts(sql, table_name)\\n\\n\\nsql = \"SELECT * FROM test.cta_sign_symptom\"\\ntable_name = \\'cTAKES_sign_symptom\\'\\n\\nmk_ctakes_concepts(sql, table_name)\\n\\nsql = \"SELECT * FROM test.cta_anatomical_site\"\\ntable_name = \\'cTAKES_anatomical_site\\'\\n\\nmk_ctakes_concepts(sql, table_name)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tables for cTAKES UMLS concept -> mention table\n",
    "# https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows\n",
    "\n",
    "def mk_ctakes_concepts(sql, table_name):\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    from sqlalchemy.engine import create_engine\n",
    "\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "\n",
    "    df = pd.read_sql(sql, engine)\n",
    "\n",
    "    # MetaMap\n",
    "    b = pd.DataFrame(df.cuiConcepts.str.split(' ').tolist(), index=df.cuiConcepts).stack()\n",
    "    b = b.reset_index()[[0, 'cuiConcepts']] # var1 variable is currently labeled 0\n",
    "    b.columns = ['linked_id', 'cuiConcepts'] # renaming var1\n",
    "    \n",
    "    # CTAKES:\n",
    "     \n",
    "    #b = pd.DataFrame(df.ontologyConceptArr.str.split(' ').tolist(), index=df.ontologyConceptArr).stack()\n",
    "    #b = b.reset_index()[[0, 'ontologyConceptArr']] # var1 variable is currently labeled 0\n",
    "    #b.columns = ['linked_id', 'ontologyConceptArr'] # renaming var1\n",
    "    \n",
    "\n",
    "    c = pd.merge(df, b)\n",
    "   \n",
    "    c.to_sql(table_name, engine, if_exists=\"replace\") \n",
    "\n",
    "    print(c[0:2])\n",
    "\n",
    "''' TABLES to make\n",
    "sql = \"SELECT * FROM test.met_org_negation\"\n",
    "table_name = 'mm_negation'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "'''\n",
    "'''\n",
    "sql = \"SELECT * FROM test.cta_disease\"\n",
    "table_name = 'cTAKES_disease'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_med\"\n",
    "table_name = 'cTAKES_medication'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_proc\"\n",
    "table_name = 'cTAKES_procedure'\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_sign_symptom\"\n",
    "table_name = 'cTAKES_sign_symptom'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_anatomical_site\"\n",
    "table_name = 'cTAKES_anatomical_site'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix XMI, adding \"id\" for those with linked features\n",
    "\n",
    "def add_attribute_sys_type(regexpatterns):\n",
    "    import re, os, glob, path\n",
    "    import regex\n",
    "\n",
    "    #directory_to_parse = '/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/quarantine/'\n",
    "\n",
    "    #for fname in glob.iglob(\"/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/quarantine/period2/*.txt\"):\n",
    "\n",
    "    for fname in glob.iglob(\"/Users/gms/development/nlp/nlpie/data/amia-2019/analysis/mipacq/rerun_post_validation/metamap_out/*.txt.xmi\"):\n",
    "\n",
    "        # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "        cd = os.path.dirname(fname)\n",
    "        u = t.split('.')[0] + '-v2.txt.xmi'\n",
    "        #print(t, cd)\n",
    "\n",
    "        #print(t)\n",
    "        with open(fname) as f:\n",
    "            with open(cd + '/' + u, 'w') as f2:\n",
    "                for line in f:\n",
    "                    for r in regexpatterns:\n",
    "                        line = re.sub(r, r + ' id=\"0\"', line)\n",
    "                    f2.write(line)\n",
    "    \n",
    "\n",
    "#regexpatterns = [r\"refsem:UmlsConcept\"]\n",
    "#regexpatterns = [r\"ts2:CuiConcept\"]\n",
    "#regexpatterns = [r\"ts2:Negation\"]\n",
    "\n",
    "#add_attribute_sys_type(regexpatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biomedicus\n",
      "[biomedicus_v2_TemporalPhrase(xmiID=8371, begin=0, end=7, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8372, begin=38, end=62, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8373, begin=87, end=96, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8374, begin=253, end=262, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8375, begin=538, end=546, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8376, begin=1118, end=1131, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8377, begin=1336, end=1359, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8378, begin=1421, end=1424, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8379, begin=1619, end=1630, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8380, begin=2231, end=2239, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8381, begin=2386, end=2400, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8382, begin=2490, end=2504, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8383, begin=2633, end=2659, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8384, begin=2688, end=2703, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8385, begin=2773, end=2787, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8386, begin=2936, end=2939, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8387, begin=3016, end=3019, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8388, begin=3835, end=3842, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8389, begin=4010, end=4019, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8390, begin=5042, end=5051, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8391, begin=5540, end=5552, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8392, begin=6906, end=6922, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8393, begin=6964, end=6975, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8394, begin=7327, end=7346, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8395, begin=7351, end=7358, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8396, begin=7372, end=7378, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8397, begin=7427, end=7450, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8398, begin=7621, end=7632, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8399, begin=7746, end=7769, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8400, begin=7780, end=7803, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8401, begin=8493, end=8497, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8402, begin=8603, end=8606, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8403, begin=9783, end=9786, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8404, begin=10308, end=10326, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8405, begin=10620, end=10644, type='biomedicus.v2.TemporalPhrase'), biomedicus_v2_TemporalPhrase(xmiID=8406, begin=10671, end=10695, type='biomedicus.v2.TemporalPhrase')]\n"
     ]
    }
   ],
   "source": [
    "# test dkpro-cassis\n",
    "from cassis import *\n",
    "def test_dkpro(fname, dir_test, ts_test, view_name):\n",
    "    with open(ts_test + 'TypeSystem.xml', 'rb') as f:\n",
    "        typesystem = load_typesystem(f)\n",
    "    init_cassis('biomedicus', typesystem)\n",
    "    \n",
    "    with open(dir_test + fname, 'rb') as f:\n",
    "        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "    view = cas.get_view(view_name)\n",
    "    #print([x for x in view.select_all()])\n",
    "    print([x for x in view.select(\"biomedicus.v2.TemporalPhrase\")]) \n",
    "    #print([x for x in view.select(\"biomedicus.v2.UmlsConcept\")]) \n",
    "    #print([x for x in view.select(\"org.apache.ctakes.typesystem.type.refsem.UmlsConcept\")]) \n",
    "    \n",
    "    #print([x for x in view.select(\"org.apache.ctakes.typesystem.type.textsem.DateAnnotation\")])\n",
    "    #print([x for x in view.select(\"org.metamap.uima.ts.Candidate\")])\n",
    "    \n",
    "    #print([x for x in view.select(\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\")])\n",
    "\n",
    "dir_test = '/Users/gms/development/nlp/nlpie/data/clinical_trial/biomedicus_out/'\n",
    "#view_name = \"_InitialView\"\n",
    "view_name = \"Analysis\"\n",
    "ts_test = \"/Users/gms/development/nlp/nlpie/scripts/jupyter/ensembling/system_annotations/typesystems/biomedicus/\"\n",
    "fname = 'M2.txt.xmi'\n",
    "                \n",
    "                \n",
    "test_dkpro(fname, dir_test, ts_test, view_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nanalytical_cui = pd.DataFrame()\\n\\nsql = \"SELECT * FROM test.biomedicus_cui where corpus = \\'mipacq\\'\"\\n\\nprint(get_analytical_set(sql)[0:1])\\n\\nframes = [ analytical_cui, get_analytical_set(sql) ]\\nanalytical_cui = pd.concat(frames, ignore_index=True, sort=False) \\n\\nsql = \"SELECT * FROM test.clamp_all_cui where corpus = \\'mipacq\\'\"\\n\\nprint(get_analytical_set(sql)[0:1])\\n\\nframes = [ analytical_cui, get_analytical_set(sql) ]\\nanalytical_cui = pd.concat(frames, ignore_index=True, sort=False) \\n\\nsql = \"SELECT * FROM test.ctakes_all_types_cui where corpus = \\'mipacq\\'\"\\n\\nprint(get_analytical_set(sql)[0:1])\\n\\nframes = [ analytical_cui, get_analytical_set(sql) ]\\nanalytical_cui = pd.concat(frames, ignore_index=True, sort=False) \\n\\nsql = \"SELECT * FROM test.metamap_all_cui where corpus = \\'mipacq\\'\"\\n\\nprint(get_analytical_set(sql)[0:1])\\nframes = [ analytical_cui, get_analytical_set(sql) ]\\nanalytical_cui = pd.concat(frames, ignore_index=True, sort=False) \\n\\nprint(analytical_cui[0:1])\\nanalytical_cui.to_csv(\\'/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts.csv\\')\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tables for\n",
    "# https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows\n",
    "\n",
    "def get_analytical_set(sql):\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    from sqlalchemy.engine import create_engine\n",
    "\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "\n",
    "    df = pd.read_sql(sql, engine)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#GENERATE analytical tables\n",
    "'''\n",
    "analytical_cui = pd.DataFrame()\n",
    "\n",
    "sql = \"SELECT * FROM test.biomedicus_cui where corpus = 'mipacq'\"\n",
    "\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "sql = \"SELECT * FROM test.clamp_all_cui where corpus = 'mipacq'\"\n",
    "\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "sql = \"SELECT * FROM test.ctakes_all_types_cui where corpus = 'mipacq'\"\n",
    "\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "sql = \"SELECT * FROM test.metamap_all_cui where corpus = 'mipacq'\"\n",
    "\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "print(analytical_cui[0:1])\n",
    "analytical_cui.to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up cui list in clamp\n",
    "#df['stridx']=df.index\n",
    "\n",
    "\n",
    "#print(df[df['cui'].str.contains(',')==True])\n",
    "\n",
    "#df['new_cui' ] = np.where(df.cui.str.contains(','), df['cui'].str.split(r'\\s*,\\s*|\\s*\\.\\s*').str[0], df['cui'])\n",
    "\n",
    "#print(df['cui'])\n",
    "#print(df[df['cui'].str.contains(',')==False])\n",
    "\n",
    "#new = df.rename(columns={'cui': 'old_cui', 'new_cui': 'cui'}).copy() \n",
    "#new.to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts_new.csv')\n",
    "#writer = pd.ExcelWriter('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble/merged_metrics.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
