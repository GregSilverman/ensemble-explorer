{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/cassis/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "# Analysis for AMIA 2019 workshop\n",
    "import os, glob\n",
    "from cassis import *\n",
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy.engine import create_engine\n",
    "import pymysql\n",
    "from sqlalchemy.sql import text\n",
    "import numpy as np\n",
    "import timeit\n",
    "#dir_test = '/Users/gms/development/nlp/nlpie/data/mimic/metamap_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    if system == \\'biomedicus\\':\\n        sys_expansion = (annotations[\\'text\\'][0], annotations[\\'begin\\'][0], annotations[\\'end\\'][0])\\n        #print(\\'system expansion:\\', annotations.head(1)[\\'text\\'][0], annotations[\\'begin\\'][0], annotations[\\'end\\'][0] )\\n\\n\\n        engine = create_engine(\\'mysql+pymysql://gms:nej123@localhost/test\\', pool_pre_ping=True)\\n                # does it exist?\\n        sql = text(\"SELECT expansion, start, end FROM test.amia_2019_ref where `case` = :e1\")\\n        resp = engine.execute(sql, e1=u).fetchall()  \\n        print(resp)\\n        ref_expansion = resp[0][0]\\n        print(\\'annotated_expansion:\\', resp[0][0])\\n        print(\\'Levenshtein distance:\\',levenshtein(sys_expansion[0], ref_expansion))\\n        print(\\'spans match:\\', annotations[\\'begin\\'][0] >= resp[0][1] &  annotations[\\'end\\'][0] <= resp[0][2] | annotations[\\'begin\\'][0] >= resp[0][1] &  annotations[\\'end\\'][0] <= resp[0][2])\\n '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#systems = ['ctakes']\n",
    "#  get annotations for testing \n",
    "def levenshtein(seq1, seq2):  \n",
    "    \"\"\"\n",
    "    from https://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/\n",
    "    \"\"\"\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    #print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "def get_ref_expansion(u):\n",
    "   \n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "            # does it exist?\n",
    "    sql = text(\"SELECT expansion, file_abbrev_acronym, start, end FROM test.amia_2019_ref where `case` = :e1\")\n",
    "    resp = engine.execute(sql, e1=u).fetchall()  \n",
    "    #print(resp)\n",
    "    \n",
    "    return resp[0][0], resp[0][1], resp[0][2], resp[0][3]\n",
    "\n",
    "def get_attribs(v):\n",
    "    attribs = []\n",
    "    for sentence in v:\n",
    "        #print(sentence)\n",
    "        for s in sentence.__dir__():\n",
    "            if '__' not in s:\n",
    "                if s not in attribs:\n",
    "                    #print(s)\n",
    "                    attribs.append(s)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    return attribs\n",
    "\n",
    "def get_eval_data(fname, system, typesystem, dir_test, engine):\n",
    "   \n",
    "    file = os.path.basename(fname)\n",
    "    u = file.split('.')[0]\n",
    "\n",
    "    expansion, abbrev, begin, end = get_ref_expansion(u)\n",
    "\n",
    "    # load cas\n",
    "    with open(dir_test + file, 'rb') as f:\n",
    "        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "\n",
    "    if system == 'biomedicus':\n",
    "        view = cas.get_view('Analysis')\n",
    "    else:\n",
    "        view = cas.get_view('_InitialView')\n",
    "\n",
    "    # sofa -> db\n",
    "    def write_sofa(u):\n",
    "        d = {}\n",
    "        d[\"note_id\"] = str(u)\n",
    "        d[\"sofa\"] = view.sofa_string\n",
    "        d[\"corpus\"] = corpus\n",
    "\n",
    "        # does it exist?\n",
    "        if engine.dialect.has_table(engine, \"sofas\"):\n",
    "            sql = text(\"SELECT * FROM test.sofas WHERE note_id = :e1\")\n",
    "            resp = engine.execute(sql, e1=u).fetchall()\n",
    "        else:\n",
    "            resp = []\n",
    "\n",
    "        if len(resp) == 0:            \n",
    "            pd.DataFrame(d, index=[0]).to_sql(\"sofas\", engine, if_exists=\"append\")  \n",
    "\n",
    "    #write_sofa(u)\n",
    "\n",
    "    if system == 'biomedicus':\n",
    "        ann = ['biomedicus.v2.Acronym']\n",
    "    elif system == 'metamap':\n",
    "        ann = ['org.metamap.uima.ts.Candidate']\n",
    "    elif system == 'clamp':\n",
    "        ann = ['edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA']\n",
    "    elif system == 'ctakes':\n",
    "        ann = ['edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA']\n",
    "\n",
    "    for t in ann:\n",
    "        \n",
    "        attribs = get_attribs(view.select(t))\n",
    "        annotation_type = t\n",
    "        x = t.split('.')\n",
    "        table_name = system[0:3] + '_' + x[0] + '_' + x[len(x)-1]\n",
    "\n",
    "        # Annotation object -> dataframe\n",
    "        def get_df(v, attribs):\n",
    "            \n",
    "            \n",
    "            d = {}\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "            # only parse if type exists in file\n",
    "            if view.select(t):\n",
    "                if len(attribs) > 0: # annotation is not empty\n",
    "                    for sentence in view.select(t):\n",
    "\n",
    "                        for i in range(len(attribs)):\n",
    "\n",
    "                            key = attribs[i]\n",
    "                            val = sentence.__getattribute__(attribs[i])\n",
    "                            if system in ['biomedicus', 'clamp']:\n",
    "\n",
    "                                if system == 'biomedicus' or system == 'clamp' and key not in ['assertion', 'attr1', 'attr2', 'attr3', 'attr4', 'semanticTag']:\n",
    "\n",
    "                                    if isinstance(val, list):\n",
    "                                        val = ' '.join(val)\n",
    "                                    d[key] = val\n",
    "\n",
    "                                    if system == 'biomedicus':\n",
    "                                        if key == 'text':\n",
    "                                            #print(val)\n",
    "                                            d['levenshtein'] = levenshtein(val.lower(), expansion.lower())\n",
    "                                            d['system_expansion'] = val.lower()\n",
    "                                        if key == 'score':\n",
    "                                            d['score'] = val\n",
    "\n",
    "                                    if system == 'clamp' and key == 'attribute':\n",
    "                                        if val is not None:\n",
    "                                            if \"umlsCuiDesc\" in json.loads(val):\n",
    "                                                d['levenshtein'] = levenshtein(json.loads(val)[\"umlsCuiDesc\"].lower(), expansion.lower())\n",
    "                                                d['score'] = json.loads(val)[\"concept_prob\"]\n",
    "                                                d['system_expansion'] = json.loads(val)[\"umlsCuiDesc\"].lower()\n",
    "                                            else:\n",
    "                                                d['levenshtein']  = 999\n",
    "                                                d['score'] = None\n",
    "                                                d['system_expansion'] = None\n",
    "                                        else:\n",
    "                                            d['levenshtein']  = 999\n",
    "                                            d['score'] = None\n",
    "                                            d['system_expansion'] = None\n",
    "\n",
    "\n",
    "                            elif system == 'metamap':\n",
    "\n",
    "                                if key not in ['matchMap', 'spans', 'head', 'overmatch', 'semanticTypes', 'sofa']:\n",
    "                                    if isinstance(val, list):\n",
    "                                        val = ' '.join(val)\n",
    "                                    d[key] = val\n",
    "\n",
    "                                    if key == 'preferred':\n",
    "                                        d['levenshtein'] = levenshtein(val.lower(), expansion.lower())\n",
    "                                        d['system_expansion'] = val.lower()\n",
    "                                    if key == 'score':\n",
    "                                        d['score'] = val\n",
    "\n",
    "\n",
    "                            if i == len(attribs) - 1:\n",
    "\n",
    "                                mask = (d['begin'] >= begin and d['end'] <= end) or (d['begin'] <= begin and d['end'] >= end) \n",
    "\n",
    "                                if mask:\n",
    "                                    d['overlap'] = 1\n",
    "                                else:\n",
    "                                    d['overlap'] = 0\n",
    "\n",
    "                                frames = [ df, pd.DataFrame(d, index=[0]) ]\n",
    "                                df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "                else: # annotation had no attributes\n",
    "                    d['levenshtein'] = 9999\n",
    "                    d['system_expansion'] = 'n/a'\n",
    "                    d['overlap'] = None\n",
    "                    d['begin'] = None\n",
    "                    d['end'] = None\n",
    "                    d['score'] = None\n",
    "                    frames = [ df, pd.DataFrame(d, index=[0]) ]\n",
    "                    df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "            df['abbrev'] = abbrev\n",
    "            df[\"expansion\"] = expansion\n",
    "            df[\"ref_begin\"] = begin\n",
    "            df[\"ref_end\"] = end\n",
    "            df[\"system\"] = system\n",
    "            df[\"type\"] = annotation_type\n",
    "            df[\"case\"] = u\n",
    "            df[\"corpus\"] = 'AMIA2019'\n",
    "            df[\"filename\"] = fname\n",
    "           \n",
    "            cols_to_keep = ['abbrev', \n",
    "                            'expansion', \n",
    "                            'ref_begin', \n",
    "                            'ref_end', \n",
    "                            'system_expansion', \n",
    "                            'begin', \n",
    "                            'end', \n",
    "                            'levenshtein', \n",
    "                            'score',\n",
    "                            'overlap', \n",
    "                            'case', \n",
    "                            'system', \n",
    "                            'type', \n",
    "                            'corpus']\n",
    "            \n",
    "            df = df[cols_to_keep]\n",
    "            \n",
    "            df.to_sql(\"amia_2019_analytical\", engine, if_exists=\"append\")  \n",
    "\n",
    "            return df\n",
    "\n",
    "        data = get_df(view.select(t), attribs)\n",
    "    #return get_df(view.select(t), attribs)\n",
    "'''\n",
    "    if system == 'biomedicus':\n",
    "        sys_expansion = (annotations['text'][0], annotations['begin'][0], annotations['end'][0])\n",
    "        #print('system expansion:', annotations.head(1)['text'][0], annotations['begin'][0], annotations['end'][0] )\n",
    "\n",
    "\n",
    "        engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "                # does it exist?\n",
    "        sql = text(\"SELECT expansion, start, end FROM test.amia_2019_ref where `case` = :e1\")\n",
    "        resp = engine.execute(sql, e1=u).fetchall()  \n",
    "        print(resp)\n",
    "        ref_expansion = resp[0][0]\n",
    "        print('annotated_expansion:', resp[0][0])\n",
    "        print('Levenshtein distance:',levenshtein(sys_expansion[0], ref_expansion))\n",
    "        print('spans match:', annotations['begin'][0] >= resp[0][1] &  annotations['end'][0] <= resp[0][2] | annotations['begin'][0] >= resp[0][1] &  annotations['end'][0] <= resp[0][2])\n",
    " '''       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc = ['IT', 'OR', 'FISH', 'MOM', 'MR', 'MS']\n",
    "\n",
    "def main():\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "    systems = ['biomedicus', 'metamap', 'clamp']\n",
    "    systems = ['clamp']\n",
    "   \n",
    "    for system in systems:\n",
    "        \n",
    "        tic=timeit.default_timer() \n",
    "\n",
    "        print(system)\n",
    "        dir_test = '/Users/gms/development/nlp/nlpie/data/AMIATutorial2019/adapt/' + system + '_out/'\n",
    "\n",
    "        with open(dir_test + 'TypeSystem.xml', 'rb') as f:\n",
    "            typesystem = load_typesystem(f)\n",
    "\n",
    "        # types for metamap\n",
    "\n",
    "        if system == 'metamap':\n",
    "            t = typesystem.create_type(name='org.apache.uima.examples.SourceDocumentInformation', supertypeName='uima.tcas.Annotation')\n",
    "            typesystem.add_feature(t, name='uri', rangeTypeName='uima.cas.String')\n",
    "            typesystem.add_feature(t, name=\"offsetInSource\", rangeTypeName=\"uima.cas.Integer\")\n",
    "            typesystem.add_feature(t, name=\"documentSize\", rangeTypeName=\"uima.cas.Integer\")\n",
    "            typesystem.add_feature(t, name=\"lastSegment\", rangeTypeName=\"uima.cas.Integer\")\n",
    "\n",
    "        # features for ctakes\n",
    "\n",
    "        if system == 'ctakes':\n",
    "            t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.DiseaseDisorderMention')\n",
    "            typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "            typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "            typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "            t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.SignSymptomMention')\n",
    "            typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "            typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "            typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "            t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.MedicationMention')\n",
    "            typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "            typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "            typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "            t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.ProcedureMention')\n",
    "            typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "            typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "            t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.AnatomicalSiteMention')\n",
    "            typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "            typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "            typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "            typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "            typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        #for a in acc:\n",
    "\n",
    "    #    data = pd.DataFrame()\n",
    "\n",
    "        i = 0\n",
    "        #for fname in glob.glob(dir_test + '*_'+ a +'.txt.xmi'):\n",
    "        for fname in glob.glob(dir_test + '31685_RA.txt.xmi'):\n",
    "        #for fname in glob.glob(dir_test + '100_AB.txt.xmi'):\n",
    "        \n",
    "            if i%1000 == 0:\n",
    "                print(i, fname)\n",
    "            i += 1\n",
    "\n",
    "\n",
    "            #frames = [ data, get_eval_data(fname, system, typesystem, dir_test) ]\n",
    "            #data = pd.concat(frames, ignore_index=True)\n",
    "            get_eval_data(fname, system, typesystem, dir_test, engine)\n",
    "       \n",
    "        toc=timeit.default_timer()\n",
    "        \n",
    "        print('elapsed ', toc - tic, ' seconds for ', system, ' !!!!')\n",
    "\n",
    "#     fname = '7_AB.txt.xmi'\n",
    "#     with open(dir_test + fname, 'rb') as f:\n",
    "#         cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    " \n",
    "#     view = cas.get_view('_InitialView')\n",
    "    \n",
    "    #print([x for x in view.select(\"org.metamap.uima.ts.Candidate\")][0])\n",
    "    #print([x for x in view.select(\"biomedicus.v2.Acronym\")])\n",
    "    #print([x for x in view.select(\"gov.nih.nlm.nls.metamap.uima.ts.Document\")])\n",
    "    #print([x for x in view.select(\"org.apache.ctakes.typesystem.type.textsem.ProcedureMention\")])\n",
    "    #print([x for x in view.select(\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\")])\n",
    "#    print([x for x in view.select_all()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clamp\n",
      "0 /Users/gms/development/nlp/nlpie/data/AMIATutorial2019/adapt/clamp_out/31685_RA.txt.xmi\n",
      "elapsed  0.8016168109999171  seconds for  clamp  !!!!\n",
      "CPU times: user 712 ms, sys: 27 ms, total: 739 ms\n",
      "Wall time: 803 ms\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    %time main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
