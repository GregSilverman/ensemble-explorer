{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation class for UIMA systems\n",
    "class AnnotationSystems(object):\n",
    "    \"\"\"\n",
    "    CAS XMI Annotations of interest\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\" \n",
    "        annotation base types\n",
    "        \"\"\"\n",
    "        \n",
    "        self.biomedicus_dir = \"biomedicus_out/\"\n",
    "        self.biomedicus_types = [\"biomedicus.v2.UmlsConcept\",\n",
    "                                 \"biomedicus.v2.Negated\",\n",
    "                                 \"biomedicus.v2.Acronym\"]\n",
    "        \n",
    "        \n",
    "        self.clamp_dir = \"clamp_out/\"\n",
    "        self.clamp_types = [\"edu.uth.clamp.nlp.typesystem.ClampNameEntityUIMA\",\n",
    "                            \"edu.uth.clamp.nlp.typesystem.ClampRelationUIMA\"]\n",
    "        \n",
    "        \n",
    "        self.ctakes_dir = \"ctakes_out/\"\n",
    "        self.ctakes_types = [\"org.apache.ctakes.typesystem.type.textsem.DiseaseDisorderMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.MedicationMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.ProcedureMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.SignSymptomMention\",\n",
    "                             \"org.apache.ctakes.typesystem.type.textsem.AnatomicalSiteMention\"]\n",
    "        \n",
    "        self.metamap_dir = \"metamap_out/\"\n",
    "        self.metamap_types = [\"org.metamap.uima.ts.Candidate\",\n",
    "                              \"org.metamap.uima.ts.CuiConcept\",\n",
    "                              \"org.metamap.uima.ts.Negation\"]\n",
    "                \n",
    "       \n",
    "    def get_system_type(self, system):\n",
    "        \n",
    "        \"\"\"\n",
    "        return system types\n",
    "        \"\"\"\n",
    "        \n",
    "        if system == \"biomedicus\":\n",
    "            view = \"Analysis\"\n",
    "            \n",
    "        else:\n",
    "            view = \"_InitialView\"\n",
    "\n",
    "        if system == 'biomedicus':\n",
    "            types = self.biomedicus_types\n",
    "            output = self.biomedicus_dir\n",
    "\n",
    "        elif system == 'clamp':\n",
    "            types = self.clamp_types\n",
    "            output = self.clamp_dir\n",
    "\n",
    "        elif system == 'ctakes':\n",
    "            types = self.ctakes_types\n",
    "            output = self.ctakes_dir\n",
    "\n",
    "        elif system == 'metamap':\n",
    "            types = self.metamap_types\n",
    "            output = self.metamap_dir\n",
    "            \n",
    "        return types, view, output\n",
    "    \n",
    "annSys = AnnotationSystems()\n",
    "\n",
    "# extract attributes from cas Annotation object\n",
    "def get_attribs(v):\n",
    "    attribs = []\n",
    "    for sentence in v:\n",
    "        #print(sentence)\n",
    "        for s in sentence.__dir__():\n",
    "            if '__' not in s:\n",
    "                if s not in attribs:\n",
    "                    #print(s)\n",
    "                    attribs.append(s)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    return attribs\n",
    "\n",
    "def get_cols_to_keep(system, t):\n",
    "    \n",
    "    if system == 'biomedicus':\n",
    "        \n",
    "        # umlsconcept\n",
    "        if 'Umls' in t:\n",
    "            cols_to_keep = ['begin', 'confidence', 'cui', 'end', 'source', 'sui', 'tui',\n",
    "                            'type', 'xmiID', 'system', 'note_id', 'corpus',\n",
    "                            'filename']\n",
    "\n",
    "        # acronym\n",
    "        if 'Acronym' in t:\n",
    "            cols_to_keep = ['begin', 'end', 'hasSpaceAfter', 'score', 'text', 'type',\n",
    "                            'xmiID', 'system', 'note_id', 'corpus', 'filename']\n",
    "\n",
    "        # negated\n",
    "        if 'Negated' in t:\n",
    "            cols_to_keep = ['begin', 'cueTerms', 'end', 'type', 'xmiID',\n",
    "                           'system', 'note_id', 'corpus', 'filename']\n",
    "        \n",
    "    elif system == 'clamp':\n",
    "        #NE uima\n",
    "        if 'NameEntityUIMA' in t:\n",
    "            cols_to_keep = ['assertion', 'attr1', 'attr2', 'attr3', 'attr4', 'attribute', 'begin',\n",
    "                           'cui', 'end', 'semanticTag', 'type', \n",
    "                           'xmiID', 'system', 'note_id', 'corpus', 'filename', 'umlsCuiDesc', 'concept_prob', 'sentence_prob']\n",
    "\n",
    "        # relation uima: TODO -> deal with named tuples!\n",
    "        if 'Relation' in t:\n",
    "            cols_to_keep = ['attr1', 'attr2', 'attr3', 'attr4', 'attribute', 'entFrom', 'entTo',\n",
    "                           'semanticTag', 'type', 'xmiID', 'system', 'note_id',\n",
    "                           'corpus', 'filename']\n",
    "        \n",
    "    elif system == 'ctakes':\n",
    "        # disease\n",
    "        if 'Disease' in t:\n",
    "            cols_to_keep = ['alleviatingFactor', 'associatedSignSymptom', 'begin', 'bodyLaterality',\n",
    "                           'bodyLocation', 'bodySide', 'conditional', 'confidence', 'course',\n",
    "                           'discoveryTechnique', 'duration', 'end', 'endTime', 'event',\n",
    "                           'exacerbatingFactor', 'generic', 'historyOf', 'id',\n",
    "                           'ontologyConceptArr', 'polarity', 'relativeTemporalContext', 'severity',\n",
    "                           'startTime', 'subject', 'type', 'typeID', 'uncertainty',\n",
    "                           'xmiID', 'system', 'note_id', 'corpus', 'filename', 'cui', 'preferredText']\n",
    "\n",
    "        # medication\n",
    "        if 'Medication' in t:\n",
    "            cols_to_keep = ['begin', 'conditional', 'confidence', 'discoveryTechnique', 'end',\n",
    "                           'endDate', 'event', 'generic', 'historyOf', 'id', 'medicationAllergy',\n",
    "                           'medicationDosage', 'medicationDuration', 'medicationForm',\n",
    "                           'medicationFrequency', 'medicationRoute', 'medicationStatusChange',\n",
    "                           'medicationStrength', 'ontologyConceptArr', 'polarity',\n",
    "                           'relativeTemporalContext', 'startDate', 'subject', 'type',\n",
    "                           'typeID', 'uncertainty', 'xmiID', 'system',\n",
    "                           'note_id', 'corpus', 'filename', 'cui', 'preferredText']\n",
    "\n",
    "        # proc\n",
    "        if 'Procedure' in t:\n",
    "            cols_to_keep = ['begin', 'bodyLaterality', 'bodyLocation', 'bodySide', 'conditional',\n",
    "                           'confidence', 'discoveryTechnique', 'duration', 'end', 'endTime',\n",
    "                           'event', 'generic', 'historyOf', 'id', 'method', 'ontologyConceptArr',\n",
    "                           'polarity', 'procedureDevice', 'relativeTemporalContext', \n",
    "                           'startTime', 'subject', 'type', 'typeID', 'uncertainty',\n",
    "                           'xmiID', 'system', 'note_id', 'corpus', 'filename', 'cui', 'preferredText']\n",
    "\n",
    "        # sign\n",
    "        if 'SignSymptom' in t:\n",
    "            cols_to_keep = ['alleviatingFactor', 'begin', 'bodyLaterality', 'bodyLocation',\n",
    "                           'bodySide', 'conditional', 'confidence', 'course', 'discoveryTechnique',\n",
    "                           'duration', 'end', 'endTime', 'event', 'exacerbatingFactor', 'generic',\n",
    "                           'historyOf', 'id', 'ontologyConceptArr', 'polarity',\n",
    "                           'relativeTemporalContext', 'severity', 'startTime', 'subject',\n",
    "                           'type', 'typeID', 'uncertainty', 'xmiID', 'system',\n",
    "                           'note_id', 'corpus', 'filename', 'cui', 'preferredText']\n",
    "\n",
    "        # anatomy\n",
    "        if 'Anatomical' in t:\n",
    "            cols_to_keep = ['begin', 'bodyLaterality', 'bodySide', 'conditional', 'confidence',\n",
    "                           'discoveryTechnique', 'end', 'entity', 'generic', 'historyOf', 'id',\n",
    "                           'ontologyConceptArr', 'polarity', 'subject', 'type', 'typeID',\n",
    "                           'uncertainty', 'xmiID', 'system', 'note_id',\n",
    "                           'corpus', 'filename', 'cui', 'preferredText']\n",
    "        \n",
    "    elif system == 'metamap':\n",
    "        #candidate\n",
    "        if 'Candidate' in t:\n",
    "            cols_to_keep = ['begin', 'concept', 'cui', 'end', 'head', 'matchMap', 'matchedwords',\n",
    "                           'overmatch', 'preferred', 'score', 'semanticTypes', 'sources',\n",
    "                           'spans', 'type', 'xmiID', 'system', 'note_id',\n",
    "                           'corpus', 'filename']\n",
    "\n",
    "        #cuiconcept\n",
    "        if 'CuiConcept' in t:\n",
    "            cols_to_keep = ['id', 'negExConcept', 'negExCui', 'type', 'xmiID',\n",
    "                           'system', 'note_id', 'corpus', 'filename']\n",
    "\n",
    "        #negation\n",
    "        if 'Negation' in t:\n",
    "            cols_to_keep = ['begin', 'cuiConcepts', 'end', 'id', 'ncSpans', 'negTrigger', 'negType',\n",
    "                           'ntSpans', 'type', 'xmiID', 'system',\n",
    "                           'note_id', 'corpus', 'filename']\n",
    "    \n",
    "    else:\n",
    "        cols_to_keep = []\n",
    "\n",
    "    return cols_to_keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cassis(system, typesystem):\n",
    "   \n",
    "    #tic=timeit.default_timer() \n",
    "\n",
    "    print(system)\n",
    "\n",
    "    # types for metamap\n",
    "\n",
    "    if system == 'metamap':\n",
    "        t = typesystem.create_type(name='org.apache.uima.examples.SourceDocumentInformation', supertypeName='uima.tcas.Annotation')\n",
    "        typesystem.add_feature(t, name='uri', rangeTypeName='uima.cas.String')\n",
    "        typesystem.add_feature(t, name=\"offsetInSource\", rangeTypeName=\"uima.cas.Integer\")\n",
    "        typesystem.add_feature(t, name=\"documentSize\", rangeTypeName=\"uima.cas.Integer\")\n",
    "        typesystem.add_feature(t, name=\"lastSegment\", rangeTypeName=\"uima.cas.Integer\")\n",
    "\n",
    "    # features for ctakes\n",
    "\n",
    "    if system == 'ctakes':\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.structured.Metadata')\n",
    "        typesystem.add_feature(t, name='patientIdentifier', rangeTypeName='uima.cas.String')\n",
    "        \n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.DiseaseDisorderMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.SignSymptomMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.MedicationMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.ProcedureMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n",
    "\n",
    "        t = typesystem.get_type('org.apache.ctakes.typesystem.type.textsem.AnatomicalSiteMention')\n",
    "        typesystem.add_feature(t, name='id', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='ontologyConceptArr', rangeTypeName='uima.cas.FSArray', elementType='org.apache.ctakes.typesystem.type.refsem.UmlsConcept')\n",
    "        typesystem.add_feature(t, name='subject', rangeTypeName='uima.cas.String')\n",
    "        typesystem.add_feature(t, name='typeID', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='discoveryTechnique', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='confidence', rangeTypeName='uima.cas.Double')\n",
    "        typesystem.add_feature(t, name='polarity', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='uncertainty', rangeTypeName='uima.cas.Integer')\n",
    "        typesystem.add_feature(t, name='conditional', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='generic', rangeTypeName='uima.cas.Boolean')\n",
    "        typesystem.add_feature(t, name='historyOf', rangeTypeName='uima.cas.Integer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# parse system annotations\n",
    "def main():\n",
    "    import os, glob\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    #from superjson import json\n",
    "    \n",
    "    from sqlalchemy.engine import create_engine\n",
    "    from sqlalchemy.sql import text\n",
    "    from cassis import load_typesystem, load_cas_from_xmi\n",
    "\n",
    "    # connection string\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)\n",
    "    systems = [\"metamap\", \"ctakes\", \"biomedicus\", \"clamp\"]\n",
    "    #systems = [\"clamp\"]\n",
    "    \n",
    "    corpora = [\"fairview\", \"mipacq\", \"i2b2\"]\n",
    "    parse_to_sql = True\n",
    "    \n",
    "    i = 0\n",
    "    if parse_to_sql:\n",
    "        \n",
    "        for corpus in corpora:\n",
    "            print(\"CORPUS:\", corpus)\n",
    "\n",
    "            for system in systems:\n",
    "\n",
    "                print(\"SYSTEM:\", system)\n",
    "\n",
    "                types, view_, output = annSys.get_system_type(system)\n",
    "                \n",
    "                dir_test = '/Users/gms/development/nlp/nlpie/scripts/jupyter/ensembling/typesystems/' + system + '/'\n",
    "\n",
    "                with open(dir_test + 'TypeSystem.xml', 'rb') as f:\n",
    "                    typesystem = load_typesystem(f)\n",
    "                \n",
    "                init_cassis(system, typesystem)\n",
    "                \n",
    "                # parse directory\n",
    "                if corpus in [\"i2b2\", \"mipacq\"]:\n",
    "                    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/' + corpus + '/rerun-november-2019/' +  system + '_out/' #data_to_analyze/all/'\n",
    "                \n",
    "                elif corpus == 'fairview':\n",
    "                    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/' + corpus + '/system_annotations/data_in_preprocessed/' +  system + '_out/'#data_to_analyze/all/'\n",
    "                    \n",
    "                else:\n",
    "                    directory_to_parse = '/Users/gms/development/nlp/nlpie/data/mimic/'\n",
    "                    \n",
    "                print(directory_to_parse)\n",
    "\n",
    "                for fname in glob.glob(directory_to_parse + '/*.xmi'):\n",
    "                #for fname in glob.glob(directory_to_parse + '/527982345.txt.xmi'):\n",
    "\n",
    "                    file = os.path.basename(fname)\n",
    "                    u = file.split('.')[0]\n",
    "\n",
    "                    print(u)\n",
    "\n",
    "                    # load cas\n",
    "                    with open(directory_to_parse + file, 'rb') as f:\n",
    "                        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "\n",
    "                    # load view\n",
    "                    view = cas.get_view(view_)\n",
    "\n",
    "                    # sofa -> db\n",
    "                    def write_sofa(u):\n",
    "                        d = {}\n",
    "                        d[\"note_id\"] = str(u)\n",
    "                        d[\"sofa\"] = view.sofa_string\n",
    "                        d[\"corpus\"] = corpus\n",
    "\n",
    "                        # does it exist?\n",
    "                        if engine.dialect.has_table(engine, \"sofas\"):\n",
    "                            sql = text(\"SELECT * FROM test.sofas WHERE note_id = :e1\")\n",
    "                            resp = engine.execute(sql, e1=u).fetchall()\n",
    "                        else:\n",
    "                            resp = []\n",
    "\n",
    "                        if len(resp) == 0:            \n",
    "                            pd.DataFrame(d, index=[0]).to_sql(\"sofas\", engine, if_exists=\"append\")  \n",
    "\n",
    "                    write_sofa(u)\n",
    "\n",
    "                    for t in types:\n",
    "                        print(\"TYPE:\", t)\n",
    "                       \n",
    "                        # get list for filtering df\n",
    "                        cols_to_keep = get_cols_to_keep(system, t)\n",
    "                        \n",
    "                        attribs = get_attribs(view.select(t))\n",
    "                        annotation_type = t\n",
    "                        x = t.split('.')\n",
    "                        table_name = system[0:3] + '_' + x[0] + '_' + x[len(x)-1]\n",
    "\n",
    "                        # Annotation object -> dataframe\n",
    "                        def get_df(v, attribs):\n",
    "                            d = {}\n",
    "                            df = pd.DataFrame()\n",
    "\n",
    "                            # only parse if type exists in file\n",
    "                            if view.select(t):\n",
    "                                for sentence in view.select(t):\n",
    "                                    \n",
    "                                    for i in range(len(attribs)):\n",
    "                                        key = attribs[i]\n",
    "                                        val = sentence.__getattribute__(attribs[i])\n",
    "                                       \n",
    "                                        # TODO: convert to list and unstack\n",
    "                                        if key == 'ontologyConceptArr':\n",
    "                                            pass\n",
    "                                    \n",
    "                                        if system == 'clamp' and key == 'attribute':\n",
    "                                            if val is not None and val:\n",
    "                                                if \"umlsCuiDesc\" in json.loads(val):\n",
    "                                                    d['umlsCuiDesc'] = json.loads(val)[\"umlsCuiDesc\"].lower()\n",
    "                                                else:\n",
    "                                                    d['umlsCuiDesc'] = None\n",
    "                                        \n",
    "                                                if \"concept_prob\" in json.loads(val):\n",
    "                                                    d['concept_prob'] = json.loads(val)[\"concept_prob\"]\n",
    "                                                else:\n",
    "                                                    d['concept_prob'] = None\n",
    "                                                \n",
    "                                                if \"sentence_prob\" in json.loads(val):\n",
    "                                                    d['sentence_prob'] = json.loads(val)[\"concept_prob\"]\n",
    "                                                else:\n",
    "                                                    d['sentence_prob'] = None\n",
    "                                                   \n",
    "                                            else:\n",
    "                                                d['umlsCuiDesc'] = None\n",
    "                                                d['concept_prob'] = None\n",
    "                                                d['sentence_prob'] = None\n",
    "                                            \n",
    "                                        if key in ['entFrom', 'entTo']:\n",
    "                                            if val.attribute:\n",
    "                                                attribute = json.loads(val.attribute)\n",
    "                                            else:\n",
    "                                                attribute = None\n",
    "                                                \n",
    "                                            val = json.dumps({\"begin\": val.begin, \"end\": val.end, \"cui\": val.cui, \"attribute\": attribute})\n",
    "                                            \n",
    "                                        if isinstance(val, list):\n",
    "                                            val = ' '.join(map(str,val)) # flatten list to space delimited variable\n",
    "                                        \n",
    "                                        d[key] = val\n",
    "                                       \n",
    "                                        # entire sentence has be iterated through\n",
    "                                        if i == len(attribs) - 1:\n",
    "                                            frames = [ df, pd.DataFrame(d, index=[0]) ]\n",
    "                                            df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "                            df[\"system\"] = system\n",
    "                            df[\"type\"] = annotation_type\n",
    "                            df[\"note_id\"] = u\n",
    "                            df[\"corpus\"] = corpus\n",
    "                            df[\"filename\"] = fname\n",
    "                            return df\n",
    "\n",
    "                        annotations = get_df(view.select(t), attribs)\n",
    "\n",
    "                        # write to database\n",
    "                        if not annotations.empty:\n",
    "                            # handle extraction of elements from named tuple converted to str\n",
    "                            if 'Mention' in t and not annotations.empty:\n",
    "                                # stack string delimited by \") /\" into multiple rows (initially represented by list of named tuples)\n",
    "                                b = pd.DataFrame(annotations.ontologyConceptArr.str.split('\\) o').tolist(), index=annotations.ontologyConceptArr).stack()\n",
    "                                b = b.reset_index()[[0, 'ontologyConceptArr']] # var1 variable is currently labeled 0\n",
    "                                b.columns = ['concept', 'ontologyConceptArr'] # renaming var1\n",
    "\n",
    "                                c = pd.merge(annotations, b)\n",
    "\n",
    "                                c['cui'] = c['concept'].str.extract(pat = 'cui=(.[^,]+)').apply(lambda s:s.str.replace(\"'\", \"\")) \n",
    "                                c['preferredText'] = c['concept'].str.extract(pat = 'preferredText=(.[^,]+)').apply(lambda s:s.str.replace(\"'\", \"\"))\n",
    "                            \n",
    "                                annotations = c\n",
    "                            \n",
    "                            annotations = annotations[cols_to_keep]\n",
    "                            annotations.to_sql(table_name, engine, if_exists=\"append\") \n",
    "   \n",
    "    # write out annotations for non-cui tables\n",
    "    else:\n",
    "        \n",
    "        sys_ann_other = pd.DataFrame()\n",
    "        for system in systems:\n",
    "                \n",
    "            types, view_, output = annSys.get_system_type(system)\n",
    "            print(\"SYSTEM:\", system)\n",
    "           \n",
    "            for t in types:\n",
    "\n",
    "                x = t.split('.')\n",
    "                table_name = system[0:3] + '_' + x[0] + '_' + x[len(x)-1]\n",
    "\n",
    "                sql = \"SELECT * FROM test.\" + table_name \n",
    "                df = pd.read_sql(sql, engine)\n",
    "\n",
    "                cols_to_keep = ['begin', 'end', 'type', 'system', 'note_id', 'corpus', 'filename']\n",
    "                #print(system, t, table_name, list(df[cols_to_keep].columns.values))\n",
    "                \n",
    "                frames = [ sys_ann_other, df[cols_to_keep] ]\n",
    "                sys_ann_other = pd.concat(frames, ignore_index=True)\n",
    "        \n",
    "        print(sys_ann_other.drop_duplicates())\n",
    "        sys_ann_other.drop_duplicates().to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_mipacq_others.csv')\n",
    "\n",
    "    print(\"done!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    from sqlalchemy.engine import create_engine\n",
    "sql = 'select ontologyConceptArr from concepts.cta_org_DiseaseDisorderMention'\n",
    "engine = create_engine('mysql+pymysql://gms:nej123@localhost/concepts', pool_pre_ping=True)\n",
    "\n",
    "\n",
    "pd.read_sql(sql, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables for cTAKES UMLS concept -> mention table\n",
    "# https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows\n",
    "\n",
    "def mk_ctakes_concepts(sql, table_name):\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    from sqlalchemy.engine import create_engine\n",
    "\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "\n",
    "    df = pd.read_sql(sql, engine)\n",
    "\n",
    "    # MetaMap\n",
    "    b = pd.DataFrame(df.cuiConcepts.str.split(' ').tolist(), index=df.cuiConcepts).stack()\n",
    "    b = b.reset_index()[[0, 'cuiConcepts']] # var1 variable is currently labeled 0\n",
    "    b.columns = ['linked_id', 'cuiConcepts'] # renaming var1\n",
    "    \n",
    "    # CTAKES:\n",
    "     \n",
    "    #b = pd.DataFrame(df.ontologyConceptArr.str.split(' ').tolist(), index=df.ontologyConceptArr).stack()\n",
    "    #b = b.reset_index()[[0, 'ontologyConceptArr']] # var1 variable is currently labeled 0\n",
    "    #b.columns = ['linked_id', 'ontologyConceptArr'] # renaming var1\n",
    "    \n",
    "\n",
    "    c = pd.merge(df, b)\n",
    "   \n",
    "    c.to_sql(table_name, engine, if_exists=\"replace\") \n",
    "\n",
    "    print(c[0:2])\n",
    "\n",
    "''' TABLES to make\n",
    "sql = \"SELECT * FROM test.met_org_negation\"\n",
    "table_name = 'mm_negation'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "'''\n",
    "'''\n",
    "sql = \"SELECT * FROM test.cta_disease\"\n",
    "table_name = 'cTAKES_disease'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_med\"\n",
    "table_name = 'cTAKES_medication'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_proc\"\n",
    "table_name = 'cTAKES_procedure'\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_sign_symptom\"\n",
    "table_name = 'cTAKES_sign_symptom'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "\n",
    "sql = \"SELECT * FROM test.cta_anatomical_site\"\n",
    "table_name = 'cTAKES_anatomical_site'\n",
    "\n",
    "mk_ctakes_concepts(sql, table_name)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix XMI, adding \"id\" for those with linked features\n",
    "\n",
    "def add_attribute_sys_type(regexpatterns):\n",
    "    import re, os, glob, path\n",
    "    import regex\n",
    "\n",
    "    #directory_to_parse = '/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/quarantine/'\n",
    "\n",
    "    #for fname in glob.iglob(\"/Users/gms/development/nlp/nlpie/data/amia-2019/i2b2/quarantine/period2/*.txt\"):\n",
    "\n",
    "    for fname in glob.iglob(\"/Users/gms/development/nlp/nlpie/data/amia-2019/analysis/mipacq/rerun_post_validation/metamap_out/*.txt.xmi\"):\n",
    "\n",
    "        # get filename and use for processed output filename\n",
    "        t = os.path.basename(fname)\n",
    "        cd = os.path.dirname(fname)\n",
    "        u = t.split('.')[0] + '-v2.txt.xmi'\n",
    "        #print(t, cd)\n",
    "\n",
    "        #print(t)\n",
    "        with open(fname) as f:\n",
    "            with open(cd + '/' + u, 'w') as f2:\n",
    "                for line in f:\n",
    "                    for r in regexpatterns:\n",
    "                        line = re.sub(r, r + ' id=\"0\"', line)\n",
    "                    f2.write(line)\n",
    "    \n",
    "\n",
    "#regexpatterns = [r\"refsem:UmlsConcept\"]\n",
    "#regexpatterns = [r\"ts2:CuiConcept\"]\n",
    "#regexpatterns = [r\"ts2:Negation\"]\n",
    "\n",
    "#add_attribute_sys_type(regexpatterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dkpro-cassis\n",
    "from cassis import *\n",
    "def test_dkpro(fname, dir_test, ts_test, view_name):\n",
    "    with open(ts_test + 'TypeSystem.xml', 'rb') as f:\n",
    "        typesystem = load_typesystem(f)\n",
    "    with open(dir_test + fname, 'rb') as f:\n",
    "        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
    "    view = cas.get_view(view_name)\n",
    "    print([x for x in view.select_all()])\n",
    "    #print([x for x in view.select(\"org.apache.ctakes.typesystem.type.refsem.UmlsConcept\")])\n",
    "\n",
    "\n",
    "# dir_test = '/Users/gms/development/nlp/nlpie/data/amia-2019/analysis/mipacq/metamap_out/'\n",
    "# view_name = \"_InitialView\"\n",
    "# ts_test = \"/Users/gms/development/nlp/nlpie/data/amia-2019/typesystems/metamap/\"\n",
    "# fname = '3283236649-v1.txt.xmi'\n",
    "# test_dkpro(fname, dir_test, ts_test, view_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables for\n",
    "# https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows\n",
    "\n",
    "def get_analytical_set(sql):\n",
    "    import pymysql\n",
    "    import pandas as pd\n",
    "    from sqlalchemy.engine import create_engine\n",
    "\n",
    "    engine = create_engine('mysql+pymysql://gms:nej123@localhost/test', pool_pre_ping=True)\n",
    "\n",
    "    df = pd.read_sql(sql, engine)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#GENERATE analytical tables\n",
    "'''\n",
    "analytical_cui = pd.DataFrame()\n",
    "\n",
    "sql = \"SELECT * FROM test.biomedicus_cui where corpus = 'mipacq'\"\n",
    "\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "sql = \"SELECT * FROM test.clamp_all_cui where corpus = 'mipacq'\"\n",
    "\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "sql = \"SELECT * FROM test.ctakes_all_types_cui where corpus = 'mipacq'\"\n",
    "\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "sql = \"SELECT * FROM test.metamap_all_cui where corpus = 'mipacq'\"\n",
    "\n",
    "print(get_analytical_set(sql)[0:1])\n",
    "frames = [ analytical_cui, get_analytical_set(sql) ]\n",
    "analytical_cui = pd.concat(frames, ignore_index=True, sort=False) \n",
    "\n",
    "print(analytical_cui[0:1])\n",
    "analytical_cui.to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up cui list in clamp\n",
    "#df['stridx']=df.index\n",
    "\n",
    "\n",
    "#print(df[df['cui'].str.contains(',')==True])\n",
    "\n",
    "#df['new_cui' ] = np.where(df.cui.str.contains(','), df['cui'].str.split(r'\\s*,\\s*|\\s*\\.\\s*').str[0], df['cui'])\n",
    "\n",
    "#print(df['cui'])\n",
    "#print(df[df['cui'].str.contains(',')==False])\n",
    "\n",
    "#new = df.rename(columns={'cui': 'old_cui', 'new_cui': 'cui'}).copy() \n",
    "#new.to_csv('/Users/gms/development/nlp/nlpie/data/amia-2019/output/analytical_cui_mipacq_concepts_new.csv')\n",
    "#writer = pd.ExcelWriter('/Users/gms/development/nlp/nlpie/data/amia-2019/output/ensemble/merged_metrics.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
