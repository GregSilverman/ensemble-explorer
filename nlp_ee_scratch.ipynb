{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pymysql\n",
    "import time \n",
    "import functools as ft\n",
    "import glob, os   \n",
    "import operator as op\n",
    "import shelve\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, permutations\n",
    "from sqlalchemy.engine import create_engine\n",
    "from datetime import datetime\n",
    "from ast import literal_eval\n",
    "from scipy import stats  \n",
    "from scipy.stats.mstats import gmean\n",
    "from pythonds.basic.stack import Stack\n",
    "from pythonds.trees.binaryTree import BinaryTree\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from typing import List, Set, Tuple \n",
    "\n",
    "\n",
    "data_directory = '/Users/gms/development/nlp/nlpie/data/ensembling-u01/output/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS\n",
    "\n",
    "def get_results():\n",
    "    results = pd.DataFrame()\n",
    "    for fname in glob.glob(data_directory + '/submission/combined/*.csv'):\n",
    "\n",
    "        #print(fname)\n",
    "        t = os.path.basename(fname)\n",
    "        corpus = t.split('_')[0]\n",
    "        #print(corpus)\n",
    "        semtypes = t.split('_')[-2:-1][0]\n",
    "        print(t.split('_')[-2:-1], t, corpus, semtypes)\n",
    "\n",
    "        temp = pd.read_csv(fname) \n",
    "\n",
    "        temp['corpus'] = corpus\n",
    "        temp['semtypes'] = semtypes\n",
    "        temp['file'] = t\n",
    "\n",
    "        frames = [ temp, results ]\n",
    "        results = pd.concat(frames)\n",
    "\n",
    "\n",
    "    merges = results.copy()\n",
    "    merges = merges.rename(index=str, columns={\"n_gold\": \"n_ref\"})\n",
    "\n",
    "    # sfingle system evaluation\n",
    "    cols_to_keep = ['merge', 'corpus', 'semtypes', 'F', 'precision', 'recall', 'n_sys', 'n_gold']    \n",
    "    #print(results[cols_to_keep][results['merge'].isin(['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'])].sort_values(by=['corpus', 'merge', 'semtypes']).rename(index=str, columns={\"merge\": \"system\", \"n_gold\": \"n_ref\"}))\n",
    "    df = results[cols_to_keep][results['merge'].isin(['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'])].sort_values(by=['corpus', 'merge', 'semtypes']).rename(index=str, columns={\"merge\": \"system\", \"n_gold\": \"n_ref\"}).copy()\n",
    "    #df.to_csv(data_directory + '/submission/single_system_summary.csv')\n",
    "\n",
    "    merges.reset_index(inplace=True)\n",
    "    merges = merges[~merges['merge'].isin(['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'])]\n",
    "    max_f = merges.copy()\n",
    "    max_p = merges.copy()\n",
    "    max_r = merges.copy()\n",
    "    #print(len(max_f), len(max_p), len(max_r))\n",
    "    \n",
    "    # https://datascience.stackexchange.com/questions/26308/after-grouping-to-minimum-value-in-pandas-how-to-display-the-matching-row-resul\n",
    "    cols_to_keep = ['merge', 'corpus', 'semtypes', 'F', 'precision', 'recall', 'n_sys', 'n_ref']    \n",
    "    f = max_f.loc[max_f.groupby(['corpus','semtypes'])['F'].idxmax()]\n",
    "    f = f[cols_to_keep].sort_values(by=['corpus','semtypes'])\n",
    "\n",
    "    cols_to_keep = ['merge', 'corpus', 'semtypes', 'F', 'precision', 'recall', 'n_sys', 'n_ref']    \n",
    "    p = max_p.loc[max_p.groupby(['corpus','semtypes'])['precision'].idxmax()]\n",
    "    p = p[cols_to_keep].sort_values(by=['corpus','semtypes'])\n",
    "\n",
    "    cols_to_keep = ['merge', 'corpus', 'semtypes', 'F', 'precision', 'recall', 'n_sys', 'n_ref']    \n",
    "    r = max_r.loc[max_r.groupby(['corpus','semtypes'])['recall'].idxmax()]\n",
    "    r = r[cols_to_keep].sort_values(by=['corpus','semtypes'])\n",
    "    #print(len(f), len(p), len(r))\n",
    "    #print(f, p, r)\n",
    "\n",
    "    writer = pd.ExcelWriter(data_directory + '/submission/max_merge_summary.xlsx', engine='xlsxwriter')\n",
    "    f.to_excel(writer, sheet_name='max F-score')\n",
    "    p.to_excel(writer, sheet_name='max precision')\n",
    "    r.to_excel(writer, sheet_name='max recall')\n",
    "    writer.save()\n",
    "    \n",
    "get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def geometric_mean(metrics):\n",
    "    \"\"\"\n",
    "    1. Get rank average of F1, TP/FN, TM\n",
    "        http://www.datasciencemadesimple.com/rank-dataframe-python-pandas-min-max-dense-rank-group/\n",
    "        https://stackoverflow.com/questions/46686315/in-pandas-how-to-create-a-new-column-with-a-rank-according-to-the-mean-values-o?rq=1\n",
    "    2. Take geomean of 2.\n",
    "        https://stackoverflow.com/questions/42436577/geometric-mean-applied-on-row\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    metrics['F1 rank']=metrics['F'].rank(ascending=0,method='average')\n",
    "    metrics['TP/FN rank']=metrics['TP/FN'].rank(ascending=0,method='average')\n",
    "    metrics['TM rank']=metrics['TM'].rank(ascending=0,method='average')\n",
    "    metrics['Gmean'] = gmean(metrics.iloc[:,-3:],axis=1)\n",
    "\n",
    "    return metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mipacq_Anatomy_combined\n",
      "mipacq_Disorders,Sign-Symptom_combined\n",
      "mipacq_Procedures_combined\n",
      "i2b2_test,treatment_combined\n",
      "mipacq_Chemicals-drug_combined\n",
      "i2b2_problem_combined\n",
      "mipacq_all_combined\n",
      "fairview_Drug_combined\n",
      "fairview_all_combined\n",
      "fairview_Procedure_combined\n",
      "fairview_Finding_combined\n",
      "i2b2_all_combined\n",
      "fairview_Anatomy_combined\n"
     ]
    }
   ],
   "source": [
    "def get_vote():\n",
    "    results = pd.DataFrame()\n",
    "    for fname in glob.glob(data_directory + '/submission/vote/*.csv'):\n",
    "\n",
    "        #print(fname)\n",
    "        t = os.path.basename(fname)\n",
    "        corpus = t.split('_')[0]\n",
    "        print(corpus)\n",
    "        semtypes = t.split('_')[-2:-1][0]\n",
    "        print(t.split('_')[-2:-1], t, corpus, semtypes)\n",
    "\n",
    "        temp = pd.read_csv(fname) \n",
    "\n",
    "        temp['corpus'] = corpus\n",
    "        temp['semtypes'] = semtypes\n",
    "        temp['file'] = t\n",
    "\n",
    "        frames = [ temp, results ]\n",
    "        results = pd.concat(frames)\n",
    "        \n",
    "    merges = results.copy()\n",
    "    merges = merges.rename(index=str, columns={\"n_gold\": \"n_ref\"})\n",
    "    \n",
    "    # sfingle system evaluation\n",
    "    cols_to_keep = ['merge', 'corpus', 'semtypes', 'F', 'precision', 'recall', 'n_sys', 'n_gold']    \n",
    "    #print(results[cols_to_keep][results['merge'].isin(['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'])].sort_values(by=['corpus', 'merge', 'semtypes']).rename(index=str, columns={\"merge\": \"system\", \"n_gold\": \"n_ref\"}))\n",
    "    #df = results[cols_to_keep][results['merge'].isin(['biomedicus', 'clamp', 'ctakes', 'metamap', 'quick_umls'])].sort_values(by=['corpus', 'merge', 'semtypes']).rename(index=str, columns={\"merge\": \"system\", \"n_gold\": \"n_ref\"}).copy()\n",
    "    results.to_csv(data_directory + '/submission/vote_summary.csv')\n",
    "\n",
    "#get_vote()\n",
    "def update_complete_data():\n",
    "    metrics = pd.DataFrame()\n",
    "    for fname in glob.glob(data_directory + '/submission/combined/*.csv'):\n",
    "\n",
    "        #print(fname)\n",
    "        t = os.path.basename(fname)\n",
    "        u = t.split('.')[0]\n",
    "        print(u)\n",
    "        now = datetime.now()\n",
    "        timestamp = datetime.timestamp(now)\n",
    "        \n",
    "        df = pd.read_csv(fname)\n",
    "        df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'F1 rank', 'TP/FN rank', 'TM rank', 'Gmean'], axis=1, inplace=True)\n",
    "        #print(df.head(1))\n",
    "        #print(geometric_mean(df)) \n",
    "        \n",
    "        new_file_name = u + '_' + str(timestamp) + '.csv'\n",
    "        geometric_mean(df).to_csv(data_directory + '/submission/combined/' + new_file_name)\n",
    "        \n",
    "update_complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df = pd.read_csv(data_directory + '/submission/single_system_summary.csv')\n",
    "#print(df)\n",
    "\n",
    "out = pd.pivot_table(df, values = ['precision', 'recall', 'F'], index=['corpus','semtypes'], columns = 'system').reset_index()\n",
    "\n",
    "out.to_csv(data_directory + '/submission/single_system_out.csv')\n",
    "'''\n",
    "#df = pd.read_csv(data_directory + '/submission/test.csv')\n",
    "# #print(df)\n",
    "\n",
    "#pd.pivot_table(df, values = ['clinical_m1', 'clinical_m2'], index=['test_number','clinical_type'], columns = 'system').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from functools import reduce\n",
    "f = pd.read_excel(open(data_directory + '/submission/max_merge_summary.xlsx', 'rb'), sheet_name='max F-score')\n",
    "#print(f)\n",
    "\n",
    "p = pd.read_excel(open(data_directory + '/submission/max_merge_summary.xlsx', 'rb'), sheet_name='max precision')\n",
    "#print(p)\n",
    "\n",
    "r = pd.read_excel(open(data_directory + '/submission/max_merge_summary.xlsx', 'rb'), sheet_name='max recall')\n",
    "#print(r)\n",
    "\n",
    "data_frames = [f, p, r]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['corpus', 'semtypes'], how='inner'), data_frames)\n",
    "df_merged = df_merged.rename(index=str, columns={\"merge_x\": \"merge_f\", \"merge_y\": \"merge_p\", \"merge\": 'merge_r', 'n_ref_x': 'n_ref'})\n",
    "\n",
    "#print(df_merged)\n",
    "cols_to_keep = ['merge_f', 'merge_p', 'merge_r', 'F', 'precision', 'recall', 'n_ref', 'corpus', 'semtypes']\n",
    "print(df_merged[cols_to_keep])\n",
    "\n",
    "df_merged[cols_to_keep].to_csv(data_directory + '/submission/max_merge_out.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nested:\n",
    "fairview_all_merge_metrics_entity_overlap_Anatomy_1578694661.483111.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Drug_1578691637.613012.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Finding_1578694540.707012.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Procedure_1578695994.216092.csv\n",
    "fairview_all_merge_metrics_entity_overlap_complete_1578628666.2874.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_complete_1578635243.689393.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_problem_1578689510.705959.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_test,treatment_1578686098.336592.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Anatomy_1578680047.974938.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Chemicals_and_drugs_1578682645.26684.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Disorders,Sign_Symptom_1578679769.464332.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Procedures_1578676610.30274.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_complete_1578672135.059832.csv\n",
    "'''\n",
    "\n",
    "'''\n",
    "nested_with_singleton:\n",
    "fairview_all_merge_metrics_entity_overlap_1578945459.512492.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Drug1578942397.436205.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Finding1578942519.761993.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Procedure1578942581.064223.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_1578945078.21741.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_problem1578943079.274995.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_test,treatment1578942903.11009.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_1578944504.010892.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Chemicals_and_drugs1578944172.737039.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Disorders,Sign_Symptom1578944028.8403.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Procedures1578943851.142459.csv\n",
    "'''\n",
    "\n",
    "'''\n",
    "paired:\n",
    "fairview_all_merge_metrics_entity_overlap_1578946718.235075.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Anatomy1578953589.256364.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Drug1578953297.264332.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Finding1578953578.940667.csv\n",
    "fairview_all_merge_metrics_entity_overlap_Procedure1578953730.388245.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_1578949083.34194.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_problem1578951222.071805.csv\n",
    "i2b2_all_merge_metrics_entity_overlap_test,treatment1578950806.296343.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_1578948214.410456.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Anatomy1578952051.5378.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Chemicals_and_drugs1578952386.368777.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Disorders,Sign_Symptom1578952028.443752.csv\n",
    "mipacq_all_merge_metrics_entity_overlap_Procedures1578951619.047393.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# combine data sets\n",
    "\n",
    "# fv\n",
    "n = pd.read_csv(data_directory + '/submission/fairview_all_merge_metrics_entity_overlap_Anatomy_1578694661.483111.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/fairview_all_merge_metrics_entity_overlap_Anatomy1578953589.256364.csv')\n",
    "\n",
    "out = pd.concat([n, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/fairview_Anatomy.csv')\n",
    "          \n",
    "print('fv anat', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/fairview_all_merge_metrics_entity_overlap_Drug_1578691637.613012.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/fairview_all_merge_metrics_entity_overlap_Drug1578942397.436205.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/fairview_all_merge_metrics_entity_overlap_Drug1578953297.264332.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/fairview_Drug.csv')\n",
    "\n",
    "print('fv drug', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/fairview_all_merge_metrics_entity_overlap_Finding_1578694540.707012.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/fairview_all_merge_metrics_entity_overlap_Finding1578942519.761993.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/fairview_all_merge_metrics_entity_overlap_Finding1578953578.940667.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/fairview_Finding.csv')\n",
    "\n",
    "print('fv find', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/fairview_all_merge_metrics_entity_overlap_Procedure_1578695994.216092.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/fairview_all_merge_metrics_entity_overlap_Procedure1578942581.064223.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/fairview_all_merge_metrics_entity_overlap_Procedure1578953730.388245.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/fairview_Procedure.csv')\n",
    "\n",
    "print('fv proc', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/fairview_all_merge_metrics_entity_overlap_complete_1578628666.2874.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/fairview_all_merge_metrics_entity_overlap_1578945459.512492.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/fairview_all_merge_metrics_entity_overlap_1578946718.235075.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/fairview_complete.csv')\n",
    "\n",
    "print('fv all', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "# i2b2\n",
    "\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/i2b2_all_merge_metrics_entity_overlap_test,treatment_1578686098.336592.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/i2b2_all_merge_metrics_entity_overlap_test,treatment1578942903.11009.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/i2b2_all_merge_metrics_entity_overlap_test,treatment1578950806.296343.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/i2b2_test,treatment.csv')\n",
    "\n",
    "print('i2b2 proc', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1), out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1), out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1)) \n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/i2b2_all_merge_metrics_entity_overlap_problem_1578689510.705959.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/i2b2_all_merge_metrics_entity_overlap_problem1578943079.274995.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/i2b2_all_merge_metrics_entity_overlap_problem1578951222.071805.csv')    \n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/i2b2_problem.csv')\n",
    "\n",
    "print('i2b2 find', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/i2b2_all_merge_metrics_entity_overlap_complete_1578635243.689393.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/i2b2_all_merge_metrics_entity_overlap_1578945078.21741.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/i2b2_all_merge_metrics_entity_overlap_1578949083.34194.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/i2b2_all.csv')\n",
    "\n",
    "print('i2b2 all', out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "# mipacq\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/mipacq_all_merge_metrics_entity_overlap_Anatomy_1578680047.974938.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/mipacq_all_merge_metrics_entity_overlap_Anatomy1578952051.5378.csv')\n",
    "\n",
    "out = pd.concat([n, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/mipacq_Anatomy.csv')\n",
    "\n",
    "print('m anat', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/mipacq_all_merge_metrics_entity_overlap_Chemicals_and_drugs_1578682645.26684.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/mipacq_all_merge_metrics_entity_overlap_Chemicals_and_drugs1578944172.737039.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/mipacq_all_merge_metrics_entity_overlap_Chemicals_and_drugs1578952386.368777.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/mipacq_Chemicals_and_drug.csv')\n",
    "\n",
    "print('m drug', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/mipacq_all_merge_metrics_entity_overlap_Disorders,Sign_Symptom_1578679769.464332.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/mipacq_all_merge_metrics_entity_overlap_Disorders,Sign_Symptom1578944028.8403.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/mipacq_all_merge_metrics_entity_overlap_Disorders,Sign_Symptom1578952028.443752.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/mipacq_Disorders,Sign_Symptom.csv')\n",
    "\n",
    "print('m find', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/mipacq_all_merge_metrics_entity_overlap_Procedures_1578676610.30274.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/mipacq_all_merge_metrics_entity_overlap_Procedures1578943851.142459.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/mipacq_all_merge_metrics_entity_overlap_Procedures1578951619.047393.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/mipacq_Procedures.csv')\n",
    "\n",
    "print('m proc', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "\n",
    "n = pd.read_csv(data_directory + '/submission/mipacq_all_merge_metrics_entity_overlap_complete_1578672135.059832.csv')\n",
    "ns = pd.read_csv(data_directory + '/submission/nested_with_singleton/mipacq_all_merge_metrics_entity_overlap_1578944504.010892.csv')\n",
    "p = pd.read_csv(data_directory + '/submission/paired/mipacq_all_merge_metrics_entity_overlap_1578948214.410456.csv')\n",
    "\n",
    "out = pd.concat([n, ns, p])\n",
    "\n",
    "out.to_csv(data_directory + '/submission/combined/mipacq_all.csv')\n",
    "print('m all', len(out), out.sort_values(by='F',ascending=False)[['F', 'merge']].head(1).values[0], out.sort_values(by='precision',ascending=False)[['precision', 'merge']].head(1).values[0], \n",
    "      out.sort_values(by='recall',ascending=False)[['recall', 'merge']].head(1).values[0])\n",
    "'''            \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
